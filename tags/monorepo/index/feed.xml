<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>monorepo on Julio Merino (jmmv.dev)</title><link>https://jmmv.dev/tags/monorepo/index/</link><description>Recent content in monorepo on Julio Merino (jmmv.dev)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 23 Aug 2023 06:00:00 -0700</lastBuildDate><atom:link href="https://jmmv.dev/tags/monorepo/index/feed.xml" rel="self" type="application/rss+xml"/><item><title>Costs exposed: Monorepo vs. multirepo</title><link>https://jmmv.dev/2023/08/costs-exposed-monorepo-multirepo.html</link><pubDate>Wed, 23 Aug 2023 06:00:00 -0700</pubDate><guid>https://jmmv.dev/2023/08/costs-exposed-monorepo-multirepo.html</guid><description>&lt;p>In software engineering organizations, there are certain practices that keep costs under control even if those &lt;em>seem&lt;/em> more expensive at first. Unfortunately, because such practices &lt;em>feel&lt;/em> more expensive, teams choose to keep their status quo even when they know it is suboptimal. This choice ends up hurting productivity and morale because planned work is continuously interrupted, which in turn drags project completion.&lt;/p>
&lt;p>The reason I say &lt;em>seem&lt;/em> and not &lt;em>are&lt;/em> is because the alternatives to these cost-exposing practices also suffer from costs. The difference is that, while the former surface costs, leading to the need to allocate time and people to infrastructure work, the latter keeps the costs smeared over teams and individuals in ways that are difficult to account and plan for.&lt;/p>
&lt;p>To illustrate what I&amp;rsquo;m trying to say, I&amp;rsquo;ll present three different scenarios in which this opinion applies. All of these case studies come from past personal experiences while working in different teams and projects. The first one covered in this post is about the adoption of a monorepo vs. the use of multiple different repositories. The other two will come in follow-up articles.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-08-23-freebsd-gnome-repos.png" length="162711" type="image/jpeg"/></item><item><title>Defining build time SLIs and SLOs</title><link>https://jmmv.dev/2021/03/build-time-slis-slos.html</link><pubDate>Fri, 12 Mar 2021 06:30:00 -0800</pubDate><guid>https://jmmv.dev/2021/03/build-time-slis-slos.html</guid><description>Companies grow, and with them do the software projects that support them. It should be no surprise that larger programs require longer build times. And, if I had to guess, you have seen how those build times eventually grow to unbearable levels, reducing productivity and degrading quality. In this post, I examine how we can leverage the common techniques we use for production services&amp;mdash;namely SLIs and SLOs&amp;mdash;to keep build times on track.</description></item><item><title>How does Google keep build times low?</title><link>https://jmmv.dev/2021/02/google-monorepos-and-caching.html</link><pubDate>Fri, 26 Feb 2021 09:50:00 -0800</pubDate><guid>https://jmmv.dev/2021/02/google-monorepos-and-caching.html</guid><description>Monorepos are an interesting beast. If mended properly, they enable a level of uniformity and code quality that is hard to achieve otherwise. If left unattended, however, they become unmanageable monsters of tangled dependencies, slow builds, and frustrating developer experiences. Whether you have a good or bad experience directly depends on the level of engineering support behind the monorepo. Simply put, monorepos require dedicated teams and tools to run nicely. In this post, I will look at how almost-perfect caching plays a key role in keeping build times manageable under such an environment.</description></item><item><title>How does Google avoid clean builds?</title><link>https://jmmv.dev/2020/12/google-no-clean-builds.html</link><pubDate>Thu, 31 Dec 2020 09:30:00 -0800</pubDate><guid>https://jmmv.dev/2020/12/google-no-clean-builds.html</guid><description>During my 11 years at Google, I can confidently count the number of times I had to do a &amp;ldquo;clean build&amp;rdquo; with one hand: their build system is so robust that incremental builds always work. Phrases like &amp;ldquo;clean everything and try building from scratch&amp;rdquo; are unheard of. So&amp;hellip; you can color me skeptical when someone says that incremental build problems are due to bugs in the build files and not due to a suboptimal build system. The answer lies in having a robust build system, and in this post I&amp;rsquo;ll examine the common causes behind incremental build breakages, what the build system can do to avoid them, and how Bazel accomplishes most of them.</description></item><item><title>Open files limit, macOS, and the JVM</title><link>https://jmmv.dev/2019/01/open-files-limit-macos-and-jvm.html</link><pubDate>Tue, 29 Jan 2019 17:15:00 -0500</pubDate><guid>https://jmmv.dev/2019/01/open-files-limit-macos-and-jvm.html</guid><description>Bazel&amp;rsquo;s original raison d&amp;rsquo;etre was to support Google&amp;rsquo;s monorepo. A consequence of using a monorepo is that some builds will become very large. And large builds can be very resource hungry, especially when using a tool like Bazel that tries to parallelize as many actions as possible for efficiency reasons. There are many resource types in a system, but today I&amp;rsquo;d like to focus on the number of open files at any given time (nofiles).</description></item><item><title>A few extra system calls... and you lose 1% build time</title><link>https://jmmv.dev/2018/04/bazel-xcode-locations-cache.html</link><pubDate>Mon, 30 Apr 2018 13:45:00 -0400</pubDate><guid>https://jmmv.dev/2018/04/bazel-xcode-locations-cache.html</guid><description>Blaze—the variant of Bazel used internally at Google—was originally designed to build the Google monorepo. One of the beauties of sticking to a monorepo is code reuse, but this has the unfortunate side-effect of dependency bloat. As a result, Bazel and Blaze have evolved to support ever-increasingly-bigger pieces of software.
The growth of the projects built by Bazel and Blaze has had the unsurprising consequence that our engineers all now have high-end workstations with access to massive amounts of distributed resources.</description></item></channel></rss>