<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Linux on Julio Merino (jmmv.dev)</title><link>https://jmmv.dev/tags/linux/index.html</link><description>Recent content in Linux on Julio Merino (jmmv.dev)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>julio@meroh.net (Julio Merino)</managingEditor><webMaster>julio@meroh.net (Julio Merino)</webMaster><copyright>Copyright 2004&#150;2025 Julio Merino</copyright><lastBuildDate>Wed, 16 Aug 2023 06:20:00 -0700</lastBuildDate><atom:link href="https://jmmv.dev/tags/linux/index/feed.xml" rel="self" type="application/rss+xml"/><item><title>Raspberry Pi 3, rfkill, and real root causing</title><link>https://jmmv.dev/2023/08/rpi3-rfkill-root-causing.html</link><pubDate>Wed, 16 Aug 2023 06:20:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2023/08/rpi3-rfkill-root-causing.html</guid><description>&lt;p>I&amp;rsquo;ve had a Raspberry Pi 3 in the garage running Raspbian so it was attached to Ethernet for a long time. A few weeks ago, however, I wanted to bring the Pi into the house so that my kid, who was showing interest in robotics, and I could play with it. That required having the ability to place the device onto the dining table, next to a laptop, which meant connecting it to WiFi. Easy peasy, right?&lt;/p>
&lt;p>Well&amp;hellip; while that should have been trivial, it did not work right away and the solutions I found online back then were all nonsensical. I gave up in desperation because I did not have enough time to find the root cause, and all interest was lost. Until last weekend when I gave this ordeal another try. At this point, I found once again the same nonsensical solutions online, got equally frustrated about the fact that they even existed, and decided to find the real answer to my problem on my own.&lt;/p>
&lt;p>Yes, this is mostly a rant about the Internet being littered with misleading answers of the kind &amp;ldquo;I reinstalled glibc and my problem is gone!&amp;rdquo;. But this is also the tale of a troubleshooting session&amp;mdash;and you know I like to blog about those.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-08-16-rpi3-go2-gpio.jpg" length="346217" type="image/jpeg"/></item><item><title>ldd(1) and untrusted binaries</title><link>https://jmmv.dev/2023/07/ldd-untrusted-binaries.html</link><pubDate>Sat, 01 Jul 2023 16:30:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2023/07/ldd-untrusted-binaries.html</guid><description>While diagnosing a non-determinism Bazel issue at work, I had to compare the dynamic libraries used by two builds of the same binary. To do so, I used &lt;code>ldd(1)&lt;/code> and I had to refer to its manual page to understand details of the output I had never paid attention to before. What I saw will surprise you: &lt;code>ldd&lt;/code> can end up &lt;em>running&lt;/em> the binary given to it, thus making it unsafe against untrusted binaries. Read on for the history I could find around this issue and what alternatives you have.</description></item><item><title>Waiting for process groups, Linux edition</title><link>https://jmmv.dev/2019/11/wait-for-process-group-linux.html</link><pubDate>Thu, 14 Nov 2019 11:30:00 +0000</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2019/11/wait-for-process-group-linux.html</guid><description>&lt;p>In the &lt;a href="https://jmmv.dev/2019/11/wait-for-process-group.html">previous post&lt;/a>, we saw why waiting for a process group to terminate is important (at least in the context of Bazel), and we also saw why this is a difficult thing to do in a portable manner. So today, let&amp;rsquo;s dive into how to do this properly on a Linux system.&lt;/p>
&lt;p>On Linux, we have two routes: using the &lt;strong>child subreaper&lt;/strong> feature or using &lt;strong>PID namespaces&lt;/strong>. We&amp;rsquo;ll focus on the former because that&amp;rsquo;s what we&amp;rsquo;ll use to fix (&lt;a href="https://github.com/bazelbuild/bazel/issues/10245">#10245&lt;/a>) the process wrapper&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, and because they are sufficient to fully address our problem.&lt;/p></description></item><item><title>Blacklisting a device in HAL</title><link>https://jmmv.dev/2008/06/blacklisting-device-in-hal.html</link><pubDate>Sun, 29 Jun 2008 08:11:00 -0400</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2008/06/blacklisting-device-in-hal.html</guid><description>I have an old Aiptek mini PenCam 1.3 MPixels, identified by USB vendor 1276 and product 20554. I want to use this webcam for videoconferencing in the machine I am setting up for this purpose. This machine carries a Fedora 9 x86_64 installation, as already mentioned in the previous post.&lt;br />&lt;br />Whenever I connect the camera to the machine, HAL detects the new device and then GNOME attempts to "mount" it using gphoto2. The result is that I get a new device on the desktop referring to the camera, which is pretty nice, but it does not work at all: accessing it raises an unexpected error and thus the photos stored in the webcam cannot be seen.&lt;br />&lt;br />Anyway, I do not care about the photo capabilities of this camera, just about its ability to stream video. Hence, I installed the &lt;tt>gspca&lt;/tt> and &lt;tt>kmod-gspca&lt;/tt> packages from the &lt;a href="http://rpm.livna.org/">livna&lt;/a> repositories and, according to the &lt;a href="http://mxhaard.free.fr/spca5xx.html">gspca&lt;/a> driver, my camera is, supposedly, fully supported.&lt;br />&lt;br />Unfortunately, I was not able to get the &lt;tt>/dev/video&lt;/tt> device: it didn't exist, even with the kernel modules loaded. After some manual investigation on the console (so that gphoto2 couldn't get in the way), I found that the video device really appears but vanishes as soon as gphoto2 attempts to access the camera. I suspect it is not possible to use the photo and video capabilities of the camera at once with the current drivers.&lt;br />&lt;br />So, how to avoid this problem? I had to tell HAL to omit this device, so that GNOME did not get any notification of its existance and therefore the interface did not attempt to mount the camera using gphoto2. However, there is few documentation on how to do this, so I had to resort to reading the files in &lt;tt>/usr/share/hal/fdi/&lt;/tt> and guess what to do.&lt;br />&lt;br />I ended up creating a &lt;tt>10-broken-cameras.fdi&lt;/tt> file in &lt;tt>/etc/hal/fdi/preprobe/&lt;/tt> with the following contents:&lt;pre>&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt;&lt;br />&lt;br />&amp;lt;deviceinfo version="0.2"&amp;gt;&lt;br /> &amp;lt;device&amp;gt;&lt;br /> &amp;lt;match key="usb.vendor_id" int="1276"&amp;gt;&lt;br /> &amp;lt;match key="usb.product_id" int="20554"&amp;gt;&lt;br /> &amp;lt;merge key="info.ignore" type="bool"&amp;gt;true&amp;lt;/merge&amp;gt;&lt;br /> &amp;lt;/match&amp;gt;&lt;br /> &amp;lt;/match&amp;gt;&lt;br /> &amp;lt;/device&amp;gt;&lt;br />&amp;lt;/deviceinfo&amp;gt;&lt;/pre>What this code snippet does is match the camera device using some of the properties that are attached to it and, once there is a match, appends the &lt;tt>info.ignore&lt;/tt> property to the device description to tell HAL to not use this device any more. In order to set up the matching of a device, you can see the full list of properties of all device descriptors using the &lt;tt>hal-device&lt;/tt> command.</description></item><item><title>Desktop effects with an nVidia card and Fedora 9</title><link>https://jmmv.dev/2008/06/desktop-effects-with-nvidia-card-and.html</link><pubDate>Sat, 28 Jun 2008 12:24:00 -0400</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2008/06/desktop-effects-with-nvidia-card-and.html</guid><description>I'm setting up a machine at home to act as a videoconferencing station so that my family can easily talk to me during the summer, while I'm in NYC. This machine is equipped with an Athlon 64-bit processor and a nVidia GeForce 6200 PCI-Express video card. I decided to install Fedora 9 in this computer because this is the distribution I'm currently using everywhere (well, everywhere except on the Mac ;-). Plus it just works (TM), or mostly.&lt;br />&lt;br />The 3D desktop is not something that is really needed for daily work, but I wanted to try it. Unfortunately, I could not get the desktop effects to work the first time I tried. I enabled the livna repositories, installed the nVidia binary drivers and configured the X server to use them. However, telling the system to enable the Desktop Effects failed, and running glxinfo crashed with a "locking assertion failure" message.&lt;br />&lt;br />Googling a bit, I found a page mentioning that one has to run the livna-config-display command to properly configure the X server. I think I did not do this, so I just ran this manually and later restarted X. No luck.&lt;br />&lt;br />Fortunately, that same page also contained a snippet of the &lt;tt>xorg.conf&lt;/tt> configuration file that was like this:&lt;br />&lt;pre>Section "Files"&lt;br /> ModulePath "/usr/lib64/xorg/modules/extensions/nvidia"&lt;br /> ModulePath "/usr/lib64/xorg/modules"&lt;br />EndSection&lt;/pre>Effectively, my configuration file was lacking the path to the nVidia extensions subdirectory. Adding that line fixed the problem: now the server loads the correct GLX plugin, instead of the "generic" one that lives in the modules directory. I guess &lt;tt>livna-config-display&lt;/tt> should have set that up automatically for me, but it didn't...&lt;br />&lt;br />The desktop effects are now working :-) Now I figure out why compiz feels so slow... specially because I have the same problem at work with an Intel 965Q video card.</description></item><item><title>lib64 problems</title><link>https://jmmv.dev/2008/06/lib64-problems.html</link><pubDate>Thu, 12 Jun 2008 11:10:00 -0400</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2008/06/lib64-problems.html</guid><description>Linux distributions for the x86_64 platform have different approaches when it comes to the installation of 32-bit and 64-bit libraries. In a 64-bit platform, 64-bit libraries are required to run all the standard applications but 32-bit libraries need to be available to provide compatibility with 32-bit binaries. In this post, I consider 64-bit applications to be the native ones and the 32-bit to be foreign.&lt;br />&lt;br />The two major approaches I have seen are:&lt;br />&lt;ul>&lt;li>lib32 and lib64 directories, leaving lib to be just a symbolic link to the directory required by the native applications. This is the approach followed by Debian. The advantage of this layout is that the lib directory is the correct one for native applications. However, foreign applications that have built-in paths to lib, if these exist, will fail to work.&lt;/li>&lt;li>lib and lib64 directories. This is the approach followed by Fedora. In this layout, the foreign applications which have built-in paths to lib will work just fine, but the native applications have to be configured explicitly to load libraries and plugins from within lib64.&lt;/li>&lt;/ul>I have found so far two instances where the Fedora approach fails because native 64-bit applications hardcode the lib name in some places, instead of using lib64. One of these were the NetworkManager configuration files, which had an incorrect setup for the OpenVPN plugin and it failed to work. This issue has already been fixed in Fedora 9. The other problem was in gnome-compiz-manager where the application tries to load plugins from the lib directory, but as it is a 64-bit binary, it failed due to a bitness mismatch. This has been &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=388511">reported&lt;/a> but is not yet fixed upstream. I'm sure several other similar problems remain to be discovered.&lt;br />&lt;br />I personally think that the Debian approach is more appropriate because it seems weird that all standard system directories, such as bin or libexec, contain 64-bit binaries but just one of them, lib, is 32-bit specific.&lt;br />&lt;br />As a side note, NetBSD follows an slightly different approach: lib contains 64-bit libraries and lib32, if installed at all, contains the 32-bit ones.</description></item><item><title>Linux is just an implementation detail</title><link>https://jmmv.dev/2008/02/linux-is-just-implementation-detail.html</link><pubDate>Sat, 02 Feb 2008 09:32:00 -0500</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2008/02/linux-is-just-implementation-detail.html</guid><description>You can't imagine how happy I was today when I read the &lt;a href="http://www.linuxtechdaily.com/2008/02/kde-4-developers-an-interview-with-sebastian-kugler/">interview with KDE 4's developer Sebastian Kuegler&lt;/a>. Question 6 asks him:&lt;blockquote>6. Are there any misconceptions about KDE 4 you see regularly and would like to address?&lt;/blockquote>And around the middle of the answer, he says:&lt;blockquote>Frankly, I don’t like the whole concept of the “Linux Desktop”. Linux is really just a kernel, and in this case very much a buzzword. Having to mention Linux (which is just a technical implementation detail of a desktop system) suggests that something is wrong. Should it matter to the user if he runs Linux or BSD on his machine? Not at all. It only matters because things just don’t work so well (mostly caused by to driver problems, often a matter of ignorance on some vendor’s side).&lt;/blockquote>Thanks Sebastian. I couldn't have said it better.&lt;br />&lt;br />What virtually all application developers are targeting —or should be targeting— is KDE &lt;i>or&lt;/i> GNOME. These are the development platforms; i.e. what provide the libraries and services required for easy development and deployment.  It doesn't make any sense to "write a graphical application for Linux", because Linux has no standard graphical interface (unless you mean the framebuffer!) and, again, Linux is just a kernel.&lt;div>&lt;br />&lt;/div>&lt;div>I &lt;i>think&lt;/i> I have already blogged about the problems of software redistribution under Linux... will look for that post and, if it is not there, it is worth a future entry.&lt;/div></description></item><item><title>Past days' work</title><link>https://jmmv.dev/2007/12/past-days-work.html</link><pubDate>Fri, 07 Dec 2007 18:06:00 -0500</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2007/12/past-days-work.html</guid><description>Been tracking and resolving a bug in Linux's SPU scheduler for the last three days, and fixed it just a moment ago! I'm happy and needed to mention this ;-)&lt;br />&lt;br />More specifically, tracking it down was fairly easy using SystemTap and Paraver (getting the two to play well together was another source of headaches), but fixing it was the most complex thing due to deadlocks popping up over and over again. Sorry, can't disclose more information about it yet; want to think a bit more how to make this public and whether my fix is really OK or not. But be sure I will!</description></item><item><title>Thanks, SystemTap!</title><link>https://jmmv.dev/2007/12/thanks-systemtap.html</link><pubDate>Sun, 02 Dec 2007 09:52:00 -0500</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2007/12/thanks-systemtap.html</guid><description>I started this week's work with the idea of instrumenting the spufs module found in Linux/Cell to be able to take some traces of the execution of Cell applications. At first, I modified that module to emit events at certain key points, which were later registered in a circular queue. Then, I implemented a file in &lt;tt>/proc&lt;/tt> so that a user-space application could read from it and free space from the queue to prevent the loss of events when it was full.&lt;br />&lt;br />That first implementation never worked well, but as I liked how it was evolving, I thought it could be a neat idea to make this "framework" more generic so that other parts of the kernel could use it. I rewrote everything with this idea in mind and then also modified the regular scheduler and the process-management system calls to also rise events for my trace. And got it working.&lt;br />&lt;br />But then, I was talking to &lt;a href="http://blogs.nopcode.org/brainstorm/">Brainstorm&lt;/a> about his new "Sun Campus Ambassador" position at the University, and during the conversation he mentioned DTrace. So I asked... "Mmm, that tool could probably simplify all my work; is it there something similar for Linux?". And yes; yes it is! Its name, &lt;a href="http://sourceware.org/systemtap/">SystemTap&lt;/a>.&lt;br />&lt;br />As the web page says, SystemTap "provides an infrastructure to simplify the gathering of information about the running Linux system". You do this by writing small scripts that hook into specific points of the kernel — at the function level, at specific mark points, etc. — and which get executed when the script is processed and installed into the live kernel as a loadable kernel module.&lt;br />&lt;br />With this tool I can discard my several-hundred-long changes to gather traces and replace them with some very, very simple SystemTap scripts. No need to rebuild the kernel, no need to deal with custom changes to it, no need to rebuild every now and then... neat!&lt;br />&lt;br />Now I'm having problems using the feature that allows to instrument kernel markers, and I need them because otherwise some private functions cannot be instrumented due to compiler optimizations (I think). OK, I'd expose those functions, but while I'm at it, I think it'd be a good idea to write a decent tapset for spufs that could later be published. And that prevents me from doing such hacks.&lt;br />&lt;br />But anyway, kudos to the SystemTap developers. I now understand why everybody is so excited about DTrace.</description></item><item><title>Hello world in Linux/ppc64</title><link>https://jmmv.dev/2007/11/hello-world-in-linuxppc64.html</link><pubDate>Sun, 25 Nov 2007 12:22:00 -0500</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2007/11/hello-world-in-linuxppc64.html</guid><description>I'm decided to improve my knowledge on the Cell platform, and the best way to get started seems to be to learn 64-bit PowerPC assembly given that the PPU uses this instruction set. Learning this will open the door to do some more interesting tricks with the architecture's low-level details.&lt;br />&lt;br />There are some excellent articles at &lt;a href="http://www.ibm.com/developerworks/">IBM developerWorks&lt;/a> dealing with this subject, and thanks to the &lt;a href="http://www.ibm.com/developerworks/library/l-powasm1.html">first one in an introductory series to PPC64&lt;/a> I've been able to write the typical hello world program :-)&lt;br />&lt;br />Without further ado, here is the code!&lt;pre>#&lt;br /># The program's static data&lt;br />#&lt;br />&lt;br />.data&lt;br />&lt;br />msg: .string "Hello, world!n"&lt;br /> length = . - msg&lt;br />&lt;br />#&lt;br /># Special section needed by the linker due to the C calling&lt;br /># conventions in this platform.&lt;br />#&lt;br />&lt;br />.section ".opd", "aw" # aw = allocatable/writable&lt;br />&lt;br />.global _start&lt;br />_start:&lt;br /> .quad ._start, .TOC.@tocbase, 0&lt;br />&lt;br />#&lt;br /># The program's code&lt;br />#&lt;br />&lt;br />.text&lt;br />&lt;br />._start:&lt;br /> li 0, 4 # write(2)&lt;br /> li 3, 1 # stdout file descriptor&lt;br /> lis 4, msg@highest # load 64-bit buffer address&lt;br /> ori 4, 4, msg@higher&lt;br /> rldicr 4, 4, 32, 31&lt;br /> oris 4, 4, msg@h&lt;br /> ori 4, 4, msg@l&lt;br /> li 5, length # buffer length&lt;br /> sc&lt;br />&lt;br /> li 0, 1 # _exit(2)&lt;br /> li 3, 0 # return success&lt;br /> sc&lt;/pre>You can build it with the following commands:&lt;pre>$ as -a64 -o hello.o hello.s&lt;br />$ ld -melf64ppc -o hello hello.o&lt;/pre>I'm curious about as(1)'s &lt;tt>-a&lt;/tt> option; its purpose is pretty obvious, but it is not documented anywhere in the manual page nor in the info files.&lt;br />&lt;br />Anyway, back to coding! I guess I'll post more about this subject if I find interesting and/or non-obvious things that are not already documented clearly anywhere. But for beginner's stuff you already have the articles linked above.</description></item><item><title>PFC report almost ready</title><link>https://jmmv.dev/2007/06/pfc-report-almost-ready.html</link><pubDate>Tue, 19 Jun 2007 11:25:00 -0400</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2007/06/pfc-report-almost-ready.html</guid><description>The deadline for &lt;a href="http://julipedia.blogspot.com/2007/01/pfc-subject-chosen.html">my PFC&lt;/a> (the project that will conclude my computer science degree) is approaching. I have to hand out the final report next week and present the project on July 6th. Its title is "&lt;span style="font-style: italic;">Efficient resource management in heterogeneous multiprocessor systems&lt;/span>" and its basic goal is to inspect the poor management of such machines in current operating systems and how this situation could be improved in the future.&lt;br />&lt;br />Our specific case study has been the Cell processor, the PlayStation 3 and Linux, as these form a clear example of an heterogeneous multiprocessor system that may become widespread due to its relatively cheap price and the attractive features (gaming, multimedia playback, etc.) it provides to a "home user".&lt;br />&lt;br />Most of the project has been an analysis of the current state of the art and the proposal of ideas at an abstract level. Due to timing constraints and the complexity of the subject (should I also mention bad planning?), I have been unable to implement most of them even though I wanted to do so at the very beginning. The code I've done is so crappy that I won't be sharing it anytime soon, but if there is interest I might clean it up (I mean, rewrite it from the ground up) and publish it to a wider audience.&lt;br />&lt;br />Anyway, to the real point of this post. I've published an &lt;a href="http://www.netbsd.org/%7Ejmmv/PFC/report.pdf">almost definitive copy of the final report&lt;/a> so that you can take a look at it if you want to. I will certainly welcome any comments you have, be it mentioning bugs, typos, wrong explanOctations or anything! Feel free to post them as comments here or to &lt;a href="mailto:jmerino%20AT%20ac%20DOT%20upc%20DOT%20edu">send me a mail&lt;/a>, but do so before next Monday as that's the deadline for printing. Many thanks in advance if you take the time to do a quick review!&lt;br />&lt;br />(And yes... this means I'll be completely free from now on to work on my SoC project, which is being delayed too much already...)&lt;br />&lt;br />&lt;b>Edit (Oct 17th)&lt;/b>: Moved the report in the server; fixed the link here.</description></item><item><title>Building an updated kernel for the PS3</title><link>https://jmmv.dev/2007/03/building-updated-kernel-for-ps3.html</link><pubDate>Fri, 16 Mar 2007 04:25:00 -0400</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2007/03/building-updated-kernel-for-ps3.html</guid><description>The mainstream Linux sources have some support for the PlayStation 3, but it is marked as incomplete. Trying to boot such a kernel results in a stalled machine, as the kernel configuration option says:&lt;br />&lt;blockquote>CONFIG_PPC_PS3: This option enables support for the Sony PS3 game console and other platforms using the PS3 hypervisor. Support for this platform is not yet complete, so enabling this will not result in a bootable kernel on a PS3 system.&lt;/blockquote>To make things easier, I'd simply have used the Linux sources provided by YellowDog Linux 5 (YDL5), which correspond to a modified 2.6.16 kernel. However, as I have to do some kernel development on this platform, I objected to using such old sources: when developing for an open source project, it is much better to use the development branch of the code — if available — because custom changes will remain synchronized with mainstream changes. This means that, if those changes are accepted by the maintainers, it will be a lot easier to later merge them with the upstream code.&lt;br />&lt;br />So, after a bit of fiddling, I found the public kernel branch used to develop for the PS3. It is named &lt;tt>ps3-linux&lt;/tt>, is maintained by Geoff Levand and can be found in the kernel's git repository under the project &lt;a href="http://git.kernel.org/?p=linux/kernel/git/geoff/ps3-linux.git;a=summary">linux/kernel/git/geoff/ps3-linux.git&lt;/a>.&lt;br />Fetching the code was "interesting". I was (and still am) a novice to &lt;a href="http://git.or.cz/">git&lt;/a>, but fortunately my prior experiences with CVS, Subversion and specially Monotone helped to understand what was going on.&lt;br />&lt;br />Let's now see how to fetch the code, cross-build a custom kernel and install it on the PS3 using YDL5.&lt;br />&lt;br />To checkout the latest code, which at this moment corresponds to a patched Linux 2.6.21-rc3 sources, do this:&lt;br />&lt;br />&lt;tt>$ git clone git://git.kernel.org/pub/scm/linux/kernel/git/geoff/ps3-linux.git ps3-linux&lt;/tt>&lt;br />&lt;br />This will clone the &lt;tt>ps3-linux&lt;/tt> project from the main repository and leave it in a directory with the same name. You can keep it up to date by running &lt;tt>git pull&lt;/tt> within the directory, but I'm not going to talk about git any more today.&lt;br />&lt;br />As I cross-compile the PS3 kernel from a FC6 Intel-based machine with the Cell SDK 2.0, I need to tell it which is the target platform and which is the cross-compiler before being able to build or even configure a kernel. I manually add these lines to the top-level &lt;tt>Makefile&lt;/tt>, but setting them in the environment should work too:&lt;br />&lt;br />&lt;tt>ARCH=powerpc&lt;br />&lt;br />CROSS_COMPILE=ppu-&lt;/tt>&lt;br />&lt;br />Now you can create a sample configuration file by executing the following command inside the tree:&lt;br />&lt;br />&lt;tt>$ make ps3_defconfig&lt;/tt>&lt;br />&lt;br />Then proceed to modify the default configuration to your likings. To ease development, I want my kernels to be as small and easy to install as possible; this reduces the test-build-install-reboot cycle to the minimum (well, not exactly; see below). Therefore I disable all stuff I do not need, which includes modules support. Why? Keeping all the code in a single image will make later installation a lot easier.&lt;br />&lt;br />Once the kernel is configured, it is time to build it. But before doing so you need to install a helper utility used by the PS3 build code: the &lt;a href="http://dtc.ozlabs.org/">Device Tree Compiler&lt;/a> (or dtc). Fetch its sources from the git repository that appears in that page, run &lt;tt>make&lt;/tt> to build it and manually install the &lt;tt>dtc&lt;/tt> binary into &lt;tt>/usr/local/bin&lt;/tt>.&lt;br />&lt;br />With the above done, just run &lt;tt>make&lt;/tt> and wait until your kernel is built. Then copy the resulting &lt;tt>vmlinux&lt;/tt> file to your PS3; I put mine in &lt;tt>/boot/vmlinux-jmerino&lt;/tt> to keep its name version-agnostic and specific to my user account. Note that I do not have to mess with modules as I disabled them; otherwise I'd have to copy them all to the machine — or alternatively set up a NFS root for simplicity as described in &lt;a href="http://www.kernel.org/pub/linux/kernel/people/geoff/cell/ps3-nfs-root-howto.txt">Geoff Levand's HOWTO&lt;/a>.&lt;br />&lt;br />To boot the kernel, you should know that the PS3 uses the &lt;tt>kboot&lt;/tt> boot loader, a minimal Linux system that chainloads another Linux system by means of the &lt;tt>kexec&lt;/tt> functionality. It is very powerful, but the documentation is scarce. Your best bet is to mimic the entries already present in the file. With this in mind, I added the following line to &lt;tt>/etc/kboot.conf&lt;/tt>:&lt;br />&lt;br />&lt;tt>jmerino='/dev/sda1:/vmlinux-jmerino root=/dev/sda2 init=/sbin/init 4'&lt;/tt>&lt;br />&lt;br />I'd much rather fetch the kernel from a TFTP server, but I have not got this to work yet. Anyway, note that the above line does &lt;i>not&lt;/i> specify an &lt;tt>initrd&lt;/tt> image, although all the other entries in the file do. I did this on purpose: the less magic in the boot, the better. However, bypassing the &lt;tt>initrd&lt;/tt> results in a failed boot with:&lt;br />&lt;br />&lt;tt>Warning: Unable to open an initial console.&lt;/tt>&lt;br />&lt;br />This is because the &lt;tt>/dev&lt;/tt> directory on the root partition is unpopulated, as YDL5 uses udev. Hence the need for an &lt;tt>initrd&lt;/tt> image. Getting a workaround for this is trivial though: just create the minimum necessary devices on the disk — "below udev" &amp;mdash;, as shown below.&lt;br />&lt;br />&lt;tt># mount --bind / /mnt&lt;br />&lt;br /># MAKEDEV -d /mnt/dev console zero null&lt;br />&lt;br /># umount /mnt&lt;/tt>&lt;br />&lt;br />And that's it! Your new, fresh and custom kernel is ready to be executed. Reboot the PS3, wait for the &lt;tt>kboot&lt;/tt> prompt and type your configuration name (&lt;tt>jmerino&lt;/tt> in my case). If all goes fine, the kernel should boot and then start userland initialization.&lt;br />&lt;br />Thanks go to the guys at the &lt;a href="https://ozlabs.org/mailman/listinfo/cbe-oss-dev">cbe-oss-dev&lt;/a> mailing list for &lt;a href="http://ozlabs.org/pipermail/cbe-oss-dev/2007-March/001314.html">helping me&lt;/a> in building the kernel and solving the missing console problem.&lt;br />&lt;br />&lt;b>Update (23:01)&lt;/b>: Added a link to a NFS-root tutorial.</description></item></channel></rss>