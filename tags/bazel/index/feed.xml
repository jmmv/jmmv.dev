<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bazel on jmmv.dev</title>
    <link>https://jmmv.dev/tags/bazel/</link>
    <description>Recent content in Bazel on jmmv.dev</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Oct 2020 05:40:00 -0700</lastBuildDate>
    
	<atom:link href="https://jmmv.dev/tags/bazel/index/feed.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The final boss: Bazel&#39;s own JNI code</title>
      <link>https://jmmv.dev/2020/10/bazel-jni.html</link>
      <pubDate>Fri, 09 Oct 2020 05:40:00 -0700</pubDate>
      
      <guid>https://jmmv.dev/2020/10/bazel-jni.html</guid>
      <description>As you might have read elsewhere, I&amp;rsquo;m leaving the Bazel team and Google in about a week. My plan for these last few weeks was to hand things off as cleanly as possible&amp;hellip; but I was also nerd-sniped by a bug that came my way a fortnight ago. Fixing it has been my self-inflicted punishment for leaving, and oh my, it has been painful. Very painful.
Let me tell you the story of this final boss.</description>
    </item>
    
    <item>
      <title>Bazel output streaming, Ctrl&#43;C, and test flakiness</title>
      <link>https://jmmv.dev/2020/09/bazel-test-streaming-bug.html</link>
      <pubDate>Fri, 18 Sep 2020 07:10:00 -0400</pubDate>
      
      <guid>https://jmmv.dev/2020/09/bazel-test-streaming-bug.html</guid>
      <description>About two weeks ago, I found a very interesting bug in Bazel&amp;rsquo;s test output streaming functionality while writing tests for a new feature related to Ctrl+C interrupts. I fixed the bug, wrote a test for it, and&amp;hellip; the test itself came back as flaky, which made me find another very subtle bug in the test that needed a one-line fix. This is the story of both.
Bazel has a feature known as test output streaming: by default, Bazel captures the outputs (stdout and stderr) of the tests it runs, saves those in local log files, and tells the user where they are when a test fails.</description>
    </item>
    
    <item>
      <title>Bazel UI locking and file downloads</title>
      <link>https://jmmv.dev/2020/09/bazel-ui-locking.html</link>
      <pubDate>Tue, 01 Sep 2020 16:40:00 -0400</pubDate>
      
      <guid>https://jmmv.dev/2020/09/bazel-ui-locking.html</guid>
      <description>&lt;p&gt;About a month ago, I was benchmarking the impact of a new Bazel feature and I noticed that a test build that should have taken only a few seconds took almost 10 minutes. My Internet connection was flaking out indeed, but something else didn&amp;rsquo;t seem right. So I looked and found that Bazel was doing network calls within a critical section, and these were the root cause behind the massive slowdown. But how did we get such an obvious no-no into the codebase? Read on to see how this happened and how gnarly it was to fix!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Shipping Bazel&#39;s new dynamic scheduler</title>
      <link>https://jmmv.dev/2020/06/shipping-bazel-new-dynamic-scheduler.html</link>
      <pubDate>Fri, 12 Jun 2020 16:00:00 -0400</pubDate>
      
      <guid>https://jmmv.dev/2020/06/shipping-bazel-new-dynamic-scheduler.html</guid>
      <description>Back in September 2019, I embarked into the task of rewriting Bazel&amp;rsquo;s dynamic scheduler to deal with slow and flaky networks. Initial testing had shown that dynamic builds might become slower, and it was all due to this feature having been designed for a different use case (in-office, high-speed network). We had to fix two different issues in the scheduler.
The first fix was making the downloads of the remote artifacts happen without holding the output lock.</description>
    </item>
    
    <item>
      <title>Running codesign over SSH with a new key</title>
      <link>https://jmmv.dev/2020/05/codesign-and-ssh.html</link>
      <pubDate>Fri, 29 May 2020 15:30:00 -0400</pubDate>
      
      <guid>https://jmmv.dev/2020/05/codesign-and-ssh.html</guid>
      <description>I just spent sometime between 30 minutes and 1 hour convincing the Mac Pro that sits in my office to successfully codesign an iOS app via Bazel. This was after having to update the signing key to a newer one and after rebooting the machine due to the macOS 10.15.5 upgradeâ€”all remotely thanks to COVID-19.
The build of the app was failing with an errSecInternalComponent error printed by codesign. It is not the first time I face this, but in all previous cases, I had either been at the computer to click through security popups, had had functional Chrome Remote Desktop access, or did not have to install a new signing key remotely.</description>
    </item>
    
    <item>
      <title>Ensuring system rewrites are truly necessary</title>
      <link>https://jmmv.dev/2020/01/system-rewrites-and-tuning.html</link>
      <pubDate>Fri, 24 Jan 2020 17:10:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2020/01/system-rewrites-and-tuning.html</guid>
      <description>I think it&amp;rsquo;s safe to say that software engineers&amp;mdash;hey, I&amp;rsquo;m one one myself!&amp;mdash;often dream about what the rewrite of a system would look like if they had the chance to start over. Oh so much more usable. Oh so much better structured. Oh so much faster! We are architects after all.
And it might be true that a rewrite can deliver those benefits. But often enough, we are too quick to let our minds wander into that territory.</description>
    </item>
    
    <item>
      <title>The OSXFUSE, hard links, and dladdr puzzle</title>
      <link>https://jmmv.dev/2020/01/osxfuse-hardlinks-dladdr.html</link>
      <pubDate>Fri, 17 Jan 2020 16:30:00 +0500</pubDate>
      
      <guid>https://jmmv.dev/2020/01/osxfuse-hardlinks-dladdr.html</guid>
      <description>Hello everyone and welcome to this new decade!
It&amp;rsquo;s already 2020 and I&amp;rsquo;m only 17 days late in writing a first post. I was planning to start with an opinion article, but as its draft is taking longer than I wanted&amp;hellip; I&amp;rsquo;ll present you the story of a recent crazy bug that has kept me busy for the last couple of days.
Java crashes with Bazel and sandboxfs On a machine running macOS Catalina, install sandboxfs and build Bazel with sandboxfs enabled, like this:</description>
    </item>
    
    <item>
      <title>Tree artifacts and transient files</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-tree-artifacts.html</link>
      <pubDate>Tue, 31 Dec 2019 13:20:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-tree-artifacts.html</guid>
      <description>To conclude the deep dive into Bazel&amp;rsquo;s dynamic spawn strategy, let&amp;rsquo;s look at the nightmare that tree artifacts have been with the local lock-free feature. And, yes, I&amp;rsquo;m double-posting today because I really want to finish these series before the end of the decade1!
Tree artifacts are a fancy name for action outputs that are directories, not files. What&amp;rsquo;s special about them is that Bazel does not know a priori what the directory contents are: the rule behind the action just specifies that there will be a directory with files, and Bazel has to treat that as the unit of output from the action.</description>
    </item>
    
    <item>
      <title>Lifting the local lock for dynamic execution</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-local-lockfree.html</link>
      <pubDate>Tue, 31 Dec 2019 07:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-local-lockfree.html</guid>
      <description>In the previous post, we saw how accounting for artifact download times makes the dynamic strategy live to its promise of delivering the best of local and remote build times.
Or does it? If you think about it closely, that change made it so that builds that were purely local couldn&amp;rsquo;t be made worse by enabling the dynamic scheduler: the dynamic strategy would always favor the local branch of a spawn if the remote one took a long time.</description>
    </item>
    
    <item>
      <title>Artifact downloads and dynamic execution</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-download-times.html</link>
      <pubDate>Mon, 30 Dec 2019 11:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-download-times.html</guid>
      <description>In the previous post of this series, we looked at how the now-legacy implementation of the dynamic strategy uses a per-spawn lock to guard accesses to the output tree. This lock is problematic for a variety of reasons and we are going to peek into one of those here.
To recap, the remote strategy does the following:
 Send spawn execution RPC to the remote service. Wait for successful execution (which can come quickly from a cache hit).</description>
    </item>
    
    <item>
      <title>Output conflicts and dynamic execution</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-output-locking.html</link>
      <pubDate>Fri, 27 Dec 2019 10:10:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-output-locking.html</guid>
      <description>When the dynamic scheduler is active, Bazel runs the same spawn (aka command line) remotely and locally at the same time via two separate strategies. These two strategies want to write to the same output files (e.g. object files, archives, or final binaries) on the local disk. In computing, two things trying to affect the same thing require some kind of coÃ¶rdination.
You might think, however, that because we assume that both strategies are equivalent and will write the same contents to disk1, this is not problematic.</description>
    </item>
    
    <item>
      <title>Bazel&#39;s dynamic strategy</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-strategy.html</link>
      <pubDate>Thu, 26 Dec 2019 10:30:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-strategy.html</guid>
      <description>After introducing Bazel&amp;rsquo;s dynamic execution a couple of posts ago, it&amp;rsquo;s time to dive into its actual implementation details as promised. But pardon for the interruption in the last post, as I had to take a little detour to cover a necessary topic (local resources) for today&amp;rsquo;s article.
Simply put, dynamic execution is implemented as &amp;ldquo;just&amp;rdquo; one more strategy called dynamic. The dynamic strategy, however, is different from all others because it does not have a corresponding spawn runner.</description>
    </item>
    
    <item>
      <title>How does Bazel track local resource usage?</title>
      <link>https://jmmv.dev/2019/12/bazel-local-resources.html</link>
      <pubDate>Mon, 23 Dec 2019 22:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-local-resources.html</guid>
      <description>How does Bazel avoid melting your workstation with concurrent subprocesses? Or&amp;hellip; tries to, because I know it still does that sometimes? There are two mechanisms as play: the jobs number and the local resources tracker. Let&amp;rsquo;s dive into them.
The jobs number, given by the --jobs flag, configures the number of concurrent Skyframe evaluators during the execution phase1. What a mouthful. What this essentially means is that jobs indicates the number of threads used to walk the graph looking for actions to execute&amp;mdash;and also executing them.</description>
    </item>
    
    <item>
      <title>Introduction to Bazel&#39;s dynamic execution</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-introduction.html</link>
      <pubDate>Fri, 20 Dec 2019 15:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-introduction.html</guid>
      <description>Bazel&amp;rsquo;s dynamic execution is a feature that makes your builds faster by using remote and local resources, transparently and at the same time. We launched this feature in Bazel 0.21 back in February 2019 along an introductory blog post and have been hard at work since then to improve it.
The reason dynamic execution makes builds faster is two-fold:
 first, because we can hide hiccups in the connectivity to the remote build service; and, second, because we can take advantage of things like persistent workers, which are designed to offer super-fast edit/build/test cycles.</description>
    </item>
    
    <item>
      <title>What are Bazel&#39;s strategies?</title>
      <link>https://jmmv.dev/2019/12/bazel-strategies.html</link>
      <pubDate>Sat, 14 Dec 2019 18:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-strategies.html</guid>
      <description>&amp;ldquo;Strategies? Will you talk about Bazel&amp;rsquo;s strategy for world domination ðŸ™€?&amp;rdquo; No&amp;hellip; not exactly that.
Dynamic execution has been quite a hot topic in my work over the last few months and I am getting ready to publish a series of posts on it soon. But before I do that, I need to first review Bazel&amp;rsquo;s execution strategies because they play a big role in understanding what dynamic execution is and how it&amp;rsquo;s implemented.</description>
    </item>
    
  </channel>
</rss>