<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Unix on Julio Merino (jmmv.dev)</title><link>https://jmmv.dev/tags/unix/index.html</link><description>Recent content in Unix on Julio Merino (jmmv.dev)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>julio@meroh.net (Julio Merino)</managingEditor><webMaster>julio@meroh.net (Julio Merino)</webMaster><copyright>Copyright 2004&ndash;2025 Julio Merino</copyright><lastBuildDate>Fri, 10 Jan 2025 09:00:00 -0800</lastBuildDate><atom:link href="https://jmmv.dev/tags/unix/index/feed.xml" rel="self" type="application/rss+xml"/><item><title>Self-documenting Makefiles</title><link>https://jmmv.dev/2025/01/make-help.html</link><pubDate>Fri, 10 Jan 2025 09:00:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/01/make-help.html</guid><description>&lt;p>Make, as arcane as a build tool can be, may still be a good first fit for certain scenarios. &amp;ldquo;Heresy!&amp;rdquo;, you say, as you hear a so-called &amp;ldquo;Bazel expert&amp;rdquo; utter these words.&lt;/p>
&lt;p>The specific problem I&amp;rsquo;m facing is that I need to glue together &lt;a href="https://jmmv.dev/2024/12/netbsd-build-system.html">the NetBSD build system&lt;/a>, &lt;a href="https://jmmv.dev/2013/11/patch-management-with-quilt.html">a quilt patch set&lt;/a>, EndBASIC&amp;rsquo;s Cargo-based Rust build, and a couple of QEMU invocations to produce a Frankenstein disk image for a Raspberry Pi. And the thing is: Make allows doing this sort of stitching with relative ease. Sure, Make is not the best option because the overall build performance is &amp;ldquo;meh&amp;rdquo; and because incremental builds are almost-impossible to get right&amp;hellip; but adopting Bazel for this project would be an almost-infinite time sink.&lt;/p>
&lt;p>Anyway. When using Make in this manner, you often end up with what&amp;rsquo;s essentially a &amp;ldquo;command dispatcher&amp;rdquo; and, over time, the number of commands grows and it&amp;rsquo;s hard to make sense of which one to use for what. Sure, you can write a &lt;code>README.md&lt;/code> with instructions, but I guarantee you that the text will get out of sync faster than you can read this article. There is a better way, though.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-01-10-make-help.png" length="110230" type="image/jpeg"/></item><item><title>Demystifying secure NFS</title><link>https://jmmv.dev/2024/11/demystifying-secure-nfs.html</link><pubDate>Sun, 03 Nov 2024 16:00:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/11/demystifying-secure-nfs.html</guid><description>&lt;p>I recently got a &lt;a href="https://sy.to/hekgh">Synology DS923+&lt;/a> for evaluation purposes which led me to setting up NFSv4 with Kerberos. I had done this about a year ago with FreeBSD as the host, and going through this process once again reminded me of how painful it is to secure an NFS connection.&lt;/p>
&lt;p>You see, Samba is much easier to set up, but because NFS is the native file sharing protocol of Unix systems, I felt compelled to use it instead. However, if you opt for NFSv3 (the &amp;ldquo;easy default&amp;rdquo;), you are left with a system that has zero security: traffic travels unencrypted and unsigned, and the server trusts the client when the client asserts who is who. Madness for today&amp;rsquo;s standards. Yet, when you look around, people say &amp;ldquo;oh, but NFSv3 is fine if you trust the network!&amp;rdquo; But seriously, who trusts the network in this day and age?&lt;/p>
&lt;p>You have to turn to NFSv4 &lt;em>and&lt;/em> combine it with Kerberos for a secure file sharing option. And let me tell you: the experience of setting these up and getting things to work is horrible, and the documentation out there is terrible. Most documents are operating-system specific so they only tell you what works when a specific server and a specific client talk to each other. Other documents just &lt;em>assume&lt;/em>, and thus omit, various important details of the configuration.&lt;/p>
&lt;p>So. This article is my recollection of &amp;ldquo;lab notes&amp;rdquo; on how to set this whole thing up along with the necessary background to understand NFSv4 and Kerberos. My specific setup involes the Synology DS923+ as the NFSv4 server; Fedora, Debian, and FreeBSD clients; and the supporting KDC on a pfSense (or FreeBSD) box.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-11-03-synology-ds923plus-nas.jpg" length="232646" type="image/jpeg"/></item><item><title>The costs of the i386 to x86-64 upgrade</title><link>https://jmmv.dev/2024/10/x86-64-programming-models.html</link><pubDate>Mon, 07 Oct 2024 09:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/10/x86-64-programming-models.html</guid><description>&lt;p>If you read my previous article on &lt;a href="https://jmmv.dev/2024/09/dos-memory-models.html">DOS memory models&lt;/a>, you may have dismissed everything I wrote as &amp;ldquo;legacy cruft from the 1990s that nobody cares about any longer&amp;rdquo;. After all, computers have evolved from sporting 8-bit processors to 64-bit processors and, on the way, the amount of memory that these computers can leverage has grown orders of magnitude: the 8086, a 16-bit machine with a 20-bit address space, could only use 1MB of memory while today&amp;rsquo;s 64-bit machines can theoretically access 16EB.&lt;/p>
&lt;p>All of this growth has been in service of ever-growing programs. But&amp;hellip; even if programs are now more sophisticated than they were before, do they all &lt;em>really&lt;/em> require access to a 64-bit address space? Has the growth from 8 to 64 bits been a net positive in performance terms?&lt;/p>
&lt;p>Let&amp;rsquo;s try to answer those questions to find some very surprising answers. But first, some theory.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-10-07-x86-64-cover-image.jpg" length="992004" type="image/jpeg"/></item><item><title>Windows NT vs. Unix: A design comparison</title><link>https://jmmv.dev/2024/09/windows-nt-vs-unix-design.html</link><pubDate>Mon, 09 Sep 2024 08:30:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/09/windows-nt-vs-unix-design.html</guid><description>&lt;p>Over the years, I&amp;rsquo;ve repeatedly heard that Windows NT is a very advanced operating system and, being a Unix person myself, it has bothered me to not know &lt;em>why&lt;/em>. I&amp;rsquo;ve been meaning to answer this question for years and I can do so now, which means I want to present you my findings.&lt;/p>
&lt;p>My desire to know about NT&amp;rsquo;s internals started in 2006 when I applied to the Google Summer of Code program to develop Boost.Process. I needed such a library for ATF, but I also saw the project as a chance to learn something about the Win32 API. This journey then continued in 2020 with me &lt;a href="https://jmmv.dev/2020/10/bye-google-hi-microsoft.html">choosing to join Microsoft&lt;/a> after a long stint at Google and me buying the &lt;a href="https://www.amazon.com/Windows-Internals-Part-architecture-management/dp/0735684189?crid=2F7UR8S48RP6O&amp;amp;dib=eyJ2IjoiMSJ9.p9cBb_-Q8GjuK0z0kDLKG6xoExPM_2QWt_jn0PlqVBSWYNyqRp2Cd7MHXFeQ4EiRACaX_Y_9xzECC0YpECzSl5kCBD3u1KUPduAgmnO732G9aqw1aLdQszw8LIXBOE1cYvOf3KYQmQ5vdFV6i4eFOttVvIa2XerkHVGiPd1OzTk32tEOchCbnUqpzW3QqCG7AjEmmKHFGuo5T2_UQDUERaSVRa26oAZHYuePCzDrwbY.bcHnZQWFYjmL64ZRnMieVsUH5JVx-T-WY88kj8V-uno&amp;amp;dib_tag=se&amp;amp;keywords=windows+internals&amp;amp;qid=1725808358&amp;amp;sprefix=windows+internals%2Caps%2C155&amp;amp;sr=8-1&amp;amp;linkCode=ll1&amp;amp;tag=blogsystem5-20&amp;amp;linkId=08d00ee830fe99b6e648add99e1b64c5&amp;amp;language=en_US&amp;amp;ref_=as_li_ss_tl">Windows Internals&lt;/a> 5th edition book in 2021 (which I never fully read due to its incredible detail and length). None of these made me learn what I wanted though: the ways in which NT fundamentally differs from Unix, if at all.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-09-09-windows-nt-vs-unix-design.jpg" length="1049554" type="image/jpeg"/></item><item><title>Picking glibc versions at runtime</title><link>https://jmmv.dev/2024/08/glibc-versions-runtime.html</link><pubDate>Sun, 11 Aug 2024 10:15:00 +0200</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/08/glibc-versions-runtime.html</guid><description>&lt;p>In a recent work discussion, I came across an argument that didn&amp;rsquo;t sound quite right. The claim was that we needed to set up containers in our developer machines in order to run tests against a modern glibc. The justifications were that using &lt;code>LD_LIBRARY_PATH&lt;/code> to load a different glibc didn&amp;rsquo;t work and statically linking glibc wasn&amp;rsquo;t possible either.&lt;/p>
&lt;p>But&amp;hellip; running a program against a version of glibc that&amp;rsquo;s different from the one installed on the system seems like a pretty standard requirement, doesn&amp;rsquo;t it? Consider this: how do the developers of glibc test their changes? glibc has existed for much longer than containers have. And before containers existed, they surely weren&amp;rsquo;t testing glibc changes by installing modified versions of the library over the system-wide one and YOLOing it.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-08-11-glibc-versions-runtime-dynamic.png" length="36593" type="image/jpeg"/></item><item><title>SSH agent forwarding and tmux done right</title><link>https://jmmv.dev/2023/11/ssh-agent-forwarding-and-tmux-done.html</link><pubDate>Fri, 17 Nov 2023 08:50:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2023/11/ssh-agent-forwarding-and-tmux-done.html</guid><description>&lt;p>The &lt;a href="https://man.openbsd.org/ssh-agent">SSH agent&lt;/a> is a little daemon that holds your private keys in memory. This is particularly handy when your keys are protected by a passphrase: you can unlock and add your keys to the agent once and, from then on, any SSH client such as &lt;code>ssh(1)&lt;/code> can interact with the keys without asking you for the passphrase again.&lt;/p>
&lt;p>The SSH agent becomes even handier when you primarily work on a remote workstation over SSH. Under these circumstances, you will often need the remote workstation to establish SSH connections to &lt;em>other&lt;/em> remote machines (e.g. to contact GitHub). In those situations, you can: copy your private keys to the remote workstation; generate different private keys on the remote workstation; or forward your SSH agent so that the remote workstation can leverage the keys from your client machine without them ever traveling over the network.&lt;/p></description></item><item><title>Useless use of GNU</title><link>https://jmmv.dev/2021/08/useless-use-of-gnu.html</link><pubDate>Wed, 25 Aug 2021 09:10:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2021/08/useless-use-of-gnu.html</guid><description>The GNU project is the source of the Unix userland utilities used on most Linux distributions. Its compatibility with standards and other Unix systems, or lack thereof, directly impacts the overall portability of any piece of software developed from GNU/Linux installations. Unfortunately, the GNU userland does not closely adhere to standards, and its widespread usage causes little incompatibilities to creep into any software created on GNU/Linux systems. Read on for why this is a problem and the pitfalls you will encounter.</description></item><item><title>Argument processing in Unix and Windows</title><link>https://jmmv.dev/2020/11/cmdline-args-unix-vs-windows.html</link><pubDate>Mon, 02 Nov 2020 06:30:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2020/11/cmdline-args-unix-vs-windows.html</guid><description>Let&amp;rsquo;s continue our dive into the very interesting topic of how Unix (or Linux or what have you) and Windows differ regarding argument processing. And by that I mean: how a program (the caller) communicates the set of arguments to pass to another program (the callee) at execution time, how the callee receives such arguments, and what are the consequences of each design.</description></item><item><title>Flags parsing in PowerShell (vs. Unix)</title><link>https://jmmv.dev/2020/10/powershell-cmdlet-params.html</link><pubDate>Wed, 28 Oct 2020 06:45:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2020/10/powershell-cmdlet-params.html</guid><description>The way PowerShell handles flags in scripts (aka cmdlets) differs completely from what Unix shells do. These differences allow PowerShell to gain insight on how scripts have to be executed, which in turn can deliver a better interactive user experience. Read on for a comparison while wearing Unix-tinted glasses.</description></item><item><title>A tour of directories as system-wide databases</title><link>https://jmmv.dev/2020/08/database-directories.html</link><pubDate>Fri, 21 Aug 2020 07:30:00 -0400</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2020/08/database-directories.html</guid><description>In the previous post, we saw how .d directories permit programmatic edits to system-wide configuration with ease. But this same concept can be applied to other kinds of tracking. Let&amp;rsquo;s dive into a few examples ranging from desktop menu entries to the package manager&amp;rsquo;s database itself.</description></item><item><title>Configuration files and .d directories</title><link>https://jmmv.dev/2020/08/config-files-vs-directories.html</link><pubDate>Mon, 17 Aug 2020 07:00:00 -0400</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2020/08/config-files-vs-directories.html</guid><description>Have you ever wondered why an increasing number of programs are configured by placing small files in .d directories instead of by just editing a single file? Have you ever wondered why these .d directories seem to proliferate in Linux installations? Read on to understand what these are and why they are useful.</description></item><item><title>Waiting for process groups, macOS edition</title><link>https://jmmv.dev/2019/11/wait-for-process-group-darwin.html</link><pubDate>Fri, 15 Nov 2019 11:00:00 +0000</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2019/11/wait-for-process-group-darwin.html</guid><description>&lt;p>In the previous posts, we saw why &lt;a href="https://jmmv.dev/2019/11/wait-for-process-group.html">waiting for a process group is complicated&lt;/a> and we covered a specific, bullet-proof mechanism to &lt;a href="https://jmmv.dev/2019/11/wait-for-process-group-linux.html">accomplish this on Linux&lt;/a>. Now is the time to investigate this same topic on macOS. Remember that the problem we are trying to solve (&lt;a href="https://github.com/bazelbuild/bazel/issues/10245">#10245&lt;/a>) is the following: given a process group, wait for all of its processes to fully terminate.&lt;/p>
&lt;p>macOS has a bunch of fancy features that &lt;a href="https://jmmv.dev/2019/03/macos-threads-qos-and-bazel.html">other systems do not have&lt;/a>, but process control is not among them. We do not have features like Linux&amp;rsquo;s child subreaper or PID namespaces to keep track of process groups. Therefore, we&amp;rsquo;ll have to roll our own. And the only way to do this is to scan the process table looking for processes with the desired process group identifier (PGID) and waiting until they are gone.&lt;/p></description></item><item><title>Waiting for process groups, Linux edition</title><link>https://jmmv.dev/2019/11/wait-for-process-group-linux.html</link><pubDate>Thu, 14 Nov 2019 11:30:00 +0000</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2019/11/wait-for-process-group-linux.html</guid><description>&lt;p>In the &lt;a href="https://jmmv.dev/2019/11/wait-for-process-group.html">previous post&lt;/a>, we saw why waiting for a process group to terminate is important (at least in the context of Bazel), and we also saw why this is a difficult thing to do in a portable manner. So today, let&amp;rsquo;s dive into how to do this properly on a Linux system.&lt;/p>
&lt;p>On Linux, we have two routes: using the &lt;strong>child subreaper&lt;/strong> feature or using &lt;strong>PID namespaces&lt;/strong>. We&amp;rsquo;ll focus on the former because that&amp;rsquo;s what we&amp;rsquo;ll use to fix (&lt;a href="https://github.com/bazelbuild/bazel/issues/10245">#10245&lt;/a>) the process wrapper&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, and because they are sufficient to fully address our problem.&lt;/p></description></item><item><title>Waiting for process groups, introduction</title><link>https://jmmv.dev/2019/11/wait-for-process-group.html</link><pubDate>Tue, 12 Nov 2019 14:20:00 +0000</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2019/11/wait-for-process-group.html</guid><description>&lt;p>&lt;strong>Process groups&lt;/strong> are a feature of Unix systems to group related processes under a common identifier, known as the &lt;strong>PGID&lt;/strong>. Using the PGID, one can look for these related process and send signals in unison to them. This is typically used by shell interpreters to manage processes.&lt;/p>
&lt;p>For example, let&amp;rsquo;s launch a shell command that puts two &lt;code>sleep&lt;/code> invocations in the background (those with the 10- and 20-second delays) and then sleeps the direct child (with a 5-second delay)&amp;mdash;while also putting the whole invocation in the background so that we can inspect what&amp;rsquo;s going on:&lt;/p></description></item><item><title>Bazel's process-wrapper helper tool</title><link>https://jmmv.dev/2019/11/bazel-process-wrapper.html</link><pubDate>Fri, 08 Nov 2019 15:30:00 +0000</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2019/11/bazel-process-wrapper.html</guid><description>&lt;p>As strange as it may sound, a very important job of any build tool is to orchestrate the execution of lots of other programs&amp;mdash;and &lt;a href="https://bazel.build/">Bazel&lt;/a> is no exception.&lt;/p>
&lt;p>Once Bazel has finished &lt;em>loading&lt;/em> and &lt;em>analyzing&lt;/em> the build graph, Bazel enters the &lt;em>execution phase&lt;/em>. In this phase, the primary thing that Bazel does is walk the graph looking for actions to execute. Then, for each action, Bazel invokes its commands&amp;mdash;things like compiler and linker invocations&amp;mdash;as subprocesses. Under the default configuration&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, all of these commands run on your machine.&lt;/p></description></item></channel></rss>