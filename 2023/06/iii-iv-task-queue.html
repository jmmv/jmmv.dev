<!doctype html><html lang=en xmlns=http://www.w3.org/1999/xhtml xmlns:fb=http://ogp.me/ns/fb#><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta property="og:site_name" content="Julio Merino (jmmv.dev)"><meta property="twitter:site" content="@jmmv"><title>A persistent task queue in Rust - Julio Merino (jmmv.dev)</title><meta property="og:title" content="A persistent task queue in Rust - Julio Merino (jmmv.dev)"><meta property="twitter:title" content="A persistent task queue in Rust - Julio Merino (jmmv.dev)"><meta name=description content="A couple of posts ago, I described why I built custom email subscriptions for this blog. I briefly mentioned that there is new automation that scrapes the RSS feed and sends new post notifications to you all. Today, it&amp;rsquo;s time to look into how this all works and how this is based on a new persistent task queuing service in Rust. The queue handles tasks to periodically scrape the RSS feed and schedule emails, all with various quota enforcers and retry policies in place. Read on for the design requirements and constraints of the task queue, how the client and worker Rust APIs look like, and how this all can be made to work inside the Azure Functions serverless runtime for minimal deployment hassle and cost."><meta property="og:description" content="A couple of posts ago, I described why I built custom email subscriptions for this blog. I briefly mentioned that there is new automation that scrapes the RSS feed and sends new post notifications to you all. Today, it&amp;rsquo;s time to look into how this all works and how this is based on a new persistent task queuing service in Rust. The queue handles tasks to periodically scrape the RSS feed and schedule emails, all with various quota enforcers and retry policies in place. Read on for the design requirements and constraints of the task queue, how the client and worker Rust APIs look like, and how this all can be made to work inside the Azure Functions serverless runtime for minimal deployment hassle and cost."><meta property="twitter:description" content="A couple of posts ago, I described why I built custom email subscriptions for this blog. I briefly mentioned that there is new automation that scrapes the RSS feed and sends new post notifications to …"><meta name=author content="Julio Merino"><meta property="twitter:creator" content="@jmmv"><meta name=generator content="Hugo 0.111.3"><meta property="og:url" content="https://jmmv.dev/2023/06/iii-iv-task-queue.html"><meta property="og:type" content="blog"><meta property="twitter:card" content="summary"><link rel=canonical href=https://jmmv.dev/2023/06/iii-iv-task-queue.html><link rel=alternate type=application/rss+xml title="Julio Merino (jmmv.dev)" href=/feed.xml><link rel=stylesheet href=/sass/main.min.161663676cac4bf21abc8967ec3267c26026aa58e9f392c5f3427e0ef089fe6b.css><link rel=stylesheet href=/css/chroma.css><link rel=icon type=image/png href=/images/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/images/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicons/favicon-96x96.png sizes=96x96><meta property="og:image" content="/images/favicons/favicon-1200x1200.png"><meta property="twitter:image" content="https://jmmv.dev/images/favicons/favicon-1200x1200.png"><script>const SITE_ID="e8da9f62-b7ac-4fe9-bf20-7c527199a376",BASE_URL="https://jmmv.dev/"</script></head><body><header class=site-header><nav class="navbar navbar-expand-lg fixed-top navbar-dark bg-primary"><a class=navbar-brand href=/><img src=/images/favicons/favicon-30x30.png width=30 height=30 class="d-inline-block align-top" alt>
&nbsp;Julio Merino</a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/about.html>About</a></li><li class=nav-item><a class=nav-link href=/essays.html>Essays</a></li><li class=nav-item><a class=nav-link href=/resume.html>Resume</a></li><li class=nav-item><a class=nav-link href=/software.html>Software</a></li></ul><ul class="navbar-nav mr-4"><li class=nav-item><a class=nav-link href=/archive.html>Archive</a></li><li class=nav-item><a class=nav-link href=/series.html>Series</a></li><li class=nav-item><a class=nav-link href=/tags.html>Tags</a></li></ul><form class=form-inline method=get role=search action=https://www.google.com/search><div class=input-group><input type=search name=query class=form-control placeholder=Search aria-label=Search><div class=input-group-append><button type=submit value=Search class="btn btn-light">
<img src=/octicons/search.svg></button></div></div><input type=hidden name=sitesearch value=https://jmmv.dev/></form></div></nav></header><div class=page-header><div class=container><h1>A persistent task queue in Rust</h1><p>June 23, 2023 &#183;
About 17 minutes
&#183;
Tags:
<a href=/tags/endtracker>endtracker</a>, <a href=/tags/iii-iv>iii-iv</a>, <a href=/tags/rust>rust</a></p></div></div><div class="container post-body"><div class=row><div class=col-md-9><div class=row><div class=col><article><p>In a recent post, I announced the very non-exciting feature of having <a href=/2023/06/in-house-email-subscriptions.html>custom-built email subscriptions</a> for this blog. Writing the subscription flow was easy, but developing the automation to, first, periodically scrape the blog&rsquo;s RSS feed and, second, schedule email notifications to readers based on the items in the feed was really time-consuming and tricky to implement.</p><p>You would say: <em>&ldquo;How is that hard? Just <a href=https://github.com/rss2email/rss2email>set up a cron job</a> that fetches the RSS feed and sends emails!&rdquo;</em> Yeah, yeah, of course, that can work. But when you add in other requirements, this approach is not so simple. Note a few things: you need to determine which posts in the feed are new and which aren&rsquo;t, which means you have to keep track of all past-seen posts; my email gateway has daily limits on how many emails I can send, so I need to schedule the submissions across multiple days; and if the submission of one email fails, I want to retry sending that one email only. Add to that the fact that I run not one but multiple sites with their own subscription features, and these processes&mdash;in particular, the email quota controls&mdash;all have to somehow agree.</p><p>The more you think about this problem, the more you realize having some sort of queue to track which emails have to be sent and which haven&rsquo;t been sent yet could be very useful. At that point, you might as well realize that such a queuing system can also support all kinds of background operations that happen in a web service, not just email submissions, and I have been needing that ability for a while now.</p><div class="container action-highlight p-4 my-4 d-md-none"><div class="row text-center"><p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.</p></div><div class=row><div class=col><div class=form-group><form action=https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add method=post><input type=text name=email placeholder="Enter your email" class="form-control input-sm text-center my-1">
<button type=submit class="btn btn-primary btn-block my-1">Subscribe</button></form></div></div></div><div class="row px-2"><div class="col col-sm-5 text-left"><small><span class=subscriber-count>0</span> subscribers</small></div><div class="col col-sm-7 text-right"><p><a rel=me href=https://mastodon.online/@jmmv><img src=/images/badges/mastodon-logo.svg width=32px height=32px alt="Follow @jmmv on Mastodon"></a>
<a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;screen_name=jmmv"><img src=/images/badges/Twitter_logo_blue.svg width=32px height=32px alt="Follow @jmmv on Twitter"></a>
<a href=/feed.xml><img src=/images/badges/feed-icon-28x28.png alt="RSS feed"></a></p></div></div></div><p>So let&rsquo;s get into specifics. Here are the conceptual tasks I envisioned within the context of <a href=/software/endtracker.html>EndTRACKER</a> (terrible name, I know), along with the names they actually got in the code, to convert an RSS feed into email notifications:</p><ul><li><p><code>ProcessFeeds</code>: Loads all feeds from the database and enqueues new <code>ScrapeFeed</code> and <code>ProcessFeed</code> tasks for every feed. This is the entry point to the system, and this task is enqueued by a timer once an hour to start the processing flow.</p></li><li><p><code>ScrapeFeed(feed)</code>: Loads the details for <code>feed</code>, downloads its registered RSS feed, and computes the delta against previously-known items. Newly-discovered feed items are inserted into a database and marked as &ldquo;not yet notified&rdquo;.</p></li><li><p><code>ProcessFeed(feed)</code>: Loads all &ldquo;not yet notified&rdquo; posts for <code>feed</code> from the database plus the list of verified email subscribers for the site that owns the feed. It then schedules one <code>SendFeedItem</code> task for every post/subscriber pair and finally marks the feed item as notified.</p></li><li><p><code>SendEmailItem(feed, item, subscriber)</code>: Loads the <code>feed</code>&rsquo;s <code>item</code> details from the database, composes an email for the <code>subscriber</code> by formatting arbitrary HTML into text, and sends the result to them. This is where sanity-checks happen, such as ensuring we have enough email submission quota left or that the subscriber hasn&rsquo;t unsubscribed, and thus this task must be retried at a later stage if it fails.</p></li></ul><p>With these task definitions in mind, it was time to go to the drawing board and design a queuing system to support them.</p><hr><p>Now, the question you surely have is: <em>&ldquo;Why bother? There are plenty of queuing services out there!&rdquo;</em> And my answer is: <em>"<a href=/2021/01/why-endbasic.html>Because why not</a>"</em>. I wanted to have some fun designing and implementing this feature, and I don&rsquo;t fancy the idea of marrying a specific cloud provider by relying on their cloud-native services: so far, the only thing I depend on for my web services is a hosted PostgreSQL instance and a bunch of Azure Functions deployments, and I could trivially move these to a VM in my home server if I had to.</p><p>Anyhow. What <em>is</em> a &ldquo;persistent task queue&rdquo; anyway, other than a mouthful? Let&rsquo;s look at the words: it is a <strong>queue</strong>, so it is an ordered record of &ldquo;things&rdquo;; it is <strong>for tasks</strong>, so it needs to offer task-specific execution logic and tracking to ensure at-most-once semantics and the like; and it is <strong>persistent</strong>, so the tasks and their statuses need to be stored somewhere.</p><h1 id=key-ideas>Key ideas</h1><p>As in any design, we have to start by enumerating the specific requirements I had for the solution to put the various design choices in context. These are:</p><ul><li><p><strong>Service-agnostic.</strong> I run a few web services, all of which share common logic via <a href=/software/iii-iv.html>the III-IV framework</a>. The queue implementation must live in this open-source framework. The framework must not know anything about the task specifics, so <em>task descriptors</em> must be defined by the services and they need to be persisted in some generic way (JSON serialization).</p></li><li><p><strong>Client and worker separation.</strong> Clients enqueuing tasks must not know anything about how to run them. Only the worker processes need to contain the code that processes the tasks. This means there ought to be two separate APIs, and there can be one or more client and/or workers running at any given time.</p></li><li><p><strong>Azure Functions deployment.</strong> The queue must run within existing services, not as a new standalone deployment. This is a restrictive requirement because my existing services are run by a serverless runtime, so the queue operations cannot rely on long-running processes.</p></li><li><p><strong>At-most once execution.</strong> Tasks have side-effects so they must run at most once. It is OK if some are lost as long as it&rsquo;s a rare occurrence, but it is <em>not acceptable</em> to run the same task twice. The fact that we run in a serverless environment helps with this because Azure Functions enforces a maximum runtime for processes, which we will take advantage of.</p></li><li><p><strong>Ability to retry tasks that fail.</strong> Some tasks will fail for expected reasons, such as when we have run out of outbound email quota for the day, and these must be postponed and retried at a later time. But some failures are not retriable, so whether a task needs to be retried or not has to be decided on an error-by-error basis.</p></li><li><p><strong>Quarantining of problematic tasks.</strong> Tasks that fail repeatedly or that cause the queue worker to crash in unexpected ways need to be moved out of the way after a few execution attempts so that they do not cause future trouble.</p></li><li><p><strong>Database-agnostic.</strong> As is the case for all of III-IV-based services, the choice of the database must be independent from the queue logic and both PostgreSQL (for production) and SQLite (for lightning-fast tests) must be supported. However, the database must be ACID because it will be used for synchronization.</p></li></ul><p>With these, you can start envisioning how the queue looks like. Beware that I&rsquo;m no expert in queuing systems, so this design and implementation are possibly flawed or incomplete in various ways&mldr; but it does the job for now. Let&rsquo;s dive into its specifics.</p><h1 id=azure-functions-integration>Azure Functions integration</h1><p>The first consumer of the task queue was going to be EndTRACKER and, right now, EndTRACKER runs as an Azure Functions serverless service: I upload a tiny Rust binary that exposes an HTTP interface and the cloud runtime takes care of spinning up short-lived containers whenever the configured HTTP routes are accessed. The only magic involved is making the Rust HTTP server expose itself via the TCP/IP port given to it in the <code>FUNCTIONS_CUSTOMHANDLER_PORT</code> environment variable&mdash;and, after that, all communication between the Azure Functions runtime and the Rust binary happens over HTTP.</p><p>This is great, but&mldr; I had to clear some questions before even attempting to write the queue service in this environment.</p><p>The first question was: was it even possible to build the queue runtime in a serverless environment? A worker is, in theory, a long-lived process that polls the queue every few seconds or minutes to detect work to do and executes such work. The answer is obviously &ldquo;yes, you can do that&rdquo;. Imagine exposing a <code>/queue-loop</code> HTTP endpoint and having a timer that calls this endpoint periodically to trigger the queue&rsquo;s processing loop. As long as the loop can execute at least one task within the maximum allowed container run time, the queue will make forward progress.</p><p>The second question was: can we integrate this timer into Azure Functions without needing a separate cron job that pokes <code>/queue-loop</code> every few minutes? The answer also seemed to be yes: Azure Functions endpoints can be exposed via different triggers. Some triggers are HTTP endpoint calls, but other triggers, such as timers, can be used. If we define a trigger like the following in a <code>functions/queue-loop.json</code> file:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;bindings&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;timerTrigger&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;direction&#34;</span><span class=p>:</span> <span class=s2>&#34;in&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;req&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;schedule&#34;</span><span class=p>:</span> <span class=s2>&#34;0 */10 * * * *&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Then the Azure Functions runtime will call this <code>queue-loop</code> function every 10 minutes given the <code>schedule</code> stanza above.</p><p>But then the third question was: this is not an HTTP trigger&mldr; can it be processed at all from a custom Rust binary, or are the officially supported SDKs relying on some <em>other</em> communication mechanism with the runtime engine to react to non-HTTP triggers?</p><p>Fortunately, the answer is also yes. It took me a bit of fiddling, but in the end I found that the runtime will invoke the <code>/queue-loop</code> POST HTTP handler (outside of the default <code>/api</code> namespace for user-supplied handlers). However, after I got this hooked up, I noticed that the Azure Functions runtime claimed that my handler failed (even when it did return a <code>200 OK</code> code) and kept re-invoking it every few seconds&mdash;as if previous calls had been lost. This took some more effort to figure out, and I had to peek into the C# SDK code to find the answer: the endpoint needs to return a valid JSON payload, not an empty document. After figuring this out, changing the endpoint to return an empty <code>{}</code> dictionary allowed the runtime to interact with my handler just fine.</p><p>I was cleared to proceed with the original idea.</p><h1 id=the-client-interface>The client interface</h1><p>Defining the right interface for tasks, especially the internal interface to process them, took many iterations. As mentioned earlier, clients must not know anything about how tasks are executed, so there have to be two separate APIs: one that is public for clients, and one that is internal to the workers.</p><p>In the end, I settled on the following client operations. Note that this is missing <em>a ton</em> of details, so don&rsquo;t take the Rust code too literally here:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>enum</span> <span class=nc>TaskResult</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// The task succeeded with an optional diagnostic/status message.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=n>Done</span><span class=p>(</span><span class=nb>Option</span><span class=o>&lt;</span><span class=nb>String</span><span class=o>&gt;</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// The task failed hard with the given error message.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=n>Failed</span><span class=p>(</span><span class=nb>String</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// The task was abandoned after N failed retries with the given error message.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=n>Abandoned</span><span class=p>(</span><span class=nb>String</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>impl</span><span class=o>&lt;</span><span class=no>DB</span><span class=p>,</span><span class=w> </span><span class=n>Task</span><span class=o>&gt;</span><span class=w> </span><span class=n>Client</span><span class=o>&lt;</span><span class=no>DB</span><span class=p>,</span><span class=w> </span><span class=n>Task</span><span class=o>&gt;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>where</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=no>DB</span>: <span class=nc>Database</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>Task</span>: <span class=nc>Serialize</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// Creates a new client that uses the `db` database for task persistence.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=k>fn</span> <span class=nf>new</span><span class=p>(</span><span class=n>db</span>: <span class=nc>DB</span><span class=p>)</span><span class=w> </span>-&gt; <span class=nc>Self</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=o>..</span><span class=p>.</span><span class=w> </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// Enqueues a new `task` and returns the identifier assigned to it.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=k>async</span><span class=w> </span><span class=k>fn</span> <span class=nf>enqueue</span><span class=p>(</span><span class=o>&amp;</span><span class=k>mut</span><span class=w> </span><span class=bp>self</span><span class=p>,</span><span class=w> </span><span class=n>task</span>: <span class=kp>&amp;</span><span class=nc>T</span><span class=p>)</span><span class=w> </span>-&gt; <span class=nb>Result</span><span class=o>&lt;</span><span class=n>Uuid</span><span class=o>&gt;</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=o>..</span><span class=p>.</span><span class=w> </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// Checks if the task `id` has finished execution by querying the database.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=k>async</span><span class=w> </span><span class=k>fn</span> <span class=nf>poll</span><span class=p>(</span><span class=o>&amp;</span><span class=k>mut</span><span class=w> </span><span class=bp>self</span><span class=p>,</span><span class=w> </span><span class=n>id</span>: <span class=nc>Uuid</span><span class=p>)</span><span class=w> </span>-&gt; <span class=nb>Result</span><span class=o>&lt;</span><span class=nb>Option</span><span class=o>&lt;</span><span class=n>TaskResult</span><span class=o>&gt;&gt;</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=o>..</span><span class=p>.</span><span class=w> </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// Waits for the task `id` to finish execution by polling it every `period`.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=k>async</span><span class=w> </span><span class=k>fn</span> <span class=nf>wait</span><span class=p>(</span><span class=o>&amp;</span><span class=k>mut</span><span class=w> </span><span class=bp>self</span><span class=p>,</span><span class=w> </span><span class=n>id</span>: <span class=nc>Uuid</span><span class=p>,</span><span class=w> </span><span class=n>period</span>: <span class=nc>Duration</span><span class=p>)</span><span class=w> </span>-&gt; <span class=nb>Result</span><span class=o>&lt;</span><span class=n>TaskResult</span><span class=o>&gt;</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=o>..</span><span class=p>.</span><span class=w> </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>We have a <code>Client</code> that is connected to a database of a generic type at construction time. This client provides a mechanism to enqueue a JSON-serializable task via an <code>enqueue</code> method, which returns the identifier of the enqueued task, and also offers methods to <code>poll</code> for the task&rsquo;s status as it runs and to <code>wait</code> until the task completes.</p><p>All operations issued by the client happen by talking to the database. To avoid a potential hot spot in inserting tasks, tasks cannot be identified by a globally-unique counter because, otherwise, multiple concurrent clients would need to synchronize on that datum. This is why tasks use UUIDs as identifiers. (I suppose using the default &ldquo;row id&rdquo; of the database could have also worked here just fine, but I&rsquo;m already using UUIDs for many other things, so that&rsquo;s what I picked.)</p><p>The above is the essence of the <code>Client</code>, but it has other methods. Take a look at <a href=https://github.com/jmmv/iii-iv/blob/eec320cd02149f223d8a9c7f8d697845ec2114d8/queue/src/driver/client.rs>the <code>client</code> module</a> for more details.</p><h1 id=the-worker-service-not-a-microservice>The worker service: not a microservice</h1><p>The worker is exposed as a <code>Worker&lt;Task></code> type which looks like this. Pardon my over-simplified Rust:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>impl</span><span class=o>&lt;</span><span class=n>Task</span><span class=o>&gt;</span><span class=w> </span><span class=n>Worker</span><span class=o>&lt;</span><span class=n>Task</span><span class=o>&gt;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>where</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>Task</span>: <span class=nc>Deserialize</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// Creates a new worker process that uses the `db` database to extract
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=sd>/// tasks and persist task state, uses `opts` for configuration, and
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=sd>/// relies on `exec` for the task execution logic.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=k>fn</span> <span class=nf>new</span><span class=o>&lt;</span><span class=n>Exec</span><span class=p>,</span><span class=w> </span><span class=n>ExecFut</span><span class=o>&gt;</span><span class=p>(</span><span class=n>db</span>: <span class=nc>DB</span><span class=p>,</span><span class=w> </span><span class=n>opts</span>: <span class=nc>WorkerOptions</span><span class=p>,</span><span class=w> </span><span class=n>exec</span>: <span class=nc>Exec</span><span class=p>)</span><span class=w> </span>-&gt; <span class=nc>Self</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>where</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=no>DB</span>: <span class=nc>Database</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>Exec</span>: <span class=nb>Fn</span><span class=p>(</span><span class=n>T</span><span class=p>)</span><span class=w> </span>-&gt; <span class=nc>ExecFut</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>ExecFut</span>: <span class=nc>Future</span><span class=o>&lt;</span><span class=n>Output</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>ExecResult</span><span class=o>&gt;</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=o>..</span><span class=p>.</span><span class=w> </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// Tells the worker to look for runnable tasks in the database and to
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=sd>/// run them.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=k>async</span><span class=w> </span><span class=k>fn</span> <span class=nf>notify</span><span class=p>(</span><span class=o>&amp;</span><span class=k>mut</span><span class=w> </span><span class=bp>self</span><span class=p>)</span><span class=w> </span>-&gt; <span class=nb>Result</span><span class=o>&lt;</span><span class=p>()</span><span class=o>&gt;</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=o>..</span><span class=p>.</span><span class=w> </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>The worker&rsquo;s <code>new</code> constructor spawns a Tokio background task that loops infinitely, polling tasks from the database <code>db</code> and using the <code>exec</code> closure to execute each runnable task. The user-configurable options provided in <code>opts</code> tune the behavior of the loop, and all of these options can be provided via environment variables.</p><p>But the infinite loop does nothing on its own. The worker loop starts idle and it only runs tasks whenever the <code>notify</code> method is called. There is an async channel between the Tokio background task and the <code>Worker</code> instance, which <code>notify</code> uses to awaken the loop. This is where the previously-described HTTP API handler <code>/queue-loop</code> comes into play: this handler wraps a <code>Worker</code> and simply invokes <code>notify</code> on it to trigger the processing loop.</p><p>As for the <code>exec</code> suppliers, these closures are intended to be stateless in memory, which simplifies their design. Remember that tasks can be executed from different workers, more than once if they have to be retried, and that the worker processes can die at any time&mldr; so keeping state in memory is nonsensical. It <em>is</em> possible to maintain state in memory in a very convoluted way, which I had to do for unit-testing purposes, but such difficulty is tolerable given this rationale.</p><p>The most interesting thing about the <code>exec</code> closure is its return type, which looks like the following:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>enum</span> <span class=nc>ExecError</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// The task hard-failed with the given error message.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=n>Failed</span><span class=p>(</span><span class=nb>String</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// The task asked to be retried after a certain delay with a diagnostic
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=sd>/// message.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=n>RetryAfterDelay</span><span class=p>(</span><span class=n>Duration</span><span class=p>,</span><span class=w> </span><span class=nb>String</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=sd>/// The task asked to be retried after a specific timestamp with a
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=sd>/// diagnostic message.
</span></span></span><span class=line><span class=cl><span class=sd></span><span class=w>    </span><span class=n>RetryAfterTimestamp</span><span class=p>(</span><span class=n>OffsetDateTime</span><span class=p>,</span><span class=w> </span><span class=nb>String</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>type</span> <span class=nc>ExecResult</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=nb>Result</span><span class=o>&lt;</span><span class=nb>Option</span><span class=o>&lt;</span><span class=nb>String</span><span class=o>&gt;</span><span class=p>,</span><span class=w> </span><span class=n>ExecError</span><span class=o>&gt;</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p>There are blanket conversions from database-layer errors (<code>DbError</code>) and business logic errors (<code>DriverError</code>) into <code>ExecError</code> that classify these error types into either fatal failures or retriable failures. This allows the Rust try operator <code>?</code> to do the right thing by default.</p><p>As in the client section, the above is just a sketch of the <code>Worker</code>. Take a look at <a href=https://github.com/jmmv/iii-iv/blob/eec320cd02149f223d8a9c7f8d697845ec2114d8/queue/src/driver/worker.rs>the <code>worker</code> module</a> for the real details.</p><h1 id=safe-retries>Safe retries</h1><p>One key requirement we haven&rsquo;t covered yet is how to achieve at-most-once execution guarantees. For this, we need to ensure that only one worker can pick up a task at any given time.</p><p>This is easy, right? We can implement a write-ahead journal for task processing, like this:</p><ol><li>Load a runnable (not-yet-running) task from the queue.</li><li>Atomically mark the task as running (thanks, ACID transactions!).</li><li>Run the task processing logic.</li><li>If the task fails, atomically mark it as failed so that it can be retried later after a configurable delay.</li><li>If the task succeeds, atomically mark it as done so that it is never considered as runnable again.</li></ol><p>This ensures that only one worker will ever pick up a task so we are protected against multiple concurrent executions. All good, right? Well&mldr; but what happens if the worker dies at any point after marking the task as running, for whatever reason? We will leave the task &ldquo;running&rdquo; so it won&rsquo;t ever be considered as runnable again, which means it&rsquo;ll never complete!</p><p>Thankfully, this is where the serverless runtime provided by Azure Functions comes in very handy. We can rely on the fact that the runtime enforces a maximum runtime limit for any request and use that fact to detect &ldquo;lost&rdquo; tasks. In other words: if we find a task in the running state that has been running for longer than the maximum allowed runtime (5 minutes by default), then we can conclude that the worker was lost and that the task has to be retried.</p><p>Which finally brings us to quarantining. A worker can die due to external reasons (exceeding its maximum runtime, hardware failure&mldr;) or it can die because the <code>exec</code> handler for the task crashed. It&rsquo;s the latter case that&rsquo;s worrying because we could have an ill-defined task that causes a repeated crash every time a worker picks it up. Such cases are rather common in large queuing systems and can cause slowdowns in task processing or a complete DOS of the service. This is why it&rsquo;s important to discard a task if it has been retried more than N times, which is what&rsquo;s represented by the <code>Abandoned</code> task state.</p><h1 id=putting-it-all-together>Putting it all together</h1><p>Two requirements of the design were to separate the queue logic from the consumer services and to <em>not</em> need extra services to be running. This posed an interesting problem.</p><p>The queue processing loop (aka the <code>Worker</code>) has to run in-process with the actual service. Now, while I do like a microservice-oriented design because it keeps responsibilities clear across components, deploying a bunch of services comes at a high maintenance cost&mdash;one that I am not willing to pay for my side projects. This is why, in EndTRACKER, I have opted for a microservice-like design with a monolithic deployment. The way this works is that the <em>code</em> in EndTRACKER is split into various REST services, and these services all get combined into one single HTTP router from <code>main.rs</code>. The result is a single binary with trivial deployment practices, but leaving an easy way out of a monolith if the need to scale any of the internal services arises.</p><p>In actual terms, this means that EndTRACKER now has an in-process <code>batch</code> &ldquo;microservice&rdquo; that simply spawns the generic <code>Worker</code> and exposes the <code>/queue-loop</code> endpoint into the HTTP router, like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=c1>// Spawn the worker, connecting it to system services and the `run_task`
</span></span></span><span class=line><span class=cl><span class=c1>// execution logic.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kd>let</span><span class=w> </span><span class=n>worker</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>iii_iv_queue</span>::<span class=n>driver</span>::<span class=n>Worker</span>::<span class=n>new</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>worker_db</span><span class=p>,</span><span class=w> </span><span class=n>clock</span><span class=p>,</span><span class=w> </span><span class=n>worker_opts</span><span class=p>,</span><span class=w> </span><span class=k>move</span><span class=w> </span><span class=o>|</span><span class=n>t</span><span class=o>|</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=n>run_task</span><span class=p>(</span><span class=o>..</span><span class=p>.)</span><span class=w> </span><span class=p>});</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>let</span><span class=w> </span><span class=n>worker</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>Arc</span>::<span class=n>from</span><span class=p>(</span><span class=n>Mutex</span>::<span class=n>from</span><span class=p>(</span><span class=n>worker</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Instantiate the service-independent queue worker from III-IV.
</span></span></span><span class=line><span class=cl><span class=c1>// This is the `/queue-loop` handler, essentially.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kd>let</span><span class=w> </span><span class=n>queue_router</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>iii_iv_queue</span>::<span class=n>rest</span>::<span class=n>worker_cron_app</span><span class=p>(</span><span class=n>worker</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Create the HTTP router for the microservice, bundling the generic
</span></span></span><span class=line><span class=cl><span class=c1>// III-IV endpoints with ours.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kd>let</span><span class=w> </span><span class=n>router</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>Router</span>::<span class=n>new</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>.</span><span class=n>route</span><span class=p>(</span><span class=s>&#34;/hourly&#34;</span><span class=p>,</span><span class=w> </span><span class=n>axum</span>::<span class=n>routing</span>::<span class=n>post</span><span class=p>(</span><span class=n>hourly</span>::<span class=n>cron_post_handler</span><span class=p>))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>.</span><span class=n>merge</span><span class=p>(</span><span class=n>queue_router</span><span class=p>);</span><span class=w>
</span></span></span></code></pre></div><p>Verbose&mldr; but not too complicated.</p><p>But wait, what is that <code>/hourly</code> endpoint that just showed up? That&rsquo;s <em>another</em> Azure Functions timer trigger that gets called every hour. <em>This</em> is where the service injects the <code>ProcessFeeds</code> master task into the queue to trigger the whole processing flow. With that task injected into the queue, the <code>/queue-loop</code> then takes over every 10 minutes to discover and process all dependent tasks as they show up.</p><h1 id=future-use-cases>Future use cases</h1><p>Before concluding, let me briefly mention a couple of additional use cases that the queue could serve. It&rsquo;s because these use cases exist that I pursued the queue solution instead of simply deploying <code>rss2email</code> as a cron job in my home server.</p><p>The first use case is going back to this long-standing to-do in the EndTRACKER codebase:</p><pre tabindex=0><code>// Ideally we should get full visibility into all history, but that
// can be very costly and we can tolerate some error here.  To fix
// this properly, though, we&#39;d need some offline data preprocessing,
// which would benefit this whole function anyway.
</code></pre><p>This comment is referring to the logic that computes the historical page views graphs <em>on demand</em>. Right now, historical queries are limited to just one month because of this, but with deferred task processing, you can imagine having a daily task that calculates which data points are missing in a timeseries and spawns tasks to generate those precomputed data points&mldr; which should be trivial to implement at this point. Furthermore, having this ability to compute summarized timeseries means I could change the service to fully discard request data after processing, further reducing the risk of keeping <em>any</em> private data in the database.</p><p>The other use case would arise if I start accepting &ldquo;customers&rdquo; in EndTRACKER. If that were the case, one feature I&rsquo;d want to expose is an &ldquo;export your data as a SQLite database&rdquo; button so that you wouldn&rsquo;t feel trapped in the platform. Implementing such a data dump cannot happen as part of a server request, so it would also benefit from happening via a deferred task.</p><p>Finally, that&rsquo;s all for today. Remember that <a href=https://github.com/jmmv/iii-iv/>III-IV is open source</a>, so this queuing system is as well. Maybe you can now find use cases for this little framework yourself!</p></article></div></div><div class="container post-links"><div class=row><div class="col mr-auto text-left"><span><a href=https://jmmv.dev/2023/06/mvc-non-ui-apps.html>&#171; Previous</a></span></div><div class="col text-center"><span><a href=/archive.html>All posts</a></span></div><div class="col ml-auto text-right"><span><a href=https://jmmv.dev/2023/06/fast-machines-slow-machines.html>Next &#187;</a></span></div></div></div><div class="container post-votes"><div class=row><div class="col-lg-4 my-2"><div class=row><div class=col><a onclick=voteThumbsUp() class="btn btn-block btn-outline-success" id=thumbs-up-btn>👍
(<span id=thumbs-up-count>0</span>)</a></div><div class=col><a onclick=voteThumbsDown() class="btn btn-block btn-outline-danger" id=thumbs-down-btn>👎
(<span id=thumbs-down-count>0</span>)</a></div></div></div><div class="col-lg-8 my-2 d-none d-sm-block"><div class=row><div class="col-md-4 text-center"><a href="https://www.reddit.com/submit?title=A+persistent+task+queue+in+Rust&amp;url=https%3A%2F%2Fjmmv.dev%2F2023%2F06%2Fiii-iv-task-queue.html" class="btn btn-block btn-outline-primary">Share on
<img src=/images/badges/reddit.png alt=Reddit width=24 height=24></a></div><div class="col-md-4 text-center"><a href="https://news.ycombinator.com/submitlink?t=A+persistent+task+queue+in+Rust&amp;u=https%3A%2F%2Fjmmv.dev%2F2023%2F06%2Fiii-iv-task-queue.html" class="btn btn-block btn-outline-primary">Share on
<img src=/images/badges/ycombinator.png alt="Hacker News" width=24 height=24></a></div><div class="col-md-4 text-center"><a href="https://twitter.com/intent/tweet?status=A+persistent+task+queue+in+Rust+%E2%80%94+https%3A%2F%2Fjmmv.dev%2F2023%2F06%2Fiii-iv-task-queue.html+%E2%80%94+cc+%40jmmv" class="btn btn-block btn-outline-primary">Share on
<img src=/images/badges/Twitter_Social_Icon_Circle_Color.png alt=Twitter width=24 height=24></a></div></div></div></div><div class="row my-4" id=postCommentRow><div class=col><div class=media><img class=mr-3 src=/octicons/pencil.svg width=32px height=32px><div class="media-body container"><form method=post id=newPost><div class=row><div class="col my-1"><textarea class=form-control rows=1 id=postCommentContent onclick=showPostComment() placeholder="Leave a comment"></textarea></div></div><div class="row newPostControls" style=display:none><div class="col my-1 form-group"><label for=postCommentAuthor>Your name (optional):</label>
<input type=text class=form-control id=postCommentAuthor></div></div><div class="row newPostControls" style=display:none><div class="col my-1 form-group"><label for=postCommentEmail>Your email (optional):</label>
<input type=text class=form-control type=email id=postCommentEmail>
<small class="form-text text-muted">Invisible to all readers; if provided, you will receive notifications when replied to (not implemented yet)</small></div></div><div class=row id=postCommentError style=display:none><div class="col mt-1 alert-danger"><p></p></div></div><div class="row newPostControls" style=display:none><button class="col-md-3 my-1 btn btn-primary" type=submit id=submitCommentButton>Post</button>
<small class="col-md-9 my-1 text-muted">Comments are subject to moderation. This feature is experimental and is powered by <a href=/software/endtracker.html>EndTRACKER</a>. If you experience any issues, please <a href=/about.html#contact>contact me off-band</a>.</small></div></form></div></div></div></div><script>function hidePostComment(){var t,e=document.getElementById("postCommentContent");e.rows=1,e.value="",t=document.getElementsByClassName("newPostControls"),Array.prototype.forEach.call(t,function(e){e.style.display="none"})}function showPostComment(){var e,t=document.getElementById("postCommentContent");t.rows=5,e=document.getElementsByClassName("newPostControls"),Array.prototype.forEach.call(e,function(e){e.style.display=""})}const form=document.querySelector("#newPost");form.onsubmit=function(e){e.preventDefault();let t=document.getElementById("postCommentAuthor").value,n=document.getElementById("postCommentEmail").value,s=document.getElementById("postCommentContent").value;postComment(t,n,s,hidePostComment)}</script></div></div><div class="col-md-3 sidebar d-none d-md-block"><div class=row><div class="col text-center p-2"><p><a href=/about.html class=clear-link><img src=/images/avatars/20181124-snow.jpg class="rounded-circle shadow my-2" style=width:100px><br><b>Julio Merino</b><br>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.</a></p><div class=row><div class=col><div class=form-group><form action=https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add method=post><input type=text name=email placeholder="Enter your email" class="form-control input-sm text-center my-1">
<button type=submit class="btn btn-primary btn-block my-1">Subscribe</button></form></div></div></div><div class="row px-2"><div class="col-sm-5 text-left"><small><span class=subscriber-count>0</span> subscribers</small></div><div class="col-sm-7 text-right"><p><a rel=me href=https://mastodon.online/@jmmv><img src=/images/badges/mastodon-logo.svg width=32px height=32px alt="Follow @jmmv on Mastodon"></a>
<a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;screen_name=jmmv"><img src=/images/badges/Twitter_logo_blue.svg width=32px height=32px alt="Follow @jmmv on Twitter"></a>
<a href=/feed.xml><img src=/images/badges/feed-icon-28x28.png alt="RSS feed"></a></p></div></div></div></div><div class=row><div class=col><h2>Featured software</h2><ul><li class=overflow-ellipsis><a href=https://www.endbasic.dev/ target=_blank>EndBASIC: Online BASIC+DOS env</a></li><li class=overflow-ellipsis><a href=https://endtracker.azurewebsites.net/ target=_blank>EndTRACKER: Services for static sites</a></li></ul></div></div><div class=row><div class=col><h2>Featured posts</h2><ul><li class=overflow-ellipsis><a href=/2023/06/fast-machines-slow-machines.html>Fast machines, slow machines</a></li><li class=overflow-ellipsis><a href=/2022/12/endbasic-0.10.html>EndBASIC 0.10: Core language, evolved</a></li><li class=overflow-ellipsis><a href=/2022/10/bye-microsoft-hi-snowflake.html>Farewell, Microsoft; hello, Snowflake!</a></li><li class=overflow-ellipsis><a href=/2022/05/rust-is-hard-but-does-it-matter.html>Rust is hard, yes, but does it matter?</a></li><li class=overflow-ellipsis><a href=/2022/04/rust-traits-and-dependency-injection.html>Rust traits and dependency injection</a></li><li class=overflow-ellipsis><a href=/2022/03/a-year-on-windows-intro.html>A year on Windows: Introduction</a></li><li class=overflow-ellipsis><a href=/2021/04/always-be-quitting.html>Always be quitting</a></li><li class=overflow-ellipsis><a href=/2021/02/google-monorepos-and-caching.html>How does Google keep build times low?</a></li><li class=overflow-ellipsis><a href=/2020/12/google-no-clean-builds.html>How does Google avoid clean builds?</a></li><li class=overflow-ellipsis><a href=/2020/12/unit-testing-a-console-app.html>Unit-testing a console app (a text editor)</a></li><li class=overflow-ellipsis><a href=/essays.html#featured>More...</a></li></ul></div></div></div></div></div><footer class=container><div class=row><div class="col-4 order-2 texr-right"><p class=float-right><a href=#>Back to top</a></p></div><div class="col-8 order-1 mr-auto"><p>Copyright 2004&ndash;2023 Julio Merino</p></div></div></footer><script type=module>
  import { addAnchorsToHeaders, addElementClasses, BatchClient } from "\/js\/main.d30f168b11d80082408f4a983af9a626c6e57d58f7846b2174bac40d43be33e3.js";

  var batchClient = new BatchClient(SITE_ID);
  batchClient.doAll({
    put_request: true, get_comments: true, get_subscriber_count: true, get_votes: true });

  window.voteThumbsUp = function() { batchClient.voteThumbsUp(); }
  window.voteThumbsDown = function() { batchClient.voteThumbsDown(); }

  window.postComment = function(...args) {
    batchClient.postComment(...args);
  };

  addAnchorsToHeaders();
  addElementClasses();
</script><noscript><img src="https://hugo-dynamic.jmmv.dev/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/pages/aHR0cHM6Ly9qbW12LmRldi8yMDIzLzA2L2lpaS1pdi10YXNrLXF1ZXVlLmh0bWw=/stamp.gif" style=display:none></noscript></body></html>