<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Julio Merino (jmmv.dev)</title><link>https://jmmv.dev/</link><description>Recent content on Julio Merino (jmmv.dev)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 30 Nov 2023 10:30:00 -0700</lastBuildDate><atom:link href="https://jmmv.dev/feed.xml" rel="self" type="application/rss+xml"/><item><title>Links: November 2023 edition</title><link>https://jmmv.dev/2023/11/links-november-2023-edition.html</link><pubDate>Thu, 30 Nov 2023 10:30:00 -0700</pubDate><guid>https://jmmv.dev/2023/11/links-november-2023-edition.html</guid><description>&lt;p>Welcome to the second edition of my &amp;ldquo;interesting links&amp;rdquo; recap, this time covering the month of November 2023.&lt;/p>
&lt;p>For context, what follows is my manual curation of cool articles, videos, and projects I stumbled upon during this time period. But this is not &lt;em>just&lt;/em> a dump of links: &lt;em>each link is accompanied by a 1-paragraph commentary&lt;/em> that justifies why I thought the material was cool, why it is relevant to this publication and, more importantly, an attempt to nudge you into reading it.&lt;/p>
&lt;p>Before we dive in, two quick things. First: I want to explicitly acknowledge all the new subscribers that have joined us since &lt;a href="/2023/11/windows-nt-peeking-into-the-cradle.html">the last post on Windows NT&lt;/a> landed on some major news sites. Thank you; I hope you find this interesting and a good reason to stick around. And, second: the &lt;a href="/2023/10/links-october-2023-edition.html">first edition&lt;/a> of this recap didn&amp;rsquo;t get any real traction, so let&amp;rsquo;s see if this one fares better. You can help by liking and resharing this post &lt;em>wink&lt;/em> &lt;em>wink&lt;/em> or&amp;hellip; as usual, by subscribing.&lt;/p>
&lt;h1 id="articles">Articles&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.notebookcheck.net/Lenovo-ThinkPad-T14s-G4-review-Business-laptop-is-better-with-AMD-Zen4.763581.0.html">&amp;ldquo;Lenovo ThinkPad T14s G4 review: Business laptop is better with AMD Zen4&amp;rdquo;&lt;/a> by Andreas Osthoff on November 1st, 2023.&lt;/strong>&lt;/p>
&lt;p>I have been eyeing the T14s that Costco has on sale for a while and, while I&amp;rsquo;m not going to get it because of the &amp;ldquo;low&amp;rdquo; screen resolution, I had to read through this review. And oh wow, what an amazing, in-depth description of the device. I&amp;rsquo;m now waiting for the X1 Nano to be in stock again&amp;hellip;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://mjg59.dreamwidth.org/68350.html">&amp;ldquo;Why ACPI?&amp;rdquo;&lt;/a> by Matthew Garrett on October 31st, 2023.&lt;/strong>&lt;/p>
&lt;p>A high-level overview of what ACPI is, why it was needed to replace APM, and how computers would look like in a world without ACPI.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://quick-lint-js.com/blog/bug-journey/">&amp;ldquo;Sometimes, it &lt;em>is&lt;/em> a compiler bug&amp;rdquo;&lt;/a> by strager on May 25th, 2022.&lt;/strong>&lt;/p>
&lt;p>Great debugging story of an obscure problem that the author hit when seeing someone else write a bug in their code, suggesting that they install a VSCode extension that would have highlighted the bug, and watching in real time how the extension then pointed at a non-existent bug. I recall hitting some compiler bugs myself (a similar issue with Rust&amp;rsquo;s incremental compilation, and various ICEs) but I have never had the patience to dig for an answer.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.xtof.info/intel80386.html">&amp;ldquo;Intel 80386, a revolutionary CPU&amp;rdquo;&lt;/a> by Christophe Meneboeuf on September 2nd, 2023.&lt;/strong>&lt;/p>
&lt;p>A good story on how the 80386 came to be and why it was important at the time. I recall reading a book (&lt;a href="https://twitter.com/jmmv/status/1721531589635813396">that I still have&lt;/a>) that described the 8086, the 80286, and the 80386 in great depth and how they differed among each other. All of the details about memory and task management felt fascinating to me at the time, and I&amp;rsquo;ve always found it weird that almost none of the features that the chips provided (segmentation instead of pagination; 4 protection levels; task, interrupt, and call gates; hardware-assisted task switching&amp;hellip;) were put to use by operating systems. Sure, their original implementation might have sucked and been slow, but if they had been used, Intel would have improved those over time.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.vidarholen.net/contents/blog/?p=1035">&amp;ldquo;What exactly was the point of [ “x$var” = “xval” ]?&amp;rdquo;&lt;/a> by Vidar on April 12th, 2021.&lt;/strong>&lt;/p>
&lt;p>One more oddity that you&amp;rsquo;ll find in shell scripts. And not just ancient ones: this still shows up regularly in auto-generated &lt;code>configure&lt;/code> scripts, or even in their &lt;code>configure.ac&lt;/code> originals because people copy/paste code snippets without thinking about them much.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://devblogs.microsoft.com/oldnewthing/20231103-00/?p=108966">&amp;ldquo;Why does unsafe multithreaded use of an &lt;code>std::unordered_map&lt;/code> crash more often than unsafe multithreaded use of a &lt;code>std::map&lt;/code>?&amp;rdquo;&lt;/a> by Raymond Chen on November 3rd, 2023.&lt;/strong>&lt;/p>
&lt;p>I always enjoy Raymond&amp;rsquo;s posts, and to be honest, his blog is what drove me into writing mine and changing the way I looked at Microsoft and Windows 9x. In this one, he entertains a question of the type &amp;ldquo;this thing is broken, but why does it look more broken in this case than in this other one?&amp;rdquo;. Obviously, The Internet cannot read subtlety.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="end-to-end-tool-testing-with-bazel.md">&amp;ldquo;End-to-end testing with Bazel and shtk&amp;rdquo;&lt;/a> by yours truly on November 4th, 2023.&lt;/strong>&lt;/p>
&lt;p>Last month, and for reasons that are not interesting, I revived an old project of mine: &lt;a href="https://shtk.jmmv.dev">shtk&lt;/a>. This, combined with my trip to BazelCon 2023, made me want to create a new ruleset to integrate shtk with Bazel builds because I know the shell is a great language to write integration tests for tools. So I ended up creating &lt;a href="https://github.com/jmmv/rules_shtk/">rules_shtk&lt;/a> and wrote this post to explain how to use it and how it can help you write better tools.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://blog.rust-lang.org/2023/11/09/parallel-rustc.html">&amp;ldquo;Faster compilation with the parallel (Rust) front-end in nightly&amp;rdquo;&lt;/a> by Nicholas Nethercote on behalf of The Parallel Rustc Working Group on November 9th, 2023.&lt;/strong>&lt;/p>
&lt;p>This is exciting work. I have an overkill server in the garage with 72 cores where I remote into for development and, most of the time, it goes vastly unused. I doubt the Rust compiler will be able to use that many cores, at least for the kind of projects I work on&amp;mdash;they aren&amp;rsquo;t &lt;em>that&lt;/em> large&amp;mdash;but still, this is exciting.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://flak.tedunangst.com/post/write-your-own-terminal">&amp;ldquo;Write your own terminal&amp;rdquo;&lt;/a> by Ted Unangst on November 10th, 2023.&lt;/strong>&lt;/p>
&lt;p>Writing a terminal is surely rewarding: as the author says, you have to do very little to get it to a functional state, but then can iterate endlessly on the details and on performance. And I know it&amp;rsquo;s fun because I had to do this for the &lt;a href="https://www.endbasic.dev/">EndBASIC&lt;/a> console. Replacing the use of Xterm.js with my own implementation showed results quickly, and I was then able to mix text and graphics seamlessly.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="why-do-i-know-shell-and-how-can-you.md">&amp;ldquo;Why do I know shell, and how can you?&amp;rdquo;&lt;/a> by yours truly on November 10th, 2023.&lt;/strong>&lt;/p>
&lt;p>I spent some time last month and this month writing more shell than usual, and people at work often ask me &amp;ldquo;why I know so many ancient incantations&amp;rdquo;. So I decided to explain how the constraints of &lt;a href="http://www.NetBSD.org/">NetBSD&lt;/a>, an open-source OS project I contributed to for many years, guided me down this path.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://virtuallyfun.com/2023/11/12/dont-waste-money-on-a-math-coprocessor-they-said/">&amp;ldquo;Don&amp;rsquo;t waste money on a math coprocessor they said&amp;rdquo;&lt;/a> by neozeed on November 12th, 2023.&lt;/strong>&lt;/p>
&lt;p>Did you know that CPUs did not use to have floating point operations and that there were optional chips you could buy to supplement the CPU with those? Say hi to the FPUs. This article dives into history and shows how installing an 80287 along an 80286 fixed a mysterious crashing bug in a game and in OS/2&amp;mdash;even when none of this code was using floating point. If you are into retro stuff, this one (and &lt;a href="https://virtuallyfun.com/">the whole blog&lt;/a> it seems!) is for you&amp;hellip; but I only wish the author came up with a precise explanation of what went wrong here.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://wingolog.org/archives/2023/11/13/i-accidentally-a-scheme">&amp;ldquo;i accidentally a scheme&amp;rdquo;&lt;/a> by wingo on November 13th, 2023.&lt;/strong>&lt;/p>
&lt;p>This article is short and not very detailed, but it contains a bunch of interesting references to programming language implementation topics and is entertaining to read. You must read the intro, though; it is just great. Plus I learned a new meme&amp;hellip; and several new words.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://yorickpeterse.com/articles/a-decade-of-developing-a-programming-language/">&amp;ldquo;A decade of developing a programming language&amp;rdquo;&lt;/a> by Yorick Peterse on November 14th, 2023.&lt;/strong>&lt;/p>
&lt;p>An easy-to-read reflection on the challenges of building a new programming language, along with some suggestions on how to approach doing so.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://lock.cmpxchg8b.com/reptar.html">&amp;ldquo;Reptar&amp;rdquo;&lt;/a> by Tavis Ormandy on November 14th, 2023.&lt;/strong>&lt;/p>
&lt;p>An article from Google&amp;rsquo;s Project Zero team describing a glitch in instruction processing that makes certain modern x86 processors enter an invalid state. Whether this can be used for privilege escalation is still unknown, but assume the worst.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="ssh-agent-forwarding-and-tmux-done.md">&amp;ldquo;SSH agent forwarding and tmux done right&amp;rdquo;&lt;/a> by yours truly on November 17th, 2023.&lt;/strong>&lt;/p>
&lt;p>If you have ever used SSH agent forwarding and you keep long-running tmux sessions on the remote machine, you know you are in for trouble. This article covers why agent forwarding breaks in this case, describes various solutions, and presents a prototype I quickly wrote (the &lt;a href="https://github.com/jmmv/ssh-agent-switcher/">ssh-agent-switcher&lt;/a>) to fix the problem.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.evanjones.ca/setenv-is-not-thread-safe.html">&amp;ldquo;Setenv is not Thread Safe and C Doesn&amp;rsquo;t Want to Fix It&amp;rdquo;&lt;/a> by Evan Jones on November 19th, 2023.&lt;/strong>&lt;/p>
&lt;p>Well, yes, it is not thread safe&amp;mdash;but you should &lt;em>not&lt;/em> be modifying the environment of your own process, except right before &lt;code>exec&lt;/code>. Environment variables &lt;em>are&lt;/em> global, untyped, not-thread-safe variables.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://pikuma.com/blog/what-is-dos4gw-protected-mode">&amp;ldquo;DOS/4GW and Protected Mode&amp;rdquo;&lt;/a> by Gustavo Pezzi on December 12th, 2021.&lt;/strong>&lt;/p>
&lt;p>Ah, the memories. Learn more about how DOS games could unleash the power of 32 bits and more than 1 MB (yes, MB) of memory by using an &amp;ldquo;extender&amp;rdquo; while running on an &amp;ldquo;OS&amp;rdquo; that was 16-bit real mode.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="code-reviews-a-success-story.md">&amp;ldquo;Code reviews: A success story&amp;rdquo;&lt;/a> by yours truly on November 21st, 2023.&lt;/strong>&lt;/p>
&lt;p>If you ask people what they think about the Pull Request process to get code merged into a project, you&amp;rsquo;ll find critics. I do think PR reviews, and in particular code reviews, are a good process that can increase the quality of the software you ship&amp;mdash;but it&amp;rsquo;s important for the people involved to understand the limitations of the process and when they need to take a different route. This Twitter thread presents a success story that I was personally involved in.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.10stripe.com/articles/why-is-56k-the-fastest-dialup-modem-speed.php">&amp;ldquo;Why is 56k the fastest dialup modem speed?&amp;rdquo;&lt;/a> by Alex Freeman probably pre-2008.&lt;/strong>&lt;/p>
&lt;p>I can hear this article. A good technical explanation on why the maximum transmission speed for dial-up connections is 56k, a number that seems pulled out of thin air, and how it&amp;rsquo;s not possible to achieve it in practice.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://devblogs.microsoft.com/oldnewthing/20231124-00/?p=109059">&amp;ldquo;On harmful overuse of &lt;code>std::move&lt;/code>&amp;rdquo;&lt;/a> by Raymond Chen on November 24th, 2023.&lt;/strong>&lt;/p>
&lt;p>So using &lt;code>std::move&lt;/code> can hurt? Thanks, C++. The article touches upon optimizations that the compiler can perform and how move construction can hamper them. Also, this reminds me how the NRVO (described in the article too) masked a bug in code I wrote long ago, and how I do not want to ever write C++ again if I can avoid it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="windows-nt-peeking-into-the-cradle.md">&amp;ldquo;Windows NT: Peeking into the cradle&amp;rdquo;&lt;/a> by yours truly on November 24th, 2023.&lt;/strong>&lt;/p>
&lt;p>A review of the &amp;ldquo;Showstopper!&amp;rdquo; book combined with my own commentary on how exciting (and tiresome) it must have been to live through the development of Windows NT: the OS that still powers most PCs in the world, more than 30 years after its inception.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://tedium.co/2023/11/24/weird-html-hacks-history/">&amp;ldquo;10 Weird HTML Hacks That Shaped The Internet&amp;rdquo;&lt;/a> by Ernie Smith on November 24th, 2023.&lt;/strong>&lt;/p>
&lt;p>This article gets my vote if only for its retro photos of Netscape 4. But, in any case, the article is a neat summary of weird things that people did (and still do!) with HTML to format their websites. The article is long, but each of the 10 entries has a very brief what/how/why summary at the top which makes it easy to decide what you want to read.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://utcc.utoronto.ca/~cks/space/blog/unix/ShellsAndCurrentDirectory">&amp;ldquo;Unix shells and the current directory&amp;rdquo;&lt;/a> by Chris Siebenmann on November 25th, 2023.&lt;/strong>&lt;/p>
&lt;p>It&amp;rsquo;s interesting to think about how the &amp;ldquo;current directory&amp;rdquo; is represented in the kernel and how, depending on the choices, the kernel may not be able to provide a &lt;code>getcwd(2)&lt;/code> system call. When that happens, how does &lt;code>pwd(1)&lt;/code> work? This article answers these questions, and more.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://muxup.com/2023q4/storing-data-in-pointers">&amp;ldquo;Storing data in pointers&amp;rdquo;&lt;/a> by Alex Bradbury on November 27th, 2023.&lt;/strong>&lt;/p>
&lt;p>Pointers are really wide, but addressable memory isn&amp;rsquo;t yet&amp;mdash;so pointers have enough room to carry data in them. This article describes how, but the more interesting part is the list at the end covering the many real-world use cases where this is done.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="other">Other&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://retrocomputing.stackexchange.com/questions/27926/who-invented-file-extensions-in-file-names">&amp;ldquo;Who invented file extensions in file names?&amp;rdquo;&lt;/a> StackExchange discussion on November 1st, 2023.&lt;/strong>&lt;/p>
&lt;p>We take file extensions as part of file names for granted today, but looking into their history, we discover that extensions were a separate metadata field in the file system, much like timestamps are. It wasn&amp;rsquo;t until Unix and its flat approach to file names that extensions became part of the file names. This is why on MS-DOS you can refer to files without specifying their extension (again, just like you can refer to files without specifying the time they were modified).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://en.wikipedia.org/wiki/Caldera_OpenLinux">&amp;ldquo;Caldera OpenLinux&amp;rdquo;&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>The very first Linux distribution I ever tried. I recall that this came with the PC Actual magazine and remember how the installation instructions in the corresponding article described a workaround for a bug in the mounting of the CD. I also remember not achieving a resolution larger than 320x200 with X11. Not a great first impression&amp;hellip; but this hooked me into the Unix world forever.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.youtube.com/watch?v=qbKGw8MQ0i8">&amp;ldquo;NTFS really isn&amp;rsquo;t that bad [video]&amp;rdquo;&lt;/a> by Robert Collins on January 16th, 2020.&lt;/strong>&lt;/p>
&lt;p>A conference presentation that describes how the speaker optimized Rust&amp;rsquo;s installation from 3 and a half minutes to just 14 seconds on Windows. NTFS isn&amp;rsquo;t the problem: it&amp;rsquo;s the applications assuming that the whole world is like Linux.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.nasm.us/">&amp;ldquo;The Netwide Assembler (NASM)&amp;rdquo;&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>Brought to memory by &lt;a href="https://news.ycombinator.com/item?id=38203553">a Hacker News discussion&lt;/a>. It&amp;rsquo;s interesting to me to see people disregard the AT&amp;amp;T syntax as unusable, which makes me feel better about never learning it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.youtube.com/watch?v=TbZ3HzvFEto">&amp;ldquo;Half-Life: 25th anniversary documentary [video]&amp;rdquo;&lt;/a> by Valve on November 17th, 2023.&lt;/strong>&lt;/p>
&lt;p>A documentary on my favorite game of all times. Well worth the watch, even for the whole family.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://effective-rust.com/">&amp;ldquo;Effective Rust&amp;rdquo;&lt;/a> online book.&lt;/strong>&lt;/p>
&lt;p>Inspired by Scott Meyer&amp;rsquo;s famous Effective C++ book, this online book takes a similar approach to show more than 30 different scenarios in how to better apply Rust. I haven&amp;rsquo;t read it cover to cover, but the few items I skimmed through seem solid. Worth a read and, as with any programming guidelines, lots of what you can find here apply to any language.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.freebsd.org/releases/14.0R/announce/">&amp;ldquo;FreeBSD 14.0-RELEASE Announcement&amp;rdquo;&lt;/a> on November 20th, 2023.&lt;/strong>&lt;/p>
&lt;p>It&amp;rsquo;s here! Go grab it while it&amp;rsquo;s hot. There are claims to significant performance improvements, so I&amp;rsquo;m eagerly awaiting to have a few spare hours to upgrade my server in the garage. I suspect I&amp;rsquo;ll only need a few minutes&amp;hellip; but need to plan for the worst case scenario.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://tmpout.sh/3/">&amp;ldquo;tmp0ut.sh #003&amp;rdquo;&lt;/a> by multiple authors on November, 2023.&lt;/strong>&lt;/p>
&lt;p>A new edition of an online underground ezine talking about security and exploits. The content is super-interesting, but the looks of this are frigging awesome too.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.xbox.com/en-US/power-on">&amp;ldquo;Power On: The Story of Xbox [video series]&amp;rdquo;&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>A 6-part documentary on how the Xbox came to be, and how it almost didn&amp;rsquo;t launch. I&amp;rsquo;ve only been able to watch the first episode so far, but it was engaging.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.youtube.com/watch?v=xi1Lq79mLeE">&amp;ldquo;The mind behind Windows: Dave Cutler&amp;rdquo;&lt;/a> by Dave&amp;rsquo;s Garage on October 21st, 2023.&lt;/strong>&lt;/p>
&lt;p>A 3-hour long interview with Dave Cutler on the creation of Windows NT. Having just written a &lt;a href="/2023/11/windows-nt-peeking-into-the-cradle.html">detailed article on this part of history&lt;/a>, this looks very interesting to watch.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://infinitemac.org/">&amp;ldquo;Infinite Mac&amp;rdquo;&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>Pick any version of System Software/Mac OS from the 1980s or 1990s and run it right in your browser. I wasn&amp;rsquo;t a Mac user until Mac OS X Tiger, so these are systems I never experienced&amp;mdash;except for System 7.5, I think, which I had to use to bootstrap a NetBSD/mac68k system. But if you did, this is a good toy to recreate memories.&lt;/p>
&lt;/li>
&lt;/ul></description><enclosure url="https://jmmv.dev/images/2023-10-31-links.png" length="56457" type="image/jpeg"/></item><item><title>Windows NT: Peeking into the cradle</title><link>https://jmmv.dev/2023/11/windows-nt-peeking-into-the-cradle.html</link><pubDate>Fri, 24 Nov 2023 09:40:00 -0800</pubDate><guid>https://jmmv.dev/2023/11/windows-nt-peeking-into-the-cradle.html</guid><description>&lt;p>It&amp;rsquo;s strange&amp;hellip; but I&amp;rsquo;ve been able to finish reading a book cover-to-cover that&amp;rsquo;s not a book for my kids. It&amp;rsquo;s hard for me to get hooked into books and find the time to read them. I think the one I finished before this might have been &amp;ldquo;&lt;a href="https://www.amazon.com/10-PRINT-CHR-205-5-RND/dp/0262018462?&amp;amp;_encoding=UTF8&amp;amp;tag=blogsystem503-20&amp;amp;linkCode=ur2&amp;amp;linkId=c3ddd9f1db5ead180ea40a44f495092b&amp;amp;camp=1789&amp;amp;creative=9325">10 PRINT&lt;/a>&amp;rdquo;, and that was over a year ago. This time, though, I completed the book on the story behind the creation of Windows NT: namely, &amp;ldquo;Showstopper!&amp;rdquo; in its short form, written by G. Pascal Zachary.&lt;/p>
&lt;p>Reading the story of how Windows NT came to be was entertaining, as it is a story of the system itself and the dynamics between Dave Cutler, the original designer and lead for NT, and the other people involved in the project. I was shy of being 10 years old when Windows NT launched and I didn&amp;rsquo;t comprehend what was going on in the operating systems world and why this release was such a big deal. Reading the book made me learn various new things about the development process, the role of Microsoft in that era, and allowed me to settle some questions I&amp;rsquo;ve had over the years.&lt;/p>
&lt;p>This article is a mixture of a book review and a collection of thoughts and reflections that the book evoked. Let&amp;rsquo;s begin because we have a lot of ground to cover.&lt;/p>
&lt;h1 id="lets-create-a-brand-new-os">Let&amp;rsquo;s create a brand new OS&lt;/h1>
&lt;p>Operating systems are pretty much a commodity these days&amp;mdash;but you couldn&amp;rsquo;t take them for granted before. There was a time during the 1980s and 1990s when a multitude of computer architectures and operating systems thrived, each offering vastly different feature sets and levels of stability than the others. Yes, DOS and Windows were the most popular choices for personal computers, but there were other contenders such as OS/2, BeOS, QNX&amp;hellip; as well as the myriad different commercial Unix derivatives. The open-source BSDs and Linux had just seen the light of day.&lt;/p>
&lt;p>Microsoft&amp;rsquo;s bet to build NT in 1988, a brand new OS from scratch, was bold. There were good reasons for taking the risk, which centered around the desire to modernize DOS and to have first-class support for networks, but investing multiple years of R&amp;amp;D on a massive project like this was risky: others had tried and failed.&lt;/p>
&lt;p>At the end of the day, Microsoft succeeded with NT. The development process took longer than anticipated, but the system finally shipped in 1993. Now, more than 30 years later, NT is behind almost all desktop and laptop computers in the world. The book claims that Cutler repeatedly told his team that they&amp;rsquo;d remember this time period as &amp;ldquo;the good old days&amp;rdquo;, and I think he was well damn right. As tough as that period must have been for everyone involved, they were writing history and setting the direction of personal computing for years to come.&lt;/p>
&lt;h1 id="development-pressure">Development pressure&lt;/h1>
&lt;p>Contrast this to the open-source BSDs and Linux, which were already a reality by NT&amp;rsquo;s launch in 1993. Linux and the original 386BSD were &amp;ldquo;hobby projects&amp;rdquo; for their creators. I&amp;rsquo;m convinced that, at the time, these people and their contributors didn&amp;rsquo;t imagine their toys as anything that would influence the world&amp;mdash;even if, in retrospect, they kinda have: Linux is the basis for almost all mobile devices and servers, and macOS is derived from those original BSDs.&lt;/p>
&lt;p>What I&amp;rsquo;m trying to get at is that there is something to be said about the different thrill of working on these projects. On the one hand, NT was in a race to ship the next revolutionary OS to power all personal computers, with intense pressure from OS/2 and other contenders, and with a design that went against established practice. On the other hand, Linux was in no such rush: its developers worked on it for their own entertainment, probably not grasping what was ahead of them.&lt;/p>
&lt;p>Having been part of the NT team and of that era of computing must have been incredibly exciting. However, it was not all roses for this team. Even though the work of the team was exciting and the potential for impact was massive, the book also shows a clear picture of a really toxic culture: leaders screaming to their peers and reports; normalized long hours and destroyed families; cross-team distrust and shaming&amp;hellip; not something you&amp;rsquo;d probably want to be involved in.&lt;/p>
&lt;h1 id="dogfooding">Dogfooding&lt;/h1>
&lt;p>Creating a new OS is fun but, unless you use the OS regularly, you will have little incentive to discover and fix sharp usability edges or certain classes of bugs. This is where dogfooding, or the practice of &lt;del>eating your own dog food&lt;/del> using your own creations, becomes key. And due to the importance of this, the book has a whole chapter on dogfooding NT.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-24-windows-nt-31-boot.png" class="with-border">
&lt;figcaption>Windows NT 3.1 boot screen. &lt;a href="https://winworldpc.com/product/windows-3/31">Courtesy of WinWorld.&lt;/a>&lt;/figcaption>
&lt;/figure>
&lt;p>The mandate to dogfood NT after it passed a certain functionality threshold comes from Cutler himself and sounds awesome&amp;hellip; and frustrating at the same time. I&amp;rsquo;ve previously dogfooded operating systems&amp;mdash;I ran NetBSD and FreeBSD CURRENT for years while I was a contributor&amp;mdash;and the infrequent crashes were annoying. Note, however, that these two systems were already past a certain stability point by the time I used them so, in general, they worked. I wonder what level of functionality the first dogfood versions of NT had but, based on what I grasp from the book, the answer is &amp;ldquo;not a lot&amp;rdquo;, which means the experience may have been quite a nightmare.&lt;/p>
&lt;p>Note that these days, it seems silly to talk about &amp;ldquo;how this OS is more stable than this other one&amp;rdquo; because all modern OSes implement similar process and file protections, but stability couldn&amp;rsquo;t be taken for granted back then. The DOS-based Windows editions really were quite unstable, and OS/2 and Unix systems put them to shame. The design of NT was going to fix these issues for the Windows world, but it had to be stabilized first too.&lt;/p>
&lt;h1 id="the-build-lab">The build lab&lt;/h1>
&lt;p>Windows releases are often referred to by specific build numbers, which always sounded weird to me: as a regular FreeBSD and NetBSD &lt;em>user&lt;/em>, I churned out multiple new builds of these whole OS &lt;em>per day&lt;/em>, and doing so was trivial and inconsequential. What was so special about Windows that individual build numbers were important? Was it really true that Windows NT 3.51, numbered build 1057, was the 1057th time that the codebase had been assembled together? And the answer is&amp;hellip; yes.&lt;/p>
&lt;p>The book talks a lot about the build lab: the &lt;em>place&lt;/em>&amp;mdash;laptops and remote work were &lt;em>definitely&lt;/em> not a thing in the early 1990s&amp;mdash;where a few engineers took the changes that everyone else made and assembled the whole system into something that could boot. This system was then distributed to the whole team for dogfooding on a daily basis.&lt;/p>
&lt;p>This sounds ridiculous, right? Why wasn&amp;rsquo;t there a CI/CD pipeline to build the system every few hours and publish the resulting image to a place where engineers could download it? Ha, ha. Things weren&amp;rsquo;t this rosy back then. Having automated tests, reproducible builds, a CI/CD system, unattended nightly builds, or even version control&amp;hellip; these are all a pretty new &amp;ldquo;inventions&amp;rdquo;. Quality control had to be done by hand, as did integrating the various pieces that formed the system.&lt;/p>
&lt;p>Regardless, even if you think about having to design a CI/CD system for an OS today, it isn&amp;rsquo;t as trivial as what you need for your run-of-the-mill GitHub project. Validating the built OS against different hardware, assessing the behavior of fundamental system components like the process scheduler, and accepting that any validation can crash the machine and require a physical power cycle&amp;hellip; is not trivial. Even relying on VMs like we do today isn&amp;rsquo;t sufficient, because you &lt;em>do&lt;/em> want to test the OS against real hardware.&lt;/p>
&lt;h1 id="portability-and-design-cleanliness">Portability and design cleanliness&lt;/h1>
&lt;p>These days we take x86-based personal computers as the one and only possibility, which wasn&amp;rsquo;t true back in the day&amp;mdash;and may not be true in the near future either. As I mentioned earlier, the computer world was full of different architectures during the 1980s and early 1990s.&lt;/p>
&lt;p>In my journey to move away from Windows, which &lt;a href="/2020/08/os2-memory-lane.html">started with OS/2 Warp 3&lt;/a> and was followed by Linux and the BSDs, I was lured by NetBSD and stuck with it for years. The main reason I ended up settling on NetBSD was its claims of being &amp;ldquo;cleanly designed&amp;rdquo;, and a big reason for needing &lt;em>and&lt;/em> having a clean design was supporting tens of different architectures out of the same codebase.&lt;/p>
&lt;p>Which is interesting because this is precisely how NT started. From reading the book, I learned that Cutler had the same mentality for his OS and, in fact, the system wasn&amp;rsquo;t ported to x86 until late in its development. He wanted developers to target non-x86 machines &lt;em>first&lt;/em> to prevent sloppy non-portable coding, because x86 machines were already the primary desktops that developers had. In fact, even as x86 increasingly became the primary target platform for NT, the team maintained a MIPS build at all times, and having most tests passing in this platform was a requirement for launching.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-24-windows-nt-351-powerpc.png" class="with-border">
&lt;figcaption>Windows NT 3.51 running on a PowerPC machine. From the &lt;a href="https://virtuallyfun.com/2020/08/02/the-lost-history-of-prep-windows-nt-3-5x-and-the-rs-6000-40p/">"The lost history of PReP: Windows NT 3.5x and the RS/6000 40p"&lt;/a> article at Virtually Fun.&lt;/figcaption>
&lt;/figure>
&lt;p>On this topic, I briefly remember some contemporary news articles in computer magazines describing how the PowerPC was going to be &amp;ldquo;the next big thing&amp;rdquo; and how NT ran on it. I did not grasp what a big deal this was at the time because based on the screenshots that they printed, Windows NT on PowerPC looked exactly the same as Windows 3.11 on my i386 PC. Well, I guess I really just didn&amp;rsquo;t understand what PowerPC nor NT were at all.&lt;/p>
&lt;h1 id="dialing-difficulty-up-to-11-with-ntfs">Dialing difficulty up to 11 with NTFS&lt;/h1>
&lt;p>This golden era also saw the creation of many new file systems. If you were on DOS and Windows 3.x land, your choices were limited, but if you were playing with Linux, you saw new file systems pop up &amp;ldquo;every week&amp;rdquo;. Things settled around the early/mid 2010s, except maybe for the uneventful launch of &lt;a href="https://en.wikipedia.org/wiki/Apple_File_System">APFS&lt;/a> in 2017.&lt;/p>
&lt;p>Creating a new OS from scratch is no easy feat, but wanting to create a brand new file system to go with it is making things difficult just because. While writing a file system is already tricky enough, &lt;em>stabilizing&lt;/em> it is a whole different story. But, as the book describes, the team felt that they needed a new file system to support the reliability and networking needs of NT, so it had to be done. FAT was nowhere close to offer them.&lt;/p>
&lt;p>And NTFS is very interesting. NTFS was a really advanced file system for its time thanks to journaling, support for multi-TB volumes, optional per-directory and per-file compression, detailed ACLs&amp;hellip; none of the Unix file systems of the era had these features. For example, ext3, which extended ext2 with journaling support, did not exist until 2001, and it has been replaced by ext4 and btrfs since. But NTFS is still chugging along in Windows 11, so it is impressive that they could make it happen on time for the OS release. (The same cannot be said about &lt;a href="https://en.wikipedia.org/wiki/WinFS">WinFS&lt;/a>&amp;hellip; which was supposed to ship with Vista and didn&amp;rsquo;t.)&lt;/p>
&lt;p>Now, I know you will complain that NTFS is slow&amp;hellip; but you know what? It almost-certainly is not. Most of the problems with NTFS performance stem from file system filters, which intercept all I/O operations to do heavy stuff like virus scanning. &lt;a href="https://www.youtube.com/watch?v=qbKGw8MQ0i8">NTFS on its own is fine&lt;/a>, but you need to write your applications with knowledge of the system you target: if you treat something as Unix when it isn&amp;rsquo;t, then bad things happen.&lt;/p>
&lt;h1 id="correctness-first-performance-second">Correctness first, performance second&lt;/h1>
&lt;p>Speaking of NTFS performance, the book also touches upon system performance. Unsurprisingly, Cutler wanted to make the system stable and well-designed first, leaving performance for later. Performance was pushed to the side for a while, but the team was confident that they could improve performance and resource consumption later. This was a good strategy, although it didn&amp;rsquo;t play out well for a while.&lt;/p>
&lt;p>What I found interesting is that the book claims that Bill Gates was obsessed with performance and routinely asked about it, because the prospective user base of NT did not have the means to buy high-end computers. Which is great&amp;hellip; but then, I just don&amp;rsquo;t know where &lt;a href="/2023/06/fast-machines-slow-machines.html">performance has gone wrong&lt;/a> at Microsoft because that doesn&amp;rsquo;t seem to be the focus anymore.&lt;/p>
&lt;p>Regardless, and even after performance work, NT was not the fastest at its launch. As the initial reviews published, the system was deemed &amp;ldquo;too big, too slow&amp;rdquo; and requiring too high hardware requirements. This seemed to affect Cutler. Right after the initial 3.1 launch, when the team deserved a break, they were back at work right away to improve these topics in preparation for the 3.51 launch.&lt;/p>
&lt;h1 id="huge-migrations-at-microsoft">Huge migrations at Microsoft&lt;/h1>
&lt;p>Apple is touted as the expert in huge migrations: they moved their hardware lineup from 68k to PowerPC, from PowerPC to x86 and, most recently, from x86 to &lt;a href="https://en.wikipedia.org/wiki/Apple_silicon">Apple Silicon&lt;/a> (ARM). They also moved from 32 bits to 64 bits, dropping 32-bit support later, and from Mac OS Classic to Mac OS X. Apple has indeed executed these huge migrations well, but at each step, they have left apps and developers behind because Apple has never been big on backwards compatibility. Somehow its customers have accepted that.&lt;/p>
&lt;p>If we peek under the covers, Microsoft has also pushed similar humongous migrations. At each step, however, Microsoft has preserved backwards compatibility as much as possible, and I think this is why these migrations seem less of a big deal than they really were.&lt;/p>
&lt;p>What am I talking about? For starters: the jump from the DOS / Windows 3.x world to Windows 95. Windows 95 unified these two systems by making DOS applications work well under Windows&amp;mdash;something that wasn&amp;rsquo;t true in 3.x. To make this possible, Windows 95 carried tons of application-specific tweaks to remain bug-for-bug compatible and, while gross, that&amp;rsquo;s what users needed. We know how big of a splash Windows 95 made.&lt;/p>
&lt;p>But the other huge migration was the jump from Windows 9x to Windows NT. Maintaining two separate operating systems with the same UI for a few years with support for roughly the same apps is a big feat, but it&amp;rsquo;s an even bigger feat to unify these two tracks into one with Windows XP. And, with that release, they were finally able to drop the Windows 9x line for good.&lt;/p>
&lt;h1 id="putting-the-windows-in-nt">Putting the Windows in NT&lt;/h1>
&lt;p>NT started as a joint project between Microsoft and IBM. The goal was to create the next OS for PC systems, named OS/2. So, while NT was designed from the ground up to support multiple personalities (or&amp;hellip; &lt;a href="/2020/11/wsl-lost-potential.html">subsystems, like WSL 1&lt;/a>), the original plan was to make NT support DOS and OS/2 applications.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-24-microsoft-os2-logo.png" class="with-border">
&lt;figcaption>Microsoft OS/2 1.3 logo. &lt;a href="https://www.os2world.com/wiki/index.php/Microsoft_OS/2_1.3">Courtesy of OS/2 World.&lt;/a>&lt;/figcaption>
&lt;/figure>
&lt;p>The Windows personality&amp;mdash;the thing that gives NT its ability to run Windows applications&amp;mdash;wasn&amp;rsquo;t in the cards at first. As the book explains, the project was originally called NT, not Windows NT, and was supposed to become OS/2. It wasn&amp;rsquo;t until later that it became clear within Microsoft that NT had to run Windows applications to not be dead on arrival, and thus Gates pushed for NT to prioritize compatibility with Windows applications. Later on, the system was renamed to Windows NT to emphasize this point, and all ties with IBM broke.&lt;/p>
&lt;p>One thing that struck as interesting was how the team struggled to fix compatibility bugs late in the development cycle, because each fixed bug resulted in a new batch of compatibility issues. It wasn&amp;rsquo;t until later in the project that a key developer had the insight to create a tracer that recorded the system/library calls an app made. This recording could then be used by developers, without the help of testers, to trivially observe the behavior of a sequence of operations on NT and adjust them. This was the magic piece that provided a path towards stability and being able to ship.&lt;/p>
&lt;p>From this work, NT also gained the ability to define &amp;ldquo;compatibility flags&amp;rdquo; for certain applications. This was necessary to work around cases where the applications did the wrong thing&amp;mdash;yet compatibility had to be kept. And this is why Windows 9x and NT had (and still have) such a great compatibility story: the system is full of levers to appease weird behaviors in random apps, even if the apps themselves do something &amp;ldquo;wrong&amp;rdquo;. Most developers would go against the latter, claiming that those are bugs in the apps and they deserve to break. Apple has taken this path. Open source tries to take this path. &lt;a href="https://www.amazon.com/Old-New-Thing-Development-Throughout/dp/0321440307?&amp;amp;_encoding=UTF8&amp;amp;tag=blogsystem503-20&amp;amp;linkCode=ur2&amp;amp;linkId=b373dc6d4f2a06aac4cfec48134f4d71&amp;amp;camp=1789&amp;amp;creative=9325">Microsoft didn&amp;rsquo;t.&lt;/a>&lt;/p>
&lt;h1 id="the-ui-matters">The UI matters&lt;/h1>
&lt;p>Another topic that the book touches upon was the animosity between Cutler and the graphics team. Cutler did not think that graphics were important, which means they were neglected for a long while. And even when a UI team was put together, Cutler was not particularly happy or impressed by them.&lt;/p>
&lt;p>However, graphics are critical and they were difficult to get right. Performance was a problem, as were the many bugs that plagued the primary UI apps of the OS. And&amp;hellip; you might have the fastest, most portable, best designed OS in the world, but if its shell is not usable nor stable&amp;hellip; nobody will care. The UI makes the OS as much as the kernel makes the OS.&lt;/p>
&lt;p>Eventually, due to the desire to support primarily Windows applications in NT, the team adopted the UI that had been developed for OS/2 and for Windows 3.x. This was critical to make the OS seem familiar, although as I briefly touched upon earlier, this also made it difficult to see how 3.x and NT differed to the untrained eye. Later in life, I had a hard time seeing how the Windows NT 4 that ran in our high school computer lab differed from the Windows 95 I had at home: to me, it just seemed slower and heavier.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-24-windows-nt-4-desktop.png" class="with-border">
&lt;figcaption>Windows NT 4 initial desktop to emphasize how it looks exactly the same as Windows 95.&lt;/figcaption>
&lt;/figure>
&lt;p>In any case, the UI is crucial to the way people appreciate an OS. And, for NT specifically, I&amp;rsquo;m sad that there is no choice: Microsoft keeps &amp;ldquo;advancing&amp;rdquo; the UI in ways that seem detrimental. In particular, modern versions of Windows feel incredibly slow in hardware barely 10 years old&amp;hellip; which is sad because you can&amp;rsquo;t do anything about it other than stay in the hardware upgrade treadmill. I want to like Windows, but recent UI changes have slowly pushed me away.&lt;/p>
&lt;h1 id="and-finally-about-the-book">And finally, about the book&lt;/h1>
&lt;p>To conclude this look into the past, let&amp;rsquo;s actually talk a tiny bit about the book that sparkled it.&lt;/p>
&lt;p>The book is definitely entertaining to read; I guess the fact that I now live in the area where this all happened helped a tiny bit make it more so. It&amp;rsquo;s easy to read. It&amp;rsquo;s fun. It makes me wish I had been born just a few years earlier to understand everything that was going on in more detail&amp;mdash;and maybe to have had a chance to become part of it. And as I mentioned in the introduction, it is engaging enough that I was able to stick with it for about three months.&lt;/p>
&lt;p>But one thing that surprised me is that the book carries a handful of really obvious, painful editing mistakes. A couple of paragraphs are completely unreadable due to broken grammar, punctuation, and capitaliazation. I&amp;rsquo;m not sure how that happened. Luckily, the unreadable parts are reduced to one or two pages&amp;hellip; so you don&amp;rsquo;t miss much.&lt;/p>
&lt;p>Hope you enjoyed this article. And if you did, I&amp;rsquo;m sure you&amp;rsquo;ll enjoy the book much more. Click on the picture to buy and read it!&lt;/p>
&lt;blockquote>
&lt;a target="_blank" href="https://www.amazon.com/Showstopper-Breakneck-Windows-Generation-Microsoft-ebook/dp/B00J5X5E9U?&amp;_encoding=UTF8&amp;tag=blogsystem503-20&amp;linkCode=ur2&amp;linkId=b3bfada207b7929529132de33861f4e3&amp;camp=1789&amp;creative=9325">
&lt;figure>
&lt;img src="/images/2023-11-24-showstopper-alone.jpg"/>
&lt;figcaption>
"Showstopper!: The Breakneck Race to Create Windows NT and the Next Generation at Microsoft", by G. Pascal Zachary.
&lt;/figcaption>
&lt;/figure>
&lt;/a>
&lt;/blockquote></description><enclosure url="https://jmmv.dev/images/2023-11-24-showstopper-pile.jpg" length="180711" type="image/jpeg"/></item><item><title>Code reviews: A success story</title><link>https://jmmv.dev/2023/11/code-reviews-a-success-story.html</link><pubDate>Tue, 21 Nov 2023 13:50:00 -0800</pubDate><guid>https://jmmv.dev/2023/11/code-reviews-a-success-story.html</guid><description>&lt;p>Code reviews have a bad rep: they are antagonistic in nature and, sometimes, pure red tape. Some argue that they are bad practice; others say that peer programming is better. And while these &lt;em>may&lt;/em> be true, I want to tell you a story about a case where code reviews worked well!&lt;/p>
&lt;p>Meet X: a junior engineer in the Bazel team circa 2018, tasked to implement two features: A and B. As you may know, Google is big into code reviews&amp;mdash;and their tooling for this is awesome; believe me&amp;mdash;so this was the standard process for X to get his code checked in.&lt;/p>
&lt;p>For Feature A, X was working with two engineers in his same office: Y and Z. Engineer Y was a junior engineer as well but with more coding experience than X. Y wrote code really fast and didn&amp;rsquo;t like process. Y rubber-stamped long code reviews with little care about the details.&lt;/p>
&lt;p>Engineer Z was a high-level tech lead in the team. Z had a lot of experience and knew the product top-to-bottom, but didn&amp;rsquo;t have much time for code reviews. Worse yet, Z didn&amp;rsquo;t have enough spare time to closely mentor X or Y.&lt;/p>
&lt;p>For Feature B, X was working with me, who was 6000 km away and with a 6-hour time difference between us. I was known for tough code reviews. I also pushed for breaking large changes into smaller commits, because it is impossible to do a thorough review otherwise.&lt;/p>
&lt;p>And I also pushed for writing unit and integration tests in each change, guiding X into a good testing approach for feature B at each small step. You might say that this is important but isn&amp;rsquo;t part of a code review, but this is where the issues surfaced.&lt;/p>
&lt;p>My review comments were copious, so I classified them in three categories: nits, which were inconsequential style changes; optional suggestions, which X could ignore; and important comments, which required X to change code or for us to have a detailed discussion.&lt;/p>
&lt;p>Importantly, I always justified my review comments, &lt;em>especially&lt;/em> if they were personal opinions or optional suggestions. Most of the time, X took my advice and addressed nits and optional suggestions, because he was convinced by my explanations.&lt;/p>
&lt;p>Other times, X pushed back. Maybe I hadn&amp;rsquo;t understood the change or maybe I was just simply wrong. These cases needed further discussion and often resulted in side 1:1 conversations or even the request to write a mini design doc to flush out unclear ideas.&lt;/p>
&lt;p>The time to ship came. For context, Bazel used to be released once every two weeks within Google. New features were gated behind feature flags, which minimized risk in the release process. And if something went wrong, the two-week release cadence allowed addressing bugs quickly.&lt;/p>
&lt;p>Feature A was ready before feature B&amp;hellip; or was it? The overhead of the reviews in A had been minimal so the code shipped quickly. However&amp;hellip; feature A did not work. X needed multiple release cycles to address bugs, all under pressure because the feature &amp;ldquo;had already launched&amp;rdquo;.&lt;/p>
&lt;p>Feature B, on the other hand&amp;hellip; took longer to ship. But once it did, it worked &lt;em>on the first try&lt;/em>. Sure, it wasn&amp;rsquo;t perfect and needed some iteration to address small issues, but the bulk of the code just worked. This made X proud and understood why I had been thorough.&lt;/p>
&lt;p>To this day, X still remembers shipping these two features. He has told the story above multiple times and praised the process we followed for feature B. For me, it was mostly &amp;ldquo;business as usual&amp;rdquo; and didn&amp;rsquo;t really notice the (positive) impact it had on him.&lt;/p>
&lt;p>X also claims to have learned a lot just by reading my comments, thinking about them, and having to do the tricky work to write small, well-tested changes. And you know what? He has recently earned the title of CTO at an exciting startup.&lt;/p>
&lt;p>Anyhow. I realize this whole story shows flaws in various places. Z should probably have paid more attention to X and Y. Maybe X should have written more-detailed design docs upfront. Maybe we should all have pair-programmed. No team is perfect.&lt;/p>
&lt;p>But code reviews do work. Yes, they can be problematic, but I don&amp;rsquo;t think that code reviews are intrinsically antagonistic: it&amp;rsquo;s the people involved. Code reviews are just &lt;em>a tool&lt;/em> to achieve the goals of quality and mentoring, and as a tool, it has to be used wisely.&lt;/p>
&lt;p>And one last thing: code reviews are truly async-friendly. This may be why they are popular in open source, and in this particular case, they truly helped X and I due to the physical distance between us. Q.E.D.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-11-21-code-review.png" length="134980" type="image/jpeg"/></item><item><title>SSH agent forwarding and tmux done right</title><link>https://jmmv.dev/2023/11/ssh-agent-forwarding-and-tmux-done.html</link><pubDate>Fri, 17 Nov 2023 08:50:00 -0800</pubDate><guid>https://jmmv.dev/2023/11/ssh-agent-forwarding-and-tmux-done.html</guid><description>&lt;p>The &lt;a href="https://man.openbsd.org/ssh-agent">SSH agent&lt;/a> is a little daemon that holds your private keys in memory. This is particularly handy when your keys are protected by a passphrase: you can unlock and add your keys to the agent once and, from then on, any SSH client such as &lt;code>ssh(1)&lt;/code> can interact with the keys without asking you for the passphrase again.&lt;/p>
&lt;p>The SSH agent becomes even handier when you primarily work on a remote workstation over SSH. Under these circumstances, you will often need the remote workstation to establish SSH connections to &lt;em>other&lt;/em> remote machines (e.g. to contact GitHub). In those situations, you can: copy your private keys to the remote workstation; generate different private keys on the remote workstation; or forward your SSH agent so that the remote workstation can leverage the keys from your client machine without them ever traveling over the network.&lt;/p>
&lt;p>Anyway. This article isn&amp;rsquo;t a tutorial on what the SSH agent &lt;em>is&lt;/em> or how to &lt;em>use&lt;/em> it; that&amp;rsquo;s already &lt;a href="https://www.ssh.com/academy/ssh/agent">well-documented elsewhere&lt;/a>. What this article does is dig deeper into how the forwarding feature works, how it becomes problematic for long-lived processes such as tmux, and what you can do about it.&lt;/p>
&lt;h1 id="agent-forwarding-101">Agent forwarding 101&lt;/h1>
&lt;p>When you connect to an SSH host, the &lt;code>sshd&lt;/code> server process receives the connection, forks itself, lowers its privileges to the user requesting the connection, creates a pseudo-terminal to host the requested program (typically a shell), and spawns such program &amp;ldquo;inside&amp;rdquo; the pseudo-terminal.&lt;/p>
&lt;p>Take a look at this process table, which shows the &lt;code>sshd&lt;/code> processes running on the server I&amp;rsquo;m typing this on:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ ps -ax -o user,pid,command | grep ssh[d]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root 3617 sshd: /usr/sbin/sshd [listener] 0 of 10-100 startups (sshd)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root 82202 sshd: jmmv [priv] (sshd)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">jmmv 82204 sshd: jmmv@pts/1 (sshd)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>What you can see in the output above is: the listener process with PID 3617 accepting connections on port 22; a &amp;ldquo;privsep&amp;rdquo; controlling process owned by root for my session with PID 82202, &lt;a href="https://security.stackexchange.com/questions/115896/can-someone-explain-how-sshd-does-privilege-separation">responsible for doing authentication&lt;/a>; and the process serving my session on the pseudo-terminal &lt;code>pts/1&lt;/code> and owned by myself with PID 82204.&lt;/p>
&lt;p>The user-owned &lt;code>sshd&lt;/code> instance on PID 82204 is what hosts the shell that you interact with on the client when connecting to an SSH server. This process is in charge of receiving your keystrokes from the network, sending them to the pseudo-terminal, and then ferrying back the pseudo-terminal&amp;rsquo;s &amp;ldquo;output&amp;rdquo; to the terminal window where your client runs. Pseudo-terminals are fascinating by the way; go read &lt;a href="https://man.netbsd.org/openpty.3">&lt;code>openpty(3)&lt;/code>&lt;/a>.&lt;/p>
&lt;p>But when you enable SSH agent forwarding with an &lt;code>ssh -A&lt;/code> invocation, something else happens. The user-owned &lt;code>sshd&lt;/code> server process creates a Unix domain socket on the remote machine and starts &lt;em>serving&lt;/em> on it. Whenever an SSH process on the remote machine connects to this local socket and sends a request to it, the &lt;code>sshd&lt;/code> process proxies the request &lt;em>back&lt;/em> to the client machine and, in turn, the client machine&amp;rsquo;s &lt;code>ssh&lt;/code> process contacts the client machine&amp;rsquo;s &lt;code>ssh-agent&lt;/code> to perform key-related operations.&lt;/p>
&lt;p>This path to the socket on the remote machine is exposed by the &lt;code>SSH_AUTH_SOCK&lt;/code> environment variable, and all SSH commands know how to access it. Here, look:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">client$ ssh -A server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server$ env | grep SSH_AUTH_SOCK
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SSH_AUTH_SOCK=/tmp/ssh-jewlWIz1jC/agent.82204
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server$ ls -l &amp;#34;${SSH_AUTH_SOCK}&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">srwxr-xr-x 1 jmmv wheel 0 Nov 17 05:30 /tmp/ssh-jewlWIz1jC/agent.82204
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Because a picture is worth a thousand words, here is the same idea in a diagram&amp;hellip; and this picture starts hinting at the problem I want to analyze:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-17-ssh-agent-1.png">
&lt;figcaption>Representation of a client machine (left) connecting to an SSH server. The SSH server (large box on the right) contains an sshd process and a tmux instance. The tmux instance shows the value of &lt;tt>SSH_AUTH_SOCK&lt;/tt>.&lt;/figcaption>
&lt;/figure>
&lt;h1 id="problems-with-long-lived-processes">Problems with long-lived processes&lt;/h1>
&lt;p>Pay close attention to what I described above: the path to the local socket created by the remote &lt;code>sshd&lt;/code> instance is specific to the (unprivileged) &lt;code>sshd&lt;/code> process handling the connection. The fact that the socket&amp;rsquo;s name contains the PID gives this away, but if you want to double-check:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">server$ sudo lsof | grep &amp;#34;${SSH_AUTH_SOCK}&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">sshd 82204 jmmv 7u unix 0xfffff80f6a50fb10 0t0 /tmp/ssh-jewlWIz1jC/agent.82204
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I did not say it explicitly, but you can guess what happens: when you disconnect from the remote session, the &lt;code>sshd&lt;/code> instance for the connection terminates and deletes its local socket on the way out. Which is normal because that process was the one in charge of proxying SSH agent connections back to the SSH client, so with the process gone, the socket becomes useless.&lt;/p>
&lt;p>Unfortunately, the fact that this is normal doesn&amp;rsquo;t make it less problematic. The path to the forwarding socket is exposed to processes via the &lt;code>SSH_AUTH_SOCK&lt;/code> environment variable, so every process started within the remote SSH session gets and &lt;em>caches&lt;/em> a copy of this path in its environment. If you have long-lived process such as &lt;code>tmux&lt;/code> that can survive &lt;em>across&lt;/em> sessions, then all of a sudden the value of &lt;code>SSH_AUTH_SOCK&lt;/code> that they cached at startup time ends up pointing to a non-existing file, breaking all future SSH agent interactions. Look:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-17-ssh-agent-2.png">
&lt;figcaption>Representation of a client machine (left) re-connecting to an SSH server after an earlier connection drops. The SSH server (large box on the right) shows how the tmux instance from the first connection "moves" to the second connection, and how the value that tmux displayed in &lt;tt>SSH_AUTH_SOCK&lt;/tt> now points to an invalid file.&lt;/figcaption>
&lt;/figure>
&lt;p>The specific sequence of events represented in the diagram above and that leads to the problem is this:&lt;/p>
&lt;ol>
&lt;li>Connect to an SSH server with SSH agent forwarding.&lt;/li>
&lt;li>Start a tmux session in the SSH server.&lt;/li>
&lt;li>Detach the tmux session.&lt;/li>
&lt;li>Log out of the SSH server.&lt;/li>
&lt;li>Reconnect to the SSH server with SSH agent forwarding.&lt;/li>
&lt;li>Attach to the existing tmux session.&lt;/li>
&lt;li>Run an SSH command.&lt;/li>
&lt;li>See the command fail to communicate with the forwarded agent.&lt;/li>
&lt;/ol>
&lt;p>So, what can we do about it?&lt;/p>
&lt;h1 id="usual-broken-solutions">Usual broken solutions&lt;/h1>
&lt;p>&lt;a href="https://blog.testdouble.com/posts/2016-11-18-reconciling-tmux-and-ssh-agent-forwarding/">Most&lt;/a> &lt;a href="https://werat.dev/blog/happy-ssh-agent-forwarding/">&amp;ldquo;solutions&amp;rdquo;&lt;/a> &lt;a href="https://without-brains.net/2020/08/05/tmux-and-ssh-agent-forwarding/">I&lt;/a> &lt;a href="https://stackoverflow.com/questions/21378569/how-to-auto-update-ssh-agent-environment-variables-when-attaching-to-existing-tm">find&lt;/a> &lt;a href="https://www.jwon.me/ssh-agent-forwarding-with-tmux/">online&lt;/a> to this problem are hyper-focused on propagating new values of &lt;code>SSH_AUTH_SOCK&lt;/code> to impacted processes. These articles present how to re-inject a fresh value of this variable into tmux. Some of them go to a greater extent by showing you how to propagate the variable&amp;rsquo;s value to the &lt;em>shells&lt;/em> already running inside tmux sessions, because obviously the shells outlast SSH sessions too and they &lt;em>also&lt;/em> have their own copy of &lt;code>SSH_AUTH_SOCK&lt;/code>.&lt;/p>
&lt;p>This mostly works but it has two problems:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>It&amp;rsquo;s a pile of hacks and a whack-a-mole battle you will not win. You can patch tmux. You can patch the shell. But what else do you run inside tmux that outlives SSH sessions? Emacs? Vim? A &amp;ldquo;transitive&amp;rdquo; outbound SSH connection? These all have their own copies of &lt;code>SSH_AUTH_SOCK&lt;/code>. You just can&amp;rsquo;t monkey-patch all possible long-lived processes that cached an ephemeral path in their environment when they started.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It&amp;rsquo;s insufficient. Some of the solutions linked to above leverage a symlink to keep the socket&amp;rsquo;s name stable. Those solutions refresh the symlink every time you log into the remote machine and then point &lt;code>SSH_AUTH_SOCK&lt;/code> to the symlink. This is good because it solves the problem of having to monkey-patch all possible long-lived processes. Unfortunately, this breaks as soon as the &lt;em>latest&lt;/em> connection to the server disconnects: once that happens, the symlink will be dangling until you establish a new session to update it.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Can we do better?&lt;/p>
&lt;h1 id="better-working-solutions">Better working solutions&lt;/h1>
&lt;p>&lt;em>Of course&lt;/em> we can do better, and in various different ways actually. I&amp;rsquo;m surprised I haven&amp;rsquo;t found any of them online with ease&amp;hellip;&lt;/p>
&lt;p>Here are some ideas:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>We can refine the symlinks approach described earlier by adding a &lt;em>logout&lt;/em> script to accompany the login script. The goal of this pair would be to keep track of all possible valid sockets and, when a session disconnects, refresh the symlink to point to a still-valid one. This can work in the common case but breaks if SSH sessions die suddenly, which is pretty normal: think putting your laptop to sleep with an open SSH session and resuming it after commuting. So&amp;hellip; this is better, but not awesome.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We can use &lt;code>LD_PRELOAD&lt;/code> to hijack calls that open a socket, check if they seem to refer to an SSH agent socket, and then redirect those to any &lt;em>other&lt;/em> alive SSH agent socket we can find on the machine. This possibly works well, but leveraging &lt;code>LD_PRELOAD&lt;/code> is a pretty heavy thing to do because it impacts &lt;em>all&lt;/em> processes. Furthermore, this variable is pretty sensitive so it is probably cleared by many programs at startup time&amp;hellip; which means it can be ineffective.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We can supplant the SSH agent with our own daemon that serves a local socket on a well-known path. This daemon then redirects all SSH agent requests to a working SSH agent socket. The &amp;ldquo;working&amp;rdquo; socket is determined by searching &lt;code>/tmp/&lt;/code> for &lt;em>any&lt;/em> agent socket that the calling user has permissions to open, and using the first one that works. We can start this daemon when the user firsts connects to the remote server, and we can fix up the &lt;code>SSH_AUTH_SOCK&lt;/code> value at login time&amp;mdash;well before any process can cache the wrong value.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>This last solution is what I prototyped in &lt;strong>&lt;a href="https://github.com/jmmv/ssh-agent-switcher/">ssh-agent-switcher&lt;/a>&lt;/strong>. It took me about an hour of evening coding to get this to work, an extra hour to write integration tests and refine the implementation, and a final half hour to set up the GitHub project. It works for me, but don&amp;rsquo;t expect it to be perfect.&lt;/p>
&lt;p>As a side note, I wrote this program in Go&amp;hellip; not because I wanted to, but because it is a necessity due to the context in which I&amp;rsquo;ll probably use this. And you know what, writing Go for this was really fun due to easy APIs, quick iteration, and simple tooling&amp;hellip; But I could only tolerate Go because I had no need to model any kind of structured data: I still find Go to be a bad choice for anything larger in scope where correctness matters.&lt;/p>
&lt;p>Now the question is: is this safe? And the answer is: I think so? The ssh-agent-switcher daemon runs in the context of your user account so it can only access sockets you already have access to. The only risk comes from the creation of the daemon&amp;rsquo;s own Unix socket: if the socket is accessible to anyone else on the remote machine, then that person would be able to access your forwarded agent and leverage the credentials that live on your client machine. I&amp;rsquo;ve taken care to create the socket with tight permissions, but the question remains: is the default location under &lt;code>/tmp/&lt;/code> good-enough? Creating temporary files with predictable names &lt;a href="https://www.netmeister.org/blog/mktemp.html">is generally unsound&lt;/a> because that leaves them subject to hijacking via symlinks&amp;hellip; but in this case, the daemon is creating a Unix domain socket, not a regular file, and I&amp;rsquo;ve not succeeded at stealing it.&lt;/p>
&lt;p>Oh, and by the way, this all explains the warning in the &lt;a href="https://man.openbsd.org/ssh">&lt;code>sshd(1)&lt;/code> manual page&lt;/a> about the use of agent forwarding:&lt;/p>
&lt;blockquote>
&lt;p>Agent forwarding should be enabled with caution. Users with the ability to bypass file permissions on the remote host (for the agent&amp;rsquo;s UNIX-domain socket) can access the local agent through the forwarded connection. An attacker cannot obtain key material from the agent, however they can perform operations on the keys that enable them to authenticate using the identities loaded into the agent. A safer alternative may be to use a jump host (see -J).&lt;/p>
&lt;/blockquote>
&lt;p>If you do not trust the administrator of a remote machine, SSHing into it and forwarding your agent will allow the remote administrator to send requests to your local agent. Be careful out there.&lt;/p></description></item><item><title>Why do I know shell, and how can you?</title><link>https://jmmv.dev/2023/11/why-do-i-know-shell-and-how-can-you.html</link><pubDate>Fri, 10 Nov 2023 08:00:00 -0800</pubDate><guid>https://jmmv.dev/2023/11/why-do-i-know-shell-and-how-can-you.html</guid><description>&lt;p>&lt;em>&amp;ldquo;Why do you know so much shell?&amp;rdquo;&lt;/em> is a question I&amp;rsquo;m getting a lot at work lately. So yeah, why? And how can you learn it too? There is no secret here: I know the shell well because I was &amp;ldquo;forced&amp;rdquo; to write tools in it for a while and, because of that, I made a conscious effort to learn the language and get better at it.&lt;/p>
&lt;p>You see, most people that write shell don&amp;rsquo;t want to deal with it. They stitch together whatever works into a script and call it a day, making a bunch of spaghetti even if it goes against the coding best practices they already know. And when they encounter some odd syntax they don&amp;rsquo;t recognize, their reaction is to say &amp;ldquo;this has to be rewritten in Python!&amp;rdquo; instead of taking a breath and trying to really understand what&amp;rsquo;s going on. It doesn&amp;rsquo;t help that plenty of senior engineers scoff at shell scripts.&lt;/p>
&lt;p>And it is true: the shell is arcane and has many flaws as a programming language. I don&amp;rsquo;t want to convince you to start writing new tools in it. But the shell is also an incredible rapid prototyping language, and you can use it to solve business problems really quickly and with surprisingly little code. If you pause for a second to learn it, you&amp;rsquo;ll realize that you can bend tradition and write maintainable shell code too. Hear out how I got into writing so much shell and how you can get better at it too.&lt;/p>
&lt;h1 id="the-constraints-of-the-bsd-systems">The constraints of the BSD systems&lt;/h1>
&lt;p>In the late 1990s, I discovered Linux and, soon after, the BSDs. I had a brief stint with OpenBSD and FreeBSD at first, but by the early 2000s, I had settled on &lt;a href="https://www.NetBSD.org/">NetBSD&lt;/a> as my daily driver. My dream had always been to create my own operating system, but the more I learned and tried to write one, the more I realized I wasn&amp;rsquo;t up to the task yet. Thus NetBSD was the perfect fit for me: all my hardware worked on it, but the system had enough rough edges that I saw the opportunity to become a contributor to a real operating system.&lt;/p>
&lt;p>NetBSD&amp;mdash;and all the BSDs really&amp;mdash;are full operating system distributions. Unlike Linux, the source code for their kernel, user space tools, and documentation lives in a single source tree (monorepo!) maintained by a single group of developers. This source tree is known as &lt;em>the base system&lt;/em> and every other third-party app comes via the ports system&amp;mdash;or &lt;a href="https://www.pkgsrc.org/">pkgsrc&lt;/a> in NetBSD-specific parlance. If this is hard to imagine, visualize your typical Windows installation: when you perform a fresh install of Windows 7 (not 10 or 11 because these get random junk auto-added), what you get is a collection of software that Microsoft has itself developed and chosen to be the basis to form Windows; everything you add to it later on, be it from Microsoft or other vendors, is not part of that base installation.&lt;/p>
&lt;p>A constraint of this arrangement is that the code in a BSD base system is self-hosting: i.e. the base system must be able to build itself so it must &lt;a href="/2015/10/compilers-in-the-bsd-base-system.html">include the compilers&lt;/a> and interpreters required to build and run its code. In NetBSD during the early 2000s, this meant choosing between C, C++, and shell. Lua has been added as a fourth choice since.&lt;/p>
&lt;p>It is of course possible to write tools for a BSD system in any language that&amp;rsquo;s not in the base system, but doing so means that the tool is relegated to live in the ports system. To make matters worse, the common practice in the BSDs was to build everything from source&amp;mdash;pre-built binary packages existed but were inflexible and usually stale&amp;mdash;and thus users frowned upon heavy dependencies. If your tiny tool required Perl or Python, for example, it would be dead on arrival because of the heavy tax imposed by the interpreter: if I recall correctly, building Perl on my Pentium II took something like 15 minutes, and building it on a 68k Mac I had took hours.&lt;/p>
&lt;h1 id="contributing-tools-to-netbsd">Contributing tools to NetBSD&lt;/h1>
&lt;p>See where this is going? I was the primary maintainer of Gnome 2.x on NetBSD and, as part of this work, I ended writing all sorts of tools to simplify the maintenance of the packages and the system as a whole. I wrote things like &lt;a href="/software/sysbuild.html">sysbuild&lt;/a>, &lt;a href="/software/pkg_comp.html">pkg_comp&lt;/a>, &lt;a href="http://cvsweb.netbsd.org/bsdweb.cgi/pkgsrc/pkgtools/pkg_alternatives/">pkg_alternatives&lt;/a>, &lt;a href="http://cvsweb.netbsd.org/bsdweb.cgi/pkgsrc/pkgtools/dfdisk/">dfdisk&lt;/a>, &lt;a href="/2022/06/autoconf-caching.html">autoswc&lt;/a>, &lt;a href="/software/etcutils.html">etcutils&lt;/a>&amp;hellip; and even &lt;a href="/2022/05/remembering-buildtool.html">my own build system&lt;/a>.&lt;/p>
&lt;p>And to write such tools&amp;hellip; which language could I use? I wanted my tools to feel part of the base system and I didn&amp;rsquo;t want to have to pay the heavy price of Perl or Python. I could have used C, but&amp;hellip; well, let&amp;rsquo;s just say that C is a terrible choice for automation tools. I could have used C++, but people &lt;em>also&lt;/em> hated it for its long compile times and the fact that, back in the pre-C++11 era, it wasn&amp;rsquo;t much better than C and compilers were really bad at supporting standards. And I could use the shell which, as ugly as it was, made programs immediately installable under any of the tens of hardware platforms that NetBSD supported, no matter how slow they were.&lt;/p>
&lt;p>So that&amp;rsquo;s how I ended up writing shell. The shell was the only realistic option I had to write the tools I wanted to write. And you know what? My scripts were bad at first, full of the problems I opened this article with. But with practice, a principled approach to writing shell &lt;del>scripts&lt;/del> programs, and an open mind to see the shell as &amp;ldquo;yet another programming language&amp;rdquo;, it turned out to be not a terrible idea in retrospect.&lt;/p>
&lt;p>My biggest shell program today is probably &lt;a href="/2017/02/introducing-pkg_comp-2.0.html">pkg_comp2&lt;/a>. If I count the lines of its source code plus its two dependencies (&lt;a href="/software/sandboxctl.html">sandboxctl&lt;/a> and &lt;a href="https://shtk.jmmv.dev/">shtk&lt;/a>), it comes to about 15,000 SLOC. More than half of those are unit and integration tests, just as commonly happens in &amp;ldquo;real software&amp;rdquo;, which shows that shell programs can mimic the good development practices of other languages. Just take a moment and skim through &lt;a href="https://github.com/jmmv/pkg_comp/blob/28dc346ade09bd620f1ec3c6ad43b98f412deaa9/pkg_comp.sh">pkg_comp.sh&lt;/a>. Does this look like your regular spaghetti shell code to you?&lt;/p>
&lt;h1 id="how-you-can-get-better-at-the-shell">How you can get better at the shell&lt;/h1>
&lt;p>I could probably write a whole book on this topic&amp;mdash;and I&amp;rsquo;ve thought about doing so&amp;hellip; would you read it?&amp;mdash;but all I can do right now is give you some ideas:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Read about the language.&lt;/strong> The shell is small. Once I decided I wanted to get better at the shell, I just opened the &lt;a href="https://man.netbsd.org/sh.1">&lt;code>sh(1)&lt;/code> manual page&lt;/a> and read it. It will take you less than 1 hour to go through the whole document. You might choose to &lt;em>also&lt;/em> read the Bash manual page&amp;mdash;and you probably should, particularly to become aware of its many &lt;a href="/2021/08/useless-use-of-gnu.html">unnecessary non-standard features&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Familiarize yourself with the Unix toolchain.&lt;/strong> Yes, the shell language is really simple, but that comes at a price: many of the things you want to do will require invoking tools like &lt;code>grep&lt;/code>, &lt;code>sed&lt;/code>, &lt;code>find&lt;/code>&amp;hellip; Which is fine because that&amp;rsquo;s the core idea behind the Unix toolchain&amp;mdash;small, composable tools&amp;mdash;but that means you need to know those tools too. The more tools you know about, the better your scripts will be. Think of these tools as the &amp;ldquo;standard library&amp;rdquo; for the shell. Manual pages are not in fashion&amp;hellip; but getting comfortable in navigating them will prove to be a useful skill.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Understand how process creation (&lt;code>fork&lt;/code> vs. &lt;code>exec&lt;/code>) and &lt;a href="/2020/11/cmdline-args-unix-vs-windows.html">argument passing&lt;/a> work in Unix.&lt;/strong> The shell is primarily designed to interact with subprocesses, so knowing these topics in detail is &lt;em>crucial&lt;/em> to truly understand how quoting, globs, redirections, and pipelines work, and also to understand the difference between built-in and external commands. For example, do you know &lt;a href="/2020/03/test-bracket.html">how &lt;code>test&lt;/code>, &lt;code>[&lt;/code> and &lt;code>[[&lt;/code> differ&lt;/a>?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Write shell scripts following the good programming practices you already know.&lt;/strong> Avoid global variables. Factor code into functions. Minimize side-effects. &lt;a href="/2023/10/unit-testing-with-shtk.html">Write unit and/or integration tests.&lt;/a> And be unconditionally strict: e.g. double-quote all variable expansions to correctly handle whitespace characters, even if in most cases you may not need to do so.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Think in terms of data flow.&lt;/strong> The shell is about combining tools as pipelines, not writing your usual imperative for loops. The more you can reason about solving problems with pipelines, the simpler and more performant your scripts will be. Functional programming FTW!&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Read Google&amp;rsquo;s &lt;a href="https://google.github.io/styleguide/shellguide.html">Shell Style Guide&lt;/a>.&lt;/strong> While I don&amp;rsquo;t necessarily agree with everything it has to say, especially around stylistic details, the &amp;ldquo;Features and bugs&amp;rdquo; and &amp;ldquo;Calling commands&amp;rdquo; sections are particularly interesting.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Use &lt;a href="https://www.shellcheck.net/">ShellCheck&lt;/a>.&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>And finally, &lt;strong>take a look at my &lt;a href="/2018/02/shell-readability-main.html">short readability series on the shell&lt;/a> from 2013.&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol></description><enclosure url="https://jmmv.dev/images/2023-11-10-sh-manpage.jpg" length="425448" type="image/jpeg"/></item><item><title>End-to-end tool testing with Bazel and shtk</title><link>https://jmmv.dev/2023/11/end-to-end-tool-testing-with-bazel.html</link><pubDate>Sat, 04 Nov 2023 07:50:00 -0700</pubDate><guid>https://jmmv.dev/2023/11/end-to-end-tool-testing-with-bazel.html</guid><description>&lt;p>If you use Bazel, your project is of moderate size. And because your project is of moderate size, it almost-certainly builds one or more binaries, at least one of which is a CLI tool. But let&amp;rsquo;s face it: you don&amp;rsquo;t have end-to-end testing for those tools, do you?&lt;/p>
&lt;p>I&amp;rsquo;m &lt;em>sure&lt;/em> you have split the binary&amp;rsquo;s &lt;code>main&lt;/code> function into its own file so that the rest of the tool can be put in a library, and I&amp;rsquo;m &lt;em>extra-sure&lt;/em> that you have unit tests for such library. But&amp;hellip; those tests do little to verify the functionality and quality of the tool &lt;em>as experienced by the end user&lt;/em>. Consider: What exactly does the tool print to the console on success? Does it show errors nicely when they happen, or does it dump internal stack traces? How does it handle unknown flags or bad arguments? Is the built-in help message nicely rendered when your terminal is really wide? What if the terminal is narrow?&lt;/p>
&lt;p>You must write end-to-end tests for your tools but, usually, that isn’t easy to do. Until today. Combining shtk with Bazel via the new &lt;code>rules_shtk&lt;/code> ruleset makes it trivial to write tests that verify the behavior of your CLI tools&amp;mdash;no matter what language they are written in&amp;mdash;and in this article I’m going to show you how.&lt;/p>
&lt;h1 id="scenario">Scenario&lt;/h1>
&lt;p>To put things in perspective, we&amp;rsquo;ll be adding tests to a trivial demo tool written in C (&lt;em>not&lt;/em> shell) that simply adds two numbers and prints the result to the standard output. You can find all of the code for this scenario under &lt;a href="https://github.com/jmmv/rules_shtk/tree/d490cc9fc43cff3db83d12b5dc1a1c6b90ed50c3/examples/test">&lt;code>rules_shtk/examples/test&lt;/code>&lt;/a>.&lt;/p>
&lt;p>Here is how the demo tool behaves after we build the &lt;code>//:adder&lt;/code> target:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-console" data-lang="console">&lt;span class="line">&lt;span class="cl">&lt;span class="gp">$&lt;/span> ./bazel-bin/adder &lt;span class="m">123&lt;/span> &lt;span class="m">456&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">The sum of 123 and 456 is 579
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="gp">$&lt;/span> ./bazel-bin/adder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder: Requires two integer arguments
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="gp">$&lt;/span> ./bazel-bin/adder &lt;span class="m">10000000&lt;/span> &lt;span class="m">345&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder: Invalid first operand: out of range
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Our mission is to add an &lt;code>//:adder_test&lt;/code> target that depends on &lt;code>//:adder&lt;/code> and that exercises the tool &lt;em>exactly as when a user runs it by hand&lt;/em>. We&amp;rsquo;ll create an &lt;code>adder_test.sh&lt;/code> file that uses the &lt;a href="/2023/10/unit-testing-with-shtk.html">shtk testing library&lt;/a> and hook it into the build as an &lt;code>shtk_test&lt;/code> target.&lt;/p>
&lt;h1 id="depending-on-rules_shtk">Depending on rules_shtk&lt;/h1>
&lt;p>&lt;code>rules_shtk&lt;/code> is a shiny new ruleset (released just yesterday) and because Bazel 7 is around the corner, I&amp;rsquo;ve opted to go all in for &lt;a href="https://bazel.build/external/overview#bzlmod">bzlmod&lt;/a>. Thanks to bzlmod, setting up a project to use these rules is trivial. All you need is to add the following line to your &lt;code>MODULE.bazel&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Add this to MODULE.bazel.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">bazel_dep&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;rules_shtk&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;1.7&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;hellip; but you&amp;rsquo;ll need to wait until &lt;a href="https://github.com/bazelbuild/bazel-central-registry/pull/1095">bazelbuild/bazel-central-registry#1095&lt;/a> is reviewed and merged. (I don&amp;rsquo;t understand why this choke point exists in the new bzlmod ecosystem; Rust&amp;rsquo;s crates.io doesn&amp;rsquo;t have it, for example.)&lt;/p>
&lt;p>In the meantime, or if you are not yet ready to upgrade to bzlmod, you can obviously use the old-fashioned and yucky &lt;code>WORKSPACE.bazel&lt;/code> file to pull &lt;code>rules_shtk&lt;/code> in:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Add this to WORKSPACE or WORKSPACE.bazel if you don&amp;#39;t use bzlmod yet.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;@bazel_tools//tools/build_defs/repo:http.bzl&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;http_archive&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">http_archive&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;bazel_skylib&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sha256&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;66ffd9315665bfaafc96b52278f57c7e2dd09f5ede279ea6d39b2be471e7e3aa&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;https://mirror.bazel.build/github.com/bazelbuild/bazel-skylib/releases/download/1.4.2/bazel-skylib-1.4.2.tar.gz&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;https://github.com/bazelbuild/bazel-skylib/releases/download/1.4.2/bazel-skylib-1.4.2.tar.gz&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;@bazel_skylib//:workspace.bzl&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;bazel_skylib_workspace&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">bazel_skylib_workspace&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">http_archive&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;rules_shtk&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sha256&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;fa47891f27d8d59609732b34dc88020331b81b9767cbd72094fec1be8af4adfc&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;https://github.com/jmmv/rules_shtk/releases/download/rules_shtk-1.7.0/rules_shtk-1.7.0.tar.gz&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">strip_prefix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;rules_shtk-1.7.0&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="requesting-an-shtk-toolchain">Requesting an shtk toolchain&lt;/h1>
&lt;p>Once you have added &lt;code>rules_shtk&lt;/code> to your project, either via bzlmod or the &lt;code>WORKSPACE.bazel&lt;/code>, you need to tell Bazel which shtk toolchain to use:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Add this to WORKSPACE or WORKSPACE.bazel.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;@rules_shtk//:repositories.bzl&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;shtk_dist&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">shtk_dist&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The parameterless &lt;code>shtk_dist&lt;/code> macro makes Bazel download &lt;a href="https://github.com/jmmv/shtk/releases/tag/shtk-1.7">shtk 1.7&lt;/a> (because we requested the 1.7.x rules) and puts it to use for all tests that we later build. You cannot configure which version of shtk to download because, so far, all shtk versions are backwards-compatible and this won&amp;rsquo;t change in the 1.x series.&lt;/p>
&lt;p>There is also an &lt;code>shtk_sytem&lt;/code> macro that makes Bazel discover the shtk toolchain installed in the system, say via your local package manager. This does not make sense for our use case (because we are only running tests within Bazel), but it can be useful if you want to build a script with &lt;code>shtk_binary&lt;/code> that can later be taken out of &lt;code>bazel-bin&lt;/code> and installed into the host system.&lt;/p>
&lt;h1 id="writing-the-test-rule">Writing the test rule&lt;/h1>
&lt;p>We now have the rules and a toolchain in place so we can proceed to add an &lt;code>shtk_test&lt;/code> target. Our goal is to test &lt;code>adder.c&lt;/code> with a new &lt;code>adder_test.sh&lt;/code> sibling file, so we can put the test target next to the binary target:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;@rules_shtk//:rules.bzl&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;shtk_test&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cc_binary&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;adder&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;adder.c&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">shtk_test&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;adder_test&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">src&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;adder_test.sh&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;:adder&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are different opinions on where tests should live but, personally, I want them as close to the code they test as possible. This makes tests discoverable when editing code, which increases the odds that developers will remember to update them. Also, nobody likes dealing with parallel deep directory hierarchies when working on a piece of code&amp;hellip; thank you, &lt;code>java&lt;/code> and &lt;code>javatests&lt;/code>.&lt;/p>
&lt;h1 id="writing-the-test-program">Writing the test program&lt;/h1>
&lt;p>All that&amp;rsquo;s left to do is an &lt;a href="https://en.wikipedia.org/wiki/Small_matter_of_programming">SMOP&lt;/a>. We need to write the tests in &lt;code>adder_test.sh&lt;/code>. Here are just a couple of examples:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># This is a portion of adder_test.sh.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_import unittest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_test addition_works
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">addition_works_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> expect_command &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -o inline:&lt;span class="s2">&amp;#34;The sum of 2 and 3 is 5\n&amp;#34;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> ../adder &lt;span class="m">2&lt;/span> &lt;span class="m">3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_test bad_arguments
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bad_arguments_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> expect_command &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -s &lt;span class="m">1&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -e inline:&lt;span class="s2">&amp;#34;adder: Requires two integer arguments\n&amp;#34;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> ../adder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I don&amp;rsquo;t want to dive into the shtk APIs too much, but I want to highlight the &lt;code>expect_command&lt;/code> calls in here. This assertion is the salient feature of shtk&amp;rsquo;s unit-testing module and is what makes testing tools a breeze. Take a look at the &lt;a href="https://shtk.jmmv.dev/shtk_unittest_assert_command.3.html">&lt;code>assert_command&lt;/code>&lt;/a> and &lt;a href="https://shtk.jmmv.dev/shtk_unittest_assert_file.3.html">&lt;code>assert_file&lt;/code>&lt;/a> documentation to demystify the &lt;code>-s&lt;/code>, &lt;code>-o&lt;/code>, and &lt;code>-e&lt;/code> flags shown above.&lt;/p>
&lt;p>One thing that needs explaining is the &lt;code>../adder&lt;/code> reference to the tool. If we look at the runfiles tree that Bazel creates when building the &lt;code>//:adder_test&lt;/code> target, we see:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-console" data-lang="console">&lt;span class="line">&lt;span class="cl">&lt;span class="gp">$&lt;/span> ls -l bazel-bin/adder_test.runfiles/_main/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">total 8K
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">lrwxrwxrwx. 1 jmmv jmmv 116 Nov 4 06:17 adder -&amp;gt; /home/jmmv/.cache/bazel/_bazel_jmmv/916b9cbf147e00ff01b88519fdb0f294/execroot/_main/bazel-out/k8-fastbuild/bin/adder
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">lrwxrwxrwx. 1 jmmv jmmv 121 Nov 4 06:17 adder_test -&amp;gt; /home/jmmv/.cache/bazel/_bazel_jmmv/916b9cbf147e00ff01b88519fdb0f294/execroot/_main/bazel-out/k8-fastbuild/bin/adder_test
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are no directories in there. So, where does that &lt;code>..&lt;/code> come from in the &lt;code>../adder&lt;/code> reference? Well&amp;hellip; shtk&amp;rsquo;s unit-testing execution engine creates a disposable subdirectory for each test it runs. The reason for this is that, when writing shell tests, it is extremely common to have to create auxiliary files, and shtk accounts for that by cleaning up whichever files you create in the current directory of a test. This is a little oddity you&amp;rsquo;ll have to keep in mind.&lt;/p>
&lt;h1 id="running-the-test">Running the test&lt;/h1>
&lt;p>All done. We can finally run the end-to-end test for our demo tool:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-console" data-lang="console">&lt;span class="line">&lt;span class="cl">&lt;span class="gp">$&lt;/span> bazel &lt;span class="nb">test&lt;/span> --nocache_test_results --test_output&lt;span class="o">=&lt;/span>streamed //:adder_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">WARNING: Streamed test output requested. All tests will be run locally, without sharding, one at a time
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: Analyzed target //:adder_test (0 packages loaded, 139 targets configured).
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: Found 1 test target...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing addition_works...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 2 3
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder -12345 12345
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing addition_works... PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_first_operand...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 123456789 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 123x 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder -123456789 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_first_operand... PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_second_operand...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0 123456789
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0 123x
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0 -123456789
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_second_operand... PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_arguments...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 1
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 1 2 3
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_arguments... PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Ran 4 tests; ALL PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Target //:adder_test up-to-date:
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go"> bazel-bin/adder_test
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: Elapsed time: 0.504s, Critical Path: 0.33s
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: 2 processes: 2 linux-sandbox.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: Build completed successfully, 2 total actions
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">//:adder_test PASSED in 0.2s
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="go">Executed 1 out of 1 test: 1 test passes.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;p>As much hate as &amp;ldquo;large&amp;rdquo; shell scripts get, the shell is a uniquely-positioned language to help you write end-to-end tests for your tools. After all, the shell is what you use to &lt;em>run&lt;/em> those precious tools, so the shell is also what you should use to run them in an automated fashion for testing purposes.&lt;/p>
&lt;p>It&amp;rsquo;s your turn now. Go read the &lt;a href="https://shtk.jmmv.dev">online documentation&lt;/a> for shtk, the previous introductory blog post, and get testing! Your users will be much happier if your tools offer excellent interfaces. And if you need ideas on what to test or how to improve the interface of your tools, take a look at the &lt;a href="/series.html#CLI design">CLI design series&lt;/a> from 2013.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-11-04-bazel-clamp.jpg" length="572746" type="image/jpeg"/></item><item><title>Links: October 2023 edition</title><link>https://jmmv.dev/2023/10/links-october-2023-edition.html</link><pubDate>Tue, 31 Oct 2023 12:30:00 -0700</pubDate><guid>https://jmmv.dev/2023/10/links-october-2023-edition.html</guid><description>&lt;p>Inspired by the works of &lt;a href="https://eatonphil.com/">Phil Eaton&lt;/a>, I&amp;rsquo;ve been highlighting articles and projects that I find interesting in &lt;del>Twitter&lt;/del> X and Mastodon. Some of these posts were more &amp;ldquo;successful&amp;rdquo; than I had expected, which I take to mean that doing this is interesting to you all. So, it&amp;rsquo;s probably a good idea to periodically collect them all in a post with a very brief commentary on each.&lt;/p>
&lt;p>Here is a recap of the interesting articles that came my way in October 2023. This does &lt;em>not&lt;/em> mean that these articles were published during this period: some of them are older but I just (re)discovered them now. I&amp;rsquo;ll avoid referencing my own articles: you can find those by &lt;a href="/archive.html">in the archive&lt;/a>.&lt;/p>
&lt;h1 id="articles">Articles&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://queue.acm.org/detail.cfm?id=3212479">&amp;ldquo;C is not a low-level language&amp;rdquo;&lt;/a> by David Chisnall on April 30th, 2018.&lt;/strong>&lt;/p>
&lt;p>This is one of those articles that requires an open mind to read and understand the main criticism that the author raises about the use of C these days.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.microsoft.com/en-us/research/uploads/prod/2019/04/fork-hotos19.pdf">&amp;ldquo;A fork() in the road&amp;rdquo;&lt;/a> by Microsoft on May 13th, 2019.&lt;/strong>&lt;/p>
&lt;p>Like the previous article, this one is a critique of one of the foundations of Unix and requires being open to criticism to see what it is about. I had read this when it came out years ago, but the article just above reminded me of it because they both fall in the same category of &amp;ldquo;articles that were written ahead of their times&amp;rdquo;.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://jvns.ca/blog/2016/06/13/should-you-be-scared-of-signals/">&amp;ldquo;Should you be scared of Unix signals?&amp;rdquo;&lt;/a> by Julia Evans on June 13th, 2016.&lt;/strong>&lt;/p>
&lt;p>A good and fun article to understand Unix signals. I didn&amp;rsquo;t know that &lt;em>Ctrl+Alt+Del&lt;/em> translated into &lt;code>SIGINT&lt;/code> to &lt;code>init(1)&lt;/code> on Linux, for example. What I was missing from this article was a mini-rant on the lack of &lt;code>SIGINFO&lt;/code> handling in Linux: if you have used other Unix systems, you know that pressing &lt;em>Ctrl+T&lt;/em> causes the running program to print progress status to the console, which is super handy when running things like &lt;code>dd(1)&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://jordankaye.dev/posts/thinking-not-typing/">&amp;ldquo;Software engineering is about thinking, not typing&amp;rdquo;&lt;/a> by Jordan Kaye on October 11th, 2023.&lt;/strong>&lt;/p>
&lt;p>Agree with the premise of the post that coding without thinking can be wasteful. Countless times, I&amp;rsquo;ve been coding deep down for an hour, only to go get coffee and realize I was on the wrong path all along. However, I&amp;rsquo;d also add that software engineering &lt;em>is&lt;/em> actually about typing: just&amp;hellip; a different kind of typing. Change proposals, design documents, opinion memos&amp;hellip; all of these have to be typed, and going through the writing process helps tremendously in organizing ideas and plans.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://ntietz.com/blog/write-more-useless-software/">&amp;ldquo;Write more &amp;ldquo;useless&amp;rdquo; software&amp;rdquo;&lt;/a> by ntietz on June 26, 2023.&lt;/strong>&lt;/p>
&lt;p>Yes, more of this! It&amp;rsquo;s fun/rewarding/exciting to write a piece of code just for the sake of it, and it&amp;rsquo;s exhausting to have to come up with &amp;ldquo;value add&amp;rdquo; rationales (&lt;em>ehem&lt;/em> monetization strategies) for every little thing we do these days. This is &lt;a href="/2021/01/why-endbasic.html">why I work on EndBASIC&lt;/a>, for example.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://fasterthanli.me/articles/just-paying-figma-15-dollars">&amp;ldquo;Just paying Figma $15/month because nothing else fucking works&amp;rdquo;&lt;/a> by fasterthanlime on October 19th, 2023.&lt;/strong>&lt;/p>
&lt;p>A fun read. This one is about how we avoid paying for cheap things for weird reasons and settle for alternatives that suck. In his case, he claims &amp;ldquo;protestant ethics&amp;rdquo; but I have the same problem and I grew up without those. And this is why I&amp;rsquo;m working on EndTRACKER instead of paying for Substack. Well, actually, I&amp;rsquo;ve just started driving Substack, so the real reason is because I want to own my content in a future-proof manner.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://jsoverson.medium.com/was-rust-worth-it-f43d171fb1b3">&amp;ldquo;Was Rust Worth It?&amp;rdquo;&lt;/a> by Jarrod Overson on October 26th, 2023.&lt;/strong>&lt;/p>
&lt;p>A very balanced review of Rust through which I found myself nodding all along the good, bad, and ugly parts. I&amp;rsquo;ve covered some of the criticisms in the past in more detail too, including in &lt;a href="/2022/05/rust-is-hard-but-does-it-matter.html">&amp;ldquo;Rust is hard, yes, but does it matter?&amp;rdquo;&lt;/a> (May 2022) and in &lt;a href="/2023/08/rust-static-dispatch-failed-experiment.html">&amp;ldquo;A failed experiment with Rust static dispatch&amp;rdquo;&lt;/a> (August 2023).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://flameeyes.blog/2020/04/30/bakery-someone-else-oven/">&amp;ldquo;The bakery is just someone else’s oven&amp;rdquo;&lt;/a> by Diego Elio Pettenò on April 30th, 2023.&lt;/strong>&lt;/p>
&lt;p>Interesting complement to the &amp;ldquo;paying Figma&amp;rdquo; article from above, which I reached through a controversial post on how X is saving money by dumping the cloud. Yes, cloud bills are huge and in &amp;ldquo;the happy case&amp;rdquo; you can probably build and host a service yourself. But when you have to start planning for corner cases and deal with operational costs, things aren&amp;rsquo;t as cheap. Plus it is critical to consider the opportunity cost of running your own services against doing something else.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://jacobbartlett.substack.com/p/through-the-ages-apple-cpu-architecture">&amp;ldquo;Through the Ages: Apple CPU Architecture&amp;rdquo;&lt;/a> by Jacob Barlett on October 30th, 2023.&lt;/strong>&lt;/p>
&lt;p>A light walk through the four different CPU architectures that Apple has used throughout its history, how they differ between each other, and how Apple has been able to successfully pull off such difficult migrations without vanishing into oblivion. But what&amp;rsquo;s &lt;em>more&lt;/em> interesting here is &lt;a href="https://lobste.rs/s/jd4ivm/through_ages_apple_cpu_architecture#c_nwtcnj">this comment from David Chisnall&lt;/a> in the Lobste.rs discussion correcting many of the simplifications and inaccuracies in the article.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="other">Other&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://github.com/skiselev/8088_bios">&amp;ldquo;8088 BIOS&amp;rdquo;&lt;/a> GitHub Project.&lt;/strong>&lt;/p>
&lt;p>I had fun peeking through the NASM source code and remembering &amp;ldquo;the good old times&amp;rdquo; of me writing boot sectors with FAT12 parsers in them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.retroshowcase.gr/cpcbox-master/index.html">&amp;ldquo;CPCBox&amp;rdquo;&lt;/a> project page.&lt;/strong>&lt;/p>
&lt;p>I keep coming to this site as part of my work on EndBASIC, and as part of wanting to play my favorite old game from when I was a kid: Builder Dash. The keyboard controls suck but choosing to use a joystick allows using the cursor keys for movement. Audio doesn&amp;rsquo;t work though, as it seems to be using some deprecated web technology.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://youtu.be/Fh_UDQnboRw">&amp;ldquo;Bill Gates demonstrates Visual Basic [video]&amp;rdquo;&lt;/a> by Bill Gates in 1991.&lt;/strong>&lt;/p>
&lt;p>What have we lost. There has not been anything similar to Visual Basic for more than 20 years now (except Delphi I hear). I remember moving to Linux and trying to find something like this, only to be told to use Glade which&amp;hellip; well&amp;hellip; a UI designer that spits out code is not the same as an integrated IDE. And nowadays, with web technologies, there is nothing that approaches this level of usability, yet?&lt;/p>
&lt;/li>
&lt;/ul></description><enclosure url="https://jmmv.dev/images/2023-10-31-links.png" length="56457" type="image/jpeg"/></item><item><title>BazelCon 2023 et al. trip report</title><link>https://jmmv.dev/2023/10/bazelcon-2023-et-al-trip-report.html</link><pubDate>Mon, 30 Oct 2023 03:00:00 -0700</pubDate><guid>https://jmmv.dev/2023/10/bazelcon-2023-et-al-trip-report.html</guid><description>&lt;p>I&amp;rsquo;m exhausted. I just came back to Seattle from a 10-day trip in which I attended three different Bazel events: the Build Meetup in Reykjavik, the Bazel Community Day in Munich, and BazelCon 2023 in Munich too. Oh, and because I was on the other side of the world, I also paid a visit to my family in Spain.&lt;/p>
&lt;p>Attending these events has been incredibly useful and productive: I got exposure to many ideas and discussions that would just not happen online, I got to build connections with very interesting people and, of course, it has also been super fun too to reconnect with old coworkers and friends.&lt;/p>
&lt;p>This article contains the summary of the things I learned and the things I want to follow up on. These are just a bunch of cleaned-up notes which I took and are in the context of &lt;em>my&lt;/em> work with &lt;a href="https://bazel.build/">Bazel&lt;/a> at &lt;a href="https://www.snowflake.com/">Snowflake&lt;/a> and &lt;em>my&lt;/em> interests on build tools, so this is not endorsed by Snowflake.&lt;/p>
&lt;h1 id="schedule">Schedule&lt;/h1>
&lt;p>Here is the general timeline of the events:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>2023-10-20 (Fri)&lt;/strong>: Build Meetup in Reykjavik hosted at the Reykjavik University and organized by Unnar from EngFlow.&lt;/li>
&lt;li>&lt;strong>2023-10-21 (Sat)&lt;/strong>: A 1-day tour of the Reykjanes peninsula with the Build Meetup crew which, while not an official conference, also led to many interesting &lt;del>hallway&lt;/del> lagoon conversations.&lt;/li>
&lt;li>&lt;strong>2023-10-23 (Mon)&lt;/strong>: Bazel Community Day hosted by Salesforce in Munich, followed by an evening of food and drinks hosted by Gradle.&lt;/li>
&lt;li>&lt;strong>2023-10-24 (Tue)&lt;/strong>: BazelCon 2023 day 1 hosted by Google Munich, which included an evening of drinks and games hosted by JetBrains.&lt;/li>
&lt;li>&lt;strong>2023-10-25 (Wed)&lt;/strong>: BazelCon 2023 day 2 hosted by Google Munich, which included another by BuildBuddy that I could not attend because I departed early.&lt;/li>
&lt;/ul>
&lt;h1 id="bazel-7">Bazel 7&lt;/h1>
&lt;p>In our Bazel migration at Snowflake, we currently rely on the Bazel 6.x series&amp;mdash;still the stable version at the time of this writing. &lt;a href="https://bazel.build/about/roadmap#bazel_70_release">Bazel 7 is around the corner&lt;/a> and it brings many improvements that will, in theory, improve the developer experience significantly. Here are my highlights:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Build without the Bytes (BwtB):&lt;/strong> We tried using this feature before but it did not work well with dynamic execution, another feature that we must use for performance reasons. Bazel 7 should fix all issues we saw because BwtB is known to not carry bug fixes that are in Bazel 7 due to backporting difficulties. Google is confident that this feature works fine now because they are using it on their corp Mac laptops instead of FUSE, because the latter has become increasingly more cumbersome to use on Macs.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Path mapping and cache key scrubbing:&lt;/strong> New features in Bazel 7 allow Bazel to reuse the cache between different configurations. For example, Java targets only need to be built once irrespective of the target platform (arm64/x86), and Bazel 7 makes this &amp;ldquo;just one build&amp;rdquo; possible. This helps increase shared cache hits, reduces CI costs, reduces Bazel configuration and Git branch switch costs, and reduces local disk usage space. These features need to be enabled via flags and rules have to opt into this behavior if it&amp;rsquo;s useful for them (the Java rules do by default).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Skymeld:&lt;/strong> &lt;a href="https://github.com/bazelbuild/bazel/issues/14057">This feature&lt;/a> interleaves the analysis and execution phases during a build and should be functional in Bazel 7. Using this feature should reduce end-to-end (E2E) build and test times, particularly for builds where the analysis phase takes a long time.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>bzlmod:&lt;/strong> We &lt;em>all&lt;/em> will be required to replace our intractable &lt;code>WORKSPACE&lt;/code> files with bzlmod by Bazel 8, and bzlmod is already the default in Bazel 7. The benefits for the &lt;em>users&lt;/em> of the build system are subtle, but they are palpable for anyone managing external dependencies or third-party package managers like pip or Maven. It&amp;rsquo;s possible to migrate incrementally by moving individual rules into using modules. Difficulties often arise when there are repo aliases in place though.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="ide-improvements">IDE improvements&lt;/h1>
&lt;p>The two news that seemed exciting to me were:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>IntelliJ BSP plugin:&lt;/strong> &lt;a href="https://www.jetbrains.com/">JetBrains&lt;/a> has been working on a new &lt;a href="https://build-server-protocol.github.io/">Build Server Protocol (BSP)&lt;/a> to fix the M:N problem for build tools and IDEs&amp;mdash;just like &lt;a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol (LSP)&lt;/a> did for language integrations. JetBrains has created a new version of the Bazel plugin that relies on a BSP server, and this new plugin better integrates with IntelliJ&amp;rsquo;s internal project modeling and with Remote IntelliJ. The plugin launched in beta during BazelCon and does not yet work with CLion, but they are targeting Spring 2024 to get both out. It&amp;rsquo;s still early to adopt this new plugin, but the future is bright: if VSCode adopts the BSP, we&amp;rsquo;ll finally get Bazel support throughout developer tools. Microsoft, your move. (And Emacs pretty please?)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>IntellIj 2023.3.3:&lt;/strong> This new release of IntelliJ should make the Bazel plugin work well for remote development. Up until now, it was possible to &lt;em>open&lt;/em> existing projects, but not &lt;em>import&lt;/em> them using the Remote IntelliJ interface, which was suboptimal for desktop-less remote VMs.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="remote-build">Remote build&lt;/h1>
&lt;p>Many presenters and attendees report that their companies use remote builds&amp;mdash;unsurprisingly, because that&amp;rsquo;s the primary promise of using Bazel&amp;mdash;and it turns out there are more companies than I thought supplying remote build and telemetry visualization services. Here are some of the interesting details I gathered:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Regional clusters:&lt;/strong> The remote build protocol is sensitive to latency, particularly for builds with low parallelism. In talking to &lt;a href="https://www.engflow.com/">EngFlow&lt;/a>, they&amp;rsquo;ve measured a 10-20% build performance improvement by deploying separate clusters in different regions for a single customer. Multiple clusters are harder to operate than just one cluster&amp;hellip; but if you accept that you need N+1 deployments &lt;em>anyway&lt;/em> for reliability, you might as well colocate them with your primary offices.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Build Barn customizations:&lt;/strong> This open source remote build implementation supports having a bidirectional replicated cache (ideal for the regional clusters mentioned above), and even having small worker pools close to the users while sharing the same central cache. &lt;a href="https://meroton.com/">Meroton&lt;/a>, who does Build Barn consulting, have set up small caches/worker pools in-office for customers, while maintaining a larger &amp;ldquo;central cache&amp;rdquo;, and gotten good results.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Build viewers:&lt;/strong> There are many different implementations of tools to visualize builds via the &lt;a href="https://bazel.build/remote/bep">Build Event Protocol (BEP)&lt;/a>. EngFlow, &lt;a href="https://www.buildbuddy.io/">BuildBuddy&lt;/a>, &lt;del>Gradle Enterprise&lt;/del> &lt;a href="https://gradle.com/">Develocity&lt;/a>&amp;hellip; all were there. As an interesting data point: Develocity can ingest data from various build systems, not just BEP, and allows computing metrics from them all in aggregate. This is not be desirable in the &amp;ldquo;end state&amp;rdquo; of a build system migration, but it&amp;rsquo;s an attractive proposition while the migration is ongoing.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>RE v3:&lt;/strong> There are ongoing discussions about whether &lt;a href="https://docs.google.com/document/d/1FxpdOzOhzOCTjjn2loppMlBzjqjU9WpYF4E1K6opxVI/edit">a new version of the protocol&lt;/a> should be designed or not. There is the thought that some features cannot be retrofitted into the previous protocol, but that&amp;rsquo;s not completely clear. Ed Schouten is requesting feedback in the document that he put together.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>In-transit compression:&lt;/strong> gRPC has support for &lt;a href="https://grpc.io/docs/guides/compression/">transparent in-transit compression&lt;/a> (not at rest). We have thought of hacking it into Build Barn because we think this would improve E2E build times for users with less-than-optimal Internet pipes, but both EngFlow (Java) and Bloomberg (Python) report that they saw worse behavior with compression enabled. They suspect gRPC may be serializing compression operations or doing something similarly-unscalable at very low levels of the stack. Build Barn is written in Go though, so the outcome of this experiment might be different. Worth a try.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Jobs configuration:&lt;/strong> The RE protocol is latency sensitive. Ulf Adams from EngFlow recommended limiting the number of jobs per user on the server side and then configuring the local jobs number to a higher level to minimize the delays that Bazel itself imposes. George Gensure also brought up that there seems to be an unnecessary semaphore in the code that computes Merkle trees, which limits throughput, and that it should be removed from Bazel.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Dynamic scheduling tweaks:&lt;/strong> &lt;a href="https://buck2.build/">Buck2&lt;/a>&amp;rsquo;s &lt;a href="https://bazel.build/remote/dynamic">&amp;ldquo;dynamic scheduler&amp;rdquo;&lt;/a> seems smarter than Bazel&amp;rsquo;s because it avoids running anything locally when the parallelism of the build graph is wide. Then, it enables parallel local execution (which they call hybrid execution) when the parallelism is narrow, as this is the common case towards the end of builds and in most incremental builds. It might be nice to try this in Bazel too because it would help reduce unnecessary network bandwidth (and also help remove the &lt;code>--dynamic_local_execution_delay&lt;/code> hack), but it may increase E2E build time for clean builds if the network is slow&amp;hellip; unless BwtB is at play, in which case this might be a win-win.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="things-to-try-out">Things to try out&lt;/h1>
&lt;p>My TODO list after speaking to people is&amp;hellip; long. Here are a bunch of things I want to try:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Visualize the build graph of our product:&lt;/strong> Bazel has flags to dump the in-memory build graph as a &lt;a href="https://graphviz.org/">Graphviz&lt;/a> file, and &lt;a href="https://github.com/tweag/skyscope/">SkyScope&lt;/a> by &lt;a href="https://www.tweag.io/">Tweag&lt;/a> allows interactively inspecting large graphs. It&amp;rsquo;d be nice to try this out and see what happens, because &lt;a href="https://medium.com/snowflake/build-farm-visualizations-5a079477502d">visualizations often help uncover issues&lt;/a> that are hard to imagine otherwise.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Buck2&amp;rsquo;s LSP for Starlark:&lt;/strong> Meta has done a lot of work in Buck2 to make Starlark easy to write. They have things like an LSP server for Starlark, static typing, static analysis, a profiler, a debugger&amp;hellip; While we cannot use features like static typing because Bazel doesn&amp;rsquo;t support them (yet?), it should be possible to leverage the LSP server for use with VSCode. It apparently has a Bazel mode.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Expendable CI jobs:&lt;/strong> Some CI jobs are not critical: for example, consider a job that exists purely to keep the Bazel remote cache warm for IntelliJ project syncs. Someone brought up the interesting idea of making these jobs monitor the build farm load and skip their execution if the farm is above a certain threshold (to preserve resources and minimize the chances of exhausting them).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Analyze breakdown of rules by type:&lt;/strong> Google reports that 30% of their rules are of the &lt;a href="https://bazel.build/reference/be/general">&lt;code>genrule&lt;/code>&lt;/a> kind, which prevents certain kinds of optimizations&amp;mdash;e.g. they are very expensive memory-wise because they do not benefit from Bazel&amp;rsquo;s depset internal representation. It&amp;rsquo;d be nice to see what our breakdown looks like in case we have to plan some refactoring.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Jenkins persistent runners:&lt;/strong> We currently tear down Jenkins runners quickly, but this discards all Git and Bazel state. For Bazel-only jobs, using persistent runners could help reduce E2E run times. &lt;a href="https://www.thoughtspot.com/">ThoughtSpot&lt;/a> reports a 40% reduction in average build/test time. &lt;a href="https://www.aspect.dev/">Aspect&lt;/a> also claims that this is an anti-pattern. BuildBuddy has done work to clone runners with hot Bazel in-memory state and claims an 8x improvement in build times.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Using actions for downloads:&lt;/strong> Even if this is unorthodox, several people use &lt;em>actions&lt;/em> to download toolchains and the like to minimize the cost of downloads during pre-analysis, to keep those downloads in the remote build farm when the client doesn&amp;rsquo;t need them at all, and to minimize local disk space. I had thought about doing this too, but I was hesitant because it feels &amp;ldquo;ugly&amp;rdquo;. It&amp;rsquo;s good to hear others have thought and tested the same idea too. Note that doing this results in &lt;a href="https://reproducible-builds.org/">reproducible builds&lt;/a> only if downloads are subject to checksum verification.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Validation actions:&lt;/strong> There are new features in Bazel to define &amp;ldquo;validation actions&amp;rdquo; to run things like linters in parallel with the build (without dependency hacks as were used before). Google is using this to run Android Lint internally, which sounds similar to other tools like the popular &lt;a href="https://spotbugs.github.io/">SpotBugs&lt;/a>. These actions can also produce diffs to apply to the source tree to fix the issues they identify.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="upstream-contributions">Upstream contributions&lt;/h1>
&lt;p>These are some long-running changes I&amp;rsquo;d like to get into upstream Bazel and that need follow up:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>C++ linker memory model:&lt;/strong> The C++ linker memory estimation in Bazel is &lt;a href="https://github.com/bazelbuild/bazel/issues/17368">way off reality&lt;/a>, and I previously upstreamed the foundations to fix the issue by exposing input sizes to the estimation logic. We still have to carry a local patch to tune the model based on our observations, but the patch is really small now. But given the diversity in the C++ ecosystem, it&amp;rsquo;d be awesome if we could parameterize the memory computation in the C++ toolchain definition somehow and avoid a local patch: imagine having a lambda that returns a CPU/RAM resource set based on the number of inputs, their size, and the compilation model. I need to engage in GitHub Discussions.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>BEP sanitization changes:&lt;/strong> I brought up that the BEP is incredibly prone to leaking secrets stored in the environment and while folks knew this happens&amp;mdash;after all, tools like BuildBuddy and EngFlow have logic to scrub secrets&amp;mdash;they were not really aware of the extent of the problem. I have a prototype patch to scrub all environment variables from the BEP (except for a limited allowed list useful for debugging) and I think we agreed that this feature would be good to upstream. So now I need to write a proper bug report and share my audits of the protocol and the proposal for a fix. Stay tuned.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>bb-clientd patch:&lt;/strong> The current implementation of &lt;a href="https://github.com/bazelbuild/bazel/pull/12823">the patch to support a FUSE-based output tree&lt;/a> is going nowhere because of the upcoming Remote Output Service formalization of this same idea. Until that&amp;rsquo;s available, I don&amp;rsquo;t think it&amp;rsquo;s worth trying to maintain this on top of Bazel 6 any longer, particularly due to the BwtB improvements that are coming in Bazel 7. It seems wiser to just wait.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="other-thoughts">Other thoughts&lt;/h1>
&lt;p>And to conclude, a bunch of disconnected notes about things that were interesting to me:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Buck2:&lt;/strong> This new build system from Meta looks really cool to me. On the plus side, it fixes some long-standing issues in Bazel, like having a truly language-agnostic core, being built from the ground up with BwtB and FUSE in mind, and super-quick startup time because it&amp;rsquo;s not Java; hindsight is 20/20 after all. But it also has its drawbacks, like no support for external dependencies yet or no local sandboxing (both of which are fixable). They also have nice features like limited dynamic dependency discovery, which makes tools like Gazelle less necessary. And&amp;hellip; they are considering writing a shim to support Bazel rules in Buck2, which would make experimentation on existing projects super-exciting.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Bazel jobs scalability:&lt;/strong> There are two problems with making Bazel scale to thousands of concurrent jobs: the &amp;ldquo;1 job = 1 thread&amp;rdquo; execution model, and memory usage due to Merkle tree computation. Ulf Adams reports that he could run Bazel with hundreds of thousands of jobs back at Google when he implemented async execution by hand&amp;mdash;the Google-internal RE protocol doesn&amp;rsquo;t use Merkle trees, so memory pressure was not an issue&amp;mdash;but unfortunately the changes were never productionized and have been backed out of Bazel due to their complexity. Java 21 brings &lt;a href="https://docs.oracle.com/en/java/javase/20/core/virtual-threads.html">virtual threads&lt;/a> and paves the way to fix this in a nicer, non-hacky way.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>bb-clientd improvements:&lt;/strong> Meroton has significant experience with deploying bb-clientd for customers and are interested in the issues we face because they are the main pushers for the Remote Output Service feature. In particular, dynamic execution doesn&amp;rsquo;t play well with bb-clientd because it causes bb-clientd to backlog downloads when local actions are frequently cancelled. It should be possible to tell bb-clientd to stop downloads and resolve these issues because the FUSE protocol supports it, but it&amp;rsquo;s not plumbed through. Also, implementing chunked downloads to support debugging of large binaries with minimal network latency sounds awesome, but we&amp;rsquo;d need to quantify the benefit first: I suspect you need just a tiny portion of multi-GB C++ debug binary to produce a stacktrace.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Virtual file systems on macOS:&lt;/strong> Both Ed Schouten from Build Barn and Neil Mitchell from Buck2 report that NFSv4 has been pretty decent on macOS when compared to FUSE to implement virtual file systems, and that it should be the primary mechanism for writing virtual file systems on macOS now. FUSE is unfortunately doomed due to Apple&amp;rsquo;s desire to kill kernel extensions, which makes it really hard to install FUSE.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Avoiding BUILD files:&lt;/strong> &lt;a href="https://www.salesforce.com/">Salesforce&lt;/a> has undergone a Bazel migration with 4000 engineers and claims that 70% have trouble writing BUILD files. Anything that can be done to hide them / automate edits is worthwhile. &lt;a href="https://investors.luminartech.com/">Luminar&lt;/a> has developed a C++ plugin for &lt;a href="https://github.com/bazelbuild/bazel-gazelle">Gazelle&lt;/a> and they use &lt;a href="https://github.com/NixOS/nixpkgs">Nix packages&lt;/a> to pull in third-party dependencies.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Coverage-guided test selection:&lt;/strong> It&amp;rsquo;s a common problem to have integration tests that depend on pretty much all of the codebase, which in turn causes test runs to take too long and nullifies Bazel&amp;rsquo;s test caching features. Coverage metrics can be useful in implementing a heuristic to identify which subset of the integration tests to run on a given change at the expense of occasional false negatives.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Classes in Starlark:&lt;/strong> Aspect has come up with an idiom to represent classes in Starlark, and they claim it has simplified maintenance of their JavaScript rules significantly. Worth a look.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Monorepos and Git:&lt;/strong> VMware claims that Perforce is much faster than Git at syncing GBs of source code (1min vs. 12min). Meroton has developed a &amp;ldquo;monorepo emulation&amp;rdquo; mode on top of many small Git repos leveraging Gerrit&amp;rsquo;s cross-repo atomic commits. AOSP (Android) has done something similar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Abusing &amp;ldquo;exec requirements&amp;rdquo; to tune remote workers:&lt;/strong> &lt;a href="https://stripe.com/">Stripe&lt;/a> has implemented lots of custom features to tune the behavior of remote workers via &amp;ldquo;exec requirement&amp;rdquo; tags at the action/target level. They can do things like mock time on the remote containers to exercise timing conditions (e.g. leap year switches) or to request access to certain internal-only network endpoints. They can also emit trace data from actions (by configuring a &amp;ldquo;listener&amp;rdquo; that propagates those details) and then merge such traces into the Bazel &lt;a href="https://bazel.build/advanced/performance/json-trace-profile">JSON trace profile&lt;/a> to show what exactly the long-running actions are doing. Think visualizing what a nested &lt;code>make -j8&lt;/code> is doing.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Building without the Internet:&lt;/strong> Salesforce mirrors all external dependencies internally and denies all downloads by default from untrusted sources. They do allow the build farm to talk to internal sources to fetch artifacts though, because their tests need to do that. The &amp;ldquo;resolved file&amp;rdquo; feature in Bazel can help create a catalog of dependencies, and the &amp;ldquo;download config&amp;rdquo; to deny external access.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>RE for arbitrary builds:&lt;/strong> EngFlow is doing a lot of work to support arbitrary builds using remote execution, not just Bazel builds. They have &amp;ldquo;revived&amp;rdquo; &lt;a href="https://github.com/bazelbuild/reclient">Google&amp;rsquo;s reclient&lt;/a>&amp;mdash;a compiler wrapper that uses RE&amp;mdash;and offer support for CMake. The idea in CMake is to use reclient where possible (compiling and linking) and to run CMake itself on a remote worker to paper over the limitations of actions not supported by reclient.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Memory consumption is a widespread problem:&lt;/strong> Everybody dislikes how Bazel consumes memory. Google is doing work on this and we should continue to see improvements. One that sounded promising is the addition of support to discard partial parts of the build graph (e.g. for things not in the critical path).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Blogging is cool:&lt;/strong> Many people opened with &amp;ldquo;I read your blog!&amp;rdquo; upon meeting them which was&amp;hellip; flattering, I must confess. I need to write more. Subscribe to this blog if you haven&amp;rsquo;t yet!&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="reference-material">Reference material&lt;/h1>
&lt;p>A bunch of papers mentioned during the many discussions that happened:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.inf.u-szeged.hu/~gertom/Kutatas/BGS12.pdf">Code Coverage-Based Regression Test Selection and Prioritization in WebKit&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://research.google/pubs/pub48413/">Code Coverage at Google&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/facebook/sapling">Sapling from Facebook (git-compatible highly-scalable SCM)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">Build systems à la carte&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/microsoft/scalar">Scalar (Microsoft extensions for very large git repos)&lt;/a>&lt;/li>
&lt;/ul></description><enclosure url="https://jmmv.dev/images/2023-10-30-bazelcon.jpg" length="663230" type="image/jpeg"/></item><item><title>Hello, Blog System/5!</title><link>https://jmmv.dev/2023/10/hello-blog-system5.html</link><pubDate>Fri, 27 Oct 2023 16:14:00 +0200</pubDate><guid>https://jmmv.dev/2023/10/hello-blog-system5.html</guid><description>&lt;p>&lt;a href="https://blogsystem5.substack.com/">Blog System/5&lt;/a> is my new Substack publication in which I write about the variety of software and systems engineering topics that pique my interest. If that sounds too generic to you, it&amp;rsquo;s because it is: there are too many cool things to write about!&lt;/p>
&lt;p>But in particular, I&amp;rsquo;ll be covering:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>operating systems, including the BSDs, Linux, macOS and maybe Windows;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>build systems, which mostly means Bazel;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>programming languages, including Rust and shell (talk about opposites!);&lt;/p>
&lt;/li>
&lt;li>
&lt;p>and general engineering practices to build sustainable, high-quality systems.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>My essays are based on my day-to-day professional experiences at Google as an SRE in the storage stack and SWE in Blaze; Microsoft as an SDE in Azure Storage; and Snowflake as a SWE in developer productivity. But also, these essays are based on my own side projects like &lt;a href="https://www.endbasic.dev/">EndBASIC&lt;/a> or &lt;a href="https://shtk.jmmv.dev/">shtk&lt;/a>, and on my distant past contributions to FreeBSD, NetBSD and Gnome.&lt;/p>
&lt;blockquote>
&lt;p>Subscribe now to help build a community of like-minded individuals. It&amp;rsquo;s free, and a stable subscribers group makes a difference!&lt;/p>
&lt;p>&lt;a href="https://blogsystem5.substack.com/">https://blogsystem5.substack.com/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h1 id="but-why">But why?&lt;/h1>
&lt;p>You may have read my blog at &lt;a href="https://jmmv.dev/">https://jmmv.dev/&lt;/a> (this site), which is still alive and kicking, so what&amp;rsquo;s up with this newsletter? Doesn&amp;rsquo;t the introduction above sound exactly like what my blog is about?&lt;/p>
&lt;p>Well&amp;hellip; yeah, but I want to run an experiment. Growing the readership of my home-grown blog has been extremely hard: some of my articles occasionally end up in the Hacker News front page, but those only result in one-off traffic spikes with no recurrent engagement, which is a tad sad. I&amp;rsquo;ve witnessed other authors build nice communities around their publications in Substack, so I want to check first-hand how this platform helps achieve those goals.&lt;/p>
&lt;p>My tentative plan is to post new articles here first and then re-post them to my personal blog a few days later. The reasons for this structure are two: first, because I want to &lt;a href="/2016/01/medium-experiment-wrapup.html">own my content long-term&lt;/a>; and, second, because I do not want to force you all to subscribe to Substack if you don&amp;rsquo;t want to: the usual &lt;a href="/feed.xml">RSS&lt;/a> and &lt;a href="/2023/06/in-house-email-subscriptions.html">email subscription mechanism&lt;/a> will continue to work.&lt;/p>
&lt;p>But&amp;hellip; I can imagine sending you some &amp;ldquo;fresh&amp;rdquo; content that wouldn&amp;rsquo;t really fit as a long-form blog article, but I&amp;rsquo;m not sure yet. So, we&amp;rsquo;ll see.&lt;/p>
&lt;h1 id="whats-in-the-name">What&amp;rsquo;s in the name?&lt;/h1>
&lt;p>It&amp;rsquo;s weird, isn&amp;rsquo;t it? Where does it come from? Simply put, I like original blog titles that refer to technology products or concepts, so I wanted one like those too. OS/2 Warp 3 was the alternate operating system that led me into my adventure away from Windows and towards great outcomes back in 1995, so Blog System/5 pays a tribute to that even if I likely won&amp;rsquo;t be blogging about OS/2 at all.&lt;/p>
&lt;p>So what about the 5? As it turns out, this is the fifth (I &lt;em>think&lt;/em>) iteration of my blog. Going back almost 20 years, my writing journey started in LiveJournal, then moved onto Blogger, then onto a brief stint with Medium, then onto my self-hosted site, and then onto here. If this experiment goes sideways&amp;hellip; well, I&amp;rsquo;ll just keep the title and number for the blog. I like odd numbers.&lt;/p>
&lt;h1 id="whats-next">What&amp;rsquo;s next?&lt;/h1>
&lt;p>Easy. You &lt;em>subscribe now&lt;/em> and you receive my detailed recap of BazelCon 2023 as soon as I finish writing it in the next few days. Plus, of course, you&amp;rsquo;ll also receive all future articles and maybe we can build a community around those topics. Don&amp;rsquo;t hesitate to share your thoughts along the way!&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-10-28-blog-system5-logo.png" length="76109" type="image/jpeg"/></item><item><title>Build farm visualizations</title><link>https://jmmv.dev/2023/10/build-farm-visualizations.html</link><pubDate>Fri, 20 Oct 2023 09:00:00 -0700</pubDate><guid>https://jmmv.dev/2023/10/build-farm-visualizations.html</guid><description>&lt;p>If you have followed our &lt;a href="https://medium.com/snowflake/tagged/infrastructure">recent infrastructure posts&lt;/a>, you know by now that we are actively migrating Snowflake&amp;rsquo;s build to Bazel. What we haven&amp;rsquo;t shared yet is that we have deployed our own &lt;a href="https://github.com/buildbarn">Build Barn&lt;/a> cluster to support Bazel&amp;rsquo;s remote execution features. We have chosen to run our own build farm service for resource governance and security purposes, but also because the behavior of this system impacts the developer experience so directly that we want to have full in-house control and knowledge of it.&lt;/p>
&lt;p>Things haven&amp;rsquo;t been smooth-sailing though. While the initial deployment was simple, resource provisioning, performance tuning, and stability have been a struggle. Folks in the Build Barn community advised us to over-provision the cache and the worker pool&amp;mdash;and we did&amp;mdash;but such advice didn&amp;rsquo;t sound quite right: we had already invested as many resources in the build farm as we were using for our legacy builds, yet the Bazel builds couldn&amp;rsquo;t keep up with the load.&lt;/p>
&lt;p>All combined, this was not a great story: users saw builds failing and we didn&amp;rsquo;t have a good grasp about what was going on. Until&amp;hellip; we could &lt;em>see&lt;/em> into the build farm behavior. As soon as we had pictures, the source of these problems became obvious. Let&amp;rsquo;s take a peek at what problems we had, how visualizations helped us diagnose them, and what solutions we applied.&lt;/p>
&lt;h1 id="initial-setup">Initial setup&lt;/h1>
&lt;p>When we deployed Build Barn at the beginning of the year in an in-house Kubernetes cluster, we didn&amp;rsquo;t put much thought into resource provisioning because our needs were modest. As we made progress through the migration, and as soon as we had the main product and its tests building with Bazel, we had to set up required Bazel build validation within our Continuous Integration (CI) system to minimize the chances of build regressions. This increased the load on the build farm as well as its reliability expectations.&lt;/p>
&lt;p>Unfortunately, these led us to infrastructure problems. When those happened, all indicators pointed at issues in the build farm&amp;rsquo;s shared cache nodes. We didn&amp;rsquo;t have many metrics in place yet, but the few we had told us that the cache wasn&amp;rsquo;t keeping up in size or in performance, and we saw significant action queuing. Our reaction was to address the seemingly-obvious cause: the shared cache nodes were backed by slow EBS devices, so we moved them to locally-attached NVMe flash drives. Surprisingly though, this made little difference in overall performance.&lt;/p>
&lt;p>Why? Why was it that the build farm could not keep up under load?&lt;/p>
&lt;h1 id="profiling">Profiling&lt;/h1>
&lt;p>My own hypothesis was that our cache nodes were starved of network. This was based on the observation that we have relatively few of them serving hundreds of workers and clients, and that the pathological workloads that brought us to the outages involved very large artifacts staged on many workers. We had no good data to prove this because we hadn&amp;rsquo;t yet added enough instrumentation to find a smoking gun, and the few metrics we had didn&amp;rsquo;t implicate the network.&lt;/p>
&lt;p>Resolving this issue was in our critical path to complete the Bazel migration so I was determined to get a better understanding of it. Two previous bits of knowledge helped reach a solution: past experience with &lt;a href="https://tools.bsc.es/paraver">Paraver&lt;/a>, a cluster-level trace visualization tool to observe execution behavior across machines, and the &lt;a href="https://bazel.build/advanced/performance/json-trace-profile">trace profile that Bazel emits&lt;/a>, which looks strikingly similar but is &lt;a href="https://www.chromium.org/developers/how-tos/trace-event-profiling-tool/">opened via Chrome&lt;/a>.&lt;/p>
&lt;p>I spent a couple of hours prototyping a Python script that queries the database into which we dump build farm events, fetches action scheduling details during a time period, and turns those into a Chrome trace. The idea here was to show, for each worker node in the cluster, what each of its execution threads was doing. That is, I was interested in seeing whether each thread was:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>idle&lt;/strong>,&lt;/li>
&lt;li>&lt;strong>downloading&lt;/strong> input artifacts from the shared cache,&lt;/li>
&lt;li>&lt;strong>executing&lt;/strong> an action,&lt;/li>
&lt;li>or &lt;strong>uploading&lt;/strong> output artifacts to the shared cache.&lt;/li>
&lt;/ol>
&lt;p>Here is one of the first pictures I obtained for a time period where we observed significant action queuing and thus build farm performance degradation:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-20-old-farm-io-issues-trace.png" class="with-border">
&lt;figcaption>2023-09-13 17:40–18:15 UTC: The X axis shows time and the Y axis shows worker nodes / thread pairs. In the Y axis you can see gray bars with the worker names, each grouping 8 execution threads. Then, for each worker node / thread pair, there are two horizontal colored bars: the bar at the top indicates the name of the action that’s currently running on the execution thread, and the bar at the bottom provides a breakdown of the download, execution, and upload phases.&lt;/figcaption>
&lt;/figure>
&lt;p>You can click to zoom into the picture, but the key thing to notice is this: orange corresponds to download/upload whereas green corresponds to execution. And the majority of the picture is orange.&lt;/p>
&lt;p>This was the first indication that we truly had networking problems as I originally set out to prove. But while this visualization is really powerful to pinpoint the issue, it&amp;rsquo;s hard to quantify it. So I performed other computations and found that, for this period of time, workers were 97% utilized yet&amp;hellip; they were only executing actions 20% of the time. A whopping 77% of the time was being lost to the network.&lt;/p>
&lt;p>Or, shown another way: if we graph the different phases per second, we get this graph:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-20-old-farm-io-issues-chart.png" class="with-border">
&lt;figcaption>2023–09–13 17:40–18:15 UTC: Tally of where build farm processing time goes during the first 100 seconds of this time window. For each second, we can see what percentage of the time is spent in each phase.&lt;/figcaption>
&lt;/figure>
&lt;p>Much easier to see the problem and much easier to see that the networking overheads are constant over time.&lt;/p>
&lt;h1 id="was-it-the-network-though">Was it the network though?&lt;/h1>
&lt;p>So far, everything pointed at the network being the problem. But then, I looked at different time periods when the cluster wasn&amp;rsquo;t experiencing queuing and I also looked at the staging cluster which barely had any traffic. And, surprise, &lt;em>all of them&lt;/em> showed the same profile: no matter how busy a cluster was, the workers were only able to execute actions for about 2/3rds of their time.&lt;/p>
&lt;p>This made no sense. If the problems were with the network, and the assumption was that the cache nodes were starved of network bandwidth, we should only see this behavior during high traffic. Without extra visibility into network metrics, which we didn&amp;rsquo;t have, I was out of ideas, so I did what I always do: write.&lt;/p>
&lt;p>I collected my thoughts into a shared document and shared it with the team. Almost accidentally, a teammate left a comment saying that the workers were using EBS for their scratch disk space. This was the &lt;em>aha moment&lt;/em> we needed: based on previous experience running Bazel on VMs backed by EBS, we knew that EBS&amp;rsquo; IOPS were insufficient for the high demands of a build, and the same likely applied to the workers.&lt;/p>
&lt;p>This theory made immediate sense to the team too, so we proceeded to reconfigure our staging cluster with tmpfs for the workers&amp;rsquo; scratch disk space instead of EBS. While RAM-hungry, tmpfs would provide us with the best-case performance scenario. If the experiment succeeded, we could later re-analyze whether we wanted to keep using RAM or to find another VM SKU type with a local disk to cut costs.&lt;/p>
&lt;p>We rolled out the change to staging and it looked very promising: our reduced collection of workers showed that the fetch and upload phases went to almost zero.&lt;/p>
&lt;h1 id="scheduler-woes">Scheduler woes&lt;/h1>
&lt;p>But here is what happened after we rolled this out to production because, even with the tmpfs fix, we observed &lt;em>another&lt;/em> queuing outage:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-20-new-farm-scheduler-issues-trace.png" class="with-border">
&lt;figcaption>2023-10-02 21:00–22:00: Trace view. Same description as before.&lt;/figcaption>
&lt;/figure>
&lt;p>There was queuing but the cluster was&amp;hellip; almost idle? Metrics said the workers&amp;rsquo; overall utilization was 14% of which 12% was execution. Put another way:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-20-new-farm-scheduler-issues-chart.png" class="with-border">
&lt;figcaption>2023-10-02 21:00–22:00: Phase breakdown during the first 100 seconds.&lt;/figcaption>
&lt;/figure>
&lt;p>As you can see in both pictures, the cluster showed almost no activity. We had significant queuing but the cluster was mostly idle. It was great to see that the fetch and upload bands had almost disappeared, but now the workers were not being utilized.&lt;/p>
&lt;p>Answering this piece of the puzzle was easier. If the workers weren&amp;rsquo;t receiving enough work to do, we had problems either in the job scheduler or in the frontends. Fortunately, we &lt;em>did&lt;/em> have metrics on the CPU consumption of these actors of the system and they showed a clear problem: the scheduler had an allocation of 0.3 CPUs and it was maxed out.&lt;/p>
&lt;p>Now&amp;hellip; 0.3 CPUs?! Yes, that was ridiculously low: when provisioning a distributed system, if you have a singleton job, you&amp;rsquo;ll want to over-provision it just in case because, in the grand scheme of things, the cost will be negligible. But we had a low reservation, probably because of a copy/pasted configuration from months ago that we had no reason to revisit.&lt;/p>
&lt;p>We had to revisit this CPU allocation now. We gave the scheduler more CPU and more RAM and waited for the next burst of activity.&lt;/p>
&lt;h1 id="stunning-performance">Stunning performance&lt;/h1>
&lt;p>Here is what we saw after bumping up the scheduler CPU and RAM reservations during another busy time period:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-20-new-farm-good-trace.png" class="with-border">
&lt;figcaption>2023-10-03 23:57–23:59: Trace view. Same description as before.&lt;/figcaption>
&lt;/figure>
&lt;p>Notice the green bars? Or rather&amp;hellip; the lack of orange bars? That&amp;rsquo;s right. The workers were now 99% utilized with 97% of their time going into execution. And if we look into the other view of this same data:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-20-new-farm-good-chart.png" class="with-border">
&lt;figcaption>2023-10-03 23:57–23:59: Phase breakdown during the first 100 seconds.&lt;/figcaption>
&lt;/figure>
&lt;p>We can also see a sea of green with almost no network transfers and no idle time during busy periods. Problem(s) solved.&lt;/p>
&lt;p>Our build farm can now support roughly 3x the load that it ran before. Disk-intensive tests are now as fast as when they run on a local development environment. And incremental builds are faster because of reduced end-to-end action execution times. But we aren&amp;rsquo;t done yet! While the system is now performing well, there are additional tuning operations we must do to improve the reliability of the system, to minimize hiccups during maintenance periods, and to reduce the overall monetary cost.&lt;/p>
&lt;h1 id="takeaways">Takeaways&lt;/h1>
&lt;p>Here are my takeaways from this exercise:&lt;/p>
&lt;ol>
&lt;li>Visualizations are an incredibly powerful tool to understand a distributed system. You can have all the metrics and time series you want about individual performance indicators, but unless you can tie them together and give them meaning, you&amp;rsquo;ll likely not understand what&amp;rsquo;s going on. In our case, the trace visualizations enlightened us almost immediately once we could see them.&lt;/li>
&lt;li>Hypotheses are great to guide investigations, but measurements are crucial to come out with the correct root causes. In this case, I started with the assumption that we had problems in the cache nodes due to network starvation, and while we did end up finding network issues, they were in a completely different part of the system.&lt;/li>
&lt;li>Investing time into learning the metrics that your team&amp;rsquo;s telemetry collects is one of the best things you can do during onboarding. For me, this is the third time I join a team and postpone learning the schema and the queries needed to make sense of the data that the team collected, and I&amp;rsquo;ve regretted the delay every time. You can solve a ton of problems by just knowing where and how to look at existing data; stopping to learn these will pay dividends quickly.&lt;/li>
&lt;li>Developer productivity is an exciting area to work on. Don&amp;rsquo;t get fooled by folks or even companies that treat build engineers as second-class citizens. Developer productivity is a really broad area of engineering that covers everything from single-machine kernel-level tuning to distributed systems troubleshooting, while also interacting with (internal) customers and creating delightful user interfaces.&lt;/li>
&lt;/ol>
&lt;p>Sounds like the kind of thing you&amp;rsquo;d like to work on? &lt;a href="https://careers.snowflake.com/us/en/search-results?keywords=developer+productivity">Join our team!&lt;/a> 🙂&lt;/p></description></item><item><title>Unit-testing shell scripts and tools with shtk</title><link>https://jmmv.dev/2023/10/unit-testing-with-shtk.html</link><pubDate>Wed, 11 Oct 2023 08:30:00 -0700</pubDate><guid>https://jmmv.dev/2023/10/unit-testing-with-shtk.html</guid><description>&lt;p>While working on this static blog a few days ago, I made a change to its templates that warranted an automated test. I could have written a trivial shell script to do it, but instead I reached out for shtk&amp;rsquo;s unit-testing module. I &lt;a href="https://twitter.com/jmmv/status/1710309896670081083">tweeted about it&lt;/a> right away to just say that you can, in fact, write tests in shell because lots of developers are skeptical about any script longer than 10 lines of code.&lt;/p>
&lt;p>Interestingly, this reply came through: a pointer to a contemporary, under-development library for writing tests in Bash. Which made me think: &amp;ldquo;Hey, I had already done that years ago&amp;hellip; but nobody knows about it. Gotta fix that with a blog post!&amp;rdquo; But first, I had to bring shtk back from its ashes because I had not touched it for more than 6 years and it wasn&amp;rsquo;t read for show and tell. So I did something that I wanted to do back in the day but never did: I put together &lt;a href="https://shtk.jmmv.dev/">a website for shtk&lt;/a> to host its &lt;a href="https://shtk.jmmv.dev/docs.html">reference manual&lt;/a> and I fixed a few obvious rough edges.&lt;/p>
&lt;p>With those tweaks out of the way, we come to this article. In here, I want to show you how writing decent tests in shell is entirely possible and how shtk&amp;rsquo;s testing platform provides unique features to do integration testing of CLI apps written in any language.&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h1 id="what-is-shtk-anyway">What is shtk anyway?&lt;/h1>
&lt;p>The Shell Toolkit, or shtk for short, is a collection of libraries to support the writing of portable shell scripts. shtk grew out of &lt;a href="http://blog.netbsd.org/tnf/entry/introducing_sysbuild_and_sysupgrade">sysbuild and sysupgrade&lt;/a>&amp;rsquo;s common code, a couple of tools I wrote over 10 years ago for NetBSD and that are fully written in shell because of the constraints of the NetBSD base system. In turn, this means that shtk is &lt;em>not&lt;/em> Bash-specific so it avoids imposing a &lt;a href="/2021/08/useless-use-of-gnu.html">useless use of GNU&lt;/a>.&lt;/p>
&lt;p>From the get go, all of shtk, sysbuild, and sysupgrade had unit tests written with atf-sh, the shell testing library of the &lt;a href="/software/atf.html">Automated Testing Framework&lt;/a>. atf-sh was a rather simplistic library created by yours truly in 2007 and required a complex runtime (atf-run or, later, &lt;a href="/software/kyua.html">Kyua&lt;/a>) to be functional. By 2014, while working at Google, I had been exposed to better ways of writing tests that blended better with the languages they supported (pyUnit and JUnit), and I knew that I needed a replacement for atf-sh.&lt;/p>
&lt;p>Hence, in 2014, I took the best parts of atf-sh, the core concepts of the xUnit test frameworks, and I created shtk&amp;rsquo;s &lt;code>unittest&lt;/code> module. I then proceeded to migrate all existing tests to this new framework and also used shtk to &lt;a href="/2017/02/introducing-pkg_comp-2.0.html">build pkg_comp 2.x later on in 2017&lt;/a>. But I failed to publicize the library because I didn&amp;rsquo;t quite know how to put together a cool-looking website and I didn&amp;rsquo;t have a good platform to talk about it&amp;mdash;both of which are fixed now.&lt;/p>
&lt;h1 id="installing-shtk">Installing shtk&lt;/h1>
&lt;p>If you are on NetBSD or on FreeBSD, you are in luck! There are packages for shtk ready to install, so go ahead and use those.&lt;/p>
&lt;p>On any other system, you&amp;rsquo;ll have to build shtk from source. Fear not, it&amp;rsquo;s easy:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ curl -LO https://github.com/jmmv/shtk/releases/download/shtk-1.7/shtk-1.7.tar.gz
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ tar xzf shtk-1.7.tar.gz
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ cd shtk-1.7
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ./configure --prefix ~/.local
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ make
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ make install
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>After a successful installation, you should have the &lt;code>shtk&lt;/code> tool in your path. If that&amp;rsquo;s not the case, do this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ PATH=&amp;#34;${HOME}/.local/bin:${PATH}&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ export MANPATH=&amp;#34;${HOME}/.local/share/man:${MANPATH}&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Setting up the &lt;code>MANPATH&lt;/code> is important. shtk&amp;rsquo;s official documentation is written as manual pages to seamlessly integrate with the Unix-y environment it&amp;rsquo;s intended to complement, so you&amp;rsquo;ll want &lt;code>man&lt;/code> invocations to work. If you are curious, start by peeking into &lt;a href="https://shtk.jmmv.dev/shtk.1.html">&lt;code>shtk(1)&lt;/code>&lt;/a> and &lt;a href="https://shtk.jmmv.dev/shtk.3.html">&lt;code>shtk(3)&lt;/code>&lt;/a>.&lt;/p>
&lt;h1 id="creating-our-first-test">Creating our first test&lt;/h1>
&lt;p>Now that we have shtk up and running, let&amp;rsquo;s create a test. Write the following contents to a file named &lt;code>demo_test.sh&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">shtk_import unittest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_test always_fails
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">always_fails_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> assert_equal &lt;span class="m">2&lt;/span> &lt;span class="m">3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;NOT REACHED!&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done? OK. Something looks funny, doesn&amp;rsquo;t it? &lt;code>shtk_import&lt;/code> is a shell function that brings the &lt;code>unittest&lt;/code> module into scope. But&amp;hellip; where does that function come from? Well, here is the thing: shtk scripts need to be &amp;ldquo;built&amp;rdquo; before they can run. In order for the above to become a runnable test program, you have to do the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ shtk build -m shtk_unittest_main demo_test.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>After running the above, you&amp;rsquo;ll end up with a &lt;code>demo_test&lt;/code> executable. This &amp;ldquo;executable&amp;rdquo; is essentially the same as &lt;code>demo_test.sh&lt;/code> but with some preamble code to set up the module import features and a call to the &lt;code>shtk_unittest_main&lt;/code> entry point to execute the tests.&lt;/p>
&lt;p>Once the script is built, run it and see the single test fail:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ ./demo_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing always_fails...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: E: Expected value 2 but got 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Testing always_fails... FAILED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Ran 1 tests; 1 FAILED
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="advanced-xunit-like-features">Advanced xUnit-like features&lt;/h1>
&lt;p>The above is nice but&amp;hellip; pretty&amp;hellip; simple? Anyone can write a conditional to check if two values are equal without the need for &amp;ldquo;fancy frameworks&amp;rdquo;, right? Right. But shtk provides much more.&lt;/p>
&lt;p>Just like asserts, shtk also comes with expects to record soft failures: all &lt;code>assert_*&lt;/code> functions have an &lt;code>expect_*&lt;/code> counterpart. If we tweak our previous test to look like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">shtk_import unittest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_test always_fails
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">always_fails_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> expect_equal &lt;span class="m">2&lt;/span> &lt;span class="m">3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;REACHED!&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> expect_equal &lt;span class="m">4&lt;/span> &lt;span class="m">5&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We get the following, which shows how the two expect commands ran and detected a failure but didn&amp;rsquo;t stop execution:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ shtk build -m shtk_unittest_main demo_test.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ./demo_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing always_fails...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Delayed failure: Expected value 2 but got 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">REACHED!
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Delayed failure: Expected value 4 but got 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Testing always_fails... FAILED (2 delayed failures)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Ran 1 tests; 1 FAILED
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In general, when writing a test, you use asserts for any step that prepares the test scenario, and you use expects for the test scenario itself. This way, the test fails early if it is unable to set up the scenario (because it makes no sense to continue if the scenario is not set up), but it prints as much diagnostic information as possible if the actual test detects problems half-way through.&lt;/p>
&lt;p>What about fixtures? Setup and teardown routines? shtk has got you covered too:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">shtk_import unittest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_fixture sample
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">sample_fixture&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> setup&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;Common setup code&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">echo&lt;/span> &lt;span class="m">123&lt;/span> &amp;gt;data.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> teardown&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;Common cleanup code&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> rm -f data.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> shtk_unittest_add_test ok
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ok_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> assert_equal &lt;span class="m">123&lt;/span> &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="k">$(&lt;/span>cat data.txt&lt;span class="k">)&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">echo&lt;/span> &lt;span class="m">125&lt;/span> &amp;gt;data.txt &lt;span class="c1"># Overwrites transient file.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> shtk_unittest_add_test not_ok
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> not_ok_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> assert_equal &lt;span class="m">125&lt;/span> &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="k">$(&lt;/span>cat data.txt&lt;span class="k">)&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Running the above does as you would expect:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ shtk build -m shtk_unittest_main demo_test.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ./demo_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing sample__ok...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Common setup code
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Common cleanup code
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing sample__ok... PASSED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing sample__not_ok...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Common setup code
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: E: Expected value 125 but got 123
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Common cleanup code
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Testing sample__not_ok... FAILED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Ran 2 tests; 1 FAILED
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note how the setup and teardown routines were executed for each test, which means that the &lt;code>data.txt&lt;/code> file was recreated for every test case and the modifications to the file from one test didn&amp;rsquo;t impact the outcome of the other.&lt;/p>
&lt;h1 id="the-secret-sauce-assert_command">The secret sauce: assert_command&lt;/h1>
&lt;p>So far, everything looks very xUnit-like. We have asserts and expects; we have test setup and teardown hooks; we have fixtures. But shell scripts are uniquely suited to test the user interface of a CLI app: after all, users interact with CLI apps from the shell, so it&amp;rsquo;s only natural to use the shell to test arbitrary tools no matter what language they are written in. This is where shtk&amp;rsquo;s magic sauce comes into play.&lt;/p>
&lt;p>shtk&amp;rsquo;s &lt;code>assert_command&lt;/code> check allows you to run an arbitrary command and to declaratively check its exit condition and its side-effects on stdout and stderr. The feature is inspired by &lt;a href="https://www.gnu.org/software/autoconf/manual/autoconf-2.68/html_node/Writing-Testsuites.html">&lt;code>AT_CHECK&lt;/code> in GNU Autoconf&lt;/a>, to which I was exposed even longer ago (circa 2005) while working on the Monotone project.&lt;/p>
&lt;p>Take a look at these tests that exercise the &lt;code>cp&lt;/code> tool and pay close attention to the &lt;code>assert_command&lt;/code> calls:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">shtk_import unittest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_test cp_ok
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cp_ok_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> touch a
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> assert_command cp a b
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">[&lt;/span> -f b &lt;span class="o">]&lt;/span> &lt;span class="o">||&lt;/span> fail &lt;span class="s2">&amp;#34;b was not created&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_test cp_missing_source
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cp_missing_source_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> assert_command -s exit:1 -e match:&lt;span class="s2">&amp;#34;No such file&amp;#34;&lt;/span> cp a b
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_test cp_unexpected_output
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cp_unexpected_output_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> assert_command -s exit:1 -o match:&lt;span class="s2">&amp;#34;Hello&amp;#34;&lt;/span> cp a b
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the first test, &lt;code>cp_ok&lt;/code>, the call to &lt;code>assert_command&lt;/code> has no flags. This means that we expect the command given to the assert to finish successfully and quietly: the exit code of &lt;code>cp a b&lt;/code> should be 0, and both stdout and stderr should be silent.&lt;/p>
&lt;p>In the second test, &lt;code>cp_missing_source&lt;/code>, the call to &lt;code>assert_command&lt;/code> specifies that the command under test has to terminate with an exit code of 1, and that stderr has match the &lt;code>No such file&lt;/code> regular expression.&lt;/p>
&lt;p>In the third test, &lt;code>cp_unexpected_output&lt;/code>, the call to &lt;code>assert_command&lt;/code> expects a message to stdout that &lt;code>cp&lt;/code> will not print, and also implies that stderr should be empty.&lt;/p>
&lt;p>When we run the above after compilation, we get:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ shtk build -m shtk_unittest_main demo_test.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ./demo_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing cp_ok...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Running checked command: cp a b
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing cp_ok... PASSED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing cp_missing_source...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Running checked command: cp a b
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing cp_missing_source... PASSED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: I: Testing cp_unexpected_output...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Running checked command: cp a b
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Expected regexp &amp;#39;Hello&amp;#39; not found in standard output:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Expected standard error to be empty; found:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cp: a: No such file or directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: E: Check of &amp;#39;cp a b&amp;#39; failed; see stdout for details
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Testing cp_unexpected_output... FAILED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">demo_test: W: Ran 3 tests; 1 FAILED
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that the first two tests passed, but pay attention to the output of the third failed test: the call to &lt;code>assert_command&lt;/code> reports that neither stdout nor stderr matched what we expected and provides details on why.&lt;/p>
&lt;p>I invite you to take a look at the documentation in &lt;a href="https://shtk.jmmv.dev/shtk_unittest_assert_command.3.html">&lt;code>shtk_unittest_assert_command(3)&lt;/code>&lt;/a> and its supporting &lt;a href="https://shtk.jmmv.dev/shtk_unittest_assert_file.3.html">&lt;code>shtk_unittest_assert_file(3)&lt;/code>&lt;/a> as the features they provide are too numerous to be captured in this post.&lt;/p>
&lt;h1 id="using-gnu-automake-as-a-test-runner">Using GNU Automake as a test runner&lt;/h1>
&lt;p>Up until here, I have shown you the features that the shtk library itself provides&amp;hellip; but a testing library to write test programs with is not very useful on its own. What happens when you want to run more than one test program at once? How do you set up the test environment so that tests always run in a consistent manner, free from side-effects? How do you collect results for reporting?&lt;/p>
&lt;p>This is where test runners come into play, and there are many to choose from. But again, given the nature of shtk and its desire to blend into Unix-y environments, integrating with the de-facto build system of all foundational software is important. So, yes, shtk tests can run via GNU Automake. The test runner provided by this build system isn&amp;rsquo;t state-of-the-art, but it is more than enough for most situations.&lt;/p>
&lt;p>Here is all it takes to hook the earlier &lt;code>demo_test.sh&lt;/code> shtk-based test into an Automake project:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-makefile" data-lang="makefile">&lt;span class="line">&lt;span class="cl">&lt;span class="nv">TESTS&lt;/span> &lt;span class="o">=&lt;/span> demo_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">check_SCRIPTS&lt;/span> &lt;span class="o">=&lt;/span> demo_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">CLEANFILES&lt;/span> &lt;span class="o">+=&lt;/span> demo_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">EXTRA_DIST&lt;/span> &lt;span class="o">+=&lt;/span> demo_test.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">demo_test&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="k">$(&lt;/span>&lt;span class="nv">srcdir&lt;/span>&lt;span class="k">)&lt;/span>/&lt;span class="n">demo_test&lt;/span>.&lt;span class="n">sh&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">$(&lt;/span>AM_V_GEN&lt;span class="k">)&lt;/span>shtk build -m shtk_unittest_main -o &lt;span class="nv">$@&lt;/span> $&amp;lt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You&amp;rsquo;d probably want to add a pkg-config check in &lt;code>configure.ac&lt;/code> to load the path to shtk from the provided &lt;code>shtk.pc&lt;/code> and reference it from here as &lt;code>$(SHTK)&lt;/code>, but I&amp;rsquo;ll leave that as an exercise for you, dear reader.&lt;/p>
&lt;p>After that, if we run &lt;code>make check&lt;/code>, we&amp;rsquo;ll see something like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">make check-TESTS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">PASS: demo_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">============================================================================
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Testsuite summary for Demo
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">============================================================================
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># TOTAL: 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># PASS: 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># SKIP: 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># XFAIL: 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># FAIL: 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># XPASS: 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># ERROR: 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">============================================================================
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Neat. Take a look at the &lt;a href="https://www.gnu.org/software/automake/manual/html_node/Tests.html">test suites documentation for GNU Automake&lt;/a> for more details on how to communicate specific return codes (such as &amp;ldquo;skip&amp;rdquo;) to the runner.&lt;/p>
&lt;h1 id="integrating-with-bazel">Integrating with Bazel&lt;/h1>
&lt;p>GNU Automake is the de-facto build system for open source projects but it&amp;rsquo;s also&amp;hellip; far from great. This is why I &lt;a href="/2022/05/remembering-buildtool.html">created Buildtool eons ago&lt;/a> and why I got interested in Bazel in the first place. So the question is: can we integrate shtk with Bazel? Of course we can!&lt;/p>
&lt;p>For the purposes of this post, I hacked up a Bazel rule to show off how running shtk tests with it would look like. And it looks exactly like you would expect:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;shtk.bzl&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;shtk_test&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">shtk_test&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;demo_test&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">src&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;demo_test.sh&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Followed by:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ bazel test --test_output=streamed :faulty_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WARNING: Streamed test output requested. All tests will be run locally, without sharding, one at a time
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: Analyzed target //:faulty_test (0 packages loaded, 2 targets configured).
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: Found 1 test target...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">faulty_test: I: Testing faulty...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">faulty_test: E: This test fails
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">faulty_test: W: Testing faulty... FAILED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">faulty_test: W: Ran 1 tests; 1 FAILED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FAIL: //:faulty_test (see /home/jmmv/.cache/bazel/_bazel_jmmv/828d51923bded9f03acff0119df51adc/execroot/demo/bazel-out/k8-fastbuild/testlogs/faulty_test/test.log)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Target //:faulty_test up-to-date:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> bazel-bin/faulty_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: Elapsed time: 0.355s, Critical Path: 0.14s
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: 2 processes: 2 linux-sandbox.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: Build completed, 1 test FAILED, 2 total actions
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">//:faulty_test FAILED in 0.0s
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> /home/jmmv/.cache/bazel/_bazel_jmmv/828d51923bded9f03acff0119df51adc/execroot/demo/bazel-out/k8-fastbuild/testlogs/faulty_test/test.log
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Executed 1 out of 1 test: 1 fails locally.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Some of the benefits of the Bazel test runner over GNU Automake&amp;rsquo;s are that Bazel adds proper test isolation and cleanup via its local sandboxing feature and that Bazel provides fine-grained test invalidation when dependencies change. These are the two primary properties you want in a modern test runner because they ensure that only the minimum subset of tests run on a given source code change, and that the test results are deterministic across invocations and machines.&lt;/p>
&lt;h1 id="the-future">The future&lt;/h1>
&lt;p>Despite its many haters, the shell is a pretty OK language &lt;em>if you treat it as such&lt;/em>. You must learn its syntax and its oddities, but once you do, you can write maintainable and moderately-long programs that are, often enough, much simpler than their Python counterparts. These programs have few dependencies and, given sufficient test coverage, can be as robust as other tools. shtk is just an ingredient that can help you in writing such large scripts in a principled manner and, especially, in testing them.&lt;/p>
&lt;p>As for what the future will bring for shtk&amp;hellip; &lt;strong>you tell me!&lt;/strong> I had not worked on this project for 6 years and absolutely nobody asked about it during this time. But&amp;hellip; things have changed a lot since then and there might actually be some interest out there. In preparation for this blog post, I migrated shtk&amp;rsquo;s CI system from Travis to GitHub Actions, created a simple website to serve the API documentation&amp;mdash;which was previously locked behind &lt;code>man&lt;/code> invocations in a terminal&amp;mdash;and moved off from Kyua to GNU Automake as the test runner for simplicity.&lt;/p>
&lt;p>Some ideas about what could be done: additional library modules/functions; a &amp;ldquo;static build&amp;rdquo; feature where the built scripts don&amp;rsquo;t require shtk to be pre-installed; and real Bazel rules (what I showed above was a macro-based hack) to incorporate shtk into your projects so that you can test your command-line tools end-to-end no matter what language they are written in.&lt;/p>
&lt;p>Please let me know if you have any interest by either voting/replying below or reaching out via social media! And don&amp;rsquo;t forget to visit the brand-new homepage at &lt;a href="https://shtk.jmmv.dev/">https://shtk.jmmv.dev/&lt;/a> to read the documentation.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-10-11-shell-hammer-wrench.jpg" length="398237" type="image/jpeg"/></item><item><title>Analyzing OOMs in IntelliJ with Bazel</title><link>https://jmmv.dev/2023/10/analyzing-ooms-in-intellij-with-bazel.html</link><pubDate>Sat, 07 Oct 2023 12:00:00 -0700</pubDate><guid>https://jmmv.dev/2023/10/analyzing-ooms-in-intellij-with-bazel.html</guid><description>&lt;p>A few months ago, we described how we fixed &lt;a href="/2023/03/addressing-bazel-ooms.html">three different OOM scenarios&lt;/a> in our ongoing migration to the Bazel build system here at Snowflake. Things had been sailing along just fine since then&amp;hellip; but a new issue showed up recently: our &lt;a href="https://ij.bazel.build/">IntelliJ with Bazel (IjwB)&lt;/a> Java project started showing OOMs during its sync phase.&lt;/p>
&lt;p>The reason this issue surfaced now is because, as we continue our migration to Bazel, our IjwB project has grown in size. Months ago, our project only covered a Java binary, but now that we have migrated all of its unit and integration tests as well, the project covers them too. It is common for tests to be more expensive to build and run than the binary they validate&amp;mdash;tests depend on the binary&amp;rsquo;s dependencies &lt;em>plus&lt;/em> many other helper tools for testing&amp;mdash;and these caused the project to grow too big to fit in our development environments. Or did they?&lt;/p>
&lt;h1 id="context-setting">Context-setting&lt;/h1>
&lt;p>We run Bazel in a memory-constrained VM. We do this intentionally to support our varied fleet of corp laptops: our new hires get top-of-the-line M2 Max Macbooks, but a substantial number of developers are a few months away from a hardware refresh and may not have as much RAM.&lt;/p>
&lt;p>Up until now, giving a 4GB max heap to Bazel had been plenty to build and test our codebase. But, remember, things weren&amp;rsquo;t always this way: about a year ago, during our initial onboarding of remote execution, we had to bump the max heap size to 12GB. This bump was not sustainable due to the VM memory limits, and these limits forced us to pause and analyze why we needed much more RAM than the previous build system for similar user flows. This principled approach led us to find the right knobs in Bazel to make it run within the more reasonable 4GB limit and thus we avoided bumping up the resource requirements of the VM.&lt;/p>
&lt;p>Syncing our project in IjwB is another one of those situations where a constrained environment has been beneficial to discover inefficiencies and fix them in a way that doesn&amp;rsquo;t require wasting everyone&amp;rsquo;s resources. The naive solution to our problems would have been to increase Bazel&amp;rsquo;s max heap to 12 GB again with a corresponding bump in the VM memory allocation, telling all engineers with older laptops to refresh them. But&amp;hellip; that&amp;rsquo;d have been expensive and, worse, it would have left a sour taste for the ongoing Bazel migration.&lt;/p>
&lt;p>So the question was: if a max heap of 4GB was sufficient to build and test all of our codebase&amp;hellip; why did we need three times more memory &amp;ldquo;just&amp;rdquo; to sync the IjwB project? Our project is big&amp;hellip; but not &lt;em>that&lt;/em> big.&lt;/p>
&lt;h1 id="ijwb-project-syncing-and-sharding">IjwB project syncing and sharding&lt;/h1>
&lt;p>Project syncing in IjwB is an expensive operation. What this process does is build the project&amp;rsquo;s targets with a &lt;a href="https://bazel.build/extending/aspects">Bazel aspect&lt;/a> provided by the &lt;a href="https://plugins.jetbrains.com/plugin/8609-bazel-for-intellij">IjwB plugin&lt;/a>. This aspect attaches to the targets defined in the project file and extracts the information that the IDE needs to index them. This aspect is expensive in terms of memory consumption and was expected to throw off our earlier predictions on Bazel&amp;rsquo;s max heap needs.&lt;/p>
&lt;p>That said, because this aspect is known to be expensive, IjwB provides &lt;a href="https://ij.bazel.build/docs/project-views.html#shard_sync">a feature to shard the syncing process&lt;/a> in an attempt to reduce peak memory consumption. The idea behind project sharding is to make IjwB run the sync process on smaller sets of targets at a time instead of on the full project at once. For example, if the project specifies &lt;code>//server/...&lt;/code> as the target pattern to sync, IjwB will query all targets beneath &lt;code>//server/...&lt;/code>, divide them into roughly-equally sized groups, and then sync those groups separately instead of passing &lt;code>//server/...&lt;/code> to a single Bazel invocation.&lt;/p>
&lt;p>This feature was originally designed at Google to help with syncing gigantic targets in their monorepo, and it worked nicely for them. But, for some reason, it did not work for us. We tried multiple sharding settings and Bazel would still OOM. The key difference between our setup and Google&amp;rsquo;s was the memory constraint on Bazel&amp;rsquo;s max heap: we set this to 4GB while Google typically runs Bazel on powerful workstations with memory to spare and thus much higher max heap sizes.&lt;/p>
&lt;p>Could we do anything about it?&lt;/p>
&lt;h1 id="profiling">Profiling&lt;/h1>
&lt;p>To understand what was going on, we had to profile heap usage. Here is a first look into Bazel&amp;rsquo;s memory consumption as displayed by VisualVM for the duration of the IjwB project sync. This run was done with about 8 shards and a max heap of 12GB to try to measure the &amp;ldquo;worst case&amp;rdquo; scenario for our build:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-07-12gb-heap-no-discard.png" class="with-border">
&lt;figcaption>Timeline of heap memory usage as captured by VisualVM with a max heap size of 12GB. The picture shows memory growing to about 7GB of retained heap even after two GC cycles.&lt;/figcaption>
&lt;/figure>
&lt;p>What&amp;rsquo;s interesting to note about this profile is that memory consumption grows over time and that JVM Garbage Collection (GC) cycles cannot bring it down to the initial low baseline. More importantly, the GC cycle after the sync steps complete still leaves the Bazel process consuming about 7GB. Based on this data, a small heap of 4GB seemed unfeasible given that Bazel wanted to retain much more memory than that. But&amp;hellip; this was surprising because sharded syncing should have kept memory usage low. So, was this memory consumption legitimate or a memory leak?&lt;/p>
&lt;p>To answer this question, I had to peek into a heap dump that I captured in VisualVM after one of the first shards completed syncing. I did this at the beginning of the process and not at the end to try to keep the dump small, but regardless, I ended up with a 5GB dump.&lt;/p>
&lt;p>Opening the heap dump in a visualization tool was its own odyssey, which I expected going in due to the dump&amp;rsquo;s size. &lt;a href="https://eclipse.dev/mat/">Eclipse Memory Analyzer&lt;/a> (MAT for short) is a highly recommended tool, so I tried to open the profile in it. After more than an hour, however, MAT wasn&amp;rsquo;t able to finish. Looking a bit more into this, I found that MAT was configured with a 1GB max heap&amp;hellip; and thus the JVM was GC-thrashing. Bumping&amp;mdash;hah, the irony!&amp;mdash;the MAT&amp;rsquo;s max heap to 8GB was sufficient to let it open the profile in just a few minutes.&lt;/p>
&lt;p>Upon opening MAT and asking for a &lt;strong>Suspected Leaks&lt;/strong> report, here is what I faced:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-07-leak-suspects-overview.png" class="with-border">
&lt;figcaption>MAT showing the Suspected Leaks overview.&lt;/figcaption>
&lt;/figure>
&lt;p>Based on this initial data, we can see that &lt;a href="https://bazel.build/reference/skyframe">Skyframe&lt;/a>&amp;mdash;the thing that holds Bazel&amp;rsquo;s in-memory graph and performs operations on it&amp;mdash;is holding onto the retained memory. But MAT is awesome! We can click on &lt;strong>Details&lt;/strong> to dig further:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-07-leak-suspects-details.png" class="with-border">
&lt;figcaption>MAT showing the Suspected Leaks details.&lt;/figcaption>
&lt;/figure>
&lt;p>And finally, we can right-click onto the Skyframe executor object retaining those 3GB of RAM to dive into the objects hanging from it:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-07-leak-suspects-classes.png" class="with-border">
&lt;figcaption>MAT drilling down into the classes consuming the most memory.&lt;/figcaption>
&lt;/figure>
&lt;p>What we see here is that below the Skyframe graph instance, memory consumption is smeared all over the place. This makes sense: Skyframe is a graph engine so memory usage will be distributed across all nodes that the engine maintains. Some of those nodes will be heavier than others, but we should expect to see a reasonably even spread.&lt;/p>
&lt;p>While poking through these entries, I reached a node that claimed &lt;code>SourceArtifactCache&lt;/code> was retaining most of the memory. In retrospect, this conclusion was wrong because &lt;code>SourceArtifactCache&lt;/code> was holding onto about 3,000,000 bytes, which was three orders of magnitude smaller than the total used memory&amp;hellip; but I misread the numbers and thought they were the same. That was a fortunate accident though. Looking through the source code for the &lt;code>SourceArtifactCache&lt;/code>, I found that it is only discarded when the analysis graph is discarded in full. And looking a bit further, I found the &lt;code>--discard_analysis_cache&lt;/code> flag to forcibly discard this cache.&lt;/p>
&lt;p>Bingo. By adding &lt;code>--discard_analysis_cache&lt;/code> to the &lt;code>sync_flags&lt;/code> list in the IjwB project definition, I could observe the following behavior during the project sync, still with a 12GB max heap:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-07-12gb-heap-discard.png" class="with-border">
&lt;figcaption>Timeline of heap memory usage as captured by VisualVM with a max heap size of 12GB. The picture shows memory growing to about 5GB of retained heap, and three highlights for when graph discards happen.&lt;/figcaption>
&lt;/figure>
&lt;p>Note the clear memory consumption drops that happen after every shard finishes syncing and Bazel discards the analysis graph. Furthermore, we can see that peak memory usage now hovers at around 4GB throughout the process, which is much better than the previous 8GB. This means that combining this flag with the sharded project sync in IjwB could lead to the initial promise of reducing memory usage by using sharding.&lt;/p>
&lt;p>Knowing this, the final question was: is the memory used above 4GB throughout this process retained, or is it memory that could be discarded by more frequent GC activity? In other words: if we clamp the max heap back down to 4GB, will GC kick in and maintain Bazel under it? Here is the answer:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-07-4gb-heap-discard.png" class="with-border">
&lt;figcaption>Timeline of heap memory usage as captured by VisualVM with a max heap size of 4GB. The picture shows memory growing close to 4GB of retained heap, with a sawtooth pattern indicating frequent GC cycles at that point in time, and four highlights for when graph discards happen later on.&lt;/figcaption>
&lt;/figure>
&lt;p>Voila. GC struggled to keep up for a brief period of time as shown in the picture, but the whole project sync process was able to complete and remained at around 2&amp;ndash;3GB throughout.&lt;/p>
&lt;p>The GC churn depicted here is still not great but it&amp;rsquo;s only a deficiency of our sharding approach. I mentioned at the beginning of the article that IjwB is in charge of project sharding, but that was an oversimplification. Due to &lt;a href="https://github.com/bazelbuild/intellij/issues/4546">an issue in the IjwB plugin&lt;/a>, we have had to temporarily implement our own sharding strategy, and our sharding causes one of the initial shards to be larger than the others. We expect to see better behavior once we switch to the plugin&amp;rsquo;s built-in sharding strategy now that &lt;a href="https://github.com/bazelbuild/intellij/pull/5085">the issue has been fixed&lt;/a>.&lt;/p>
&lt;h1 id="takeaways">Takeaways&lt;/h1>
&lt;p>The obvious takeaway from all of this is: if IjwB&amp;rsquo;s sharding feature is insufficient to let you sync large projects under a tight memory constraint, try to pass &lt;code>--discard_analysis_cache&lt;/code> in &lt;code>sync_flags&lt;/code> and see if it helps. This may let you lower your overall Bazel memory footprint, freeing resources for other processes.&lt;/p>
&lt;p>But what&amp;rsquo;s more interesting is that while environments with tight memory limits are annoying to deal with, pausing to analyze why new Bazel-based workflows seem to need more memory than legacy ones can help identify alternative solutions. In the previous article, we found how to keep Bazel&amp;rsquo;s memory under control when handling hundreds of remote build actions, and in this article, we found how to tame memory usage during IjwB project syncs. While dealing with these issues is tricky, it is crucial to address them during a build system migration to increase trust in the new system.&lt;/p>
&lt;p>To conclude, let me say that memory-constrained scenarios like ours are not common and that Bazel is already doing the right thing in the common case. That doesn&amp;rsquo;t mean there is no room for improvement, so we filed bug &lt;a href="https://github.com/bazelbuild/bazel/issues/19412">#19412&lt;/a> to start a discussion. The upstream Bazel developers confirmed that they are working on optimizing memory consumption and also suggested that we try other flags such as &lt;code>--notrack_incremental_state&lt;/code>. Furthermore, there might actually be undiagnosed inefficiencies in the aspect that IjwB uses to sync the project. Watch that bug for further developments!&lt;/p></description></item><item><title>5 ways to instantiate Rust structs in tests</title><link>https://jmmv.dev/2023/10/rust-test-structs.html</link><pubDate>Fri, 06 Oct 2023 09:00:00 -0700</pubDate><guid>https://jmmv.dev/2023/10/rust-test-structs.html</guid><description>&lt;p>I&amp;rsquo;m a big fan of static typing and I&amp;rsquo;ve found that using narrow types for each entity in the object model of my programs reduces errors. Rust is particularly well-suited at this task: its lack of implicit type conversions eliminates surprises, and its ownership semantics allow type transformations with zero cost.&lt;/p>
&lt;p>Unfortunately, (ab)using narrow types in an app&amp;rsquo;s domain is &lt;em>really&lt;/em> annoying when writing tests. While non-test code rarely instantiates new objects&amp;mdash;in the case of a REST service, this would only happen at the service&amp;rsquo;s boundaries&amp;mdash;tests instantiate objects infinitely more times than non-test code. Code patterns that may seem reasonable in non-test code can become unbearable in tests.&lt;/p>
&lt;p>In this post, I want to look into the various ways in which you can instantiate strongly-typed objects. For each, I show examples and describe their pros and cons. And yes, as a matter of fact, I have tried them all before&amp;hellip; and I can&amp;rsquo;t yet make my mind as to which one is best.&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h1 id="context-setting">Context-setting&lt;/h1>
&lt;p>Let me introduce you to the &lt;code>Comment&lt;/code> type from the EndTRACKER codebase&amp;mdash;a type that represents a textual comment that someone left on a webpage. I&amp;rsquo;ve simplified it a little for illustration purposes, but the core properties of the type remain:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="k">struct&lt;/span> &lt;span class="nc">Comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">site_id&lt;/span>: &lt;span class="nc">Uuid&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">path&lt;/span>: &lt;span class="nc">Url&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">timestamp&lt;/span>: &lt;span class="nc">OffsetDateTime&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">content&lt;/span>: &lt;span class="nb">String&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">author&lt;/span>: &lt;span class="nb">Option&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="nb">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">email&lt;/span>: &lt;span class="nb">Option&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">EmailAddress&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Said core properties are:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Four required fields for every comment: &lt;code>site_id&lt;/code>, &lt;code>path&lt;/code>, &lt;code>timestamp&lt;/code> and &lt;code>content&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Two optional fields that are only present if the user writing the comment chose to provide them: &lt;code>author&lt;/code> and &lt;code>email&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Strongly-typed fields. Note that only two of them are raw strings; the rest are &lt;em>narrower&lt;/em> types that enforce structure on their values.&lt;/p>
&lt;p>This is important because, for example, while URLs can be represented as strings, they are &lt;em>not&lt;/em> strings. The domain of all possible URLs is narrower than the domain of all possible strings because URLs have internal structure. Using a narrow type to represent URLs enforces that, once a URL object exists, we can pass it around and all consumers can assume it has undergone proper validation.&lt;/p>
&lt;p>Note that strong typing can be done in pretty much any language, really, but Rust shines here. It also helps that using narrow types is common practice in this language: in JavaScript, for example, the above would probably have been represented as a loosely-typed &lt;code>Object&lt;/code>; and in Python, it would have been shoehorned into a string-to-whatever dictionary.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Let&amp;rsquo;s look at the ways in which &lt;code>Comment&lt;/code> objects can be constructed. Remember that I&amp;rsquo;m focusing on object creation as part of tests. For this reason, it is not necessary to propagate errors to the caller: panicking internally to fail the test is just fine, which simplifies the design a lot.&lt;/p>
&lt;h1 id="option-1-struct-literals">Option 1: Struct literals&lt;/h1>
&lt;p>In the most simple form, a test instantiates a &lt;code>Comment&lt;/code> object by specifying &lt;em>all&lt;/em> fields:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">site_id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">path&lt;/span>: &lt;span class="nc">url&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;http://example.com/post.html&amp;#34;&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">timestamp&lt;/span>: &lt;span class="nc">datetime&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2023&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">03&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">19&lt;/span>:&lt;span class="mi">25&lt;/span>:&lt;span class="mi">00&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="no">UTC&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">content&lt;/span>: &lt;span class="s">&amp;#34;Irrelevant text&amp;#34;&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">to_owned&lt;/span>&lt;span class="p">(),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">author&lt;/span>: &lt;span class="nb">Some&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;The Author&amp;#34;&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">to_owned&lt;/span>&lt;span class="p">()),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">email&lt;/span>: &lt;span class="nb">Some&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;the-email@example.com&amp;#34;&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">into&lt;/span>&lt;span class="p">()),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Pros:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Clarity.&lt;/strong> It&amp;rsquo;s painfully obvious what each field contains in every test object.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Refactor-proof.&lt;/strong> When modifying the &lt;code>Comment&lt;/code> definition, you are forced to revise all places where the object is constructed. This makes you reassess whether existing tests need to care about the changes or not.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Cons:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Lack of conciseness.&lt;/strong> Not all tests care about all possible fields of a type. Some tests may want to validate ordering, in which case they care about specific &lt;code>timestamp&lt;/code> values, whereas other tests may want to check protections against HTML injection, in which case they care about &lt;code>content&lt;/code>. But this is not clear in the test because the test is forced to specify values for all fields even if they are irrelevant.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Refactoring difficulties.&lt;/strong> Even though I listed refactoring in the pros, refactoring is also a con. Having to adjust tens or hundreds of tests every time the struct definition changes is a daunting task, particularly when, in general, existing tests do not care about new fields.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="option-2-the-default-trait">Option 2: The Default trait&lt;/h1>
&lt;p>The standard answer to the cons listed above is to implement &lt;code>Default&lt;/code> for the type and thus rely on default values for all fields that are irrelevant in a given context. Ideally, by deriving or implementing &lt;code>Default&lt;/code>, we would do something like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">site_id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">path&lt;/span>: &lt;span class="nc">url&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;http://example.com/post.html&amp;#34;&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="o">..&lt;/span>&lt;span class="nb">Default&lt;/span>::&lt;span class="nb">Default&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Unfortunately, this does not work other than for trivial structs. The problem here is that not all types in the &lt;code>Comment&lt;/code> struct implement &lt;code>Default&lt;/code>, and this problem compounds with any additional type you nest. In this particular example, a &lt;code>Url&lt;/code> cannot be empty and an &lt;code>OffsetDateTime&lt;/code> does not have a reasonable zero value.&lt;/p>
&lt;p>One possible solution to this issue is fabricate fake values for all fields. To do this, you can rely on the &lt;code>derivative&lt;/code> crate and use it to supply alternate default values for those fields that don&amp;rsquo;t have one of their own. It is critical to do this &lt;em>only&lt;/em> for debug builds so that these fake definitions never taint production. Here is how this would look like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#[cfg_attr(test, derive(Derivative))]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[cfg_attr(test, derivative(Default))]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">pub&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">struct&lt;/span> &lt;span class="nc">Comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="cp">#[cfg_attr(test, derivative(Default(value = &lt;/span>&lt;span class="s">&amp;#34;Uuid::new_v4()&amp;#34;&lt;/span>&lt;span class="cp">)))]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">pub&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">site_id&lt;/span>: &lt;span class="nc">Uuid&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="cp">#[cfg_attr(test, derivative(Default(value = r#&lt;/span>&lt;span class="s">&amp;#34;url!(&amp;#34;&lt;/span>&lt;span class="cp">https://UNSET/&lt;/span>&lt;span class="s">&amp;#34;)&amp;#34;&lt;/span>&lt;span class="cp">#)))]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">pub&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">path&lt;/span>: &lt;span class="nc">Url&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="cp">#[cfg_attr(test, derivative(Default(value = &lt;/span>&lt;span class="s">&amp;#34;OffsetDateTime::UNIX_EPOCH&amp;#34;&lt;/span>&lt;span class="cp">)))]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">pub&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">timestamp&lt;/span>: &lt;span class="nc">OffsetDateTime&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="cp">#[cfg_attr(test, derivative(Default(value = r#&lt;/span>&lt;span class="s">&amp;#34;&amp;#34;&lt;/span>&lt;span class="cp">Irrelevant&lt;/span>&lt;span class="s">&amp;#34;.to_owned()&amp;#34;&lt;/span>&lt;span class="cp">#)))]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">pub&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">content&lt;/span>: &lt;span class="nb">String&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">pub&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">author&lt;/span>: &lt;span class="nb">Option&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="nb">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">pub&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">email&lt;/span>: &lt;span class="nb">Option&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">EmailAddress&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>With this, the above instantiation of a &lt;code>Comment&lt;/code> with partial defaults becomes possible.&lt;/p>
&lt;p>Pros:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Concise and refactor-friendly.&lt;/strong> Tests can now declare objects with only the few properties they care about. Due to this, adding new fields to the &lt;code>Comment&lt;/code> struct does not require modifying the majority of existing tests.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Standard.&lt;/strong> Deriving &lt;code>Default&lt;/code> is a common idiom in Rust, so this leads to few surprises.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Cons:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Complexity.&lt;/strong> The type definitions are quite convoluted, particularly due to the need to couple these fake values to debug builds only.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Noisy.&lt;/strong> Having to call &lt;code>..Default::default()&lt;/code> each time we instantiate a struct is annoying and adds a lot of visual noise.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="option-3-macros">Option 3: Macros&lt;/h1>
&lt;p>Using macros to instantiate test data is a common idiom in Rust: the macros provide a simpler syntax to instantiate objects and they forcibly unwrap result values because it&amp;rsquo;s OK to panic tests on invalid data. In fact, note that in the above examples I&amp;rsquo;ve already used two macros: &lt;code>url!&lt;/code> to construct &lt;code>Url&lt;/code> values from hardcoded strings assumed to be valid, and &lt;code>datetime!&lt;/code> to construct &lt;code>OffsetDateTime&lt;/code> values from a readable mini-DSL.&lt;/p>
&lt;p>We could define a &lt;code>comment!&lt;/code> macro that allowed &amp;ldquo;keyword-like&amp;rdquo; arguments to instantiate a test &lt;code>Comment&lt;/code> object, like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="fm">comment!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">site_id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">path&lt;/span>: &lt;span class="nc">url&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;http://example.com/post.html&amp;#34;&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Pros:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Concise.&lt;/strong> Same as the &lt;code>Default&lt;/code> approach: tests only declare the properties they must declare for the test to pass.&lt;/li>
&lt;/ul>
&lt;p>Cons:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Refactoring-unfriendly.&lt;/strong> The Rust auto-formatter does not reformat code inside macros. I rely on this feature too much these days because it&amp;rsquo;s very liberating to not have to care about manual formatting, so this is a non-option for me.&lt;/li>
&lt;/ul>
&lt;h1 id="option-4-the-builder-pattern">Option 4: The builder pattern&lt;/h1>
&lt;p>The next possibility is to use the builder pattern, which I have &lt;a href="/2020/12/builder-pattern-for-tests.html">previously leveraged to define declarative tests&lt;/a>. Constructing a &lt;code>Comment&lt;/code> would then look something like this and, in fact, that&amp;rsquo;s what I had in the code for a little while:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">CommentBuilder&lt;/span>::&lt;span class="n">new&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">site_id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="fm">url!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;https://example.com/page.html&amp;#34;&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="fm">datetime!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2023&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">03&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">19&lt;/span>:&lt;span class="mi">25&lt;/span>:&lt;span class="mi">00&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="no">UTC&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;Irrelevant text&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">unwrap&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">with_author&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;The author&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">unwrap&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">with_email&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;the-email@example.com&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">unwrap&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">build&lt;/span>&lt;span class="p">();&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This usage of a builder is a bit unorthodox and&amp;hellip; really ugly: the constructor takes positional arguments for all required fields and the various setters return errors when the input values cannot be converted to the inner types that back them. These design decisions came from the fact that I used this builder in non-test code too, so errors had to be propagated.&lt;/p>
&lt;p>But this is not the only way to define a builder. A more traditional application of the builder pattern would result in:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">CommentBuilder&lt;/span>::&lt;span class="n">default&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">site_id&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">site_id&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="fm">url!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;https://example.com/page.html&amp;#34;&lt;/span>&lt;span class="p">)))&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">timestamp&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="fm">datetime!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2023&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">03&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">19&lt;/span>:&lt;span class="mi">25&lt;/span>:&lt;span class="mi">00&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="no">UTC&lt;/span>&lt;span class="p">))&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">content&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;Irrelevant text&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">author&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;The author&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">email&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;the-email@example.com&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">build&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">unwrap&lt;/span>&lt;span class="p">();&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This second version of the pattern looks better in general (and you could argue that the original version was a mistake). So let&amp;rsquo;s analyze this second version.&lt;/p>
&lt;p>Pros:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Automatic type conversions.&lt;/strong> The setters can &lt;a href="/2020/04/rust-into-trait.html">leverage &lt;code>Into&lt;/code>&lt;/a> and &lt;code>AsRef&lt;/code>, making it possible to call them quite naturally without needing to create auxiliary types by hand. Note how, for example, &lt;code>email()&lt;/code> takes a string even if the backing type is &lt;code>EmailAddress&lt;/code> because the setter accepts &lt;code>Into&amp;lt;EmailAddress&amp;gt;&lt;/code> and the type implements &lt;code>From&amp;lt;&amp;amp;'static str&amp;gt;&lt;/code> (in test builds &lt;em>only&lt;/em>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Conciseness.&lt;/strong> As is the case for the &lt;code>Default&lt;/code> and the macro options, this solution also accepts specifying only the fields that are required for each test. The builder can set defaults for everything else.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Cons:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Verbosity.&lt;/strong> This is no simpler than the &lt;code>Default&lt;/code> option and requires non-trivial code to implement the builder itself.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Delayed validation.&lt;/strong> Delaying validation until the call to &lt;code>build()&lt;/code> isn&amp;rsquo;t always easy. Consider &lt;code>email&lt;/code> again: if we make the &lt;code>email()&lt;/code> setter construct the internal &lt;code>EmailAddress&lt;/code> object, then &lt;code>email()&lt;/code> has to either return an error (a requirement for production usage) or panic (if the builder is exclusively for tests). But if we try to delay error reporting until &lt;code>build()&lt;/code> is called, then the setter cannot leverage &lt;code>Into&lt;/code> and needs to either accept strings alone or already-constructed &lt;code>EmailAddress&lt;/code> objects.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="option-5-helper-functions">Option 5: Helper functions&lt;/h1>
&lt;p>The final possibility is to define helper functions to instantiate our test objects. And if we are defining helper functions, those can do additional work like storing the objects in a database (which is what most of my tests need to do anyway). Here is an example of such a function:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">context&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TestContext&lt;/span>::&lt;span class="n">setup&lt;/span>&lt;span class="p">();&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="c1">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">comment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">context&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">put_comment&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">site_id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="fm">url!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;https://example.com/page.html&amp;#34;&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="fm">datetime!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2023&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">03&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">19&lt;/span>:&lt;span class="mi">25&lt;/span>:&lt;span class="mi">00&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="no">UTC&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;Hello&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nb">None&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">await&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Pros:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Extra logic.&lt;/strong> A helper function can take care of instantiating the test object, but can &lt;em>also&lt;/em> perform other operations such as persisting the object. For tests, this can turn out to be very useful in encapsulating sequences of operations.&lt;/li>
&lt;/ul>
&lt;p>Cons:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Inflexibility.&lt;/strong> Helper functions sound nice at first because they only take the fewest arguments possible to satisfy the needs of the tests. But things get unwieldy quickly: in the example above, you can already see a wart in the API because there is a confusing &lt;code>None&lt;/code> that should probably not be there. This ends happening because different tests need different properties to be set and a single function won&amp;rsquo;t satisfy them all, so you end up with parameterized helper functions that contain superfluous in the common case, or with multiple helper functions targeted at different test scenarios.&lt;/li>
&lt;/ul>
&lt;p>This approach is very tempting to use because declaring new functions is easy and looks simple, but I&amp;rsquo;ve &lt;em>never ever&lt;/em> seen it evolve well long-term in any language. Stay away except for the most trivial cases.&lt;/p>
&lt;h1 id="whats-best">What&amp;rsquo;s best?&lt;/h1>
&lt;p>To be honest&amp;hellip; I do not know. I have tried all of the above and I&amp;rsquo;m not completely satisfied with any option. To let you into a secret, the EndTRACKER data model currently contains a mishmash of all these options because I&amp;rsquo;ve been experimenting with new ideas over time and haven&amp;rsquo;t yet settled on the one I like the best. (Yes, yes, I know. Consistency should have trumped &amp;ldquo;prettiness&amp;rdquo;, but hey, I write side projects because I enjoy exploring different dark corners of my tech of choice.)&lt;/p>
&lt;p>Right now my thoughts are these: the builder pattern seems to be the nicest option &lt;em>if&lt;/em> you restrict it to tests, because then the builder can encapsulate error unwrapping and callers set all fields by name. However, I&amp;rsquo;m having a hard time justifying this option in favor of the &lt;code>Default&lt;/code> option, because callers look equally complex and the builder option requires a lot of boilerplate to write the builders themselves. And I kinda would like to use the macro option, but the fact that it doesn&amp;rsquo;t work well with auto-formatting is a deal breaker.&lt;/p>
&lt;p>What are &lt;em>your&lt;/em> thoughts?&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-10-06-rust-test-structs.png" length="138979" type="image/jpeg"/></item><item><title>Good performance is not just big O</title><link>https://jmmv.dev/2023/09/performance-is-not-big-o.html</link><pubDate>Fri, 08 Sep 2023 10:00:00 -0700</pubDate><guid>https://jmmv.dev/2023/09/performance-is-not-big-o.html</guid><description>&lt;p>Having a fast and responsive app is orthogonal to &amp;ldquo;knowing your big &lt;i>O&lt;/i>s&amp;rdquo;. Unfortunately, most tech companies over-emphasize algorithms in interviews and downplay systems knowledge, and I believe that&amp;rsquo;s one reason behind sluggish apps and bloated systems.&lt;/p>
&lt;p>I&amp;rsquo;ve seen this play out repeatedly. Interviewers ask a LeetCode-style coding question, which is then followed by the ritual of discussing time and memory complexity. Candidates ace the answers. But then&amp;hellip; their &amp;ldquo;real&amp;rdquo; code suffers from subtle yet impactful performance problems.&lt;/p>
&lt;p>Focusing on big &lt;em>O&lt;/em> complexity rarely matters in most apps. Sure, it&amp;rsquo;s important to think about your algorithmic choices, but there are so many more details to worry about that have a direct impact on app performance and responsiveness. Let&amp;rsquo;s look at a bunch of them!&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>On algorithms&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>📜 Is your complex O(n) algorithm faster than the trivial O(n&lt;sup>2&lt;/sup>)? Theoretical complexity matters, but know your expected value of &amp;ldquo;n&amp;rdquo;. The linear algorithm may be slower than the quadratic one for your specific scenarios and harder to prove correct.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>📜 Are you aware of how interfaces can bite you? E.g. in Java, the &lt;code>List.get&lt;/code> generic method will run in O(1) time for &lt;code>ArrayList&lt;/code> but in O(n) time for &lt;code>LinkedList&lt;/code>, and computing dict hash keys is likely not O(1). These are &lt;em>not&lt;/em> obvious at the call site.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>📜 Do you grasp how much work fits in short periods of time? 1ps, 1ns, 1us, 1ms, 1s&amp;hellip; they all sound small but their relative differences are huge. Map them to 1 second, 16 minutes, 277 hours, 380 months, and 317 centuries respectively. Not the same, huh?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>On storage&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>💾 Where does your data live? Different memory/storage mediums have vastly different access times. Know the relative differences in speed between register accesses (ps), L1/L2/L3 (few ns), RAM (many ns), SSD (us), HDD (few ms), and network (many ms).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>💾 How do you access storage drives? Large sequential I/O operations are faster than lots of random small ones. This is true of HDDs (seek time is ~3-10ms), but also of SSDs due to the fact that processing more ops takes more processing time.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>💾 What about the file system on top of those drives? ext4, ZFS, NTFS&amp;hellip; they are all vastly different, and the types of I/O patterns that work well in one may be slow in another.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>💾 Are you accessing an SSD or an old spinning hard disk? Hard disks still exist. It might be safe to assume SSDs for certain apps, but not always. E.g. users may store large photo libraries in HDDs: can you handle I/O from those efficiently?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>💾 Are you doing pure data copies via the CPU? There are features like DMA to offload data transfers to I/O devices, and there are features to minimize userspace&amp;lt;-&amp;gt;kernel copies. But, in any case, memory bandwidth isn&amp;rsquo;t free and is rarely thought about.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>On networking&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>🌐 Do you know that high latency usually limits max bandwidth? Bandwidth and latency are two orthogonal metrics. Most networked apps will probably feel fine on a low-bandwidth connection but will feel terrible on a high-latency one. Simulate these scenarios.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🌐 How do you handle high network latency? Does your code block, slowing down everything else? Do you really have to block the UI? Can you schedule other work too happen in the meantime?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🌐 How many network requests do you need per interaction? Each request adds a multi-ms penalty and every request increases the chances of hitting high latency. If a service you depend on gives you p50=10ms and p99=1s, you&amp;rsquo;ll hit a 1s delay if you send 100 requests.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🌐 How do you handle retries on failed requests? Any retry will tank performance and how you expose or hide what&amp;rsquo;s going on can make a world of a difference. Perception matters.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>On data handling&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>❄️ Are you using your database&amp;rsquo;s query facilities or are you fetching all data and then filtering on your own? Databases can perform elaborate queries. Favor running those on the database: the server is closer to the data and you&amp;rsquo;ll minimize network transfers.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>❄️ Are your database queries degrading to full table scans? Maybe you don&amp;rsquo;t have the right indexes or partitioning schemes to support the common queries that your app needs. Analyze and profile query execution. You probably don&amp;rsquo;t need to jump to NoSQL.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🪵 How many log messages do you emit? Logging is not free. It has a cost on performance (I&amp;rsquo;ve seen servers spend ~20% of their CPU &lt;em>just&lt;/em> for background logging, all the time), and noisy logs also have an operational cost.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>On CPU and memory&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>🖥️ How do you lay large amounts of data in memory? What are the access patterns? Cache locality matters. Remember the relative differences in access times between the L1, L2 and L3 caches vs. main memory (days vs. years if scaled up).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🖥️ How data-intensive are your tight loops? It&amp;rsquo;s easy to think about CPU speed, RAM usage and I/O times&amp;hellip; but memory bandwidth is a fourth dimension that almost nobody thinks about, and it is becoming scarcer with faster CPUs and I/O.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>On concurrency&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>🧵 Do you take advantage of multiple cores? Single cores aren&amp;rsquo;t getting faster fast enough anymore, but computers usually have cores to spare. Can you use them at all? Effectively?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🧵 Do you use multiple threads to parallelize CPU-intensive operations, or do you use them to handle blocking I/O? In the former case, you want as many threads as cores. In the latter, switching to an event loop model may work better than a large thread pool.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🧵 Do you perform expensive computation on the thread that&amp;rsquo;s responsive for the app&amp;rsquo;s UI? This will introduce pauses and render your app unusable for periods of time, which will make it feel slow. Perception matters.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>On graphics&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>✏️ Are you rendering directly onto the screen? Flushing your drawing operations right away? Read on double buffering, but beware of the latency you introduce by delaying the final display.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>✏️ Are you leveraging your graphic card&amp;rsquo;s features, or are you drawing on the CPU? Contrary to popular belief, fancy desktop effects are not expensive if done on the GPU&amp;mdash;and, actually, doing them on the GPU frees CPU resources.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>On development time&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>🗣️ How much performance are you leaving on the table by &amp;ldquo;coding faster&amp;rdquo; in an interpreted language? Computers might be &amp;ldquo;fast enough&amp;rdquo; now, but interpreted languages tend to be slower than compiled ones and may make the overall system sluggish.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🪨 How big is your compiled app? Multi-MB apps are a problem when downloaded over the network, but they are also a problem on disk because they are slow to install and uninstall. Big apps may run fast, but they start slow. Perception matters.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>⌚ How long does your code take to compile? If it takes too long, the team suffers and features and bug fixes will be delayed. Different choices in how you write code and how you modularize it can bring big differences in productivity.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>⌚ How long do the tests take to run? If they take too long, they won&amp;rsquo;t be run on every commit, introducing friction for everyone else down the road and delaying product launches.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>That&amp;rsquo;s all I could think of for now! I&amp;rsquo;m not a performance expert at all, but I do like systems and enjoy thinking about their holistic behavior. If you have any more tips, feel free to add them to the thread and I may incorporate them into the list!&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-09-08-speed-bumps-limit.jpg" length="372231" type="image/jpeg"/></item><item><title>Costs exposed: Frameworks</title><link>https://jmmv.dev/2023/08/costs-exposed-frameworks.html</link><pubDate>Thu, 31 Aug 2023 07:00:00 -0700</pubDate><guid>https://jmmv.dev/2023/08/costs-exposed-frameworks.html</guid><description>&lt;p>&lt;a href="/2023/06/fast-machines-slow-machines.html">&amp;ldquo;Fast machines, slow machines&amp;rdquo;&lt;/a>&amp;hellip; ah, the post that spawned these series. As I frantically typed that article while replying to angry tweets, the thought came to mind: software engineering as a whole is hyper-focused on lowering the costs to write new code, yet there is a disregard for the costs that these improvements bring to other disciplines in a company on even to end users.&lt;/p>
&lt;p>So, in this series finale, I want to compare how some choices that apparently lower development costs actually increase costs elsewhere. I also want to highlight how, if we made different decisions during development, we could possibly expose those extra costs early on. This is beneficial because exposing costs upfront allows us to make tough choices when there is still a chance of changing course.&lt;/p>
&lt;p>To make things specific, I will look at how the use of modern frameworks that facilitate development can end up hurting performance, reliability, and usability. So let&amp;rsquo;s start with a three-part rant first (sorry) and then let&amp;rsquo;s look at what we might do.&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;hr>
&lt;p>First, we have performance problems caused by the layers upon layers of &lt;a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/">leaky abstractions&lt;/a> that frameworks add.&lt;/p>
&lt;p>Every layer of abstraction that we add to a piece of software hurts performance: each layer adds code and, with very few exceptions, more code requires more cycles to build and run. As an example, think about the ever-increasing network round trips that the simplest interaction with an app has to perform and how poorly these degrade with bad network conditions. Or think about how slowly a run-of-the-mill Electron app starts and how much disk space it takes.&lt;/p>
&lt;p>Sadly, this piling of abstraction layers has been happening for years. One possible rationale: the benefits of adding one more layer look great on paper and the incremental cost of such layer tends to be small, so the cost is easy to justify. It makes sense every time. Unfortunately, when many of these seemingly-small costs compound, systems become sluggish.&lt;/p>
&lt;p>&amp;ldquo;But the developers saved some time!&amp;rdquo; I hear&amp;hellip; while these savings in coding costs transform into &lt;em>everyone else&lt;/em> requiring more powerful machines over time. End users have to upgrade their phones and laptops periodically just to keep up with the software bloat treadmill, and what they can do with their newer hardware isn&amp;rsquo;t massively different from what they could do with the iteration that came right before.&lt;/p>
&lt;p>Plus these slowdowns impact production servers as well, not just end users, and the extra costs in the datacenter are orders of magnitude larger than what a single user will experience. I&amp;rsquo;m still shocked by how, for example, Google has insanely-fast internal infrastructure&amp;hellip; yet those incredible systems exist to support huge binaries and highly-coupled micro-services that maybe shouldn&amp;rsquo;t have existed in their current form. For example, we did have discussions in the Bazel team about adding limits to what a build should support, and we did start &lt;a href="/2021/03/build-time-slis-slos.html">measuring costs&lt;/a> to try to address those&amp;hellip; but it was too late to tame the beast.&lt;/p>
&lt;hr>
&lt;p>Second, we have &amp;ldquo;DevOps problems&amp;rdquo; caused by the &amp;ldquo;easy-to-use&amp;rdquo; frameworks and their tooling.&lt;/p>
&lt;p>The fact that writing code is easier than before does not necessarily mean that deploying and maintaining the resulting systems is easier too. In fact, the opposite tends to happen: these days it sounds inconceivable to launch a service on just one machine, while it was the norm not so long ago. &amp;ldquo;How will it scale to billions of users? How will it have 100 9s of reliability?&amp;rdquo; everyone asks, without facing the reality that scaling needs may never arise or that occasional downtime is acceptable.&lt;/p>
&lt;p>Instead, we adopt languages with complex runtimes and fragile and dog-slow tooling, and we push micro-service architectures from the get go. We end up with systems that require cluster orchestrators like Kubernetes, distributed storage, messaging queues, complex monitoring systems, containers&amp;hellip; or, in other words, a myriad of dependencies, each needing a different language runtime, deployment practices, and operational checklists. Running these systems now requires multiple large SRE teams.&lt;/p>
&lt;p>Paradoxically, I would even say that the risk of downtime in these often-over-engineered systems is higher than the simpler alternatives. Operating a single machine exposed the cost of needing reliable hardware, power, and a few sysadmins, while operating large distributed systems hides such cost behind &amp;ldquo;unavoidable&amp;rdquo; cloud bills, confusing reporting structures, and a bunch of &lt;a href="/2023/08/costs-exposed-on-call-ticket-handling.html">poorly-run support rotations&lt;/a>. But hey, these problems are so detached from the initial coding activities&amp;mdash;and sometimes from the developers themselves!&amp;mdash;that it&amp;rsquo;s hard to think about the consequences of favoring certain languages or frameworks.&lt;/p>
&lt;hr>
&lt;p>And third, we have extra usability costs caused by unification where unification wasn&amp;rsquo;t asked for.&lt;/p>
&lt;p>The obvious example here is the push towards single codebases that can run on the web, iOS, and Android, ranging from large wide-screen monitors to tiny portrait phone screens. Developers rejoice in their ability to share code&amp;mdash;they can ship faster!&amp;mdash;but&amp;hellip; are users happy? Apps are now their own silos that behave differently from all others and don&amp;rsquo;t integrate with the platforms their run on. &amp;ldquo;Too much whitespace&amp;rdquo; is a common cry.&lt;/p>
&lt;p>Now, don&amp;rsquo;t get me wrong. I am a developer too, and &lt;em>of course&lt;/em> I like frameworks that allow me to avoid code duplication. In fact, code duplication is a problem from a usability perspective too because bugs and features will differ in different versions of the same app. But why should we, the users, pay for a loss of platform uniformity and usability so that companies can ship a product faster?&lt;/p>
&lt;hr>
&lt;p>Anyhow, enough for the rant.&lt;/p>
&lt;p>What can we do about this? I&amp;rsquo;m not sure if there is much we &lt;em>can&lt;/em> do. The incentives just aren&amp;rsquo;t there as Luke Plant claims in &lt;a href="https://lukeplant.me.uk/blog/posts/no-one-actually-wants-simplicity/">&amp;ldquo;No one actually wants simplicity&amp;rdquo;&lt;/a>. And even if we &lt;em>could&lt;/em> do something, we may not be able to like Yossi Kreinin describes in &lt;a href="https://yosefk.com/blog/dont-ask-if-a-monorepo-is-good-for-you-ask-if-youre-good-enough-for-a-monorepo.html">&amp;ldquo;Don&amp;rsquo;t ask if a monorepo is good for you&amp;mdash;ask if you&amp;rsquo;re good enough for a monorepo&amp;rdquo;&lt;/a>.&lt;/p>
&lt;p>But here is the thing: it is &lt;em>good&lt;/em> that building prototypes for new apps and features is cheaper and faster than ever before. Companies can quickly try and validate new products and features. Solo developers can launch apps in just a few days and have them reach thousands or millions of people. Yet&amp;hellip; do the benefits really last? These initial cost-saving measures end up hiding bigger costs down the road. Initial prototypes are never thrown away in favor of a rewrite&amp;mdash;as everyone says you should really do&amp;mdash;and once the ball of mud grows, it&amp;rsquo;s too expensive and too late to tame it.&lt;/p>
&lt;p>Another problem is that most engineers haven&amp;rsquo;t done any performance work. It is common, based on my observations in dozens of interviews, to believe that performance is about big-O notation. But, usually, that doesn&amp;rsquo;t matter. What matters to deliver a great user experience lies in other dimensions like minimizing I/O operations, tuning indexes in a database, caring about cache locality, or keeping binary sizes under control. There is a real need for mentoring&amp;hellip; but these activities are rarely rewarded organizationally.&lt;/p>
&lt;p>I would ask that, if you happen to do project planning or headcount allocation, do not treat coding as special. Yes, coding is important, but the cost of writing &lt;em>new&lt;/em> code is only a small fraction of delivering a product. Once a product is past a certain size, all other costs like refactoring or servicing become more important, and the costs that were saved by easing coding come to smear everything else. And, please, remember about the impact that these choices have on end user performance.&lt;/p>
&lt;hr>
&lt;p>Let&amp;rsquo;s end on a positive tone because we do have some nice things.&lt;/p>
&lt;p>I&amp;rsquo;m happy that Go has brought back the idea that trivial deployments and software distribution are beneficial thanks to its push for static binaries. Developers have lost some of their freedom by how opinionated Go is, but everyone else has gained something.&lt;/p>
&lt;p>I&amp;rsquo;m happy that some companies push for homogenization to reduce operational costs at the expense of limiting development choices. See how Google is famous for only allowing certain programming languages in production services, or how Snowflake is adopting Bazel to remove moving parts from the build process. These actions reduce developer choice (a cost to them) but bring savings elsewhere.&lt;/p>
&lt;p>And I&amp;rsquo;m happy that Rust&amp;rsquo;s memory safety and zero-cost abstractions increase initial development cost at the expense of faster and more reliable apps for end users. Oh, and it simplifies future maintenance costs for developers too! Refactorings are a joy to execute in a Rust code base.&lt;/p>
&lt;p>Now pardon me while I go back to work unironically on &lt;a href="/software/iii-iv.html">my framework&lt;/a>.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-08-31-dirt-pile.jpg" length="773447" type="image/jpeg"/></item></channel></rss>