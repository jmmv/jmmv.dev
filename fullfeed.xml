<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Julio Merino (jmmv.dev)</title><link>https://jmmv.dev/</link><description>Recent content on Julio Merino (jmmv.dev)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 17 Jan 2024 09:00:00 -0700</lastBuildDate><atom:link href="https://jmmv.dev/feed.xml" rel="self" type="application/rss+xml"/><item><title>From 0 to 1 MB in DOS</title><link>https://jmmv.dev/2024/01/from-0-to-1-mb-in-dos.html</link><pubDate>Wed, 17 Jan 2024 09:00:00 -0700</pubDate><guid>https://jmmv.dev/2024/01/from-0-to-1-mb-in-dos.html</guid><description>&lt;p>Since the last article on &lt;a href="/2023/12/the-ides-we-had-30-years-ago.html">the text-based IDEs of old&lt;/a>, I&amp;rsquo;ve been meaning to write about the GCC port to DOS, namely &lt;a href="https://www.delorie.com/djgpp/">DJGPP&lt;/a>. As I worked on the draft for that topic, I realized that there is a ton of ground to cover to set the stage so I took most of the content on memory management out and wrote this separate post.&lt;/p>
&lt;p>This article is a deep dive on how DOS had to pull out tricks to maximize the use of the very limited 1 MB address space of the 8086. Those tricks could exist because of the features later introduced by the 80286 and the 80386, but these were just clutches to paper over the fact that DOS could not leverage the real improvements provided by protected mode.&lt;/p>
&lt;p>This detour is long but I hope you&amp;rsquo;ll enjoy it as much as I enjoyed researching the topic. I&amp;rsquo;ll walk you through the changes in the x86 architecture over time, starting with the 8086 and ending in the 80386, and how DOS kept up along the way. I&amp;rsquo;ll conclude with a peek into DOS&amp;rsquo; own &lt;tt>MEM&lt;/tt> and MemMaker utilities. I must omit details to keep the text manageable in size though, so please excuse the lack of detail in some areas; just follow the links to external documentation to learn more.&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>&lt;em>Before we begin, I&amp;rsquo;d like to thank neozeed from &lt;a href="https://virtuallyfun.com/">Virtually Fun&lt;/a> for his in-depth review of this article. Head to his blog for a lot of interesting and related content!&lt;/em>&lt;/p>
&lt;h1 id="the-8086-and-real-mode">The 8086 and real mode&lt;/h1>
&lt;p>Back in the 1980s, the &lt;a href="https://en.wikipedia.org/wiki/Intel_8086">Intel 8086&lt;/a> was &lt;em>the&lt;/em> processor for PCs (along with its crippled sibling 8088 which I&amp;rsquo;ll ignore throughout this post). The 8086 was a simple chip with significant limitations, but it was incredibly successful and is the foundation of the x86 architecture that we still use today. Because the 8086 powered PCs, and DOS was the operating system that IBM chose for the PC, DOS was designed to work for the 8086.&lt;/p>
&lt;p>For the purposes of our article, let&amp;rsquo;s focus on two details: the 8086 CPU had a 20-bit address bus, which means it could only address 1 MB of memory, and it was a 16-bit CPU, which means that its internal registers were all 16-bit long. Which begs the question: if registers could only represent &lt;code>2^16 = 64K&lt;/code> different values, how could code reference a 20-bit address space?&lt;/p>
&lt;p>The answer is &lt;em>segmentation&lt;/em>. In the 8086, every instruction that references memory does so by specifying an address as two separate 16-bit quantities: a &lt;em>segment&lt;/em> and an &lt;em>offset&lt;/em> within the segment. Because segments are 16-bit long, there can be up to 64KB segments&amp;mdash;and if we take the 1 MB total address space and divide it by 64KB, we deduce that segments are offset from each other by 16 bytes.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-8086-segments.png" />
&lt;figcaption>Representation of the way segmentation slices the 8086 1 MB address space into 64KB overlapping segments offset by 16 bytes from each other.&lt;/figcaption>
&lt;/figure>
&lt;p>There are two things of note in the diagram. First, segments overlap, meaning that a single memory location can be referenced by many different segment/offset combinations. And, second, all segments after &lt;code>0xF000&lt;/code> reference memory positions above the 1 MB address space that don&amp;rsquo;t exist, which the 8086 chose to wrap around by ignoring the 21st bit of an address. After all, there is no 21st line in the address bus.&lt;/p>
&lt;p>When accessing a piece of memory with an address of the form &lt;code>segment:offset&lt;/code>, say &lt;code>81DA:72C3&lt;/code>, the 8086 multiplies &lt;code>0x81DA&lt;/code> by 16 (a simple 4-bit shift to the left) and adds the &lt;code>0x72C3&lt;/code> offset to the result to obtain address &lt;code>0x89063&lt;/code>. From there on, the 8086 reads from or writes to that memory location and calls it a day. There is no &lt;a href="https://en.wikipedia.org/wiki/Memory_management_unit">Memory Management Unit (MMU)&lt;/a>: every memory access can reference any address, and all accesses are legal (including those that wrap around!) which means null or dangling pointer dereferences don&amp;rsquo;t cause any sort of crash.&lt;/p>
&lt;p>This type of MMU-less segmented addressing is known as &lt;em>real mode&lt;/em>, but this name didn&amp;rsquo;t appear until the 80286 had to give it a name to distinguish it from &lt;em>protected mode&lt;/em>. But before introducing the latter, let&amp;rsquo;s talk about memory maps for a second.&lt;/p>
&lt;h1 id="conventional-and-upper-memory">Conventional and upper memory&lt;/h1>
&lt;p>Just because the 8086 processor can reference 1 MB of memory does not mean that 8086 machines came equipped with 1 full MB of RAM. Machines typically included &lt;em>less&lt;/em> than that for cost reasons, so it&amp;rsquo;s critical to understand that the &lt;em>address space&lt;/em>&amp;mdash;that is, the set of addresses that can be &lt;em>referenced&lt;/em>&amp;mdash;is different from the amount of memory installed. No surprise there: the same is true today of modern 64-bit CPUs.&lt;/p>
&lt;p>This fact was advantageous because certain system devices prefer to expose themselves as part of the address space. For example: the BIOS ROM is accessible via a range of addresses in upper memory. Or another example: video cards tend to expose their framebuffer as a memory-mapped device so that applications can directly write to well-known addresses to manipulate video memory&amp;mdash;bypassing the separate I/O bus and instruction set.&lt;/p>
&lt;p>The question is: where do such devices live within the address space? The choice is pretty much arbitrary, so what IBM did was split the &lt;a href="https://wiki.osdev.org/Memory_Map_(x86)">address space of the original PC&lt;/a> in two parts. The first 640 KB, known as &lt;em>conventional memory&lt;/em>, were mapped to available RAM and were readily usable by applications. The upper 384 KB, known as &lt;em>upper memory&lt;/em> or the &lt;em>Upper Memory Area (UMA)&lt;/em>, were reserved for memory-mapped devices. This assignment of &lt;em>meaning&lt;/em> to portions of the address space for specific purposes is what&amp;rsquo;s called a &lt;em>memory map&lt;/em>, and this was the memory map of the original PC.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-8086-memory-map.png" />
&lt;figcaption>Representation of the 8086 PC memory map. Solid blocks correspond to mapped memory and dashed parts correspond to unmapped memory.&lt;/figcaption>
&lt;/figure>
&lt;p>Note how conventional memory may not be fully usable: as shocking as it may sound today, PCs could have even less than 640 KB of installed RAM. More importantly for our purposes, the upper memory is &lt;em>sparse&lt;/em>: certain address ranges are assigned to devices, but there may be gaps between devices. What happens when reading from or writing to unmapped addresses is hard to tell as this depends on the chipset&amp;mdash;not the CPU&amp;mdash;but remember that all accesses had to be valid in some form.&lt;/p>
&lt;p>And by the way, there is one teeny tiny exception to the &amp;ldquo;all first 640 KB are free to use to applications&amp;rdquo;: the very first 1 KB of RAM is reserved for the Interrupt Vector Table, which is what the 8086 uses to look for interrupt handlers when it receives an interrupt, and a few more bytes after that are used by the BIOS to map volatile data. We can ignore these.&lt;/p>
&lt;h1 id="expanded-memory-specification-ems">Expanded Memory Specification (EMS)&lt;/h1>
&lt;p>As you can imagine, 640 KB of RAM were soon &lt;em>not&lt;/em> enough for many programs. Applications needed access to more memory, but the limitations of the 8086 20-bit address bus made it difficult. Yet there was a need for an immediate solution. The &lt;a href="https://en.wikipedia.org/wiki/Expanded_memory">Expanded Memory Specification (EMS)&lt;/a> was one of those first solutions and was originally designed by Lotus in order to support their star application &lt;a href="https://en.wikipedia.org/wiki/Lotus_1-2-3">1-2-3&lt;/a>.&lt;/p>
&lt;p>The idea is simple. Remember how upper memory is &lt;em>sparse&lt;/em>? What if we could map a window in that address space to a different portion of memory? And what if we could control, via software, which portion of memory was exposed through such window at any given time?&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-8086-ems.png" />
&lt;figcaption>Representation of the 8086 PC memory map and an EMS window in upper memory mapped to a portion of memory provided by an external ISA card.&lt;/figcaption>
&lt;/figure>
&lt;p>This is precisely what EMS did. EMS brought the idea of having a software API that allowed applications to select views into &amp;ldquo;other&amp;rdquo; memory by mapping a 64 KB window in upper memory to another memory chip. Originally, this other memory was supplied by expansion ISA cards like the one below, which means that EMS required hardware support and hardware-specific drivers to perform the window remappings. This also means, by the way, that this memory could be much slower than standard RAM.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-emulex-persyst-4mb-isa.jpg" />
&lt;figcaption>An Emulex Persyst ISA card providing 4 MB of additional memory. It's notable how huge this was. Photo taken from the Wikipedia; &lt;a href="https://en.wikipedia.org/wiki/File:EmulexPersyst_4M_ISA.jpeg">see original&lt;/a>.&lt;/figcaption>
&lt;/figure>
&lt;p>As you can imagine, this trick offered the theoretical ability to access &lt;em>any&lt;/em> amount of extra RAM on a machine&amp;hellip; at the expense of having to structure your application so that it explicitly (re)configured the window. Implementing such applications is difficult and is also insufficient when applications need a larger address space to function comfortably. EMS was a useful kludge, but still a kludge.&lt;/p>
&lt;h1 id="the-80286-and-protected-mode">The 80286 and protected mode&lt;/h1>
&lt;p>As the needs of programs and operating systems grew, processors themselves needed to grow more advanced features as well. In particular, they needed to gain the ability to access much more than just 1 MB of memory, and they needed to offer memory protection features to isolate programs from each other.&lt;/p>
&lt;p>The 80286, still a 16-bit CPU, grew the address space to 24 bits to support up to 16 MB of RAM. It introduced a MMU to offer memory isolation. But there was a problem here: the 8086 memory addressing mode of 16-bit &lt;code>segment:offset&lt;/code> pairs did not permit addressing memory beyond the first 1 MB. Thus the 80286 had to find a different way to reference the RAM beyond 1 MB, also known as &lt;em>extended memory&lt;/em>, and it did so by introducing a completely different operation mode known as &lt;em>protected mode&lt;/em>.&lt;/p>
&lt;p>Once in protected mode, all memory access rules change. For one, the MMU takes charge of all memory accesses, ensuring that they are valid according to predefined protections. For another, the &lt;code>segment:offset&lt;/code> addresses change their semantics. The segment portion of an address stops being a scaled down memory address, and instead becomes an &lt;em>index&lt;/em> &lt;a href="https://wiki.osdev.org/Global_Descriptor_Table">into a table&lt;/a> (the GDT or LDT) of segment descriptors. Each segment descriptor describes the base address of a segment as a 32-bit quantity, the size of the segment as a 20-bit quantity, the access protections of the segment, and a bunch of flags.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-80286-mmu-access.png" />
&lt;figcaption>Diagram representing the operations that the 80286 does, in hardware, to resolve a &lt;tt>segment:address&lt;/tt> memory reference.&lt;/figcaption>
&lt;/figure>
&lt;p>Under this model, instead of having an address like &lt;code>81DA:72C3&lt;/code>, we might see &lt;code>13:72C3&lt;/code>. To access this address, the MMU looks up entry 13 in the GDT, finds a descriptor that says that the segment starts at address &lt;code>0x81DA&lt;/code> and that it is &lt;code>0x7200&lt;/code> bytes long, and concludes that the &lt;code>13:72C3&lt;/code> reference is out of bounds, raising a &lt;a href="https://en.wikipedia.org/wiki/General_protection_fault">General Protection Fault&lt;/a> hardware exception (your dreaded &lt;a href="https://en.wikipedia.org/wiki/Segmentation_fault">&amp;ldquo;Segmentation fault&amp;rdquo;&lt;/a> error these days).&lt;/p>
&lt;p>But this access model is really different from what DOS applications were used to in real mode, and DOS itself was only designed to run in real mode. So DOS and all of its ecosystem were stuck in the real mode world, limited to addressing just 1 MB of memory without the ability to access extended memory&amp;hellip; or were they?&lt;/p>
&lt;h1 id="the-high-memory-area-hma">The High Memory Area (HMA)&lt;/h1>
&lt;p>Avid readers might have noticed in a previous picture that, in real mode, there are a few segments that could, in theory, allow access to addresses above the 1 MB mark. Take &lt;code>FFFF:0010&lt;/code>, which is &lt;code>0xFFFF * 0x10 + 0x10 = 0x100000 = 2^20&lt;/code> or 1 followed by 20 zeroes in binary form. This is the first address into extended memory. The 8086 was able to produce such addresses, but they would wrap around because the 8086 had no way to issue the 21st bit to the memory bus.&lt;/p>
&lt;p>For compatibility reasons, the 80286 had to truncate these addresses in real mode, and it did so by wiring the 21st line of the address bus (the A20) to zero. But what if the addresses &lt;em>didn&amp;rsquo;t&lt;/em> wrap around? What if we told the 80286 to &lt;em>not&lt;/em> truncate them? This can, in fact, be done by enabling the &lt;a href="https://en.wikipedia.org/wiki/A20_line#A20_gate">A20 gate&lt;/a>&amp;mdash;a task achieved via the keyboard controller, mind you. Enabling the A20 is a prerequisite for entering protected mode, but if done in real mode, it becomes possible to access an extra 64 KB of memory. This extra memory is known as the &lt;a href="https://en.wikipedia.org/wiki/High_memory_area">High Memory Area (HMA)&lt;/a>.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-80286-hma.png" />
&lt;figcaption>Representation of the way segmentation slices the 80286 real mode 1 MB address space into 64KB overlapping segments offset by 16 bytes from each other, and how the last few segments can be made to spill into extended memory.&lt;/figcaption>
&lt;/figure>
&lt;p>The HMA isn&amp;rsquo;t big by any means, but conventional memory was so limited that any tricks to gain extra memory were welcome and DOS did precisely that. By loading the &lt;code>HIMEM.SYS&lt;/code> driver and by specifying &lt;code>DOS=HIGH&lt;/code> in the &lt;code>CONFIG.SYS&lt;/code> file, DOS would relocate parts of itself into the HMA to free up to 64 KB of conventional memory.&lt;/p>
&lt;p>Unfortunately, 64 KB of extra memory really aren&amp;rsquo;t that much. This is a nice trick, but applications really needed access to more memory.&lt;/p>
&lt;h1 id="extended-memory-specification-xms">eXtended Memory Specification (XMS)&lt;/h1>
&lt;p>Another technique to access extended memory (the memory visible beyond the first 1 MB) came in the form of the &lt;a href="https://en.wikipedia.org/wiki/Extended_memory#Extended_Memory_Specification_(XMS)">eXtended Memory Specification (XMS)&lt;/a>.&lt;/p>
&lt;p>The idea of XMS is to provide an API that real mode applications can use to allocate chunks of extended memory and to copy data from/to those chunks via explicit calls. This is different from EMS because we aren&amp;rsquo;t talking about a fixed window of the address space referencing some external memory: we are talking about an API that is able to allocate arbitrary chunks of memory and return references to them, much like &lt;code>malloc&lt;/code> and &lt;code>free&lt;/code> do. Applications then use extra APIs to copy memory from/to those extended memory chunks into conventional memory.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-80386-xms.png" />
&lt;figcaption>Representation of the 80286 memory map with a block of extended memory copied into conventional memory by means of XMS.&lt;/figcaption>
&lt;/figure>
&lt;p>To implement the &lt;a href="http://www.phatcode.net/res/219/files/xms30.txt">XMS API&lt;/a>, a driver such as &lt;code>HIMEM.SYS&lt;/code> uses protected mode to manipulate the extended memory blocks, but the real mode applications never have to. Because XMS requires protected mode, this feature is only available in the 80286 and above processors, whereas EMS could be used by the 8086 with the right hardware assistance.&lt;/p>
&lt;p>Much like EMS, XMS provided the theoretical ability to access an unlimited amount of extended memory from real mode at the expense of having to manually transfer small pieces of it into the limited 1 MB address space. This is not a trivial difficulty and is why even modern architectures like the &lt;a href="https://en.wikipedia.org/wiki/Cell_(processor)">Cell processor&lt;/a> and its &lt;a href="https://en.wikipedia.org/wiki/Cell_(processor)#Synergistic_Processing_Elements_(SPE)">SPEs&lt;/a> with a separate and limited address space didn&amp;rsquo;t succeed.&lt;/p>
&lt;p>So far so good, but&amp;hellip; we can still squeeze some extra memory out of the real mode segmented address space. In particular, we still have some gaps in upper memory that we haven&amp;rsquo;t put to use.&lt;/p>
&lt;h1 id="the-80386-and-vm86-mode">The 80386 and VM86 mode&lt;/h1>
&lt;p>To make further improvements possible, we need the additional processor features that came with the 80386. Compared to the 80286, the 80386 was a 32-bit processor capable of addressing up to 4 GB of RAM. More interesting for our discussion, however, were the addition of pagination&amp;mdash;which is the foundation of any modern operating system&amp;mdash;and a new execution mode known as &lt;a href="https://en.wikipedia.org/wiki/Virtual_8086_mode">&lt;em>Virtual 8086&lt;/em>&lt;/a> or VM86 for short.&lt;/p>
&lt;p>VM86 was originally envisioned to fix a major deficiency in the 80286: that is, the ability to run &lt;em>multiple&lt;/em> concurrent real mode applications from within a protected mode operating system because that&amp;rsquo;s what Windows and OS/2 wanted to provide. In today&amp;rsquo;s terms, VM86 acts as virtual machine hypervisor, providing the processor with a mechanism to enter a mode that behaves like real mode but that is backed by the protected mode MMU. All memory accesses are subject to translation via pagination and all privileged operations trap into protected mode, meaning that a hypervisor process can place VM86 tasks anywhere in the 4 GB memory address space and can context-switch between them.&lt;/p>
&lt;p>But what if our hypervisor only spawned a single VM86 task to run DOS in? What if, then, the hypervisor leveraged the MMU to relocate portions of the real mode address space into portions of extended memory? That way, we could emulate EMS without dedicated hardware, providing applications a trivial way to peek into extended memory via 64 KB windows, or we could play other tricks&amp;hellip; like UMBs.&lt;/p>
&lt;h1 id="upper-memory-blocks-umbs">Upper Memory Blocks (UMBs)&lt;/h1>
&lt;p>Remember the sparse upper memory area? Those 384 KB of memory wired to hardware devices but with gaps in them? What if we could take those gaps in upper memory and map them to some extended memory so that they were directly addressable from real mode? This is precisely what &lt;a href="https://en.wikipedia.org/wiki/Upper_memory_area">Upper Memory Blocks (UMBs)&lt;/a> are: portions of the upper memory area remapped to extended memory by means of VM86, transparently offering access to more memory from real mode.&lt;/p>
&lt;p>As an example, think about the video memory mappings in the original PC specification. The memory map reserved two chunks of the address space for video: one for monochrome displays and one for color displays. But only one of them can be in use at any given time. So whichever video mode is selected leaves the address space of the other mode unused, and thus such address space can be leveraged by the system as an UMB into which to load drivers or place user data.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-80386-umb.png" />
&lt;figcaption>Representation of the 80386 VM86 memory map with two UMBs in upper memory mapped to extended memory by means of the MMU and its pagination features.&lt;/figcaption>
&lt;/figure>
&lt;p>In DOS, the &lt;code>EMM386.EXE&lt;/code> driver is in charge of providing UMBs. In principle, the chipset could also implement them in older processors, but the 80386 made this all possible in software by entering VM86 and then leveraging pagination to map pages of extended memory in the upper memory area.&lt;/p>
&lt;p>When UMBs are available, DOS offered ways to move load drivers and &lt;a href="https://en.wikipedia.org/wiki/Terminate-and-stay-resident_program">TSR programs&lt;/a> into UMBs by specifying &lt;code>DOS=UMB&lt;/code> in the &lt;code>CONFIG.SYS&lt;/code> file and then using the &lt;code>DEVICEHIGH&lt;/code> and &lt;code>LOADHIGH&lt;/code> commands.&lt;/p>
&lt;h1 id="putting-it-all-together">Putting it all together&lt;/h1>
&lt;p>In summary, we have seen four different techniques that evolved over time to squeeze the most memory out of the incredibly limited 1 MB address space of the 8086. These limitations haunted the PC ecosystem until Windows took over and it can be argued that Windows &amp;ldquo;won&amp;rdquo; because it made it much easier to take advantage of the larger address space of the 80386. Until that happened, however, users had to live with the EMS, XMS, HMA, and UMB mess.&lt;/p>
&lt;p>And a mess it was, and it was so pervasive that it leaked to users. Let&amp;rsquo;s take a look at the output of the &lt;code>MEM&lt;/code> command, which was a very common utility to run when trying to maximize free conventional memory. In one of its simplest forms, &lt;code>MEM /C&lt;/code>, the command shows a summary of the memory usage per program and whether they are loaded in conventional or upper memory:&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-mem-c-1.png" />
&lt;figcaption>First page of the output of the &lt;tt>MEM /C /P&lt;/tt> command.&lt;/figcaption>
&lt;/figure>
&lt;p>&lt;code>MEM /D&lt;/code>, which I did not know about back in the day, is more interesting. I have to show you its output as three separate images due to console size limitations:&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-mem-d-1.png" />
&lt;figcaption>First page of the output of the &lt;tt>MEM /D /P&lt;/tt> command.&lt;/figcaption>
&lt;/figure>
&lt;figure>
&lt;img src="/images/2024-01-17-mem-d-2.png" />
&lt;figcaption>Second page of the output of the &lt;tt>MEM /D /P&lt;/tt> command.&lt;/figcaption>
&lt;/figure>
&lt;figure>
&lt;img src="/images/2024-01-17-mem-d-3.png" />
&lt;figcaption>Third page of the output of the &lt;tt>MEM /D /P&lt;/tt> command.&lt;/figcaption>
&lt;/figure>
&lt;p>&lt;code>MEM /D&lt;/code> shows us the memory map of the machine along with details about the location of each program. We can also see mentions of the conventional vs. upper address space, whether the HMA is in use, and consumption of XMS memory.&lt;/p>
&lt;p>But in all of these outputs, we see that upper memory is not in use &lt;em>at all&lt;/em>. Why is that? Well, because MS-DOS out of the box doesn&amp;rsquo;t attempt to load drivers into it. For that, we have to manually modify &lt;code>CONFIG.SYS&lt;/code> and &lt;code>AUTOEXEC.BAT&lt;/code> with special commands and reorder entries to maximize the usage of the upper memory and the HMA. A black art.&lt;/p>
&lt;p>Which brings me to MemMaker, a tool that debuted with MS-DOS 6. This tool attempted to automatically reconfigure all drivers and TSRs loaded during boot so that the largest/majority of them fit in upper memory, leaving as much conventional memory free for application usage.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-memmaker-intro.png" />
&lt;figcaption>Welcome page to the MemMaker utility.&lt;/figcaption>
&lt;/figure>
&lt;p>As automated as it was, however, I&amp;rsquo;d say that MemMaker was an experts-only tool. Take a look at its advanced configuration options page, which I had to fiddle with to make the tool work in a KVM virtual machine running MS-DOS 6.22. You really need to understand the intricate details of real mode memory management to know what each of these options is about.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-memmaker-options.png" />
&lt;figcaption>Advanced options in the MemMaker utility.&lt;/figcaption>
&lt;/figure>
&lt;p>But if you made MemMaker run successfully, it would then greet you with a pretty cool page after a reboot. This page showed a breakdown of the changes made by MemMaker and how it was able to reclaim conventional memory.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-memmaker-results.png" />
&lt;figcaption>Final report of the changes made by the MemMaker utility.&lt;/figcaption>
&lt;/figure>
&lt;p>After that, we can look at the changes that MemMaker applied to the &lt;code>CONFIG.SYS&lt;/code> and &lt;code>AUTOEXEC.BAT&lt;/code> files. I never truly understood what all of these magic numbers meant, but now that I went through the hassle of researching and writing this article, I finally do. Just 30 years after I regularly used MemMaker to be able to play games in my multimedia 80386.&lt;/p>
&lt;figure>
&lt;img src="/images/2024-01-17-memmaker-changes.png" />
&lt;figcaption>Content of the &lt;tt>CONFIG.SYS&lt;/tt> and &lt;tt>AUTOEXEC.BAT&lt;/tt> files after MemMaker is done making changes.&lt;/figcaption>
&lt;/figure>
&lt;p>You can much read more in Microsoft&amp;rsquo;s own now-archived &lt;a href="https://jeffpar.github.io/kbarchive/kb/095/Q95555/">KB-Q9555 article&lt;/a> or the &lt;a href="https://archive.org/details/DOS_Beyond_640K_2nd_edition">DOS Beyond 640KB book&lt;/a>.&lt;/p>
&lt;p>And that&amp;rsquo;s it for today folks. I intentionally did &lt;em>not&lt;/em> touch on DPMI&amp;mdash;the technology that truly allowed DOS applications to break free from the 1 MB memory limitation&amp;mdash;because I&amp;rsquo;m saving that for the next article. So, make sure to come back for more!&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-01-17-8086-dos.jpg" length="220943" type="image/jpeg"/></item><item><title>Links: December 2023 edition</title><link>https://jmmv.dev/2023/12/links-december-2023-edition.html</link><pubDate>Sun, 31 Dec 2023 09:40:00 +0100</pubDate><guid>https://jmmv.dev/2023/12/links-december-2023-edition.html</guid><description>&lt;p>December draws to a close as does 2023, which means it&amp;rsquo;s time for yet another monthly links recap.&lt;/p>
&lt;p>For context to everyone new around here, what follows is my manual curation of cool articles, videos, and projects I stumbled upon during this time period. But this is not &lt;em>just&lt;/em> a dump of links: &lt;em>each link is accompanied by a short commentary&lt;/em> that justifies why I thought the material was interesting, why it is relevant to this publication and, more importantly, an attempt to nudge you into reading it.&lt;/p>
&lt;p>December has been a slow month though. During the first half, only a handful of articles caught my attention; and during the second half, I&amp;rsquo;ve been traveling so I haven&amp;rsquo;t paid much attention to news sites. In any case, there is some good content to enjoy this month. Read on and have a good entry to 2024!&lt;/p>
&lt;p>Happy new year!&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://dudemanguy.github.io/blog/posts/2022-06-10-wayland-xorg/wayland-xorg.html">&amp;ldquo;Wayland Isn&amp;rsquo;t Going to Save The Linux Desktop&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By dudemanguy on June 10, 2022&lt;/em>&lt;/p>
&lt;p>Do you know how Wayland works, how it differs from X.org, and how it has some architectural limitations that prevent it from solving some problems that X11 does not have? If not, this one is for you. This article is from 2022 but recently surfaced as a timely rant because Fedora is planning to drop X.org in the upcoming Fedora 40 release.&lt;/p>
&lt;p>Things will be&amp;hellip; &amp;ldquo;fun&amp;rdquo; for some of us soon. In my case, I use Fedora 39 and Wayland recently decided to stop working on my Mac Pro 2013 and fell back to X.org. And on my Surface Go 2, on which I need to use &amp;ldquo;bounce keys&amp;rdquo; to prevent repeated input due to some issues with the keyboard, the feature only works with X.org and not Wayland.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2023/12/strings-encodings-nuls-and-bazel.html">&amp;ldquo;Strings, encodings, NULs and Bazel&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By yours truly on December 3rd, 2023&lt;/em>&lt;/p>
&lt;p>I came across a random tweet that suggested newcomers to C to represent strings as an array plus a length, without the traditional NUL terminator. The slightly-inflammatory tweet prompted me to write about why doing this is a bad idea and showed an example of the inefficiencies that arise from choosing to go your own way.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://virtuallyfun.com/2023/12/08/bsd-on-windows-things-i-wish-i-knew-existed/">&amp;ldquo;BSD on Windows: Things I wish I knew existed&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By neozeed on December 8th, 2023&lt;/em>&lt;/p>
&lt;p>Here is a thing from 1995 that I didn&amp;rsquo;t know existed: a BSD Unix distribution that ran on Windows 3.x. I wonder why this didn&amp;rsquo;t catch on but the likes of Cygwin did. By the way, this post made me remember &lt;strong>&lt;a href="https://www.delorie.com/djgpp/">DJGPP&lt;/a>&lt;/strong>, a distribution of GCC for DOS, and it&amp;rsquo;s something I&amp;rsquo;m considering to analyze and write about in an upcoming article.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2023/12/a-cli-text-editor-in-my-windows.html">&amp;ldquo;A CLI text editor? In my Windows?&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By yours truly on December 8th, 2023&lt;/em>&lt;/p>
&lt;p>The Windows Terminal team at Microsoft is considering the addition of a command-line text editor by default in Windows. The thing is: Windows used to ship with one (&lt;code>EDIT.COM&lt;/code>) until they dropped the editor when moving to 64-bit editions&amp;hellip; and I&amp;rsquo;m kinda proposing that they bring something like the old editor back.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://github.com/TobyLobster/multiply_test">&amp;ldquo;6502 Integer Multiplication - which is best?&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By Toby Nelson&lt;/em>&lt;/p>
&lt;p>Discovered via a &lt;a href="https://news.ycombinator.com/item?id=38598940">discussion in HN&lt;/a>, this is a project that collects more than 120 multiplication algorithms and analyzes their behavior in detail on the 6502 8-bit processor. I barely knew this processor existed before seeing this article so I don&amp;rsquo;t particularly care for it, but the analysis is just mesmerizing and worth a read.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://www.whizzy.org/2023-12-14-bricked-xmas/">&amp;ldquo;Bricked Xmas&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By Will Cooke on December 14th, 2023&lt;/em>&lt;/p>
&lt;p>An article on how to reverse-engineer Christmas LED lights that use Bluetooth to control the flashing patterns and how this process resulted in the bricking of said lights. The most interesting content in the article is the very foundations of reverse engineering a binary protocol when all you can do is see packets flow through the wire.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2023/12/hard-disk-leds-and-noisy-machines.html">&amp;ldquo;Hard disk LEDs and noisy machines&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By yours truly on December 15th, 2023&lt;/em>&lt;/p>
&lt;p>While looking at yet another unexplained performance inefficiency that I observed, I wondered how many of these slip through because the machines we have today are &amp;ldquo;so powerful and quiet&amp;rdquo; that they absorb such abuse of resources without making a big fuss. I wrote a Twitter thread that explains how useful it was to have flashing LEDs for disk activity and loud fans during heavy CPU load, with a suggestion on what to do these days instead on your silent laptops.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://belkadan.com/blog/2022/10/Swift-in-the-OS/">&amp;ldquo;Swift was always going to be part of the OS&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By Jordan Rose on October 9th, 2022&lt;/em>&lt;/p>
&lt;p>Using a language as part of an OS poses challenges on how the language and the OS can evolve, if at all, while preserving backwards compatibility. This article explains such difficulties in the context of Swift and justifies the choices that Apple made to allow using Swift for its own frameworks. The same challenges are not unique as they also apply to e.g. .NET in Windows, which Microsoft chose to solve in different ways.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://tim.siosm.fr/blog/2023/12/19/ssh-over-unix-socket/">&amp;ldquo;sudo without a setuid binary or SSH over a UNIX socket&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By Timothée Ravier on December 19th, 2023&lt;/em>&lt;/p>
&lt;p>Have you ever considered using SSH as a replacement for &lt;code>sudo&lt;/code> by leveraging a Unix socket and file permissions to protect access? I hadn&amp;rsquo;t, but after reading the title, this interesting solution sounded obvious. There is a lot of nuance though, so make sure to read on.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2023/12/bazel-interview-at-software-engineering.html">&amp;ldquo;Bazel interview at Software Engineering Daily&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By yours truly on December 21st, 2023&lt;/em>&lt;/p>
&lt;p>Two months ago, Jordi Mon Companys interviewed me about various Bazel topics and the podcast episode finally came out this month. I wrote a detailed summary of the 45-minute recording so that you can know what to expect and where exactly to fast-forward to if you want to skip certain topics.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://arne.me/articles/emacs-from-scratch-part-one-foundations">&amp;ldquo;Emacs From Scratch, Part 1: Foundations&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By Arne Bahlo on December 22nd, 2023&lt;/em>&lt;/p>
&lt;p>Doom Emacs is my go-to editor. This Emacs &amp;ldquo;distribution&amp;rdquo; is great because its configuration files are trivial to read and edit, but I still feel a bit uncomfortable due to the many abstractions in between those files and the &amp;ldquo;real Emacs&amp;rdquo;&amp;mdash;particularly when Doom Emacs greets me with &amp;ldquo;loaded 200 packages&amp;rdquo; that I know little about. In that regard, this article series seems promising and I might go back to configuring a minimal setup at some point. (The second part is already out at the time of this writing, by the way.)&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://retrofun.pl/2023/12/18/was-basic-that-horrible-or-better/">&amp;ldquo;Was BASIC that horrible or&amp;hellip; better?&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By Ikari on December 18th, 2023&lt;/em>&lt;/p>
&lt;p>BASIC has received a lot of hatred throughout the years, with Dijkstra claiming &amp;ldquo;It is practically impossible to teach good programming to students that have had a prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of regeneration.&amp;rdquo; Which, OK, fine. I can see that happening if you look at the original Dartmouth BASIC from the 1970s&amp;hellip; but later editions of BASIC included proper flow control to make these criticisms unfounded. Much more on this topic in the referenced article.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2023/12/the-ides-we-had-30-years-ago.html">&amp;ldquo;The IDEs we had 30 years ago&amp;hellip; and we lost&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By yours truly on December 25th, 2023&lt;/em>&lt;/p>
&lt;p>My Christmas gift to you all: a tour of the text-based IDEs we had about 30 years ago in DOS land to show how powerful and tiny they were at the time. The article contrasts them with the huge beasts we have nowadays and how they aren&amp;rsquo;t really that novel. And I write this as a &amp;ldquo;Unix convert&amp;rdquo; for many years.&lt;/p>
&lt;p>This is one of my most popular articles and further proves that my experiment with the move to Substack is worthwhile to gain an audience. Previous similarly-successful articles in my blog only brought in a handful of new subscribers, but this one has already raked tens in.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://github.com/minimaxir/hacker-news-undocumented/blob/master/README.md">&amp;ldquo;A List of Hacker News&amp;rsquo;s Undocumented Features and Behaviors&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By Max Woolf&lt;/em>&lt;/p>
&lt;p>If you are an avid Hacker News user like I am, this living guide is a must read. You&amp;rsquo;ll learn many of the ways in which content moderation works, a bunch of hidden endpoints, and the kinds of features that karma points enable.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://blog.yossarian.net/2020/06/13/How-x86_64-addresses-memory">&amp;ldquo;How x86_64 addresses memory&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>By William Woodruff on June 13th, 2020&lt;/em>&lt;/p>
&lt;p>&lt;code>mov&lt;/code> is &lt;em>the&lt;/em> x86 instruction, and this article does a good job at looking at all possible memory addressing modes. The reason this is interesting is because the article also looks at &lt;em>why&lt;/em> each addressing mode is useful by mapping it to a C construct that benefits from it.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-10-31-links.png" length="56457" type="image/jpeg"/></item><item><title>The IDEs we had 30 years ago... and we lost</title><link>https://jmmv.dev/2023/12/the-ides-we-had-30-years-ago.html</link><pubDate>Mon, 25 Dec 2023 10:40:00 +0100</pubDate><guid>https://jmmv.dev/2023/12/the-ides-we-had-30-years-ago.html</guid><description>&lt;p>I grew up learning to program in the late 1980s / early 1990s. Back then, I did not fully comprehend what I was doing and why the tools I used were impressive given the constraints of the hardware we had. Having gained more knowledge throughout the years, it is now really fun to pick up DOSBox to re-experience those programs and compare them with our current state of affairs.&lt;/p>
&lt;p>This time around, I want to look at the pure text-based IDEs that we had in that era before Windows eclipsed the PC industry. I want to do this because those IDEs had little to envy from the IDEs of today&amp;mdash;yet it feels as if we went through a dark era where we lost most of those features for years and they are only resurfacing now.&lt;/p>
&lt;p>If anything, stay for a nostalgic ride back in time and a little rant on &amp;ldquo;bloat&amp;rdquo;. But, more importantly, read on to gain perspective on what existed before so that you can evaluate future feature launches more critically.&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h1 id="first-editors-and-tuis">First editors and TUIs&lt;/h1>
&lt;p>In the 1990s, almost every DOS program you ran had a full-screen Text User Interface (TUI) which sported text-based windows, drop shadows, colors, and mouse support. Here is just one example:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-edit-com-colors.png" class="with-border">
&lt;figcaption>The MS-DOS Editor (aka &lt;tt>EDIT.COM&lt;/tt>) with one of its settings dialog open. Note the menu bar, the rich dialog with list selectors and buttons, and the status bar documenting navigation shortcuts.&lt;/figcaption>
&lt;/figure>
&lt;p>Each program was its own island because its interface was unique to the program. However, they were all so similar in how they looked like&amp;mdash;80x25 characters didn&amp;rsquo;t leave much room for uniqueness&amp;mdash;and how they worked that the differences didn&amp;rsquo;t really get in the way of usability and discoverability. Once you learned that the Alt key opened the menus and that Tab moved across input fields and buttons, you could navigate almost any program with ease.&lt;/p>
&lt;p>But let&amp;rsquo;s talk about editors. MS-DOS shipped with a TUI text editor since version 5 (1991), which &lt;a href="/2023/12/a-cli-text-editor-in-my-windows.html">I previously covered in a recent article&lt;/a> and is shown above. This editor &amp;ldquo;worked&amp;rdquo;, but it was really inconvenient for coding: you needed to exit the editor to compile and run your code, and when you re-ran the editor, you&amp;rsquo;d have to navigate back to where you were before.&lt;/p>
&lt;p>&amp;ldquo;In my house&amp;rdquo;, we used something called &lt;a href="https://en.wikipedia.org/wiki/Borland_Sidekick">SideKick Plus&lt;/a> (1984), which wasn&amp;rsquo;t really a code editor: it was more of a Personal Information Management (PIM) system with a built-in notepad. The cool thing about it, however, was that it was a Terminate and Stay Resident (TSR) program, which meant that it loaded in the background and you could bring it up at any time by pressing Ctrl+Alt.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-sidekick-plus.png" class="with-border">
&lt;figcaption>SideKick Plus' main screen after pressing Ctrl+Alt to bring it up. Note how DOS remains in the background.&lt;/figcaption>
&lt;/figure>
&lt;p>Think of this TSR feature as rudimentary multitasking for an OS that did &lt;em>not&lt;/em> have multitasking. This was really effective because quickly switching between code editing and building is critical for an efficient inner development loop. (And by the way, this past experience explains the design of the &lt;a href="https://www.endbasic.dev/docs.html#intro-first">code editing flow in EndBASIC&lt;/a>. I did not implement the equivalent of Ctrl+Alt, but I&amp;rsquo;ve considered it many times.)&lt;/p>
&lt;p>By this point, however, real IDEs had already existed for a few years. Turbo Pascal 1.0 (1983) shows the beginning of an integrated experience, although it did not feature its iconic TUI yet. QuickBASIC 2.0 (1986) shows more of a &amp;ldquo;traditional&amp;rdquo; TUI (the same as &lt;code>EDIT.COM&lt;/code>, because they are the same editor), and MS-DOS 5 came with QBasic, a reduced version of QuickBASIC that didn&amp;rsquo;t allow compiling to native code but that had the same look.&lt;/p>
&lt;h1 id="the-borland-turbo-series">The Borland Turbo series&lt;/h1>
&lt;p>The crown jewel of IDEs, in my opinion, were the later Borland Turbo series, which included Turbo C++ (1990), Turbo Assembler and Turbo Pascal. These IDEs were language specific, but they had full-screen TUIs and were extremely powerful.&lt;/p>
&lt;p>Here, take a look at what we had. Syntax highlighting:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-turbo-cpp-syntax-highlighting.png" class="with-border">
&lt;figcaption>Borland Turbo C++ showing a "Hello World" program to demonstrate syntax highlighting.&lt;/figcaption>
&lt;/figure>
&lt;p>Compiler integration and diagnostics:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-turbo-cpp-warnings.png" class="with-border">
&lt;figcaption>Borland Turbo C++ after compiling a program, showing a warning because I did not return a value from &lt;tt>main()&lt;/tt>.&lt;/figcaption>
&lt;/figure>
&lt;p>Integrated project and build system management:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-turbo-cpp-project.png" class="with-border">
&lt;figcaption>Borland Turbo C++ showing its project management and multi-window features. In the picture, you can see two C++ source files, with one depending on the other, and the project window listing all files that need to be compiled together.&lt;/figcaption>
&lt;/figure>
&lt;p>A debugger with breakpoints, stack traces, and the like:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-turbo-cpp-debugger.png" class="with-border">
&lt;figcaption>Borland Turbo C++ showing a debugging session with a program that contains multiple functions, a breakpoint, and the current call stack.&lt;/figcaption>
&lt;/figure>
&lt;p>And even a full reference manual:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-turbo-cpp-help.png" class="with-border">
&lt;figcaption>Borland Turbo C++ showing its integrated help system, with the "Hello World" program in the background and the help for &lt;tt>printf&lt;/tt>.&lt;/figcaption>
&lt;/figure>
&lt;p>Remember: all of this in the early 1990s&amp;mdash;a little over 30 years ago at the time of this writing.&lt;/p>
&lt;p>I was an avid user of Turbo C++, with which I learned a lot. I remember using their &lt;code>conio.h&lt;/code> libraries to implement TUIs of my own, and then their builtin &lt;code>graphics.h&lt;/code> libraries to play with implementing GUIs. And note: this was &lt;em>without the Internet&lt;/em>. There was no option for many to just &amp;ldquo;look up how things worked&amp;rdquo; in Stack Overflow: the IDE had to be discoverable right away (which it was) and self-contained to offer you a complete development experience.&lt;/p>
&lt;h1 id="what-about-linux-back-then">What about Linux back then?&lt;/h1>
&lt;p>Now take a moment to compare this scene with Linux in the early 1990s.&lt;/p>
&lt;p>In Linux, almost every program was &lt;em>also&lt;/em> text based, but those programs did not come with a full-screen TUI. It just wasn&amp;rsquo;t &amp;ldquo;the Unix way&amp;rdquo;. I remember watching the X11 configuration tool (&lt;a href="https://www.xfree86.org/3.3.6/QuickStart3.html">&lt;code>XF86Setup&lt;/code>&lt;/a>) or the OpenBSD installer and feeling shocked by how simplistic those were: me, a young teenager with barely any &amp;ldquo;real&amp;rdquo; coding experience, had written better-looking programs already.&lt;/p>
&lt;p>In any case, this didn&amp;rsquo;t stop me from my quest to &lt;em>not&lt;/em> use Windows. I continued to learn the ways of Linux and soon faced the &amp;ldquo;best&amp;rdquo; editors recommended by every book and community online: Vim and Emacs. And I could not understand why they were praised. Using these was like stepping back into the past. They were full-screen programs indeed, but they seemed pretty arcane. Vim did have syntax highlighting but it was far from being an IDE. Emacs could be configured to integrate with some code assisting features and the like, but it was far from being &amp;ldquo;fire and forget&amp;rdquo; like the Turbo family of IDEs.&lt;/p>
&lt;p>Just look at the default Emacs configuration &lt;em>today&lt;/em>, which hasn&amp;rsquo;t changed much (if at all) since then. It does have windows, but they aren&amp;rsquo;t decorated. It didn&amp;rsquo;t have colors (and now barely has), because why? It didn&amp;rsquo;t use to have mouse support. It &lt;em>does&lt;/em> have a menu bar though, but it is just a gimmick? If you press &lt;tt>M-`&lt;/tt> as the instructions tell you, you face a truly strange interface to navigate the menu&amp;mdash;which makes one wonder why they even bothered to waste a full line of screen real state to show a menu bar that does nothing.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-emacs-menubar.png" class="with-border">
&lt;figcaption>A fresh installation of Emacs in the console, with the standard welcome screen in the background and the "menu" open after pressing &lt;tt>M-`&lt;/tt>.&lt;/figcaption>
&lt;/figure>
&lt;p>Now try giving this to anyone with little coding experience and getting them to create, compile, and debug a program. They will have trouble just navigating the editor, and they won&amp;rsquo;t find any of the features that would allow for project management or compiler integration.&lt;/p>
&lt;p>For comparison, in writing this post, I fired up Turbo C++ in DOSBox and I was able to create a &amp;ldquo;hello world&amp;rdquo; project and navigate the environment in minutes&amp;mdash;all without prior knowledge (everything I had known has been forgotten by now). The environment is intuitive and, as an IDE, integrated all around.&lt;/p>
&lt;h1 id="contemporary-tui-ides">Contemporary TUI IDEs&lt;/h1>
&lt;p>Anyhow. Let&amp;rsquo;s forget about the past and look at what we have today in TUI-land. I don&amp;rsquo;t want to look at GUIs because&amp;hellip; well, Visual Basic was the pinnacle of graphics programming and we don&amp;rsquo;t have that either anymore&amp;mdash;which is also a topic for another day. (Well, OK, you have &lt;a href="https://gambas.sourceforge.net/">Gambas&lt;/a>&amp;hellip; but who knows about it?)&lt;/p>
&lt;p>The closest more-modern equivalent to the Borland Turbo C++ environment is &lt;a href="https://directory.fsf.org/wiki/RHIDE">RHIDE&lt;/a>. As you can see in the picture below, it looks incredibly similar&amp;mdash;and you&amp;rsquo;d be forgiven if you thought this &lt;em>is&lt;/em> Turbo C++. Unfortunately, it is DOS-only and seems to be mostly abandoned by now with its latest release dated 7 years ago.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-rhide.png" class="with-border">
&lt;figcaption>The RHIDE IDE showing the same "hello world" program as before, with no errors nor warnings after compilation.&lt;/figcaption>
&lt;/figure>
&lt;p>Then we have &lt;a href="https://www.freepascal.org/">Free Pascal&lt;/a>. This is the closest you&amp;rsquo;ll get to the old experience but with a modern codebase, running natively on Unix systems and leveraging terminals of any size.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-free-pascal.png" class="with-border">
&lt;figcaption>The Free Pascal IDE with a trivial "hello world" program and overlapping windows for a built-in ASCII table and a calculator.&lt;/figcaption>
&lt;/figure>
&lt;p>And lastly we have &lt;a href="https://qb64.com/">QB64&lt;/a>. This closely resembles Microsoft QuickBasic but&amp;hellip; don&amp;rsquo;t let it trick you: even though it looks like a TUI, it is actually a GUI application that simulates a TUI. You cannot run QB64 in a terminal.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-qb64.png" class="with-border">
&lt;figcaption>The QB64 IDE, which looks textual but is actually a graphical program.&lt;/figcaption>
&lt;/figure>
&lt;p>Both Free Pascal and QB64 are maintained and under relatively-active development, with their most recent releases in 2021&amp;hellip; but they are mostly ignored because they expose arcane languages that most people have no interest in these days.&lt;/p>
&lt;h1 id="real-contemporary-console-ides">&amp;ldquo;Real&amp;rdquo; contemporary console IDEs&lt;/h1>
&lt;p>So what are we left with for &lt;em>modern&lt;/em> languages today?&lt;/p>
&lt;p>The state of the art seems to be &lt;a href="https://neovim.io/">Neovim&lt;/a>, &lt;a href="https://github.com/doomemacs/doomemacs">Doom Emacs&lt;/a>, or even &lt;a href="https://helix-editor.com/">Helix&lt;/a>. These editors are very powerful and, thanks to various plugins, offer reasonable IDE-like experiences. That said, if you ask me, none of these provide the same kind of experience that the previous Borland products offered: their interfaces are obscure and, due to their multi-language nature, they work OK for almost everything but they aren&amp;rsquo;t great for anything. &amp;ldquo;Jack of all trades, master of none&amp;rdquo; if you will.&lt;/p>
&lt;p>In any case, the preferred &amp;ldquo;simple&amp;rdquo; TUI editor, based on what I observed in the deranged &lt;a href="https://github.com/microsoft/terminal/discussions/16440">microsoft/terminal#16440&lt;/a> discussion, seems to be&amp;hellip; &lt;a href="https://www.nano-editor.org/">GNU Nano&lt;/a>&amp;hellip; which OK, it works, but first: it&amp;rsquo;s no IDE, and second, to me this looks like WordStar. Yeah, I know it isn&amp;rsquo;t WordStar: if you want WordStar, the closest you&amp;rsquo;ll find is &lt;a href="https://joe-editor.sourceforge.io/">Joe&lt;/a>, but the &lt;em>looks&lt;/em> of Nano remind me of my first experiences with a word processor back in the CP/M days. Here, look:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-25-nano.png" class="with-border">
&lt;figcaption>The GNU Nano editor in its default setup, with an empty file open.&lt;/figcaption>
&lt;/figure>
&lt;p>So even though we &lt;em>do&lt;/em> have powerful console editors these days, they don&amp;rsquo;t quite offer the same usable experience we had 30 years ago. In fact, it feels like during these 30 years, we regressed in many ways, and only now are reaching feature parity with some of the features we used to have.&lt;/p>
&lt;p>It is natural that TUIs diminished in popularity once graphical OSes gained traction, and it is somewhat interesting that they are making a comeback just now. As for why, I think we have to thank the invention of &lt;a href="https://microsoft.github.io/language-server-protocol/">LSP&lt;/a> for most of the recent progress in this area. TUI editors were &amp;ldquo;on hold&amp;rdquo; for many years because building IDE features for them was a lot of effort and their small maintainer base could not afford to implement them. LSP unlocked access to existing language-specific integrations and reinfused interest in the old-and-trusty Vim and Emacs. Hopefully, the upcoming &lt;a href="https://build-server-protocol.github.io/">BSP&lt;/a> will do even more to make these TUIs more IDE-like.&lt;/p>
&lt;h1 id="why-tui-ides-anyway">Why TUI IDEs anyway?&lt;/h1>
&lt;p>It is fair to ask &amp;ldquo;Who cares? Every desktop and laptop runs a graphical OS now!&amp;rdquo;&lt;/p>
&lt;p>And it&amp;rsquo;s a good question. In general, you probably &lt;em>don&amp;rsquo;t&lt;/em> want a TUI IDE. If VSCode is your jam, its remoting abilities are superb and VSCode has a reasonably good graphical interface without being a full-blown IDE. But there are a few things that VSCode doesn&amp;rsquo;t give us.&lt;/p>
&lt;p>The first is that a TUI IDE is excellent for work on remote machines&amp;mdash;even better than VSCode. You can SSH into &lt;em>any&lt;/em> machine with ease and launch the IDE. &lt;a href="/2015/09/my-coding-workflow.html">Combine it with tmux and you get &amp;ldquo;full&amp;rdquo; multitasking.&lt;/a> Yes, you could instead use a remote desktop client instead of SSH, but I&amp;rsquo;ve always found them clunky due to lag and the improper integration with the local desktop shortcuts.&lt;/p>
&lt;p>The second is that &lt;a href="https://code.visualstudio.com/docs/remote/faq#_why-arent-the-remote-development-extensions-or-their-components-open-source">VSCode&amp;rsquo;s remote extensions are &lt;em>not&lt;/em> open source&lt;/a>, which isn&amp;rsquo;t a major problem&amp;hellip; except for the fact that they don&amp;rsquo;t work on, say, FreeBSD and there is no way to fix them. So this makes it impossible for me to remote into my primary development server with VSCode.&lt;/p>
&lt;p>And the third is&amp;hellip; reduced resource consumption.&lt;/p>
&lt;h1 id="bloat-everywhere">Bloat everywhere&lt;/h1>
&lt;p>I can&amp;rsquo;t leave without ranting about &amp;ldquo;bloat&amp;rdquo; for a little bit. Borland Turbo C++, with all its bells and whistles (the UI, the C++ toolchain, the integrated manuals&amp;hellip;), is less than 9 MB after installation and ran within 640kb of RAM.&lt;/p>
&lt;p>For comparison, Helix is 16 MB on disk, which is pretty impressive (and honestly unexpected), but Doom Emacs is about 500 MBs and consumes many MBs of RAM. Note, however, that none of these numbers account for the language toolchains or help systems, and toolchains nowadays rank in the GBs of disk space.&lt;/p>
&lt;p>To get &amp;ldquo;real&amp;rdquo; IDEs, we have to jump to graphical programs like IntelliJ or VSCode. VSCode, for example, is about 350 MBs on disk (surprisingly less than Doom Emacs) but it will eat your computer for lunch: it&amp;rsquo;s Electron after all. I have noticed very significant savings in laptop battery life by dropping VSCode and moving to Doom Emacs.&lt;/p>
&lt;p>So the question I want to part with is: have we advanced &lt;em>much&lt;/em> in 30 years? Modern IDEs have some better refactoring tools, better features, and support more languages, but fundamentally&amp;hellip; they haven&amp;rsquo;t changed much. The only major difference that we are &lt;em>starting&lt;/em> to see might be AI-assisted coding, but this is a feature mostly provided by a remote service, not even by the installed code!&lt;/p>
&lt;p>And that&amp;rsquo;s all for today. On my side, I&amp;rsquo;ll happily continue using &lt;em>all of&lt;/em> Doom Emacs, Vim, VSCode, and IntelliJ depending on the situation. Merry Christmas if this is your thing!&lt;/p></description></item><item><title>Bazel interview at Software Engineering Daily</title><link>https://jmmv.dev/2023/12/bazel-interview-at-software-engineering.html</link><pubDate>Thu, 21 Dec 2023 09:50:00 +0100</pubDate><guid>https://jmmv.dev/2023/12/bazel-interview-at-software-engineering.html</guid><description>&lt;p>Just a bit over 2 months ago, on October 5th, 2023, Jordi Mon Companys interviewed me about Bazel for an episode in the &lt;a href="https://softwareengineeringdaily.com/">Software Engineering Daily&lt;/a> podcast. The episode finally came out on December 18th, 2023, so here is your announcement to stop by and listen to it!&lt;/p>
&lt;figure>
&lt;a href="https://softwareengineeringdaily.com/2023/12/18/bonus-episode-bazel-with-julio-merino/" target="_blank">
&lt;img src="/images/2023-12-21-bazel-interview-cover.jpg" class="with-border" />
&lt;/a>
&lt;figcaption>
&lt;a href="https://softwareengineeringdaily.com/2023/12/18/bonus-episode-bazel-with-julio-merino/" target="_blank">
Cover image (and link) to the Bazel interview in Software Engineering Daily.
&lt;/a>
&lt;/figcaption>
&lt;/figure>
&lt;p>If you don&amp;rsquo;t have time to listen to the whole 45 minutes, or if you want to get a sense of what you will get out of it, here is a recap of everything we touched on. Every paragraph is annotated with the rough time where the discussion starts so that you can jump right in to whatever interests you the most.&lt;/p>
&lt;h1 id="my-background">My background&lt;/h1>
&lt;p>&lt;strong>[01:10]&lt;/strong> Introduction about myself. Really brief overview about my roles and the companies I&amp;rsquo;ve been at throughout the years.&lt;/p>
&lt;p>&lt;strong>[01:58]&lt;/strong> A retrospective about how I got into computers and why I think things were much easier to dive into years ago. In other words, a plug for &lt;a href="https://www.endbasic.dev/">EndBASIC&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[03:34]&lt;/strong> My history with open source projects and how I got into Linux, the BSDs, and why I ended up as a contributor to NetBSD.&lt;/p>
&lt;p>&lt;strong>[05:05]&lt;/strong> How my background helped me join Google as a Site Reliability Engineer (SRE), even if I did not have much experience in systems administration. SRE is a really cool position because of the many paths that lead into it!&lt;/p>
&lt;p>&lt;strong>[05:51]&lt;/strong> Why I moved years later to the Bazel team as a software engineer while remaining at Google.&lt;/p>
&lt;h1 id="introduction-to-bazel">Introduction to Bazel&lt;/h1>
&lt;p>&lt;strong>[06:57]&lt;/strong> Google and internal tools. Why Google invented &amp;ldquo;everything&amp;rdquo; in house, including Bazel and the distributed build services it relies on.&lt;/p>
&lt;p>&lt;strong>[08:35]&lt;/strong> Brief introduction to what Bazel is: a polyglot build system.&lt;/p>
&lt;p>&lt;strong>[10:11]&lt;/strong> Thoughts on the distinction&amp;mdash;or rather, lack thereof&amp;mdash;between build systems and CI systems. While they have been traditionally thought of as separate, they are pretty intertwined and you need your CI system to be as aware of the build process as possible to be maximally efficient.&lt;/p>
&lt;p>&lt;strong>[10:56]&lt;/strong> Brief introduction to what the Starlark language is, why it exists, and how it is used to define Bazel rules. Includes a brief explanation of major Bazel concepts such as targets, rules, and actions.&lt;/p>
&lt;p>&lt;strong>[13:28]&lt;/strong> Thoughts on why Bazel is a good fit for a monorepo.&lt;/p>
&lt;h1 id="build-incrementality">Build incrementality&lt;/h1>
&lt;p>&lt;strong>[14:45]&lt;/strong> Description of how build incrementality works and how Bazel determines which parts of the build graph to rebuild. Covers how traditional file systems use timestamps, how Bazel tries to do something better, and how you can do even fancier stuff if you have the right support from the file system.&lt;/p>
&lt;p>&lt;strong>[17:36]&lt;/strong> Deeper dive into Skyframe: the component within Bazel that tracks the build graph and helps decide which parts need to be rebuilt every time.&lt;/p>
&lt;p>&lt;strong>[19:02]&lt;/strong> Separation of local machine vs. remote machine resources: what parts of the build happen where? Is the build graph &amp;ldquo;in the cloud&amp;rdquo; too?&lt;/p>
&lt;p>&lt;strong>[20:06]&lt;/strong> Notes on how Bazel decides how to behave (spolier alert: manual configuration) and a mini-rant about Bazel having too many flags.&lt;/p>
&lt;h1 id="dependency-management">Dependency management&lt;/h1>
&lt;p>&lt;strong>[21:12]&lt;/strong> Exploring dependency management for third-party packages, focusing on how Google had traditionally done this in their monorepo.&lt;/p>
&lt;p>&lt;strong>[22:16]&lt;/strong> Deeper dive into the history of dependency management by looking into how the workspace file came to be and why it has limitations.&lt;/p>
&lt;p>&lt;strong>[24:01]&lt;/strong> Extending Bazel, or rather the difference between the Java core vs. the Starlark ecosystem, and how the Build API bridges the gap between the two.&lt;/p>
&lt;p>&lt;strong>[25:34]&lt;/strong> Brief digression into the newly-released &lt;a href="https://buck2.build/">Buck2&lt;/a>.&lt;/p>
&lt;h1 id="bazel-migrations">Bazel migrations&lt;/h1>
&lt;p>&lt;strong>[26:23]&lt;/strong> Migrating to Bazel at a company like Snowflake. Exploration of where the difficulties arise.&lt;/p>
&lt;p>&lt;strong>[28:50]&lt;/strong> Discussion on how platform engineering is becoming its own thing, with the goal of building developer tools and experiences as company-internal products.&lt;/p>
&lt;p>&lt;strong>[30:44]&lt;/strong> Highlights of the primary (positive) benefits for the users after a Bazel migration: fast builds and &lt;a href="/2020/12/google-no-clean-builds.html">no more &amp;ldquo;make clean&amp;rdquo;&lt;/a>.&lt;/p>
&lt;h1 id="remote-execution">Remote execution&lt;/h1>
&lt;p>&lt;strong>[32:59]&lt;/strong> Integration of Bazel with remote services. Differences between remote caching and remote execution, and an exploration of different implementations of each.&lt;/p>
&lt;p>&lt;strong>[34:25]&lt;/strong> Brief discussion on generating SBOMs and how Bazel&amp;rsquo;s dependency tracking is perfectly aligned to provide these.&lt;/p>
&lt;p>&lt;strong>[35:26]&lt;/strong> Sandboxing. A discussion on the different levels of what you can restrict per platform and the trade-offs in complexity and performance. In other words: sandboxing is a spectrum.&lt;/p>
&lt;h1 id="forward-looking-plans">Forward-looking plans&lt;/h1>
&lt;p>&lt;strong>[37:15]&lt;/strong> Bazel&amp;rsquo;s future plans. Not my plans nor predictions, but rather what&amp;rsquo;s coming up in Bazel 7. (&lt;a href="https://blog.bazel.build/2023/12/11/bazel-7-release.html">Already released&lt;/a> at the time of this writing.)&lt;/p>
&lt;p>&lt;strong>[38:14]&lt;/strong> My wishlist for Bazel, which is basically &lt;a href="/2015/04/on-bazel-and-open-source.html">what I brought up back in 2015&lt;/a>: it&amp;rsquo;d be awesome if it was smaller so that it could be usable in the smaller projects that lie in the foundations of the Unix systems we use today.&lt;/p>
&lt;p>&lt;strong>[38:49]&lt;/strong> Thoughts on the upcoming BazelCon. (It was awesome. See &lt;a href="/2023/10/bazelcon-2023-et-al-trip-report.html">my attendance report&lt;/a>!)&lt;/p>
&lt;h1 id="source-control">Source control&lt;/h1>
&lt;p>&lt;strong>[39:30]&lt;/strong> Digression on source control, how Git is not great for monorepos, and how Google ended up building their own thing after using Perforce for many years. Also a brief explanation on how Bazel can leverage source control system integrations for better performance.&lt;/p>
&lt;p>&lt;strong>[42:28]&lt;/strong> And a related follow-up topic: test selection strategies in a massive monorepo, starting with how unit tests are easy to handle but doing something smart about integration tests requires heurisitics or maybe some sort of AI.&lt;/p>
&lt;p>And that&amp;rsquo;s about it. Hope you enjoy this episode!&lt;/p></description></item><item><title>Hard disk LEDs and noisy machines</title><link>https://jmmv.dev/2023/12/hard-disk-leds-and-noisy-machines.html</link><pubDate>Fri, 15 Dec 2023 09:20:00 -0700</pubDate><guid>https://jmmv.dev/2023/12/hard-disk-leds-and-noisy-machines.html</guid><description>&lt;p>The computers of yesteryear had this little feature known as blinking LED lights 🔆. They also had this other feature called noisy disks 💾 and loud fans 🪭. Uh wait. Features? Why &amp;ldquo;features&amp;rdquo; and not &amp;ldquo;annoyances&amp;rdquo;?! 🧵👇&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-15-retro-pc-leds.jpg" class="with-border">
&lt;figcaption>Front panel of a common PC case in the late 1990s. My Pentium MMX 166 was hosted in one of these.&lt;/figcaption>
&lt;/figure>
&lt;p>You see, these bright lights and loud noises acted as canaries 🐦 in a performance mine. They gave developers a chance to notice when things were off performance-wise. If your code abused the CPU or the hard disk by mistake, you could tell right away.&lt;/p>
&lt;p>Nowadays, developer machines tend to be quiet under heavy load, and the vast majority of laptops don&amp;rsquo;t even have lights anymore. The obvious example are Macs: they haven&amp;rsquo;t had hard disk LEDs for a really long time, and since the M1, they are silent and cold too.&lt;/p>
&lt;p>These characteristics are nice from a usability perspective. Unfortunately, as a developer, you now need to first &lt;em>imagine&lt;/em> that something is wrong before even deciding to look for a problem. If the thought never crosses your mind, then you may never look.&lt;/p>
&lt;p>Let me give you a few examples of the kinds of inefficiencies that I&amp;rsquo;m talking about. These would have been trivially noticed by the presence of indicators. These are all based on real-world situations I faced at some point in the (recent) past.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>🪵 In a project I worked on, our development builds started writing about 80 MB of log messages &lt;em>per second&lt;/em> to disk. No matter how you look at it, that&amp;rsquo;s &lt;em>a lot&lt;/em> of disk traffic, and yet&amp;hellip; the problematic code passed code review and was merged into the main branch.&lt;/p>
&lt;p>The only indication that something was wrong was when &lt;em>other&lt;/em> developers came asking for help because their local disk space was running out faster than usual. There was no other symptom behind the problem.&lt;/p>
&lt;p>You&amp;rsquo;d hope that this inefficiency would be caught while qualifying the new release for production because, in theory, such logging waste would translate in an increase in CPU consumption or network bandwidth. But&amp;hellip; I&amp;rsquo;m not so sure the issue would have been noticed.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🌐 In another project I worked on, I noticed that Bazel took an incredibly long time to complete some actions. It wasn&amp;rsquo;t until I looked in detail that I saw it stuck in a loop fetching the same remote artifact over and over again due to connection resets.&lt;/p>
&lt;p>The build completed successfully after many minutes once Bazel gave up on the downloads and fell back local execution. There was no reason to suspect that something was wrong other than &amp;ldquo;these actions are just huge&amp;rdquo;. In reality, though, there was a bug somewhere.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>🧱 Just today, I was in a video call and noticed that my laptop was reading 100MB/s from disk non-stop. I concluded the meeting but the disk reads didn&amp;rsquo;t stop. A quick peek at &lt;code>top&lt;/code> showed something called &lt;code>WallpaperVideoExtension&lt;/code> that seemed to have gone rogue.&lt;/p>
&lt;p>This background process was consuming one full CPU, but such load wasn&amp;rsquo;t enough to make the system feel slower nor noisier. I suppose I would eventually have noticed that the battery was running out quicker than usual, but maybe not.&lt;/p>
&lt;p>Killing the process made the problem go away and the constant disk reads stopped. Looking online, I find other instances of &lt;code>WallpaperVideoExtension&lt;/code> consuming lots of CPU and memory, so this seems to be a bug. But if it&amp;rsquo;s common, why wasn&amp;rsquo;t it noticed in the first place?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>In any case, this last scenario gives you a hint 🔍 as to where I&amp;rsquo;m going: how did I even notice this last problem? After all, my M1 Mac was working just fine: it was just slightly warmer than usual but there was no loud fan noise nor lights to tell me about disk activity.&lt;/p>
&lt;p>The answer is simple: I have an omnipresent performance monitor in my screen that shows CPU load, memory pressure, disk I/O throughput, and network traffic. This monitor is always visible, taking little space in the menu bar or the task bar.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-15-istat-menus.png" class="with-border">
&lt;figcaption>iStat Menus on the macOS menu bar, with the panel for CPU usage tracking open.&lt;/figcaption>
&lt;/figure>
&lt;p>Every time I sense something is a tiny bit off, I glance 👀 at the monitor. You cannot imagine how many times I&amp;rsquo;ve gone &amp;ldquo;huh, that&amp;rsquo;s interesting&amp;rdquo; by seeing unexpected activity and then went on to discover big performance problems somewhere in the system.&lt;/p>
&lt;p>My recommendation is that you stop what you are doing and go and install such a performance monitor &lt;em>right now&lt;/em>. I&amp;rsquo;d even argue that having one always visible should be a hard requirement for any development machine and corp IT departments should preinstall one.&lt;/p>
&lt;p>Personally, I&amp;rsquo;m a huge fan of &lt;a href="https://bjango.com/mac/istatmenus/">iStat Menus&lt;/a> for macOS and have been using it for years. But if macOS is not your thing, you can find similar tools for other platforms like &lt;a href="https://extensions.gnome.org/extension/3010/system-monitor-next/">system-monitor-next&lt;/a> for Gnome.&lt;/p>
&lt;p>Unfortunately, these monitors only help if you develop on your local machine&amp;mdash;a workflow that&amp;rsquo;s becoming exceedingly rare. If, instead, you SSH into remote virtual machines to do your development or use VSCode&amp;rsquo;s remote features, you&amp;rsquo;ll need a different answer.&lt;/p>
&lt;p>This is a situation I face right now. The modern ThinkStation I have in the garage is well-equipped with useful lights&amp;hellip; but I only access it over SSH for development so those lights and its disk noises are kinda useless from where I sit.&lt;/p>
&lt;p>And I&amp;rsquo;m not sure what the right answer here is. If you have been around for a while, you may remember &lt;a href="http://gkrellm.srcbox.net">GKrellM&lt;/a>, which I was an avid user of. This system monitor had the ability to display &lt;em>remote&lt;/em> machine activity and I&amp;rsquo;d love to have that again.&lt;/p></description></item><item><title>A CLI text editor? In my Windows?</title><link>https://jmmv.dev/2023/12/a-cli-text-editor-in-my-windows.html</link><pubDate>Fri, 08 Dec 2023 14:45:00 -0800</pubDate><guid>https://jmmv.dev/2023/12/a-cli-text-editor-in-my-windows.html</guid><description>&lt;p>&lt;em>It&amp;rsquo;s more likely than you think!&lt;/em>&lt;/p>
&lt;p>In a surprising twist of events, Microsoft is &lt;a href="https://twitter.com/plante_msft/status/1732857615997132834">exploring the addition of a command-line (CLI) text editor to Windows&lt;/a>. If you ask me, &lt;em>not&lt;/em> having a CLI text editor on Windows is mind-boggling: you can access a Windows machine via SSH these days, so not having an editor that works in the console is a big handicap for remote system administration. So, should Windows bundle a CLI text editor? Of course it should.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-08-windows-95-edit-com.png" class="with-border">
&lt;figcaption>Windows 95 running an MS-DOS Prompt with the &lt;tt>EDIT.COM&lt;/tt> that shipped with it.&lt;/figcaption>
&lt;/figure>
&lt;p>But&amp;hellip; wait as second. Didn&amp;rsquo;t Windows use to ship with a CLI text editor? The one inherited from MS-DOS? Yes it did. So what happened? How was the editor lost? Let&amp;rsquo;s take a peek at the history and let&amp;rsquo;s see if you agree with me that Microsoft should revive the old editor instead of bundling modern-yet-alien Vim or Emacs.&lt;/p>
&lt;p>By the way, this post is brought to you by the inspiration provided by my first paid subscriber. Thank you very much, K., for taking this step and supporting my work.&lt;/p>
&lt;h1 id="in-the-beginning-there-was-edlin">In the beginning, there was Edlin&lt;/h1>
&lt;p>Early versions of DOS (1980) all the way through MS-DOS 5.0 (1990) included a &amp;ldquo;line editor&amp;rdquo; called &lt;a href="https://en.wikipedia.org/wiki/Edlin">Edlin&lt;/a> and nothing else. You may have never heard of or used a line editor, so let me show you how they look like and work. Here is a sample session with Edlin:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">C:\&amp;gt;EDLIN TEST.TXT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New file
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">*I
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1:*second line
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2:*delete me
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3:*[Ctrl+Z followed by Enter]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">*L
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1: second line
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2: delete me
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">*1I
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1:*first line
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2:*[Ctrl+Z followed by Enter]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">*L
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1: first line
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2:*second line
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3: delete me
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">*3D
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">*W
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">*E
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">C:\&amp;gt;TYPE TEST.TXT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">first line
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">second line
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">C:\&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As you can see from the above, a line editor does not have a full-screen UI. Instead, the editor works by letting you issue textual commands that affect the contents of a file. You can insert new lines, delete existing ones, modify their content, and list what the file has in it&amp;mdash;much like how you enter programs in a line-oriented BASIC interpreter or how you interact with the files on your machine via the shell.&lt;/p>
&lt;p>Needless to say, and while line editors work and are truly amenable to scripting, they are not particularly intuitive nor user-friendly. I have to wonder why MS-DOS shipped with &lt;em>just&lt;/em> Edlin until 1990. After all, by the time Edlin was created in 1980, full-screen editors like &lt;code>vi(1)&lt;/code> had already existed for 4 years so it&amp;rsquo;s not like they were impossible to create. However, it&amp;rsquo;s plausible that the limitations of DOS and the machines that DOS ran on made it much more difficult to recreate an editor like &lt;code>vi(1)&lt;/code>, which was made for Unix systems that ran on more powerful hardware.&lt;/p>
&lt;p>As an aside: &lt;code>ed(1)&lt;/code> and &lt;code>ex(1)&lt;/code> are similar to Edlin and you have both &lt;em>today&lt;/em> on pretty much any Unix or Linux system you access. And the &lt;code>vi(1)&lt;/code> that you like is &amp;ldquo;just&amp;rdquo; a facade over &lt;code>ex(1)&lt;/code>. When you use the &lt;code>:&lt;/code> command to get to the &lt;code>vi(1)&lt;/code> prompt to type a command, what you are typing are &lt;code>ex(1)&lt;/code> commands. Keep that in mind if you ever face a situation where the terminal doesn&amp;rsquo;t work and all you can use are the line editors: previous &lt;code>vi(1)&lt;/code> knowledge could come in handy.&lt;/p>
&lt;h1 id="and-microsoft-said-let-there-be-editcom">And Microsoft said, &amp;ldquo;Let there be EDIT.COM&amp;rdquo;&lt;/h1>
&lt;p>In 1990, Microsoft launched MS-DOS 5.0 and, with it, a full-screen text editor called &lt;a href="https://en.wikipedia.org/wiki/MS-DOS_Editor">MS-DOS Editor&lt;/a>, or &lt;code>EDIT.COM&lt;/code> for short. This editor was built on QBasic and it featured a full-screen interactive UI. The latest version of the editor, which was included with Windows 9x (MS-DOS 7.x), looked like this:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-08-dosbox-edit-com.png" class="with-border">
&lt;figcaption>The original &lt;tt>EDIT.COM&lt;/tt> from Windows 9x running in DOSBox.&lt;/figcaption>
&lt;/figure>
&lt;p>This new version of the editor was obviously much more usable and welcoming than Edlin. As you can see from the picture, &lt;code>EDIT.COM&lt;/code> featured a full-screen windowed textual interface with support for multiple files (in its Windows 9x versions), drop down menus, and even mouse integration. These interfaces were extremely common back in the day in DOS: almost every program you ran launched a full-screen UI with textual windows and menus.&lt;/p>
&lt;p>Interestingly, interfaces like these were never a thing on Unix systems and I must confess I was shocked when I first moved from DOS to Linux. I was used to Borland Turbo C++ and WordPerfect 5.1, so when I faced &lt;code>vi(1)&lt;/code> on Linux for the first time, I couldn&amp;rsquo;t believe my eyes: what was this barren interface with its awkward commands? I eventually learned the &lt;code>vi(1)&lt;/code> and Emacs ways, but it&amp;rsquo;s a pity that those interfaces have been lost. They were really intuitive and powerful, and they would be wonderful to have in these days of cloud computing where we access remote computers over SSH all the time.&lt;/p>
&lt;h1 id="but-then-darkness-settled-in">But then&amp;hellip; darkness settled in&lt;/h1>
&lt;p>Unfortunately, both Edlin and &lt;code>EDIT.COM&lt;/code> were 16-bit DOS applications and they were never ported to 32-bit Windows. They were able to stay bundled with all 32-bit x86 Windows editions up to Windows 10 because Windows could run such ancient binaries via &lt;a href="https://en.wikipedia.org/wiki/Virtual_DOS_machine">NT&amp;rsquo;s Virtual DOS Machines&lt;/a>&amp;hellip; but the two editors were scraped in the x64 editions. Yes, this means that all 64-bit Windows editions have been devoid of a CLI text editor from the beginning.&lt;/p>
&lt;p>You could say that this is not a big deal because Windows still includes Notepad and Notepad is similar to &lt;code>EDIT.COM&lt;/code> in its feature set. And yes, they are similar&amp;hellip; but with a critical and obvious difference: Notepad cannot be used on a remote machine via SSH. For someone that has grown up routinely accessing other machines to do work on them via SSH, this sounded like a ridiculous move and further perpetuated the feeling that administering a Windows machine from the shell was a joke&amp;mdash;even with all effort that the PowerShell developers have put to make this possible.&lt;/p>
&lt;h1 id="and-in-the-end-there-may-be-light">And in the end, there may be light&lt;/h1>
&lt;p>But hey, it seems like Microsoft may be correcting course here thanks to, and this is the big surprise, the Windows Terminal team. In discussion &lt;a href="https://github.com/microsoft/terminal/discussions/16440">#16440&lt;/a>, the team is exploring (re)adding a CLI text editor to Windows. As the discussion says: &lt;em>&amp;ldquo;A CLI editor is a core tool for system admins, developers, and power users.&amp;rdquo;&lt;/em> Well, yes, no kidding. I&amp;rsquo;m just surprised it took this long to reach this conclusion.&lt;/p>
&lt;p>Now, what would &lt;em>you&lt;/em> pick as the default text editor for the Windows textual console?&lt;/p>
&lt;p>Personally, and while I&amp;rsquo;d quickly say &amp;ldquo;just bundle Vim&amp;rdquo; like many others have&amp;hellip; I acknowledge it would feel out of place. Vim, Emacs, or even Nano are &lt;em>not&lt;/em> Windows applications. Yes, they work on Windows, but they don&amp;rsquo;t embody the traditional way things have worked on this platform. I feel that integrating any of these editors into Windows would further perpetuate the impression that Windows is just trying to copy Linux without actually being Linux.&lt;/p>
&lt;p>So, if you ask me, I&amp;rsquo;d vote for the re-addition of &lt;code>EDIT.COM&lt;/code>. Obviously not a verbatim copy of what it was because it&amp;rsquo;d be nice to have one or two extra features added to it: I&amp;rsquo;d personally welcome making the editor respect indentation when inserting lines and maybe having some sort of syntax highlighting (without going all the way with LSP support). The key would be to preserve the simple, full-screen UI.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-12-08-yori-yedit.png" class="with-border">
&lt;figcaption>YEdit running in a Yori Windows Terminal session on Windows 11.&lt;/figcaption>
&lt;/figure>
&lt;p>And as it turns out, the foundations for this already exist in &lt;a href="http://www.malsmith.net/edit/">YEdit&lt;/a>, a modern free reimplementation of the old editor for Windows. It has even been brought up in the discussion, so it seems I&amp;rsquo;m not the only one thinking this way.&lt;/p>
&lt;p>In any case, I encourage you to leave your thoughts in the comments section below or, even better, join the official discussion at &lt;a href="https://github.com/microsoft/terminal/discussions/16440">microsoft/terminal#16440&lt;/a>.&lt;/p></description></item><item><title>Strings, encodings, NULs and Bazel</title><link>https://jmmv.dev/2023/12/strings-encodings-nuls-and-bazel.html</link><pubDate>Sun, 03 Dec 2023 10:30:00 -0700</pubDate><guid>https://jmmv.dev/2023/12/strings-encodings-nuls-and-bazel.html</guid><description>&lt;p>Just yesterday, &lt;a href="https://twitter.com/vkrajacic/status/1730891609191981305">Twitter user @vkrajacic wrote&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>Advice for new C programmers: &amp;ldquo;Avoid null-terminated strings; they&amp;rsquo;re outdated, inefficient and impractical.&amp;rdquo;&lt;/p>
&lt;p>Create your own type with basic functions. It&amp;rsquo;s not that hard, and it goes a long way. One of the benefits of this approach, among others, is slicing without copying.&lt;/p>
&lt;/blockquote>
&lt;p>This suggestion has its merits and I understand where it is coming from: &lt;em>performance&lt;/em>. You see: the traditional way to represent strings in C is to use &lt;a href="https://en.wikipedia.org/wiki/Null_character">NUL-terminated byte arrays&lt;/a>. Yet&amp;hellip; this has deemed to be &lt;a href="https://queue.acm.org/detail.cfm?id=2010365">the most expensive one-byte mistake&lt;/a> because of the adverse performance implications that this carries. (NUL, &lt;em>not&lt;/em> NULL, is the better name for the &lt;code>\0&lt;/code> byte by the way.)&lt;/p>
&lt;p>It is of course possible to do differently. Pascal, for example, used a 1-byte prefix to indicate how long strings are. This representation takes the same space as a NUL terminator and fixes the performance problems, but it carries the downside of limiting strings to 255 bytes in length. And you can do as the original author said: amend your strings with a (larger) size field so you do not suffer from this limitation.&lt;/p>
&lt;p>So, yes, it &lt;em>is&lt;/em> possible to use strings without NUL terminators. Unfortunately, you are in for pain if you do so for one simple reason: interop. Your code does not run in a vacuum: it runs in the context of an existing operating system, and it probably uses one or more libraries. Almost all operating systems to date, if not all, expose a C API (libc and system calls), which means that they expect strings to be NUL-terminated. And the same is true for all interesting libraries out there.&lt;/p>
&lt;p>And for this reason, I want to tell you a little story about how I found this painful problem when I was working on Bazel a few years ago.&lt;/p>
&lt;hr>
&lt;p>Bazel is primarily a Java program. Bazel also has a bunch of C and C++ code integrated via JNI, which is used to reach certain system calls and libraries that are only available in C. For &lt;a href="https://www.oracle.com/technical-resources/articles/javase/supplementary.html">historical reasons&lt;/a>, Java uses UTF-16 to represent strings but&amp;hellip; most operating systems out there &lt;em>do not&lt;/em>. As a consequence, every JNI call has to start with a conversion from UTF-16 into whatever the operating system may accept, which typically is Latin-1 or UTF-8. This is a costly, unavoidable step.&lt;/p>
&lt;p>Fortunately, Java 9 introduced a new feature called &lt;a href="https://openjdk.org/jeps/254">&lt;em>compact strings&lt;/em>&lt;/a>. When this feature is enabled, the JVM represents strings as Latin-1 wherever possible: as long as the string&amp;rsquo;s characters can be represented with this encoding, UTF-16 doesn&amp;rsquo;t enter the picture. This is great because most strings that Bazel handles are file paths&amp;mdash;it handles &lt;em>a lot&lt;/em> of paths&amp;mdash;and these can typically be represented in Latin-1. With this feature, we could modify &lt;a href="https://cs.opensource.google/bazel/bazel/+/master:src/main/native/latin1_jni_path.cc;drc=26c7e10739907332e70d31e68d2bd2ff2e9a84fb">the JNI shims&lt;/a> to reuse the in-memory bytes &lt;em>as is&lt;/em>, without a costly conversion in the common case.&lt;/p>
&lt;p>But there is an unfortunate twist. The Latin-1 compact strings that the JVM creates are &lt;em>not&lt;/em> NUL-terminated. This means that, even if the string bytes that Java hands to C are exactly as we need them in memory to call some other API, they are not directly usable. As a result, the JNI code is forced to make a &lt;em>copy&lt;/em> of the string just so that it can pad it with a NUL terminator.&lt;/p>
&lt;p>Which is&amp;hellip; sad and wasteful. As I mentioned, Bazel handles a ton of paths. Most of the memory bloat in the Bazel server process comes from the need to track file paths and command line arguments, and when you have many of these strings amounting to GBs of RAM, you can imagine that processing and copying them is costly too. I think I did measure a not-insignificant runtime penalty from these unnecessary copies back in the day, but I forget the details now.&lt;/p>
&lt;p>So, be careful: it&amp;rsquo;s entirely reasonable to annotate string representations with their size, and you should do so where possible because of the performance gains that come with it. But when you do this, don&amp;rsquo;t forget to pad the strings with a NUL character for the cases where you need interop. You don&amp;rsquo;t want to be making unnecessary string copies just because of this, and you don&amp;rsquo;t know when you&amp;rsquo;ll need the interop.&lt;/p>
&lt;p>C++&amp;rsquo;s &lt;code>std::string&lt;/code>, for example, uses a combination of a NUL terminator and a size length, which allows it to be efficient for manipulation but also allows passing the &amp;ldquo;raw bytes&amp;rdquo; to C interfaces. I suppose Go and Rust do the same, but I haven&amp;rsquo;t looked. &lt;a href="https://www.brandons.me/blog/why-rust-strings-seem-hard">Strings are hard though&lt;/a> and some languages do better than others in handling them.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-12-03-threads.jpg" length="589063" type="image/jpeg"/></item><item><title>Links: November 2023 edition</title><link>https://jmmv.dev/2023/11/links-november-2023-edition.html</link><pubDate>Thu, 30 Nov 2023 10:30:00 -0700</pubDate><guid>https://jmmv.dev/2023/11/links-november-2023-edition.html</guid><description>&lt;p>Welcome to the second edition of my &amp;ldquo;interesting links&amp;rdquo; recap, this time covering the month of November 2023.&lt;/p>
&lt;p>For context, what follows is my manual curation of cool articles, videos, and projects I stumbled upon during this time period. But this is not &lt;em>just&lt;/em> a dump of links: &lt;em>each link is accompanied by a 1-paragraph commentary&lt;/em> that justifies why I thought the material was cool, why it is relevant to this publication and, more importantly, an attempt to nudge you into reading it.&lt;/p>
&lt;p>Before we dive in, two quick things. First: I want to explicitly acknowledge all the new subscribers that have joined us since &lt;a href="/2023/11/windows-nt-peeking-into-the-cradle.html">the last post on Windows NT&lt;/a> landed on some major news sites. Thank you; I hope you find this interesting and a good reason to stick around. And, second: the &lt;a href="/2023/10/links-october-2023-edition.html">first edition&lt;/a> of this recap didn&amp;rsquo;t get any real traction, so let&amp;rsquo;s see if this one fares better. You can help by liking and resharing this post &lt;em>wink&lt;/em> &lt;em>wink&lt;/em> or&amp;hellip; as usual, by subscribing.&lt;/p>
&lt;h1 id="articles">Articles&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.notebookcheck.net/Lenovo-ThinkPad-T14s-G4-review-Business-laptop-is-better-with-AMD-Zen4.763581.0.html">&amp;ldquo;Lenovo ThinkPad T14s G4 review: Business laptop is better with AMD Zen4&amp;rdquo;&lt;/a> by Andreas Osthoff on November 1st, 2023.&lt;/strong>&lt;/p>
&lt;p>I have been eyeing the T14s that Costco has on sale for a while and, while I&amp;rsquo;m not going to get it because of the &amp;ldquo;low&amp;rdquo; screen resolution, I had to read through this review. And oh wow, what an amazing, in-depth description of the device. I&amp;rsquo;m now waiting for the X1 Nano to be in stock again&amp;hellip;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://mjg59.dreamwidth.org/68350.html">&amp;ldquo;Why ACPI?&amp;rdquo;&lt;/a> by Matthew Garrett on October 31st, 2023.&lt;/strong>&lt;/p>
&lt;p>A high-level overview of what ACPI is, why it was needed to replace APM, and how computers would look like in a world without ACPI.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://quick-lint-js.com/blog/bug-journey/">&amp;ldquo;Sometimes, it &lt;em>is&lt;/em> a compiler bug&amp;rdquo;&lt;/a> by strager on May 25th, 2022.&lt;/strong>&lt;/p>
&lt;p>Great debugging story of an obscure problem that the author hit when seeing someone else write a bug in their code, suggesting that they install a VSCode extension that would have highlighted the bug, and watching in real time how the extension then pointed at a non-existent bug. I recall hitting some compiler bugs myself (a similar issue with Rust&amp;rsquo;s incremental compilation, and various ICEs) but I have never had the patience to dig for an answer.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.xtof.info/intel80386.html">&amp;ldquo;Intel 80386, a revolutionary CPU&amp;rdquo;&lt;/a> by Christophe Meneboeuf on September 2nd, 2023.&lt;/strong>&lt;/p>
&lt;p>A good story on how the 80386 came to be and why it was important at the time. I recall reading a book (&lt;a href="https://twitter.com/jmmv/status/1721531589635813396">that I still have&lt;/a>) that described the 8086, the 80286, and the 80386 in great depth and how they differed among each other. All of the details about memory and task management felt fascinating to me at the time, and I&amp;rsquo;ve always found it weird that almost none of the features that the chips provided (segmentation instead of pagination; 4 protection levels; task, interrupt, and call gates; hardware-assisted task switching&amp;hellip;) were put to use by operating systems. Sure, their original implementation might have sucked and been slow, but if they had been used, Intel would have improved those over time.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.vidarholen.net/contents/blog/?p=1035">&amp;ldquo;What exactly was the point of [ “x$var” = “xval” ]?&amp;rdquo;&lt;/a> by Vidar on April 12th, 2021.&lt;/strong>&lt;/p>
&lt;p>One more oddity that you&amp;rsquo;ll find in shell scripts. And not just ancient ones: this still shows up regularly in auto-generated &lt;code>configure&lt;/code> scripts, or even in their &lt;code>configure.ac&lt;/code> originals because people copy/paste code snippets without thinking about them much.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://devblogs.microsoft.com/oldnewthing/20231103-00/?p=108966">&amp;ldquo;Why does unsafe multithreaded use of an &lt;code>std::unordered_map&lt;/code> crash more often than unsafe multithreaded use of a &lt;code>std::map&lt;/code>?&amp;rdquo;&lt;/a> by Raymond Chen on November 3rd, 2023.&lt;/strong>&lt;/p>
&lt;p>I always enjoy Raymond&amp;rsquo;s posts, and to be honest, his blog is what drove me into writing mine and changing the way I looked at Microsoft and Windows 9x. In this one, he entertains a question of the type &amp;ldquo;this thing is broken, but why does it look more broken in this case than in this other one?&amp;rdquo;. Obviously, The Internet cannot read subtlety.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="end-to-end-tool-testing-with-bazel.md">&amp;ldquo;End-to-end testing with Bazel and shtk&amp;rdquo;&lt;/a> by yours truly on November 4th, 2023.&lt;/strong>&lt;/p>
&lt;p>Last month, and for reasons that are not interesting, I revived an old project of mine: &lt;a href="https://shtk.jmmv.dev">shtk&lt;/a>. This, combined with my trip to BazelCon 2023, made me want to create a new ruleset to integrate shtk with Bazel builds because I know the shell is a great language to write integration tests for tools. So I ended up creating &lt;a href="https://github.com/jmmv/rules_shtk/">rules_shtk&lt;/a> and wrote this post to explain how to use it and how it can help you write better tools.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://blog.rust-lang.org/2023/11/09/parallel-rustc.html">&amp;ldquo;Faster compilation with the parallel (Rust) front-end in nightly&amp;rdquo;&lt;/a> by Nicholas Nethercote on behalf of The Parallel Rustc Working Group on November 9th, 2023.&lt;/strong>&lt;/p>
&lt;p>This is exciting work. I have an overkill server in the garage with 72 cores where I remote into for development and, most of the time, it goes vastly unused. I doubt the Rust compiler will be able to use that many cores, at least for the kind of projects I work on&amp;mdash;they aren&amp;rsquo;t &lt;em>that&lt;/em> large&amp;mdash;but still, this is exciting.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://flak.tedunangst.com/post/write-your-own-terminal">&amp;ldquo;Write your own terminal&amp;rdquo;&lt;/a> by Ted Unangst on November 10th, 2023.&lt;/strong>&lt;/p>
&lt;p>Writing a terminal is surely rewarding: as the author says, you have to do very little to get it to a functional state, but then can iterate endlessly on the details and on performance. And I know it&amp;rsquo;s fun because I had to do this for the &lt;a href="https://www.endbasic.dev/">EndBASIC&lt;/a> console. Replacing the use of Xterm.js with my own implementation showed results quickly, and I was then able to mix text and graphics seamlessly.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="why-do-i-know-shell-and-how-can-you.md">&amp;ldquo;Why do I know shell, and how can you?&amp;rdquo;&lt;/a> by yours truly on November 10th, 2023.&lt;/strong>&lt;/p>
&lt;p>I spent some time last month and this month writing more shell than usual, and people at work often ask me &amp;ldquo;why I know so many ancient incantations&amp;rdquo;. So I decided to explain how the constraints of &lt;a href="http://www.NetBSD.org/">NetBSD&lt;/a>, an open-source OS project I contributed to for many years, guided me down this path.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://virtuallyfun.com/2023/11/12/dont-waste-money-on-a-math-coprocessor-they-said/">&amp;ldquo;Don&amp;rsquo;t waste money on a math coprocessor they said&amp;rdquo;&lt;/a> by neozeed on November 12th, 2023.&lt;/strong>&lt;/p>
&lt;p>Did you know that CPUs did not use to have floating point operations and that there were optional chips you could buy to supplement the CPU with those? Say hi to the FPUs. This article dives into history and shows how installing an 80287 along an 80286 fixed a mysterious crashing bug in a game and in OS/2&amp;mdash;even when none of this code was using floating point. If you are into retro stuff, this one (and &lt;a href="https://virtuallyfun.com/">the whole blog&lt;/a> it seems!) is for you&amp;hellip; but I only wish the author came up with a precise explanation of what went wrong here.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://wingolog.org/archives/2023/11/13/i-accidentally-a-scheme">&amp;ldquo;i accidentally a scheme&amp;rdquo;&lt;/a> by wingo on November 13th, 2023.&lt;/strong>&lt;/p>
&lt;p>This article is short and not very detailed, but it contains a bunch of interesting references to programming language implementation topics and is entertaining to read. You must read the intro, though; it is just great. Plus I learned a new meme&amp;hellip; and several new words.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://yorickpeterse.com/articles/a-decade-of-developing-a-programming-language/">&amp;ldquo;A decade of developing a programming language&amp;rdquo;&lt;/a> by Yorick Peterse on November 14th, 2023.&lt;/strong>&lt;/p>
&lt;p>An easy-to-read reflection on the challenges of building a new programming language, along with some suggestions on how to approach doing so.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://lock.cmpxchg8b.com/reptar.html">&amp;ldquo;Reptar&amp;rdquo;&lt;/a> by Tavis Ormandy on November 14th, 2023.&lt;/strong>&lt;/p>
&lt;p>An article from Google&amp;rsquo;s Project Zero team describing a glitch in instruction processing that makes certain modern x86 processors enter an invalid state. Whether this can be used for privilege escalation is still unknown, but assume the worst.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="ssh-agent-forwarding-and-tmux-done.md">&amp;ldquo;SSH agent forwarding and tmux done right&amp;rdquo;&lt;/a> by yours truly on November 17th, 2023.&lt;/strong>&lt;/p>
&lt;p>If you have ever used SSH agent forwarding and you keep long-running tmux sessions on the remote machine, you know you are in for trouble. This article covers why agent forwarding breaks in this case, describes various solutions, and presents a prototype I quickly wrote (the &lt;a href="https://github.com/jmmv/ssh-agent-switcher/">ssh-agent-switcher&lt;/a>) to fix the problem.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.evanjones.ca/setenv-is-not-thread-safe.html">&amp;ldquo;Setenv is not Thread Safe and C Doesn&amp;rsquo;t Want to Fix It&amp;rdquo;&lt;/a> by Evan Jones on November 19th, 2023.&lt;/strong>&lt;/p>
&lt;p>Well, yes, it is not thread safe&amp;mdash;but you should &lt;em>not&lt;/em> be modifying the environment of your own process, except right before &lt;code>exec&lt;/code>. Environment variables &lt;em>are&lt;/em> global, untyped, not-thread-safe variables.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://pikuma.com/blog/what-is-dos4gw-protected-mode">&amp;ldquo;DOS/4GW and Protected Mode&amp;rdquo;&lt;/a> by Gustavo Pezzi on December 12th, 2021.&lt;/strong>&lt;/p>
&lt;p>Ah, the memories. Learn more about how DOS games could unleash the power of 32 bits and more than 1 MB (yes, MB) of memory by using an &amp;ldquo;extender&amp;rdquo; while running on an &amp;ldquo;OS&amp;rdquo; that was 16-bit real mode.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="code-reviews-a-success-story.md">&amp;ldquo;Code reviews: A success story&amp;rdquo;&lt;/a> by yours truly on November 21st, 2023.&lt;/strong>&lt;/p>
&lt;p>If you ask people what they think about the Pull Request process to get code merged into a project, you&amp;rsquo;ll find critics. I do think PR reviews, and in particular code reviews, are a good process that can increase the quality of the software you ship&amp;mdash;but it&amp;rsquo;s important for the people involved to understand the limitations of the process and when they need to take a different route. This Twitter thread presents a success story that I was personally involved in.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.10stripe.com/articles/why-is-56k-the-fastest-dialup-modem-speed.php">&amp;ldquo;Why is 56k the fastest dialup modem speed?&amp;rdquo;&lt;/a> by Alex Freeman probably pre-2008.&lt;/strong>&lt;/p>
&lt;p>I can hear this article. A good technical explanation on why the maximum transmission speed for dial-up connections is 56k, a number that seems pulled out of thin air, and how it&amp;rsquo;s not possible to achieve it in practice.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://devblogs.microsoft.com/oldnewthing/20231124-00/?p=109059">&amp;ldquo;On harmful overuse of &lt;code>std::move&lt;/code>&amp;rdquo;&lt;/a> by Raymond Chen on November 24th, 2023.&lt;/strong>&lt;/p>
&lt;p>So using &lt;code>std::move&lt;/code> can hurt? Thanks, C++. The article touches upon optimizations that the compiler can perform and how move construction can hamper them. Also, this reminds me how the NRVO (described in the article too) masked a bug in code I wrote long ago, and how I do not want to ever write C++ again if I can avoid it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="windows-nt-peeking-into-the-cradle.md">&amp;ldquo;Windows NT: Peeking into the cradle&amp;rdquo;&lt;/a> by yours truly on November 24th, 2023.&lt;/strong>&lt;/p>
&lt;p>A review of the &amp;ldquo;Showstopper!&amp;rdquo; book combined with my own commentary on how exciting (and tiresome) it must have been to live through the development of Windows NT: the OS that still powers most PCs in the world, more than 30 years after its inception.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://tedium.co/2023/11/24/weird-html-hacks-history/">&amp;ldquo;10 Weird HTML Hacks That Shaped The Internet&amp;rdquo;&lt;/a> by Ernie Smith on November 24th, 2023.&lt;/strong>&lt;/p>
&lt;p>This article gets my vote if only for its retro photos of Netscape 4. But, in any case, the article is a neat summary of weird things that people did (and still do!) with HTML to format their websites. The article is long, but each of the 10 entries has a very brief what/how/why summary at the top which makes it easy to decide what you want to read.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://utcc.utoronto.ca/~cks/space/blog/unix/ShellsAndCurrentDirectory">&amp;ldquo;Unix shells and the current directory&amp;rdquo;&lt;/a> by Chris Siebenmann on November 25th, 2023.&lt;/strong>&lt;/p>
&lt;p>It&amp;rsquo;s interesting to think about how the &amp;ldquo;current directory&amp;rdquo; is represented in the kernel and how, depending on the choices, the kernel may not be able to provide a &lt;code>getcwd(2)&lt;/code> system call. When that happens, how does &lt;code>pwd(1)&lt;/code> work? This article answers these questions, and more.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://muxup.com/2023q4/storing-data-in-pointers">&amp;ldquo;Storing data in pointers&amp;rdquo;&lt;/a> by Alex Bradbury on November 27th, 2023.&lt;/strong>&lt;/p>
&lt;p>Pointers are really wide, but addressable memory isn&amp;rsquo;t yet&amp;mdash;so pointers have enough room to carry data in them. This article describes how, but the more interesting part is the list at the end covering the many real-world use cases where this is done.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="other">Other&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://retrocomputing.stackexchange.com/questions/27926/who-invented-file-extensions-in-file-names">&amp;ldquo;Who invented file extensions in file names?&amp;rdquo;&lt;/a> StackExchange discussion on November 1st, 2023.&lt;/strong>&lt;/p>
&lt;p>We take file extensions as part of file names for granted today, but looking into their history, we discover that extensions were a separate metadata field in the file system, much like timestamps are. It wasn&amp;rsquo;t until Unix and its flat approach to file names that extensions became part of the file names. This is why on MS-DOS you can refer to files without specifying their extension (again, just like you can refer to files without specifying the time they were modified).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://en.wikipedia.org/wiki/Caldera_OpenLinux">&amp;ldquo;Caldera OpenLinux&amp;rdquo;&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>The very first Linux distribution I ever tried. I recall that this came with the PC Actual magazine and remember how the installation instructions in the corresponding article described a workaround for a bug in the mounting of the CD. I also remember not achieving a resolution larger than 320x200 with X11. Not a great first impression&amp;hellip; but this hooked me into the Unix world forever.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.youtube.com/watch?v=qbKGw8MQ0i8">&amp;ldquo;NTFS really isn&amp;rsquo;t that bad [video]&amp;rdquo;&lt;/a> by Robert Collins on January 16th, 2020.&lt;/strong>&lt;/p>
&lt;p>A conference presentation that describes how the speaker optimized Rust&amp;rsquo;s installation from 3 and a half minutes to just 14 seconds on Windows. NTFS isn&amp;rsquo;t the problem: it&amp;rsquo;s the applications assuming that the whole world is like Linux.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.nasm.us/">&amp;ldquo;The Netwide Assembler (NASM)&amp;rdquo;&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>Brought to memory by &lt;a href="https://news.ycombinator.com/item?id=38203553">a Hacker News discussion&lt;/a>. It&amp;rsquo;s interesting to me to see people disregard the AT&amp;amp;T syntax as unusable, which makes me feel better about never learning it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.youtube.com/watch?v=TbZ3HzvFEto">&amp;ldquo;Half-Life: 25th anniversary documentary [video]&amp;rdquo;&lt;/a> by Valve on November 17th, 2023.&lt;/strong>&lt;/p>
&lt;p>A documentary on my favorite game of all times. Well worth the watch, even for the whole family.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://effective-rust.com/">&amp;ldquo;Effective Rust&amp;rdquo;&lt;/a> online book.&lt;/strong>&lt;/p>
&lt;p>Inspired by Scott Meyer&amp;rsquo;s famous Effective C++ book, this online book takes a similar approach to show more than 30 different scenarios in how to better apply Rust. I haven&amp;rsquo;t read it cover to cover, but the few items I skimmed through seem solid. Worth a read and, as with any programming guidelines, lots of what you can find here apply to any language.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.freebsd.org/releases/14.0R/announce/">&amp;ldquo;FreeBSD 14.0-RELEASE Announcement&amp;rdquo;&lt;/a> on November 20th, 2023.&lt;/strong>&lt;/p>
&lt;p>It&amp;rsquo;s here! Go grab it while it&amp;rsquo;s hot. There are claims to significant performance improvements, so I&amp;rsquo;m eagerly awaiting to have a few spare hours to upgrade my server in the garage. I suspect I&amp;rsquo;ll only need a few minutes&amp;hellip; but need to plan for the worst case scenario.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://tmpout.sh/3/">&amp;ldquo;tmp0ut.sh #003&amp;rdquo;&lt;/a> by multiple authors on November, 2023.&lt;/strong>&lt;/p>
&lt;p>A new edition of an online underground ezine talking about security and exploits. The content is super-interesting, but the looks of this are frigging awesome too.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.xbox.com/en-US/power-on">&amp;ldquo;Power On: The Story of Xbox [video series]&amp;rdquo;&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>A 6-part documentary on how the Xbox came to be, and how it almost didn&amp;rsquo;t launch. I&amp;rsquo;ve only been able to watch the first episode so far, but it was engaging.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.youtube.com/watch?v=xi1Lq79mLeE">&amp;ldquo;The mind behind Windows: Dave Cutler&amp;rdquo;&lt;/a> by Dave&amp;rsquo;s Garage on October 21st, 2023.&lt;/strong>&lt;/p>
&lt;p>A 3-hour long interview with Dave Cutler on the creation of Windows NT. Having just written a &lt;a href="/2023/11/windows-nt-peeking-into-the-cradle.html">detailed article on this part of history&lt;/a>, this looks very interesting to watch.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://infinitemac.org/">&amp;ldquo;Infinite Mac&amp;rdquo;&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>Pick any version of System Software/Mac OS from the 1980s or 1990s and run it right in your browser. I wasn&amp;rsquo;t a Mac user until Mac OS X Tiger, so these are systems I never experienced&amp;mdash;except for System 7.5, I think, which I had to use to bootstrap a NetBSD/mac68k system. But if you did, this is a good toy to recreate memories.&lt;/p>
&lt;/li>
&lt;/ul></description><enclosure url="https://jmmv.dev/images/2023-10-31-links.png" length="56457" type="image/jpeg"/></item><item><title>Windows NT: Peeking into the cradle</title><link>https://jmmv.dev/2023/11/windows-nt-peeking-into-the-cradle.html</link><pubDate>Fri, 24 Nov 2023 09:40:00 -0800</pubDate><guid>https://jmmv.dev/2023/11/windows-nt-peeking-into-the-cradle.html</guid><description>&lt;p>It&amp;rsquo;s strange&amp;hellip; but I&amp;rsquo;ve been able to finish reading a book cover-to-cover that&amp;rsquo;s not a book for my kids. It&amp;rsquo;s hard for me to get hooked into books and find the time to read them. I think the one I finished before this might have been &amp;ldquo;&lt;a href="https://www.amazon.com/10-PRINT-CHR-205-5-RND/dp/0262018462?&amp;amp;_encoding=UTF8&amp;amp;tag=blogsystem503-20&amp;amp;linkCode=ur2&amp;amp;linkId=c3ddd9f1db5ead180ea40a44f495092b&amp;amp;camp=1789&amp;amp;creative=9325">10 PRINT&lt;/a>&amp;rdquo;, and that was over a year ago. This time, though, I completed the book on the story behind the creation of Windows NT: namely, &amp;ldquo;Showstopper!&amp;rdquo; in its short form, written by G. Pascal Zachary.&lt;/p>
&lt;p>Reading the story of how Windows NT came to be was entertaining, as it is a story of the system itself and the dynamics between Dave Cutler, the original designer and lead for NT, and the other people involved in the project. I was shy of being 10 years old when Windows NT launched and I didn&amp;rsquo;t comprehend what was going on in the operating systems world and why this release was such a big deal. Reading the book made me learn various new things about the development process, the role of Microsoft in that era, and allowed me to settle some questions I&amp;rsquo;ve had over the years.&lt;/p>
&lt;p>This article is a mixture of a book review and a collection of thoughts and reflections that the book evoked. Let&amp;rsquo;s begin because we have a lot of ground to cover.&lt;/p>
&lt;h1 id="lets-create-a-brand-new-os">Let&amp;rsquo;s create a brand new OS&lt;/h1>
&lt;p>Operating systems are pretty much a commodity these days&amp;mdash;but you couldn&amp;rsquo;t take them for granted before. There was a time during the 1980s and 1990s when a multitude of computer architectures and operating systems thrived, each offering vastly different feature sets and levels of stability than the others. Yes, DOS and Windows were the most popular choices for personal computers, but there were other contenders such as OS/2, BeOS, QNX&amp;hellip; as well as the myriad different commercial Unix derivatives. The open-source BSDs and Linux had just seen the light of day.&lt;/p>
&lt;p>Microsoft&amp;rsquo;s bet to build NT in 1988, a brand new OS from scratch, was bold. There were good reasons for taking the risk, which centered around the desire to modernize DOS and to have first-class support for networks, but investing multiple years of R&amp;amp;D on a massive project like this was risky: others had tried and failed.&lt;/p>
&lt;p>At the end of the day, Microsoft succeeded with NT. The development process took longer than anticipated, but the system finally shipped in 1993. Now, more than 30 years later, NT is behind almost all desktop and laptop computers in the world. The book claims that Cutler repeatedly told his team that they&amp;rsquo;d remember this time period as &amp;ldquo;the good old days&amp;rdquo;, and I think he was well damn right. As tough as that period must have been for everyone involved, they were writing history and setting the direction of personal computing for years to come.&lt;/p>
&lt;h1 id="development-pressure">Development pressure&lt;/h1>
&lt;p>Contrast this to the open-source BSDs and Linux, which were already a reality by NT&amp;rsquo;s launch in 1993. Linux and the original 386BSD were &amp;ldquo;hobby projects&amp;rdquo; for their creators. I&amp;rsquo;m convinced that, at the time, these people and their contributors didn&amp;rsquo;t imagine their toys as anything that would influence the world&amp;mdash;even if, in retrospect, they kinda have: Linux is the basis for almost all mobile devices and servers, and macOS is derived from those original BSDs.&lt;/p>
&lt;p>What I&amp;rsquo;m trying to get at is that there is something to be said about the different thrill of working on these projects. On the one hand, NT was in a race to ship the next revolutionary OS to power all personal computers, with intense pressure from OS/2 and other contenders, and with a design that went against established practice. On the other hand, Linux was in no such rush: its developers worked on it for their own entertainment, probably not grasping what was ahead of them.&lt;/p>
&lt;p>Having been part of the NT team and of that era of computing must have been incredibly exciting. However, it was not all roses for this team. Even though the work of the team was exciting and the potential for impact was massive, the book also shows a clear picture of a really toxic culture: leaders screaming to their peers and reports; normalized long hours and destroyed families; cross-team distrust and shaming&amp;hellip; not something you&amp;rsquo;d probably want to be involved in.&lt;/p>
&lt;h1 id="dogfooding">Dogfooding&lt;/h1>
&lt;p>Creating a new OS is fun but, unless you use the OS regularly, you will have little incentive to discover and fix sharp usability edges or certain classes of bugs. This is where dogfooding, or the practice of &lt;del>eating your own dog food&lt;/del> using your own creations, becomes key. And due to the importance of this, the book has a whole chapter on dogfooding NT.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-24-windows-nt-31-boot.png" class="with-border">
&lt;figcaption>Windows NT 3.1 boot screen. &lt;a href="https://winworldpc.com/product/windows-3/31">Courtesy of WinWorld.&lt;/a>&lt;/figcaption>
&lt;/figure>
&lt;p>The mandate to dogfood NT after it passed a certain functionality threshold comes from Cutler himself and sounds awesome&amp;hellip; and frustrating at the same time. I&amp;rsquo;ve previously dogfooded operating systems&amp;mdash;I ran NetBSD and FreeBSD CURRENT for years while I was a contributor&amp;mdash;and the infrequent crashes were annoying. Note, however, that these two systems were already past a certain stability point by the time I used them so, in general, they worked. I wonder what level of functionality the first dogfood versions of NT had but, based on what I grasp from the book, the answer is &amp;ldquo;not a lot&amp;rdquo;, which means the experience may have been quite a nightmare.&lt;/p>
&lt;p>Note that these days, it seems silly to talk about &amp;ldquo;how this OS is more stable than this other one&amp;rdquo; because all modern OSes implement similar process and file protections, but stability couldn&amp;rsquo;t be taken for granted back then. The DOS-based Windows editions really were quite unstable, and OS/2 and Unix systems put them to shame. The design of NT was going to fix these issues for the Windows world, but it had to be stabilized first too.&lt;/p>
&lt;h1 id="the-build-lab">The build lab&lt;/h1>
&lt;p>Windows releases are often referred to by specific build numbers, which always sounded weird to me: as a regular FreeBSD and NetBSD &lt;em>user&lt;/em>, I churned out multiple new builds of these whole OS &lt;em>per day&lt;/em>, and doing so was trivial and inconsequential. What was so special about Windows that individual build numbers were important? Was it really true that Windows NT 3.51, numbered build 1057, was the 1057th time that the codebase had been assembled together? And the answer is&amp;hellip; yes.&lt;/p>
&lt;p>The book talks a lot about the build lab: the &lt;em>place&lt;/em>&amp;mdash;laptops and remote work were &lt;em>definitely&lt;/em> not a thing in the early 1990s&amp;mdash;where a few engineers took the changes that everyone else made and assembled the whole system into something that could boot. This system was then distributed to the whole team for dogfooding on a daily basis.&lt;/p>
&lt;p>This sounds ridiculous, right? Why wasn&amp;rsquo;t there a CI/CD pipeline to build the system every few hours and publish the resulting image to a place where engineers could download it? Ha, ha. Things weren&amp;rsquo;t this rosy back then. Having automated tests, reproducible builds, a CI/CD system, unattended nightly builds, or even version control&amp;hellip; these are all a pretty new &amp;ldquo;inventions&amp;rdquo;. Quality control had to be done by hand, as did integrating the various pieces that formed the system.&lt;/p>
&lt;p>Regardless, even if you think about having to design a CI/CD system for an OS today, it isn&amp;rsquo;t as trivial as what you need for your run-of-the-mill GitHub project. Validating the built OS against different hardware, assessing the behavior of fundamental system components like the process scheduler, and accepting that any validation can crash the machine and require a physical power cycle&amp;hellip; is not trivial. Even relying on VMs like we do today isn&amp;rsquo;t sufficient, because you &lt;em>do&lt;/em> want to test the OS against real hardware.&lt;/p>
&lt;h1 id="portability-and-design-cleanliness">Portability and design cleanliness&lt;/h1>
&lt;p>These days we take x86-based personal computers as the one and only possibility, which wasn&amp;rsquo;t true back in the day&amp;mdash;and may not be true in the near future either. As I mentioned earlier, the computer world was full of different architectures during the 1980s and early 1990s.&lt;/p>
&lt;p>In my journey to move away from Windows, which &lt;a href="/2020/08/os2-memory-lane.html">started with OS/2 Warp 3&lt;/a> and was followed by Linux and the BSDs, I was lured by NetBSD and stuck with it for years. The main reason I ended up settling on NetBSD was its claims of being &amp;ldquo;cleanly designed&amp;rdquo;, and a big reason for needing &lt;em>and&lt;/em> having a clean design was supporting tens of different architectures out of the same codebase.&lt;/p>
&lt;p>Which is interesting because this is precisely how NT started. From reading the book, I learned that Cutler had the same mentality for his OS and, in fact, the system wasn&amp;rsquo;t ported to x86 until late in its development. He wanted developers to target non-x86 machines &lt;em>first&lt;/em> to prevent sloppy non-portable coding, because x86 machines were already the primary desktops that developers had. In fact, even as x86 increasingly became the primary target platform for NT, the team maintained a MIPS build at all times, and having most tests passing in this platform was a requirement for launching.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-24-windows-nt-351-powerpc.png" class="with-border">
&lt;figcaption>Windows NT 3.51 running on a PowerPC machine. From the &lt;a href="https://virtuallyfun.com/2020/08/02/the-lost-history-of-prep-windows-nt-3-5x-and-the-rs-6000-40p/">"The lost history of PReP: Windows NT 3.5x and the RS/6000 40p"&lt;/a> article at Virtually Fun.&lt;/figcaption>
&lt;/figure>
&lt;p>On this topic, I briefly remember some contemporary news articles in computer magazines describing how the PowerPC was going to be &amp;ldquo;the next big thing&amp;rdquo; and how NT ran on it. I did not grasp what a big deal this was at the time because based on the screenshots that they printed, Windows NT on PowerPC looked exactly the same as Windows 3.11 on my i386 PC. Well, I guess I really just didn&amp;rsquo;t understand what PowerPC nor NT were at all.&lt;/p>
&lt;h1 id="dialing-difficulty-up-to-11-with-ntfs">Dialing difficulty up to 11 with NTFS&lt;/h1>
&lt;p>This golden era also saw the creation of many new file systems. If you were on DOS and Windows 3.x land, your choices were limited, but if you were playing with Linux, you saw new file systems pop up &amp;ldquo;every week&amp;rdquo;. Things settled around the early/mid 2010s, except maybe for the uneventful launch of &lt;a href="https://en.wikipedia.org/wiki/Apple_File_System">APFS&lt;/a> in 2017.&lt;/p>
&lt;p>Creating a new OS from scratch is no easy feat, but wanting to create a brand new file system to go with it is making things difficult just because. While writing a file system is already tricky enough, &lt;em>stabilizing&lt;/em> it is a whole different story. But, as the book describes, the team felt that they needed a new file system to support the reliability and networking needs of NT, so it had to be done. FAT was nowhere close to offer them.&lt;/p>
&lt;p>And NTFS is very interesting. NTFS was a really advanced file system for its time thanks to journaling, support for multi-TB volumes, optional per-directory and per-file compression, detailed ACLs&amp;hellip; none of the Unix file systems of the era had these features. For example, ext3, which extended ext2 with journaling support, did not exist until 2001, and it has been replaced by ext4 and btrfs since. But NTFS is still chugging along in Windows 11, so it is impressive that they could make it happen on time for the OS release. (The same cannot be said about &lt;a href="https://en.wikipedia.org/wiki/WinFS">WinFS&lt;/a>&amp;hellip; which was supposed to ship with Vista and didn&amp;rsquo;t.)&lt;/p>
&lt;p>Now, I know you will complain that NTFS is slow&amp;hellip; but you know what? It almost-certainly is not. Most of the problems with NTFS performance stem from file system filters, which intercept all I/O operations to do heavy stuff like virus scanning. &lt;a href="https://www.youtube.com/watch?v=qbKGw8MQ0i8">NTFS on its own is fine&lt;/a>, but you need to write your applications with knowledge of the system you target: if you treat something as Unix when it isn&amp;rsquo;t, then bad things happen.&lt;/p>
&lt;h1 id="correctness-first-performance-second">Correctness first, performance second&lt;/h1>
&lt;p>Speaking of NTFS performance, the book also touches upon system performance. Unsurprisingly, Cutler wanted to make the system stable and well-designed first, leaving performance for later. Performance was pushed to the side for a while, but the team was confident that they could improve performance and resource consumption later. This was a good strategy, although it didn&amp;rsquo;t play out well for a while.&lt;/p>
&lt;p>What I found interesting is that the book claims that Bill Gates was obsessed with performance and routinely asked about it, because the prospective user base of NT did not have the means to buy high-end computers. Which is great&amp;hellip; but then, I just don&amp;rsquo;t know where &lt;a href="/2023/06/fast-machines-slow-machines.html">performance has gone wrong&lt;/a> at Microsoft because that doesn&amp;rsquo;t seem to be the focus anymore.&lt;/p>
&lt;p>Regardless, and even after performance work, NT was not the fastest at its launch. As the initial reviews published, the system was deemed &amp;ldquo;too big, too slow&amp;rdquo; and requiring too high hardware requirements. This seemed to affect Cutler. Right after the initial 3.1 launch, when the team deserved a break, they were back at work right away to improve these topics in preparation for the 3.51 launch.&lt;/p>
&lt;h1 id="huge-migrations-at-microsoft">Huge migrations at Microsoft&lt;/h1>
&lt;p>Apple is touted as the expert in huge migrations: they moved their hardware lineup from 68k to PowerPC, from PowerPC to x86 and, most recently, from x86 to &lt;a href="https://en.wikipedia.org/wiki/Apple_silicon">Apple Silicon&lt;/a> (ARM). They also moved from 32 bits to 64 bits, dropping 32-bit support later, and from Mac OS Classic to Mac OS X. Apple has indeed executed these huge migrations well, but at each step, they have left apps and developers behind because Apple has never been big on backwards compatibility. Somehow its customers have accepted that.&lt;/p>
&lt;p>If we peek under the covers, Microsoft has also pushed similar humongous migrations. At each step, however, Microsoft has preserved backwards compatibility as much as possible, and I think this is why these migrations seem less of a big deal than they really were.&lt;/p>
&lt;p>What am I talking about? For starters: the jump from the DOS / Windows 3.x world to Windows 95. Windows 95 unified these two systems by making DOS applications work well under Windows&amp;mdash;something that wasn&amp;rsquo;t true in 3.x. To make this possible, Windows 95 carried tons of application-specific tweaks to remain bug-for-bug compatible and, while gross, that&amp;rsquo;s what users needed. We know how big of a splash Windows 95 made.&lt;/p>
&lt;p>But the other huge migration was the jump from Windows 9x to Windows NT. Maintaining two separate operating systems with the same UI for a few years with support for roughly the same apps is a big feat, but it&amp;rsquo;s an even bigger feat to unify these two tracks into one with Windows XP. And, with that release, they were finally able to drop the Windows 9x line for good.&lt;/p>
&lt;h1 id="putting-the-windows-in-nt">Putting the Windows in NT&lt;/h1>
&lt;p>NT started as a joint project between Microsoft and IBM. The goal was to create the next OS for PC systems, named OS/2. So, while NT was designed from the ground up to support multiple personalities (or&amp;hellip; &lt;a href="/2020/11/wsl-lost-potential.html">subsystems, like WSL 1&lt;/a>), the original plan was to make NT support DOS and OS/2 applications.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-24-microsoft-os2-logo.png" class="with-border">
&lt;figcaption>Microsoft OS/2 1.3 logo. &lt;a href="https://www.os2world.com/wiki/index.php/Microsoft_OS/2_1.3">Courtesy of OS/2 World.&lt;/a>&lt;/figcaption>
&lt;/figure>
&lt;p>The Windows personality&amp;mdash;the thing that gives NT its ability to run Windows applications&amp;mdash;wasn&amp;rsquo;t in the cards at first. As the book explains, the project was originally called NT, not Windows NT, and was supposed to become OS/2. It wasn&amp;rsquo;t until later that it became clear within Microsoft that NT had to run Windows applications to not be dead on arrival, and thus Gates pushed for NT to prioritize compatibility with Windows applications. Later on, the system was renamed to Windows NT to emphasize this point, and all ties with IBM broke.&lt;/p>
&lt;p>One thing that struck as interesting was how the team struggled to fix compatibility bugs late in the development cycle, because each fixed bug resulted in a new batch of compatibility issues. It wasn&amp;rsquo;t until later in the project that a key developer had the insight to create a tracer that recorded the system/library calls an app made. This recording could then be used by developers, without the help of testers, to trivially observe the behavior of a sequence of operations on NT and adjust them. This was the magic piece that provided a path towards stability and being able to ship.&lt;/p>
&lt;p>From this work, NT also gained the ability to define &amp;ldquo;compatibility flags&amp;rdquo; for certain applications. This was necessary to work around cases where the applications did the wrong thing&amp;mdash;yet compatibility had to be kept. And this is why Windows 9x and NT had (and still have) such a great compatibility story: the system is full of levers to appease weird behaviors in random apps, even if the apps themselves do something &amp;ldquo;wrong&amp;rdquo;. Most developers would go against the latter, claiming that those are bugs in the apps and they deserve to break. Apple has taken this path. Open source tries to take this path. &lt;a href="https://www.amazon.com/Old-New-Thing-Development-Throughout/dp/0321440307?&amp;amp;_encoding=UTF8&amp;amp;tag=blogsystem503-20&amp;amp;linkCode=ur2&amp;amp;linkId=b373dc6d4f2a06aac4cfec48134f4d71&amp;amp;camp=1789&amp;amp;creative=9325">Microsoft didn&amp;rsquo;t.&lt;/a>&lt;/p>
&lt;h1 id="the-ui-matters">The UI matters&lt;/h1>
&lt;p>Another topic that the book touches upon was the animosity between Cutler and the graphics team. Cutler did not think that graphics were important, which means they were neglected for a long while. And even when a UI team was put together, Cutler was not particularly happy or impressed by them.&lt;/p>
&lt;p>However, graphics are critical and they were difficult to get right. Performance was a problem, as were the many bugs that plagued the primary UI apps of the OS. And&amp;hellip; you might have the fastest, most portable, best designed OS in the world, but if its shell is not usable nor stable&amp;hellip; nobody will care. The UI makes the OS as much as the kernel makes the OS.&lt;/p>
&lt;p>Eventually, due to the desire to support primarily Windows applications in NT, the team adopted the UI that had been developed for OS/2 and for Windows 3.x. This was critical to make the OS seem familiar, although as I briefly touched upon earlier, this also made it difficult to see how 3.x and NT differed to the untrained eye. Later in life, I had a hard time seeing how the Windows NT 4 that ran in our high school computer lab differed from the Windows 95 I had at home: to me, it just seemed slower and heavier.&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-24-windows-nt-4-desktop.png" class="with-border">
&lt;figcaption>Windows NT 4 initial desktop to emphasize how it looks exactly the same as Windows 95.&lt;/figcaption>
&lt;/figure>
&lt;p>In any case, the UI is crucial to the way people appreciate an OS. And, for NT specifically, I&amp;rsquo;m sad that there is no choice: Microsoft keeps &amp;ldquo;advancing&amp;rdquo; the UI in ways that seem detrimental. In particular, modern versions of Windows feel incredibly slow in hardware barely 10 years old&amp;hellip; which is sad because you can&amp;rsquo;t do anything about it other than stay in the hardware upgrade treadmill. I want to like Windows, but recent UI changes have slowly pushed me away.&lt;/p>
&lt;h1 id="and-finally-about-the-book">And finally, about the book&lt;/h1>
&lt;p>To conclude this look into the past, let&amp;rsquo;s actually talk a tiny bit about the book that sparkled it.&lt;/p>
&lt;p>The book is definitely entertaining to read; I guess the fact that I now live in the area where this all happened helped a tiny bit make it more so. It&amp;rsquo;s easy to read. It&amp;rsquo;s fun. It makes me wish I had been born just a few years earlier to understand everything that was going on in more detail&amp;mdash;and maybe to have had a chance to become part of it. And as I mentioned in the introduction, it is engaging enough that I was able to stick with it for about three months.&lt;/p>
&lt;p>But one thing that surprised me is that the book carries a handful of really obvious, painful editing mistakes. A couple of paragraphs are completely unreadable due to broken grammar, punctuation, and capitaliazation. I&amp;rsquo;m not sure how that happened. Luckily, the unreadable parts are reduced to one or two pages&amp;hellip; so you don&amp;rsquo;t miss much.&lt;/p>
&lt;p>Hope you enjoyed this article. And if you did, I&amp;rsquo;m sure you&amp;rsquo;ll enjoy the book much more. Click on the picture to buy and read it!&lt;/p>
&lt;blockquote>
&lt;a target="_blank" href="https://www.amazon.com/Showstopper-Breakneck-Windows-Generation-Microsoft-ebook/dp/B00J5X5E9U?&amp;_encoding=UTF8&amp;tag=blogsystem503-20&amp;linkCode=ur2&amp;linkId=b3bfada207b7929529132de33861f4e3&amp;camp=1789&amp;creative=9325">
&lt;figure>
&lt;img src="/images/2023-11-24-showstopper-alone.jpg"/>
&lt;figcaption>
"Showstopper!: The Breakneck Race to Create Windows NT and the Next Generation at Microsoft", by G. Pascal Zachary.
&lt;/figcaption>
&lt;/figure>
&lt;/a>
&lt;/blockquote></description><enclosure url="https://jmmv.dev/images/2023-11-24-showstopper-pile.jpg" length="180711" type="image/jpeg"/></item><item><title>Code reviews: A success story</title><link>https://jmmv.dev/2023/11/code-reviews-a-success-story.html</link><pubDate>Tue, 21 Nov 2023 13:50:00 -0800</pubDate><guid>https://jmmv.dev/2023/11/code-reviews-a-success-story.html</guid><description>&lt;p>Code reviews have a bad rep: they are antagonistic in nature and, sometimes, pure red tape. Some argue that they are bad practice; others say that peer programming is better. And while these &lt;em>may&lt;/em> be true, I want to tell you a story about a case where code reviews worked well!&lt;/p>
&lt;p>Meet X: a junior engineer in the Bazel team circa 2018, tasked to implement two features: A and B. As you may know, Google is big into code reviews&amp;mdash;and their tooling for this is awesome; believe me&amp;mdash;so this was the standard process for X to get his code checked in.&lt;/p>
&lt;p>For Feature A, X was working with two engineers in his same office: Y and Z. Engineer Y was a junior engineer as well but with more coding experience than X. Y wrote code really fast and didn&amp;rsquo;t like process. Y rubber-stamped long code reviews with little care about the details.&lt;/p>
&lt;p>Engineer Z was a high-level tech lead in the team. Z had a lot of experience and knew the product top-to-bottom, but didn&amp;rsquo;t have much time for code reviews. Worse yet, Z didn&amp;rsquo;t have enough spare time to closely mentor X or Y.&lt;/p>
&lt;p>For Feature B, X was working with me, who was 6000 km away and with a 6-hour time difference between us. I was known for tough code reviews. I also pushed for breaking large changes into smaller commits, because it is impossible to do a thorough review otherwise.&lt;/p>
&lt;p>And I also pushed for writing unit and integration tests in each change, guiding X into a good testing approach for feature B at each small step. You might say that this is important but isn&amp;rsquo;t part of a code review, but this is where the issues surfaced.&lt;/p>
&lt;p>My review comments were copious, so I classified them in three categories: nits, which were inconsequential style changes; optional suggestions, which X could ignore; and important comments, which required X to change code or for us to have a detailed discussion.&lt;/p>
&lt;p>Importantly, I always justified my review comments, &lt;em>especially&lt;/em> if they were personal opinions or optional suggestions. Most of the time, X took my advice and addressed nits and optional suggestions, because he was convinced by my explanations.&lt;/p>
&lt;p>Other times, X pushed back. Maybe I hadn&amp;rsquo;t understood the change or maybe I was just simply wrong. These cases needed further discussion and often resulted in side 1:1 conversations or even the request to write a mini design doc to flush out unclear ideas.&lt;/p>
&lt;p>The time to ship came. For context, Bazel used to be released once every two weeks within Google. New features were gated behind feature flags, which minimized risk in the release process. And if something went wrong, the two-week release cadence allowed addressing bugs quickly.&lt;/p>
&lt;p>Feature A was ready before feature B&amp;hellip; or was it? The overhead of the reviews in A had been minimal so the code shipped quickly. However&amp;hellip; feature A did not work. X needed multiple release cycles to address bugs, all under pressure because the feature &amp;ldquo;had already launched&amp;rdquo;.&lt;/p>
&lt;p>Feature B, on the other hand&amp;hellip; took longer to ship. But once it did, it worked &lt;em>on the first try&lt;/em>. Sure, it wasn&amp;rsquo;t perfect and needed some iteration to address small issues, but the bulk of the code just worked. This made X proud and understood why I had been thorough.&lt;/p>
&lt;p>To this day, X still remembers shipping these two features. He has told the story above multiple times and praised the process we followed for feature B. For me, it was mostly &amp;ldquo;business as usual&amp;rdquo; and didn&amp;rsquo;t really notice the (positive) impact it had on him.&lt;/p>
&lt;p>X also claims to have learned a lot just by reading my comments, thinking about them, and having to do the tricky work to write small, well-tested changes. And you know what? He has recently earned the title of CTO at an exciting startup.&lt;/p>
&lt;p>Anyhow. I realize this whole story shows flaws in various places. Z should probably have paid more attention to X and Y. Maybe X should have written more-detailed design docs upfront. Maybe we should all have pair-programmed. No team is perfect.&lt;/p>
&lt;p>But code reviews do work. Yes, they can be problematic, but I don&amp;rsquo;t think that code reviews are intrinsically antagonistic: it&amp;rsquo;s the people involved. Code reviews are just &lt;em>a tool&lt;/em> to achieve the goals of quality and mentoring, and as a tool, it has to be used wisely.&lt;/p>
&lt;p>And one last thing: code reviews are truly async-friendly. This may be why they are popular in open source, and in this particular case, they truly helped X and I due to the physical distance between us. Q.E.D.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-11-21-code-review.png" length="134980" type="image/jpeg"/></item><item><title>SSH agent forwarding and tmux done right</title><link>https://jmmv.dev/2023/11/ssh-agent-forwarding-and-tmux-done.html</link><pubDate>Fri, 17 Nov 2023 08:50:00 -0800</pubDate><guid>https://jmmv.dev/2023/11/ssh-agent-forwarding-and-tmux-done.html</guid><description>&lt;p>The &lt;a href="https://man.openbsd.org/ssh-agent">SSH agent&lt;/a> is a little daemon that holds your private keys in memory. This is particularly handy when your keys are protected by a passphrase: you can unlock and add your keys to the agent once and, from then on, any SSH client such as &lt;code>ssh(1)&lt;/code> can interact with the keys without asking you for the passphrase again.&lt;/p>
&lt;p>The SSH agent becomes even handier when you primarily work on a remote workstation over SSH. Under these circumstances, you will often need the remote workstation to establish SSH connections to &lt;em>other&lt;/em> remote machines (e.g. to contact GitHub). In those situations, you can: copy your private keys to the remote workstation; generate different private keys on the remote workstation; or forward your SSH agent so that the remote workstation can leverage the keys from your client machine without them ever traveling over the network.&lt;/p>
&lt;p>Anyway. This article isn&amp;rsquo;t a tutorial on what the SSH agent &lt;em>is&lt;/em> or how to &lt;em>use&lt;/em> it; that&amp;rsquo;s already &lt;a href="https://www.ssh.com/academy/ssh/agent">well-documented elsewhere&lt;/a>. What this article does is dig deeper into how the forwarding feature works, how it becomes problematic for long-lived processes such as tmux, and what you can do about it.&lt;/p>
&lt;h1 id="agent-forwarding-101">Agent forwarding 101&lt;/h1>
&lt;p>When you connect to an SSH host, the &lt;code>sshd&lt;/code> server process receives the connection, forks itself, lowers its privileges to the user requesting the connection, creates a pseudo-terminal to host the requested program (typically a shell), and spawns such program &amp;ldquo;inside&amp;rdquo; the pseudo-terminal.&lt;/p>
&lt;p>Take a look at this process table, which shows the &lt;code>sshd&lt;/code> processes running on the server I&amp;rsquo;m typing this on:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ ps -ax -o user,pid,command | grep ssh[d]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root 3617 sshd: /usr/sbin/sshd [listener] 0 of 10-100 startups (sshd)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root 82202 sshd: jmmv [priv] (sshd)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">jmmv 82204 sshd: jmmv@pts/1 (sshd)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>What you can see in the output above is: the listener process with PID 3617 accepting connections on port 22; a &amp;ldquo;privsep&amp;rdquo; controlling process owned by root for my session with PID 82202, &lt;a href="https://security.stackexchange.com/questions/115896/can-someone-explain-how-sshd-does-privilege-separation">responsible for doing authentication&lt;/a>; and the process serving my session on the pseudo-terminal &lt;code>pts/1&lt;/code> and owned by myself with PID 82204.&lt;/p>
&lt;p>The user-owned &lt;code>sshd&lt;/code> instance on PID 82204 is what hosts the shell that you interact with on the client when connecting to an SSH server. This process is in charge of receiving your keystrokes from the network, sending them to the pseudo-terminal, and then ferrying back the pseudo-terminal&amp;rsquo;s &amp;ldquo;output&amp;rdquo; to the terminal window where your client runs. Pseudo-terminals are fascinating by the way; go read &lt;a href="https://man.netbsd.org/openpty.3">&lt;code>openpty(3)&lt;/code>&lt;/a>.&lt;/p>
&lt;p>But when you enable SSH agent forwarding with an &lt;code>ssh -A&lt;/code> invocation, something else happens. The user-owned &lt;code>sshd&lt;/code> server process creates a Unix domain socket on the remote machine and starts &lt;em>serving&lt;/em> on it. Whenever an SSH process on the remote machine connects to this local socket and sends a request to it, the &lt;code>sshd&lt;/code> process proxies the request &lt;em>back&lt;/em> to the client machine and, in turn, the client machine&amp;rsquo;s &lt;code>ssh&lt;/code> process contacts the client machine&amp;rsquo;s &lt;code>ssh-agent&lt;/code> to perform key-related operations.&lt;/p>
&lt;p>This path to the socket on the remote machine is exposed by the &lt;code>SSH_AUTH_SOCK&lt;/code> environment variable, and all SSH commands know how to access it. Here, look:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">client$ ssh -A server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server$ env | grep SSH_AUTH_SOCK
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SSH_AUTH_SOCK=/tmp/ssh-jewlWIz1jC/agent.82204
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">server$ ls -l &amp;#34;${SSH_AUTH_SOCK}&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">srwxr-xr-x 1 jmmv wheel 0 Nov 17 05:30 /tmp/ssh-jewlWIz1jC/agent.82204
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Because a picture is worth a thousand words, here is the same idea in a diagram&amp;hellip; and this picture starts hinting at the problem I want to analyze:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-17-ssh-agent-1.png">
&lt;figcaption>Representation of a client machine (left) connecting to an SSH server. The SSH server (large box on the right) contains an sshd process and a tmux instance. The tmux instance shows the value of &lt;tt>SSH_AUTH_SOCK&lt;/tt>.&lt;/figcaption>
&lt;/figure>
&lt;h1 id="problems-with-long-lived-processes">Problems with long-lived processes&lt;/h1>
&lt;p>Pay close attention to what I described above: the path to the local socket created by the remote &lt;code>sshd&lt;/code> instance is specific to the (unprivileged) &lt;code>sshd&lt;/code> process handling the connection. The fact that the socket&amp;rsquo;s name contains the PID gives this away, but if you want to double-check:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">server$ sudo lsof | grep &amp;#34;${SSH_AUTH_SOCK}&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">sshd 82204 jmmv 7u unix 0xfffff80f6a50fb10 0t0 /tmp/ssh-jewlWIz1jC/agent.82204
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I did not say it explicitly, but you can guess what happens: when you disconnect from the remote session, the &lt;code>sshd&lt;/code> instance for the connection terminates and deletes its local socket on the way out. Which is normal because that process was the one in charge of proxying SSH agent connections back to the SSH client, so with the process gone, the socket becomes useless.&lt;/p>
&lt;p>Unfortunately, the fact that this is normal doesn&amp;rsquo;t make it less problematic. The path to the forwarding socket is exposed to processes via the &lt;code>SSH_AUTH_SOCK&lt;/code> environment variable, so every process started within the remote SSH session gets and &lt;em>caches&lt;/em> a copy of this path in its environment. If you have long-lived process such as &lt;code>tmux&lt;/code> that can survive &lt;em>across&lt;/em> sessions, then all of a sudden the value of &lt;code>SSH_AUTH_SOCK&lt;/code> that they cached at startup time ends up pointing to a non-existing file, breaking all future SSH agent interactions. Look:&lt;/p>
&lt;figure>
&lt;img src="/images/2023-11-17-ssh-agent-2.png">
&lt;figcaption>Representation of a client machine (left) re-connecting to an SSH server after an earlier connection drops. The SSH server (large box on the right) shows how the tmux instance from the first connection "moves" to the second connection, and how the value that tmux displayed in &lt;tt>SSH_AUTH_SOCK&lt;/tt> now points to an invalid file.&lt;/figcaption>
&lt;/figure>
&lt;p>The specific sequence of events represented in the diagram above and that leads to the problem is this:&lt;/p>
&lt;ol>
&lt;li>Connect to an SSH server with SSH agent forwarding.&lt;/li>
&lt;li>Start a tmux session in the SSH server.&lt;/li>
&lt;li>Detach the tmux session.&lt;/li>
&lt;li>Log out of the SSH server.&lt;/li>
&lt;li>Reconnect to the SSH server with SSH agent forwarding.&lt;/li>
&lt;li>Attach to the existing tmux session.&lt;/li>
&lt;li>Run an SSH command.&lt;/li>
&lt;li>See the command fail to communicate with the forwarded agent.&lt;/li>
&lt;/ol>
&lt;p>So, what can we do about it?&lt;/p>
&lt;h1 id="usual-broken-solutions">Usual broken solutions&lt;/h1>
&lt;p>&lt;a href="https://blog.testdouble.com/posts/2016-11-18-reconciling-tmux-and-ssh-agent-forwarding/">Most&lt;/a> &lt;a href="https://werat.dev/blog/happy-ssh-agent-forwarding/">&amp;ldquo;solutions&amp;rdquo;&lt;/a> &lt;a href="https://without-brains.net/2020/08/05/tmux-and-ssh-agent-forwarding/">I&lt;/a> &lt;a href="https://stackoverflow.com/questions/21378569/how-to-auto-update-ssh-agent-environment-variables-when-attaching-to-existing-tm">find&lt;/a> &lt;a href="https://www.jwon.me/ssh-agent-forwarding-with-tmux/">online&lt;/a> to this problem are hyper-focused on propagating new values of &lt;code>SSH_AUTH_SOCK&lt;/code> to impacted processes. These articles present how to re-inject a fresh value of this variable into tmux. Some of them go to a greater extent by showing you how to propagate the variable&amp;rsquo;s value to the &lt;em>shells&lt;/em> already running inside tmux sessions, because obviously the shells outlast SSH sessions too and they &lt;em>also&lt;/em> have their own copy of &lt;code>SSH_AUTH_SOCK&lt;/code>.&lt;/p>
&lt;p>This mostly works but it has two problems:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>It&amp;rsquo;s a pile of hacks and a whack-a-mole battle you will not win. You can patch tmux. You can patch the shell. But what else do you run inside tmux that outlives SSH sessions? Emacs? Vim? A &amp;ldquo;transitive&amp;rdquo; outbound SSH connection? These all have their own copies of &lt;code>SSH_AUTH_SOCK&lt;/code>. You just can&amp;rsquo;t monkey-patch all possible long-lived processes that cached an ephemeral path in their environment when they started.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It&amp;rsquo;s insufficient. Some of the solutions linked to above leverage a symlink to keep the socket&amp;rsquo;s name stable. Those solutions refresh the symlink every time you log into the remote machine and then point &lt;code>SSH_AUTH_SOCK&lt;/code> to the symlink. This is good because it solves the problem of having to monkey-patch all possible long-lived processes. Unfortunately, this breaks as soon as the &lt;em>latest&lt;/em> connection to the server disconnects: once that happens, the symlink will be dangling until you establish a new session to update it.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Can we do better?&lt;/p>
&lt;h1 id="better-working-solutions">Better working solutions&lt;/h1>
&lt;p>&lt;em>Of course&lt;/em> we can do better, and in various different ways actually. I&amp;rsquo;m surprised I haven&amp;rsquo;t found any of them online with ease&amp;hellip;&lt;/p>
&lt;p>Here are some ideas:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>We can refine the symlinks approach described earlier by adding a &lt;em>logout&lt;/em> script to accompany the login script. The goal of this pair would be to keep track of all possible valid sockets and, when a session disconnects, refresh the symlink to point to a still-valid one. This can work in the common case but breaks if SSH sessions die suddenly, which is pretty normal: think putting your laptop to sleep with an open SSH session and resuming it after commuting. So&amp;hellip; this is better, but not awesome.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We can use &lt;code>LD_PRELOAD&lt;/code> to hijack calls that open a socket, check if they seem to refer to an SSH agent socket, and then redirect those to any &lt;em>other&lt;/em> alive SSH agent socket we can find on the machine. This possibly works well, but leveraging &lt;code>LD_PRELOAD&lt;/code> is a pretty heavy thing to do because it impacts &lt;em>all&lt;/em> processes. Furthermore, this variable is pretty sensitive so it is probably cleared by many programs at startup time&amp;hellip; which means it can be ineffective.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We can supplant the SSH agent with our own daemon that serves a local socket on a well-known path. This daemon then redirects all SSH agent requests to a working SSH agent socket. The &amp;ldquo;working&amp;rdquo; socket is determined by searching &lt;code>/tmp/&lt;/code> for &lt;em>any&lt;/em> agent socket that the calling user has permissions to open, and using the first one that works. We can start this daemon when the user firsts connects to the remote server, and we can fix up the &lt;code>SSH_AUTH_SOCK&lt;/code> value at login time&amp;mdash;well before any process can cache the wrong value.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>This last solution is what I prototyped in &lt;strong>&lt;a href="https://github.com/jmmv/ssh-agent-switcher/">ssh-agent-switcher&lt;/a>&lt;/strong>. It took me about an hour of evening coding to get this to work, an extra hour to write integration tests and refine the implementation, and a final half hour to set up the GitHub project. It works for me, but don&amp;rsquo;t expect it to be perfect.&lt;/p>
&lt;p>As a side note, I wrote this program in Go&amp;hellip; not because I wanted to, but because it is a necessity due to the context in which I&amp;rsquo;ll probably use this. And you know what, writing Go for this was really fun due to easy APIs, quick iteration, and simple tooling&amp;hellip; But I could only tolerate Go because I had no need to model any kind of structured data: I still find Go to be a bad choice for anything larger in scope where correctness matters.&lt;/p>
&lt;p>Now the question is: is this safe? And the answer is: I think so? The ssh-agent-switcher daemon runs in the context of your user account so it can only access sockets you already have access to. The only risk comes from the creation of the daemon&amp;rsquo;s own Unix socket: if the socket is accessible to anyone else on the remote machine, then that person would be able to access your forwarded agent and leverage the credentials that live on your client machine. I&amp;rsquo;ve taken care to create the socket with tight permissions, but the question remains: is the default location under &lt;code>/tmp/&lt;/code> good-enough? Creating temporary files with predictable names &lt;a href="https://www.netmeister.org/blog/mktemp.html">is generally unsound&lt;/a> because that leaves them subject to hijacking via symlinks&amp;hellip; but in this case, the daemon is creating a Unix domain socket, not a regular file, and I&amp;rsquo;ve not succeeded at stealing it.&lt;/p>
&lt;p>Oh, and by the way, this all explains the warning in the &lt;a href="https://man.openbsd.org/ssh">&lt;code>sshd(1)&lt;/code> manual page&lt;/a> about the use of agent forwarding:&lt;/p>
&lt;blockquote>
&lt;p>Agent forwarding should be enabled with caution. Users with the ability to bypass file permissions on the remote host (for the agent&amp;rsquo;s UNIX-domain socket) can access the local agent through the forwarded connection. An attacker cannot obtain key material from the agent, however they can perform operations on the keys that enable them to authenticate using the identities loaded into the agent. A safer alternative may be to use a jump host (see -J).&lt;/p>
&lt;/blockquote>
&lt;p>If you do not trust the administrator of a remote machine, SSHing into it and forwarding your agent will allow the remote administrator to send requests to your local agent. Be careful out there.&lt;/p></description></item><item><title>Why do I know shell, and how can you?</title><link>https://jmmv.dev/2023/11/why-do-i-know-shell-and-how-can-you.html</link><pubDate>Fri, 10 Nov 2023 08:00:00 -0800</pubDate><guid>https://jmmv.dev/2023/11/why-do-i-know-shell-and-how-can-you.html</guid><description>&lt;p>&lt;em>&amp;ldquo;Why do you know so much shell?&amp;rdquo;&lt;/em> is a question I&amp;rsquo;m getting a lot at work lately. So yeah, why? And how can you learn it too? There is no secret here: I know the shell well because I was &amp;ldquo;forced&amp;rdquo; to write tools in it for a while and, because of that, I made a conscious effort to learn the language and get better at it.&lt;/p>
&lt;p>You see, most people that write shell don&amp;rsquo;t want to deal with it. They stitch together whatever works into a script and call it a day, making a bunch of spaghetti even if it goes against the coding best practices they already know. And when they encounter some odd syntax they don&amp;rsquo;t recognize, their reaction is to say &amp;ldquo;this has to be rewritten in Python!&amp;rdquo; instead of taking a breath and trying to really understand what&amp;rsquo;s going on. It doesn&amp;rsquo;t help that plenty of senior engineers scoff at shell scripts.&lt;/p>
&lt;p>And it is true: the shell is arcane and has many flaws as a programming language. I don&amp;rsquo;t want to convince you to start writing new tools in it. But the shell is also an incredible rapid prototyping language, and you can use it to solve business problems really quickly and with surprisingly little code. If you pause for a second to learn it, you&amp;rsquo;ll realize that you can bend tradition and write maintainable shell code too. Hear out how I got into writing so much shell and how you can get better at it too.&lt;/p>
&lt;h1 id="the-constraints-of-the-bsd-systems">The constraints of the BSD systems&lt;/h1>
&lt;p>In the late 1990s, I discovered Linux and, soon after, the BSDs. I had a brief stint with OpenBSD and FreeBSD at first, but by the early 2000s, I had settled on &lt;a href="https://www.NetBSD.org/">NetBSD&lt;/a> as my daily driver. My dream had always been to create my own operating system, but the more I learned and tried to write one, the more I realized I wasn&amp;rsquo;t up to the task yet. Thus NetBSD was the perfect fit for me: all my hardware worked on it, but the system had enough rough edges that I saw the opportunity to become a contributor to a real operating system.&lt;/p>
&lt;p>NetBSD&amp;mdash;and all the BSDs really&amp;mdash;are full operating system distributions. Unlike Linux, the source code for their kernel, user space tools, and documentation lives in a single source tree (monorepo!) maintained by a single group of developers. This source tree is known as &lt;em>the base system&lt;/em> and every other third-party app comes via the ports system&amp;mdash;or &lt;a href="https://www.pkgsrc.org/">pkgsrc&lt;/a> in NetBSD-specific parlance. If this is hard to imagine, visualize your typical Windows installation: when you perform a fresh install of Windows 7 (not 10 or 11 because these get random junk auto-added), what you get is a collection of software that Microsoft has itself developed and chosen to be the basis to form Windows; everything you add to it later on, be it from Microsoft or other vendors, is not part of that base installation.&lt;/p>
&lt;p>A constraint of this arrangement is that the code in a BSD base system is self-hosting: i.e. the base system must be able to build itself so it must &lt;a href="/2015/10/compilers-in-the-bsd-base-system.html">include the compilers&lt;/a> and interpreters required to build and run its code. In NetBSD during the early 2000s, this meant choosing between C, C++, and shell. Lua has been added as a fourth choice since.&lt;/p>
&lt;p>It is of course possible to write tools for a BSD system in any language that&amp;rsquo;s not in the base system, but doing so means that the tool is relegated to live in the ports system. To make matters worse, the common practice in the BSDs was to build everything from source&amp;mdash;pre-built binary packages existed but were inflexible and usually stale&amp;mdash;and thus users frowned upon heavy dependencies. If your tiny tool required Perl or Python, for example, it would be dead on arrival because of the heavy tax imposed by the interpreter: if I recall correctly, building Perl on my Pentium II took something like 15 minutes, and building it on a 68k Mac I had took hours.&lt;/p>
&lt;h1 id="contributing-tools-to-netbsd">Contributing tools to NetBSD&lt;/h1>
&lt;p>See where this is going? I was the primary maintainer of Gnome 2.x on NetBSD and, as part of this work, I ended writing all sorts of tools to simplify the maintenance of the packages and the system as a whole. I wrote things like &lt;a href="/software/sysbuild.html">sysbuild&lt;/a>, &lt;a href="/software/pkg_comp.html">pkg_comp&lt;/a>, &lt;a href="http://cvsweb.netbsd.org/bsdweb.cgi/pkgsrc/pkgtools/pkg_alternatives/">pkg_alternatives&lt;/a>, &lt;a href="http://cvsweb.netbsd.org/bsdweb.cgi/pkgsrc/pkgtools/dfdisk/">dfdisk&lt;/a>, &lt;a href="/2022/06/autoconf-caching.html">autoswc&lt;/a>, &lt;a href="/software/etcutils.html">etcutils&lt;/a>&amp;hellip; and even &lt;a href="/2022/05/remembering-buildtool.html">my own build system&lt;/a>.&lt;/p>
&lt;p>And to write such tools&amp;hellip; which language could I use? I wanted my tools to feel part of the base system and I didn&amp;rsquo;t want to have to pay the heavy price of Perl or Python. I could have used C, but&amp;hellip; well, let&amp;rsquo;s just say that C is a terrible choice for automation tools. I could have used C++, but people &lt;em>also&lt;/em> hated it for its long compile times and the fact that, back in the pre-C++11 era, it wasn&amp;rsquo;t much better than C and compilers were really bad at supporting standards. And I could use the shell which, as ugly as it was, made programs immediately installable under any of the tens of hardware platforms that NetBSD supported, no matter how slow they were.&lt;/p>
&lt;p>So that&amp;rsquo;s how I ended up writing shell. The shell was the only realistic option I had to write the tools I wanted to write. And you know what? My scripts were bad at first, full of the problems I opened this article with. But with practice, a principled approach to writing shell &lt;del>scripts&lt;/del> programs, and an open mind to see the shell as &amp;ldquo;yet another programming language&amp;rdquo;, it turned out to be not a terrible idea in retrospect.&lt;/p>
&lt;p>My biggest shell program today is probably &lt;a href="/2017/02/introducing-pkg_comp-2.0.html">pkg_comp2&lt;/a>. If I count the lines of its source code plus its two dependencies (&lt;a href="/software/sandboxctl.html">sandboxctl&lt;/a> and &lt;a href="https://shtk.jmmv.dev/">shtk&lt;/a>), it comes to about 15,000 SLOC. More than half of those are unit and integration tests, just as commonly happens in &amp;ldquo;real software&amp;rdquo;, which shows that shell programs can mimic the good development practices of other languages. Just take a moment and skim through &lt;a href="https://github.com/jmmv/pkg_comp/blob/28dc346ade09bd620f1ec3c6ad43b98f412deaa9/pkg_comp.sh">pkg_comp.sh&lt;/a>. Does this look like your regular spaghetti shell code to you?&lt;/p>
&lt;h1 id="how-you-can-get-better-at-the-shell">How you can get better at the shell&lt;/h1>
&lt;p>I could probably write a whole book on this topic&amp;mdash;and I&amp;rsquo;ve thought about doing so&amp;hellip; would you read it?&amp;mdash;but all I can do right now is give you some ideas:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Read about the language.&lt;/strong> The shell is small. Once I decided I wanted to get better at the shell, I just opened the &lt;a href="https://man.netbsd.org/sh.1">&lt;code>sh(1)&lt;/code> manual page&lt;/a> and read it. It will take you less than 1 hour to go through the whole document. You might choose to &lt;em>also&lt;/em> read the Bash manual page&amp;mdash;and you probably should, particularly to become aware of its many &lt;a href="/2021/08/useless-use-of-gnu.html">unnecessary non-standard features&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Familiarize yourself with the Unix toolchain.&lt;/strong> Yes, the shell language is really simple, but that comes at a price: many of the things you want to do will require invoking tools like &lt;code>grep&lt;/code>, &lt;code>sed&lt;/code>, &lt;code>find&lt;/code>&amp;hellip; Which is fine because that&amp;rsquo;s the core idea behind the Unix toolchain&amp;mdash;small, composable tools&amp;mdash;but that means you need to know those tools too. The more tools you know about, the better your scripts will be. Think of these tools as the &amp;ldquo;standard library&amp;rdquo; for the shell. Manual pages are not in fashion&amp;hellip; but getting comfortable in navigating them will prove to be a useful skill.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Understand how process creation (&lt;code>fork&lt;/code> vs. &lt;code>exec&lt;/code>) and &lt;a href="/2020/11/cmdline-args-unix-vs-windows.html">argument passing&lt;/a> work in Unix.&lt;/strong> The shell is primarily designed to interact with subprocesses, so knowing these topics in detail is &lt;em>crucial&lt;/em> to truly understand how quoting, globs, redirections, and pipelines work, and also to understand the difference between built-in and external commands. For example, do you know &lt;a href="/2020/03/test-bracket.html">how &lt;code>test&lt;/code>, &lt;code>[&lt;/code> and &lt;code>[[&lt;/code> differ&lt;/a>?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Write shell scripts following the good programming practices you already know.&lt;/strong> Avoid global variables. Factor code into functions. Minimize side-effects. &lt;a href="/2023/10/unit-testing-with-shtk.html">Write unit and/or integration tests.&lt;/a> And be unconditionally strict: e.g. double-quote all variable expansions to correctly handle whitespace characters, even if in most cases you may not need to do so.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Think in terms of data flow.&lt;/strong> The shell is about combining tools as pipelines, not writing your usual imperative for loops. The more you can reason about solving problems with pipelines, the simpler and more performant your scripts will be. Functional programming FTW!&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Read Google&amp;rsquo;s &lt;a href="https://google.github.io/styleguide/shellguide.html">Shell Style Guide&lt;/a>.&lt;/strong> While I don&amp;rsquo;t necessarily agree with everything it has to say, especially around stylistic details, the &amp;ldquo;Features and bugs&amp;rdquo; and &amp;ldquo;Calling commands&amp;rdquo; sections are particularly interesting.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Use &lt;a href="https://www.shellcheck.net/">ShellCheck&lt;/a>.&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>And finally, &lt;strong>take a look at my &lt;a href="/2018/02/shell-readability-main.html">short readability series on the shell&lt;/a> from 2013.&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol></description><enclosure url="https://jmmv.dev/images/2023-11-10-sh-manpage.jpg" length="425448" type="image/jpeg"/></item><item><title>End-to-end tool testing with Bazel and shtk</title><link>https://jmmv.dev/2023/11/end-to-end-tool-testing-with-bazel.html</link><pubDate>Sat, 04 Nov 2023 07:50:00 -0700</pubDate><guid>https://jmmv.dev/2023/11/end-to-end-tool-testing-with-bazel.html</guid><description>&lt;p>If you use Bazel, your project is of moderate size. And because your project is of moderate size, it almost-certainly builds one or more binaries, at least one of which is a CLI tool. But let&amp;rsquo;s face it: you don&amp;rsquo;t have end-to-end testing for those tools, do you?&lt;/p>
&lt;p>I&amp;rsquo;m &lt;em>sure&lt;/em> you have split the binary&amp;rsquo;s &lt;code>main&lt;/code> function into its own file so that the rest of the tool can be put in a library, and I&amp;rsquo;m &lt;em>extra-sure&lt;/em> that you have unit tests for such library. But&amp;hellip; those tests do little to verify the functionality and quality of the tool &lt;em>as experienced by the end user&lt;/em>. Consider: What exactly does the tool print to the console on success? Does it show errors nicely when they happen, or does it dump internal stack traces? How does it handle unknown flags or bad arguments? Is the built-in help message nicely rendered when your terminal is really wide? What if the terminal is narrow?&lt;/p>
&lt;p>You must write end-to-end tests for your tools but, usually, that isn’t easy to do. Until today. Combining shtk with Bazel via the new &lt;code>rules_shtk&lt;/code> ruleset makes it trivial to write tests that verify the behavior of your CLI tools&amp;mdash;no matter what language they are written in&amp;mdash;and in this article I’m going to show you how.&lt;/p>
&lt;h1 id="scenario">Scenario&lt;/h1>
&lt;p>To put things in perspective, we&amp;rsquo;ll be adding tests to a trivial demo tool written in C (&lt;em>not&lt;/em> shell) that simply adds two numbers and prints the result to the standard output. You can find all of the code for this scenario under &lt;a href="https://github.com/jmmv/rules_shtk/tree/d490cc9fc43cff3db83d12b5dc1a1c6b90ed50c3/examples/test">&lt;code>rules_shtk/examples/test&lt;/code>&lt;/a>.&lt;/p>
&lt;p>Here is how the demo tool behaves after we build the &lt;code>//:adder&lt;/code> target:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-console" data-lang="console">&lt;span class="line">&lt;span class="cl">&lt;span class="gp">$&lt;/span> ./bazel-bin/adder &lt;span class="m">123&lt;/span> &lt;span class="m">456&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">The sum of 123 and 456 is 579
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="gp">$&lt;/span> ./bazel-bin/adder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder: Requires two integer arguments
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="gp">$&lt;/span> ./bazel-bin/adder &lt;span class="m">10000000&lt;/span> &lt;span class="m">345&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder: Invalid first operand: out of range
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Our mission is to add an &lt;code>//:adder_test&lt;/code> target that depends on &lt;code>//:adder&lt;/code> and that exercises the tool &lt;em>exactly as when a user runs it by hand&lt;/em>. We&amp;rsquo;ll create an &lt;code>adder_test.sh&lt;/code> file that uses the &lt;a href="/2023/10/unit-testing-with-shtk.html">shtk testing library&lt;/a> and hook it into the build as an &lt;code>shtk_test&lt;/code> target.&lt;/p>
&lt;h1 id="depending-on-rules_shtk">Depending on rules_shtk&lt;/h1>
&lt;p>&lt;code>rules_shtk&lt;/code> is a shiny new ruleset (released just yesterday) and because Bazel 7 is around the corner, I&amp;rsquo;ve opted to go all in for &lt;a href="https://bazel.build/external/overview#bzlmod">bzlmod&lt;/a>. Thanks to bzlmod, setting up a project to use these rules is trivial. All you need is to add the following line to your &lt;code>MODULE.bazel&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Add this to MODULE.bazel.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">bazel_dep&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;rules_shtk&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;1.7&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;hellip; but you&amp;rsquo;ll need to wait until &lt;a href="https://github.com/bazelbuild/bazel-central-registry/pull/1095">bazelbuild/bazel-central-registry#1095&lt;/a> is reviewed and merged. (I don&amp;rsquo;t understand why this choke point exists in the new bzlmod ecosystem; Rust&amp;rsquo;s crates.io doesn&amp;rsquo;t have it, for example.)&lt;/p>
&lt;p>In the meantime, or if you are not yet ready to upgrade to bzlmod, you can obviously use the old-fashioned and yucky &lt;code>WORKSPACE.bazel&lt;/code> file to pull &lt;code>rules_shtk&lt;/code> in:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Add this to WORKSPACE or WORKSPACE.bazel if you don&amp;#39;t use bzlmod yet.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;@bazel_tools//tools/build_defs/repo:http.bzl&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;http_archive&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">http_archive&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;bazel_skylib&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sha256&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;66ffd9315665bfaafc96b52278f57c7e2dd09f5ede279ea6d39b2be471e7e3aa&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;https://mirror.bazel.build/github.com/bazelbuild/bazel-skylib/releases/download/1.4.2/bazel-skylib-1.4.2.tar.gz&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;https://github.com/bazelbuild/bazel-skylib/releases/download/1.4.2/bazel-skylib-1.4.2.tar.gz&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;@bazel_skylib//:workspace.bzl&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;bazel_skylib_workspace&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">bazel_skylib_workspace&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">http_archive&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;rules_shtk&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sha256&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;fa47891f27d8d59609732b34dc88020331b81b9767cbd72094fec1be8af4adfc&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">urls&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;https://github.com/jmmv/rules_shtk/releases/download/rules_shtk-1.7.0/rules_shtk-1.7.0.tar.gz&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">strip_prefix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;rules_shtk-1.7.0&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="requesting-an-shtk-toolchain">Requesting an shtk toolchain&lt;/h1>
&lt;p>Once you have added &lt;code>rules_shtk&lt;/code> to your project, either via bzlmod or the &lt;code>WORKSPACE.bazel&lt;/code>, you need to tell Bazel which shtk toolchain to use:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Add this to WORKSPACE or WORKSPACE.bazel.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;@rules_shtk//:repositories.bzl&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;shtk_dist&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">shtk_dist&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The parameterless &lt;code>shtk_dist&lt;/code> macro makes Bazel download &lt;a href="https://github.com/jmmv/shtk/releases/tag/shtk-1.7">shtk 1.7&lt;/a> (because we requested the 1.7.x rules) and puts it to use for all tests that we later build. You cannot configure which version of shtk to download because, so far, all shtk versions are backwards-compatible and this won&amp;rsquo;t change in the 1.x series.&lt;/p>
&lt;p>There is also an &lt;code>shtk_sytem&lt;/code> macro that makes Bazel discover the shtk toolchain installed in the system, say via your local package manager. This does not make sense for our use case (because we are only running tests within Bazel), but it can be useful if you want to build a script with &lt;code>shtk_binary&lt;/code> that can later be taken out of &lt;code>bazel-bin&lt;/code> and installed into the host system.&lt;/p>
&lt;h1 id="writing-the-test-rule">Writing the test rule&lt;/h1>
&lt;p>We now have the rules and a toolchain in place so we can proceed to add an &lt;code>shtk_test&lt;/code> target. Our goal is to test &lt;code>adder.c&lt;/code> with a new &lt;code>adder_test.sh&lt;/code> sibling file, so we can put the test target next to the binary target:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;@rules_shtk//:rules.bzl&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;shtk_test&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cc_binary&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;adder&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;adder.c&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">shtk_test&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;adder_test&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">src&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;adder_test.sh&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;:adder&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are different opinions on where tests should live but, personally, I want them as close to the code they test as possible. This makes tests discoverable when editing code, which increases the odds that developers will remember to update them. Also, nobody likes dealing with parallel deep directory hierarchies when working on a piece of code&amp;hellip; thank you, &lt;code>java&lt;/code> and &lt;code>javatests&lt;/code>.&lt;/p>
&lt;h1 id="writing-the-test-program">Writing the test program&lt;/h1>
&lt;p>All that&amp;rsquo;s left to do is an &lt;a href="https://en.wikipedia.org/wiki/Small_matter_of_programming">SMOP&lt;/a>. We need to write the tests in &lt;code>adder_test.sh&lt;/code>. Here are just a couple of examples:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># This is a portion of adder_test.sh.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_import unittest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_test addition_works
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">addition_works_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> expect_command &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -o inline:&lt;span class="s2">&amp;#34;The sum of 2 and 3 is 5\n&amp;#34;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> ../adder &lt;span class="m">2&lt;/span> &lt;span class="m">3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">shtk_unittest_add_test bad_arguments
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bad_arguments_test&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> expect_command &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -s &lt;span class="m">1&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -e inline:&lt;span class="s2">&amp;#34;adder: Requires two integer arguments\n&amp;#34;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> ../adder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I don&amp;rsquo;t want to dive into the shtk APIs too much, but I want to highlight the &lt;code>expect_command&lt;/code> calls in here. This assertion is the salient feature of shtk&amp;rsquo;s unit-testing module and is what makes testing tools a breeze. Take a look at the &lt;a href="https://shtk.jmmv.dev/shtk_unittest_assert_command.3.html">&lt;code>assert_command&lt;/code>&lt;/a> and &lt;a href="https://shtk.jmmv.dev/shtk_unittest_assert_file.3.html">&lt;code>assert_file&lt;/code>&lt;/a> documentation to demystify the &lt;code>-s&lt;/code>, &lt;code>-o&lt;/code>, and &lt;code>-e&lt;/code> flags shown above.&lt;/p>
&lt;p>One thing that needs explaining is the &lt;code>../adder&lt;/code> reference to the tool. If we look at the runfiles tree that Bazel creates when building the &lt;code>//:adder_test&lt;/code> target, we see:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-console" data-lang="console">&lt;span class="line">&lt;span class="cl">&lt;span class="gp">$&lt;/span> ls -l bazel-bin/adder_test.runfiles/_main/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">total 8K
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">lrwxrwxrwx. 1 jmmv jmmv 116 Nov 4 06:17 adder -&amp;gt; /home/jmmv/.cache/bazel/_bazel_jmmv/916b9cbf147e00ff01b88519fdb0f294/execroot/_main/bazel-out/k8-fastbuild/bin/adder
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">lrwxrwxrwx. 1 jmmv jmmv 121 Nov 4 06:17 adder_test -&amp;gt; /home/jmmv/.cache/bazel/_bazel_jmmv/916b9cbf147e00ff01b88519fdb0f294/execroot/_main/bazel-out/k8-fastbuild/bin/adder_test
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are no directories in there. So, where does that &lt;code>..&lt;/code> come from in the &lt;code>../adder&lt;/code> reference? Well&amp;hellip; shtk&amp;rsquo;s unit-testing execution engine creates a disposable subdirectory for each test it runs. The reason for this is that, when writing shell tests, it is extremely common to have to create auxiliary files, and shtk accounts for that by cleaning up whichever files you create in the current directory of a test. This is a little oddity you&amp;rsquo;ll have to keep in mind.&lt;/p>
&lt;h1 id="running-the-test">Running the test&lt;/h1>
&lt;p>All done. We can finally run the end-to-end test for our demo tool:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-console" data-lang="console">&lt;span class="line">&lt;span class="cl">&lt;span class="gp">$&lt;/span> bazel &lt;span class="nb">test&lt;/span> --nocache_test_results --test_output&lt;span class="o">=&lt;/span>streamed //:adder_test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">WARNING: Streamed test output requested. All tests will be run locally, without sharding, one at a time
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: Analyzed target //:adder_test (0 packages loaded, 139 targets configured).
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: Found 1 test target...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing addition_works...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 2 3
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder -12345 12345
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing addition_works... PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_first_operand...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 123456789 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 123x 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder -123456789 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_first_operand... PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_second_operand...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0 123456789
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0 123x
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 0 -123456789
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_second_operand... PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_arguments...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 1
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Running checked command: ../adder 1 2 3
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Testing bad_arguments... PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">adder_test: I: Ran 4 tests; ALL PASSED
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">Target //:adder_test up-to-date:
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go"> bazel-bin/adder_test
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: Elapsed time: 0.504s, Critical Path: 0.33s
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: 2 processes: 2 linux-sandbox.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">INFO: Build completed successfully, 2 total actions
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">//:adder_test PASSED in 0.2s
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="go">Executed 1 out of 1 test: 1 test passes.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="go">There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;p>As much hate as &amp;ldquo;large&amp;rdquo; shell scripts get, the shell is a uniquely-positioned language to help you write end-to-end tests for your tools. After all, the shell is what you use to &lt;em>run&lt;/em> those precious tools, so the shell is also what you should use to run them in an automated fashion for testing purposes.&lt;/p>
&lt;p>It&amp;rsquo;s your turn now. Go read the &lt;a href="https://shtk.jmmv.dev">online documentation&lt;/a> for shtk, the previous introductory blog post, and get testing! Your users will be much happier if your tools offer excellent interfaces. And if you need ideas on what to test or how to improve the interface of your tools, take a look at the &lt;a href="/series.html#CLI design">CLI design series&lt;/a> from 2013.&lt;/p></description><enclosure url="https://jmmv.dev/images/2023-11-04-bazel-clamp.jpg" length="572746" type="image/jpeg"/></item><item><title>Links: October 2023 edition</title><link>https://jmmv.dev/2023/10/links-october-2023-edition.html</link><pubDate>Tue, 31 Oct 2023 12:30:00 -0700</pubDate><guid>https://jmmv.dev/2023/10/links-october-2023-edition.html</guid><description>&lt;p>Inspired by the works of &lt;a href="https://eatonphil.com/">Phil Eaton&lt;/a>, I&amp;rsquo;ve been highlighting articles and projects that I find interesting in &lt;del>Twitter&lt;/del> X and Mastodon. Some of these posts were more &amp;ldquo;successful&amp;rdquo; than I had expected, which I take to mean that doing this is interesting to you all. So, it&amp;rsquo;s probably a good idea to periodically collect them all in a post with a very brief commentary on each.&lt;/p>
&lt;p>Here is a recap of the interesting articles that came my way in October 2023. This does &lt;em>not&lt;/em> mean that these articles were published during this period: some of them are older but I just (re)discovered them now. I&amp;rsquo;ll avoid referencing my own articles: you can find those by &lt;a href="/archive.html">in the archive&lt;/a>.&lt;/p>
&lt;h1 id="articles">Articles&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://queue.acm.org/detail.cfm?id=3212479">&amp;ldquo;C is not a low-level language&amp;rdquo;&lt;/a> by David Chisnall on April 30th, 2018.&lt;/strong>&lt;/p>
&lt;p>This is one of those articles that requires an open mind to read and understand the main criticism that the author raises about the use of C these days.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.microsoft.com/en-us/research/uploads/prod/2019/04/fork-hotos19.pdf">&amp;ldquo;A fork() in the road&amp;rdquo;&lt;/a> by Microsoft on May 13th, 2019.&lt;/strong>&lt;/p>
&lt;p>Like the previous article, this one is a critique of one of the foundations of Unix and requires being open to criticism to see what it is about. I had read this when it came out years ago, but the article just above reminded me of it because they both fall in the same category of &amp;ldquo;articles that were written ahead of their times&amp;rdquo;.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://jvns.ca/blog/2016/06/13/should-you-be-scared-of-signals/">&amp;ldquo;Should you be scared of Unix signals?&amp;rdquo;&lt;/a> by Julia Evans on June 13th, 2016.&lt;/strong>&lt;/p>
&lt;p>A good and fun article to understand Unix signals. I didn&amp;rsquo;t know that &lt;em>Ctrl+Alt+Del&lt;/em> translated into &lt;code>SIGINT&lt;/code> to &lt;code>init(1)&lt;/code> on Linux, for example. What I was missing from this article was a mini-rant on the lack of &lt;code>SIGINFO&lt;/code> handling in Linux: if you have used other Unix systems, you know that pressing &lt;em>Ctrl+T&lt;/em> causes the running program to print progress status to the console, which is super handy when running things like &lt;code>dd(1)&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://jordankaye.dev/posts/thinking-not-typing/">&amp;ldquo;Software engineering is about thinking, not typing&amp;rdquo;&lt;/a> by Jordan Kaye on October 11th, 2023.&lt;/strong>&lt;/p>
&lt;p>Agree with the premise of the post that coding without thinking can be wasteful. Countless times, I&amp;rsquo;ve been coding deep down for an hour, only to go get coffee and realize I was on the wrong path all along. However, I&amp;rsquo;d also add that software engineering &lt;em>is&lt;/em> actually about typing: just&amp;hellip; a different kind of typing. Change proposals, design documents, opinion memos&amp;hellip; all of these have to be typed, and going through the writing process helps tremendously in organizing ideas and plans.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://ntietz.com/blog/write-more-useless-software/">&amp;ldquo;Write more &amp;ldquo;useless&amp;rdquo; software&amp;rdquo;&lt;/a> by ntietz on June 26, 2023.&lt;/strong>&lt;/p>
&lt;p>Yes, more of this! It&amp;rsquo;s fun/rewarding/exciting to write a piece of code just for the sake of it, and it&amp;rsquo;s exhausting to have to come up with &amp;ldquo;value add&amp;rdquo; rationales (&lt;em>ehem&lt;/em> monetization strategies) for every little thing we do these days. This is &lt;a href="/2021/01/why-endbasic.html">why I work on EndBASIC&lt;/a>, for example.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://fasterthanli.me/articles/just-paying-figma-15-dollars">&amp;ldquo;Just paying Figma $15/month because nothing else fucking works&amp;rdquo;&lt;/a> by fasterthanlime on October 19th, 2023.&lt;/strong>&lt;/p>
&lt;p>A fun read. This one is about how we avoid paying for cheap things for weird reasons and settle for alternatives that suck. In his case, he claims &amp;ldquo;protestant ethics&amp;rdquo; but I have the same problem and I grew up without those. And this is why I&amp;rsquo;m working on EndTRACKER instead of paying for Substack. Well, actually, I&amp;rsquo;ve just started driving Substack, so the real reason is because I want to own my content in a future-proof manner.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://jsoverson.medium.com/was-rust-worth-it-f43d171fb1b3">&amp;ldquo;Was Rust Worth It?&amp;rdquo;&lt;/a> by Jarrod Overson on October 26th, 2023.&lt;/strong>&lt;/p>
&lt;p>A very balanced review of Rust through which I found myself nodding all along the good, bad, and ugly parts. I&amp;rsquo;ve covered some of the criticisms in the past in more detail too, including in &lt;a href="/2022/05/rust-is-hard-but-does-it-matter.html">&amp;ldquo;Rust is hard, yes, but does it matter?&amp;rdquo;&lt;/a> (May 2022) and in &lt;a href="/2023/08/rust-static-dispatch-failed-experiment.html">&amp;ldquo;A failed experiment with Rust static dispatch&amp;rdquo;&lt;/a> (August 2023).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://flameeyes.blog/2020/04/30/bakery-someone-else-oven/">&amp;ldquo;The bakery is just someone else’s oven&amp;rdquo;&lt;/a> by Diego Elio Pettenò on April 30th, 2023.&lt;/strong>&lt;/p>
&lt;p>Interesting complement to the &amp;ldquo;paying Figma&amp;rdquo; article from above, which I reached through a controversial post on how X is saving money by dumping the cloud. Yes, cloud bills are huge and in &amp;ldquo;the happy case&amp;rdquo; you can probably build and host a service yourself. But when you have to start planning for corner cases and deal with operational costs, things aren&amp;rsquo;t as cheap. Plus it is critical to consider the opportunity cost of running your own services against doing something else.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://jacobbartlett.substack.com/p/through-the-ages-apple-cpu-architecture">&amp;ldquo;Through the Ages: Apple CPU Architecture&amp;rdquo;&lt;/a> by Jacob Barlett on October 30th, 2023.&lt;/strong>&lt;/p>
&lt;p>A light walk through the four different CPU architectures that Apple has used throughout its history, how they differ between each other, and how Apple has been able to successfully pull off such difficult migrations without vanishing into oblivion. But what&amp;rsquo;s &lt;em>more&lt;/em> interesting here is &lt;a href="https://lobste.rs/s/jd4ivm/through_ages_apple_cpu_architecture#c_nwtcnj">this comment from David Chisnall&lt;/a> in the Lobste.rs discussion correcting many of the simplifications and inaccuracies in the article.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="other">Other&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://github.com/skiselev/8088_bios">&amp;ldquo;8088 BIOS&amp;rdquo;&lt;/a> GitHub Project.&lt;/strong>&lt;/p>
&lt;p>I had fun peeking through the NASM source code and remembering &amp;ldquo;the good old times&amp;rdquo; of me writing boot sectors with FAT12 parsers in them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://www.retroshowcase.gr/cpcbox-master/index.html">&amp;ldquo;CPCBox&amp;rdquo;&lt;/a> project page.&lt;/strong>&lt;/p>
&lt;p>I keep coming to this site as part of my work on EndBASIC, and as part of wanting to play my favorite old game from when I was a kid: Builder Dash. The keyboard controls suck but choosing to use a joystick allows using the cursor keys for movement. Audio doesn&amp;rsquo;t work though, as it seems to be using some deprecated web technology.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://youtu.be/Fh_UDQnboRw">&amp;ldquo;Bill Gates demonstrates Visual Basic [video]&amp;rdquo;&lt;/a> by Bill Gates in 1991.&lt;/strong>&lt;/p>
&lt;p>What have we lost. There has not been anything similar to Visual Basic for more than 20 years now (except Delphi I hear). I remember moving to Linux and trying to find something like this, only to be told to use Glade which&amp;hellip; well&amp;hellip; a UI designer that spits out code is not the same as an integrated IDE. And nowadays, with web technologies, there is nothing that approaches this level of usability, yet?&lt;/p>
&lt;/li>
&lt;/ul></description><enclosure url="https://jmmv.dev/images/2023-10-31-links.png" length="56457" type="image/jpeg"/></item><item><title>BazelCon 2023 et al. trip report</title><link>https://jmmv.dev/2023/10/bazelcon-2023-et-al-trip-report.html</link><pubDate>Mon, 30 Oct 2023 03:00:00 -0700</pubDate><guid>https://jmmv.dev/2023/10/bazelcon-2023-et-al-trip-report.html</guid><description>&lt;p>I&amp;rsquo;m exhausted. I just came back to Seattle from a 10-day trip in which I attended three different Bazel events: the Build Meetup in Reykjavik, the Bazel Community Day in Munich, and BazelCon 2023 in Munich too. Oh, and because I was on the other side of the world, I also paid a visit to my family in Spain.&lt;/p>
&lt;p>Attending these events has been incredibly useful and productive: I got exposure to many ideas and discussions that would just not happen online, I got to build connections with very interesting people and, of course, it has also been super fun too to reconnect with old coworkers and friends.&lt;/p>
&lt;p>This article contains the summary of the things I learned and the things I want to follow up on. These are just a bunch of cleaned-up notes which I took and are in the context of &lt;em>my&lt;/em> work with &lt;a href="https://bazel.build/">Bazel&lt;/a> at &lt;a href="https://www.snowflake.com/">Snowflake&lt;/a> and &lt;em>my&lt;/em> interests on build tools, so this is not endorsed by Snowflake.&lt;/p>
&lt;h1 id="schedule">Schedule&lt;/h1>
&lt;p>Here is the general timeline of the events:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>2023-10-20 (Fri)&lt;/strong>: Build Meetup in Reykjavik hosted at the Reykjavik University and organized by Unnar from EngFlow.&lt;/li>
&lt;li>&lt;strong>2023-10-21 (Sat)&lt;/strong>: A 1-day tour of the Reykjanes peninsula with the Build Meetup crew which, while not an official conference, also led to many interesting &lt;del>hallway&lt;/del> lagoon conversations.&lt;/li>
&lt;li>&lt;strong>2023-10-23 (Mon)&lt;/strong>: Bazel Community Day hosted by Salesforce in Munich, followed by an evening of food and drinks hosted by Gradle.&lt;/li>
&lt;li>&lt;strong>2023-10-24 (Tue)&lt;/strong>: BazelCon 2023 day 1 hosted by Google Munich, which included an evening of drinks and games hosted by JetBrains.&lt;/li>
&lt;li>&lt;strong>2023-10-25 (Wed)&lt;/strong>: BazelCon 2023 day 2 hosted by Google Munich, which included another by BuildBuddy that I could not attend because I departed early.&lt;/li>
&lt;/ul>
&lt;h1 id="bazel-7">Bazel 7&lt;/h1>
&lt;p>In our Bazel migration at Snowflake, we currently rely on the Bazel 6.x series&amp;mdash;still the stable version at the time of this writing. &lt;a href="https://bazel.build/about/roadmap#bazel_70_release">Bazel 7 is around the corner&lt;/a> and it brings many improvements that will, in theory, improve the developer experience significantly. Here are my highlights:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Build without the Bytes (BwtB):&lt;/strong> We tried using this feature before but it did not work well with dynamic execution, another feature that we must use for performance reasons. Bazel 7 should fix all issues we saw because BwtB is known to not carry bug fixes that are in Bazel 7 due to backporting difficulties. Google is confident that this feature works fine now because they are using it on their corp Mac laptops instead of FUSE, because the latter has become increasingly more cumbersome to use on Macs.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Path mapping and cache key scrubbing:&lt;/strong> New features in Bazel 7 allow Bazel to reuse the cache between different configurations. For example, Java targets only need to be built once irrespective of the target platform (arm64/x86), and Bazel 7 makes this &amp;ldquo;just one build&amp;rdquo; possible. This helps increase shared cache hits, reduces CI costs, reduces Bazel configuration and Git branch switch costs, and reduces local disk usage space. These features need to be enabled via flags and rules have to opt into this behavior if it&amp;rsquo;s useful for them (the Java rules do by default).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Skymeld:&lt;/strong> &lt;a href="https://github.com/bazelbuild/bazel/issues/14057">This feature&lt;/a> interleaves the analysis and execution phases during a build and should be functional in Bazel 7. Using this feature should reduce end-to-end (E2E) build and test times, particularly for builds where the analysis phase takes a long time.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>bzlmod:&lt;/strong> We &lt;em>all&lt;/em> will be required to replace our intractable &lt;code>WORKSPACE&lt;/code> files with bzlmod by Bazel 8, and bzlmod is already the default in Bazel 7. The benefits for the &lt;em>users&lt;/em> of the build system are subtle, but they are palpable for anyone managing external dependencies or third-party package managers like pip or Maven. It&amp;rsquo;s possible to migrate incrementally by moving individual rules into using modules. Difficulties often arise when there are repo aliases in place though.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="ide-improvements">IDE improvements&lt;/h1>
&lt;p>The two news that seemed exciting to me were:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>IntelliJ BSP plugin:&lt;/strong> &lt;a href="https://www.jetbrains.com/">JetBrains&lt;/a> has been working on a new &lt;a href="https://build-server-protocol.github.io/">Build Server Protocol (BSP)&lt;/a> to fix the M:N problem for build tools and IDEs&amp;mdash;just like &lt;a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol (LSP)&lt;/a> did for language integrations. JetBrains has created a new version of the Bazel plugin that relies on a BSP server, and this new plugin better integrates with IntelliJ&amp;rsquo;s internal project modeling and with Remote IntelliJ. The plugin launched in beta during BazelCon and does not yet work with CLion, but they are targeting Spring 2024 to get both out. It&amp;rsquo;s still early to adopt this new plugin, but the future is bright: if VSCode adopts the BSP, we&amp;rsquo;ll finally get Bazel support throughout developer tools. Microsoft, your move. (And Emacs pretty please?)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>IntellIj 2023.3.3:&lt;/strong> This new release of IntelliJ should make the Bazel plugin work well for remote development. Up until now, it was possible to &lt;em>open&lt;/em> existing projects, but not &lt;em>import&lt;/em> them using the Remote IntelliJ interface, which was suboptimal for desktop-less remote VMs.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="remote-build">Remote build&lt;/h1>
&lt;p>Many presenters and attendees report that their companies use remote builds&amp;mdash;unsurprisingly, because that&amp;rsquo;s the primary promise of using Bazel&amp;mdash;and it turns out there are more companies than I thought supplying remote build and telemetry visualization services. Here are some of the interesting details I gathered:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Regional clusters:&lt;/strong> The remote build protocol is sensitive to latency, particularly for builds with low parallelism. In talking to &lt;a href="https://www.engflow.com/">EngFlow&lt;/a>, they&amp;rsquo;ve measured a 10-20% build performance improvement by deploying separate clusters in different regions for a single customer. Multiple clusters are harder to operate than just one cluster&amp;hellip; but if you accept that you need N+1 deployments &lt;em>anyway&lt;/em> for reliability, you might as well colocate them with your primary offices.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Build Barn customizations:&lt;/strong> This open source remote build implementation supports having a bidirectional replicated cache (ideal for the regional clusters mentioned above), and even having small worker pools close to the users while sharing the same central cache. &lt;a href="https://meroton.com/">Meroton&lt;/a>, who does Build Barn consulting, have set up small caches/worker pools in-office for customers, while maintaining a larger &amp;ldquo;central cache&amp;rdquo;, and gotten good results.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Build viewers:&lt;/strong> There are many different implementations of tools to visualize builds via the &lt;a href="https://bazel.build/remote/bep">Build Event Protocol (BEP)&lt;/a>. EngFlow, &lt;a href="https://www.buildbuddy.io/">BuildBuddy&lt;/a>, &lt;del>Gradle Enterprise&lt;/del> &lt;a href="https://gradle.com/">Develocity&lt;/a>&amp;hellip; all were there. As an interesting data point: Develocity can ingest data from various build systems, not just BEP, and allows computing metrics from them all in aggregate. This is not be desirable in the &amp;ldquo;end state&amp;rdquo; of a build system migration, but it&amp;rsquo;s an attractive proposition while the migration is ongoing.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>RE v3:&lt;/strong> There are ongoing discussions about whether &lt;a href="https://docs.google.com/document/d/1FxpdOzOhzOCTjjn2loppMlBzjqjU9WpYF4E1K6opxVI/edit">a new version of the protocol&lt;/a> should be designed or not. There is the thought that some features cannot be retrofitted into the previous protocol, but that&amp;rsquo;s not completely clear. Ed Schouten is requesting feedback in the document that he put together.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>In-transit compression:&lt;/strong> gRPC has support for &lt;a href="https://grpc.io/docs/guides/compression/">transparent in-transit compression&lt;/a> (not at rest). We have thought of hacking it into Build Barn because we think this would improve E2E build times for users with less-than-optimal Internet pipes, but both EngFlow (Java) and Bloomberg (Python) report that they saw worse behavior with compression enabled. They suspect gRPC may be serializing compression operations or doing something similarly-unscalable at very low levels of the stack. Build Barn is written in Go though, so the outcome of this experiment might be different. Worth a try.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Jobs configuration:&lt;/strong> The RE protocol is latency sensitive. Ulf Adams from EngFlow recommended limiting the number of jobs per user on the server side and then configuring the local jobs number to a higher level to minimize the delays that Bazel itself imposes. George Gensure also brought up that there seems to be an unnecessary semaphore in the code that computes Merkle trees, which limits throughput, and that it should be removed from Bazel.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Dynamic scheduling tweaks:&lt;/strong> &lt;a href="https://buck2.build/">Buck2&lt;/a>&amp;rsquo;s &lt;a href="https://bazel.build/remote/dynamic">&amp;ldquo;dynamic scheduler&amp;rdquo;&lt;/a> seems smarter than Bazel&amp;rsquo;s because it avoids running anything locally when the parallelism of the build graph is wide. Then, it enables parallel local execution (which they call hybrid execution) when the parallelism is narrow, as this is the common case towards the end of builds and in most incremental builds. It might be nice to try this in Bazel too because it would help reduce unnecessary network bandwidth (and also help remove the &lt;code>--dynamic_local_execution_delay&lt;/code> hack), but it may increase E2E build time for clean builds if the network is slow&amp;hellip; unless BwtB is at play, in which case this might be a win-win.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="things-to-try-out">Things to try out&lt;/h1>
&lt;p>My TODO list after speaking to people is&amp;hellip; long. Here are a bunch of things I want to try:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Visualize the build graph of our product:&lt;/strong> Bazel has flags to dump the in-memory build graph as a &lt;a href="https://graphviz.org/">Graphviz&lt;/a> file, and &lt;a href="https://github.com/tweag/skyscope/">SkyScope&lt;/a> by &lt;a href="https://www.tweag.io/">Tweag&lt;/a> allows interactively inspecting large graphs. It&amp;rsquo;d be nice to try this out and see what happens, because &lt;a href="https://medium.com/snowflake/build-farm-visualizations-5a079477502d">visualizations often help uncover issues&lt;/a> that are hard to imagine otherwise.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Buck2&amp;rsquo;s LSP for Starlark:&lt;/strong> Meta has done a lot of work in Buck2 to make Starlark easy to write. They have things like an LSP server for Starlark, static typing, static analysis, a profiler, a debugger&amp;hellip; While we cannot use features like static typing because Bazel doesn&amp;rsquo;t support them (yet?), it should be possible to leverage the LSP server for use with VSCode. It apparently has a Bazel mode.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Expendable CI jobs:&lt;/strong> Some CI jobs are not critical: for example, consider a job that exists purely to keep the Bazel remote cache warm for IntelliJ project syncs. Someone brought up the interesting idea of making these jobs monitor the build farm load and skip their execution if the farm is above a certain threshold (to preserve resources and minimize the chances of exhausting them).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Analyze breakdown of rules by type:&lt;/strong> Google reports that 30% of their rules are of the &lt;a href="https://bazel.build/reference/be/general">&lt;code>genrule&lt;/code>&lt;/a> kind, which prevents certain kinds of optimizations&amp;mdash;e.g. they are very expensive memory-wise because they do not benefit from Bazel&amp;rsquo;s depset internal representation. It&amp;rsquo;d be nice to see what our breakdown looks like in case we have to plan some refactoring.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Jenkins persistent runners:&lt;/strong> We currently tear down Jenkins runners quickly, but this discards all Git and Bazel state. For Bazel-only jobs, using persistent runners could help reduce E2E run times. &lt;a href="https://www.thoughtspot.com/">ThoughtSpot&lt;/a> reports a 40% reduction in average build/test time. &lt;a href="https://www.aspect.dev/">Aspect&lt;/a> also claims that this is an anti-pattern. BuildBuddy has done work to clone runners with hot Bazel in-memory state and claims an 8x improvement in build times.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Using actions for downloads:&lt;/strong> Even if this is unorthodox, several people use &lt;em>actions&lt;/em> to download toolchains and the like to minimize the cost of downloads during pre-analysis, to keep those downloads in the remote build farm when the client doesn&amp;rsquo;t need them at all, and to minimize local disk space. I had thought about doing this too, but I was hesitant because it feels &amp;ldquo;ugly&amp;rdquo;. It&amp;rsquo;s good to hear others have thought and tested the same idea too. Note that doing this results in &lt;a href="https://reproducible-builds.org/">reproducible builds&lt;/a> only if downloads are subject to checksum verification.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Validation actions:&lt;/strong> There are new features in Bazel to define &amp;ldquo;validation actions&amp;rdquo; to run things like linters in parallel with the build (without dependency hacks as were used before). Google is using this to run Android Lint internally, which sounds similar to other tools like the popular &lt;a href="https://spotbugs.github.io/">SpotBugs&lt;/a>. These actions can also produce diffs to apply to the source tree to fix the issues they identify.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="upstream-contributions">Upstream contributions&lt;/h1>
&lt;p>These are some long-running changes I&amp;rsquo;d like to get into upstream Bazel and that need follow up:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>C++ linker memory model:&lt;/strong> The C++ linker memory estimation in Bazel is &lt;a href="https://github.com/bazelbuild/bazel/issues/17368">way off reality&lt;/a>, and I previously upstreamed the foundations to fix the issue by exposing input sizes to the estimation logic. We still have to carry a local patch to tune the model based on our observations, but the patch is really small now. But given the diversity in the C++ ecosystem, it&amp;rsquo;d be awesome if we could parameterize the memory computation in the C++ toolchain definition somehow and avoid a local patch: imagine having a lambda that returns a CPU/RAM resource set based on the number of inputs, their size, and the compilation model. I need to engage in GitHub Discussions.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>BEP sanitization changes:&lt;/strong> I brought up that the BEP is incredibly prone to leaking secrets stored in the environment and while folks knew this happens&amp;mdash;after all, tools like BuildBuddy and EngFlow have logic to scrub secrets&amp;mdash;they were not really aware of the extent of the problem. I have a prototype patch to scrub all environment variables from the BEP (except for a limited allowed list useful for debugging) and I think we agreed that this feature would be good to upstream. So now I need to write a proper bug report and share my audits of the protocol and the proposal for a fix. Stay tuned.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>bb-clientd patch:&lt;/strong> The current implementation of &lt;a href="https://github.com/bazelbuild/bazel/pull/12823">the patch to support a FUSE-based output tree&lt;/a> is going nowhere because of the upcoming Remote Output Service formalization of this same idea. Until that&amp;rsquo;s available, I don&amp;rsquo;t think it&amp;rsquo;s worth trying to maintain this on top of Bazel 6 any longer, particularly due to the BwtB improvements that are coming in Bazel 7. It seems wiser to just wait.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="other-thoughts">Other thoughts&lt;/h1>
&lt;p>And to conclude, a bunch of disconnected notes about things that were interesting to me:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Buck2:&lt;/strong> This new build system from Meta looks really cool to me. On the plus side, it fixes some long-standing issues in Bazel, like having a truly language-agnostic core, being built from the ground up with BwtB and FUSE in mind, and super-quick startup time because it&amp;rsquo;s not Java; hindsight is 20/20 after all. But it also has its drawbacks, like no support for external dependencies yet or no local sandboxing (both of which are fixable). They also have nice features like limited dynamic dependency discovery, which makes tools like Gazelle less necessary. And&amp;hellip; they are considering writing a shim to support Bazel rules in Buck2, which would make experimentation on existing projects super-exciting.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Bazel jobs scalability:&lt;/strong> There are two problems with making Bazel scale to thousands of concurrent jobs: the &amp;ldquo;1 job = 1 thread&amp;rdquo; execution model, and memory usage due to Merkle tree computation. Ulf Adams reports that he could run Bazel with hundreds of thousands of jobs back at Google when he implemented async execution by hand&amp;mdash;the Google-internal RE protocol doesn&amp;rsquo;t use Merkle trees, so memory pressure was not an issue&amp;mdash;but unfortunately the changes were never productionized and have been backed out of Bazel due to their complexity. Java 21 brings &lt;a href="https://docs.oracle.com/en/java/javase/20/core/virtual-threads.html">virtual threads&lt;/a> and paves the way to fix this in a nicer, non-hacky way.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>bb-clientd improvements:&lt;/strong> Meroton has significant experience with deploying bb-clientd for customers and are interested in the issues we face because they are the main pushers for the Remote Output Service feature. In particular, dynamic execution doesn&amp;rsquo;t play well with bb-clientd because it causes bb-clientd to backlog downloads when local actions are frequently cancelled. It should be possible to tell bb-clientd to stop downloads and resolve these issues because the FUSE protocol supports it, but it&amp;rsquo;s not plumbed through. Also, implementing chunked downloads to support debugging of large binaries with minimal network latency sounds awesome, but we&amp;rsquo;d need to quantify the benefit first: I suspect you need just a tiny portion of multi-GB C++ debug binary to produce a stacktrace.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Virtual file systems on macOS:&lt;/strong> Both Ed Schouten from Build Barn and Neil Mitchell from Buck2 report that NFSv4 has been pretty decent on macOS when compared to FUSE to implement virtual file systems, and that it should be the primary mechanism for writing virtual file systems on macOS now. FUSE is unfortunately doomed due to Apple&amp;rsquo;s desire to kill kernel extensions, which makes it really hard to install FUSE.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Avoiding BUILD files:&lt;/strong> &lt;a href="https://www.salesforce.com/">Salesforce&lt;/a> has undergone a Bazel migration with 4000 engineers and claims that 70% have trouble writing BUILD files. Anything that can be done to hide them / automate edits is worthwhile. &lt;a href="https://investors.luminartech.com/">Luminar&lt;/a> has developed a C++ plugin for &lt;a href="https://github.com/bazelbuild/bazel-gazelle">Gazelle&lt;/a> and they use &lt;a href="https://github.com/NixOS/nixpkgs">Nix packages&lt;/a> to pull in third-party dependencies.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Coverage-guided test selection:&lt;/strong> It&amp;rsquo;s a common problem to have integration tests that depend on pretty much all of the codebase, which in turn causes test runs to take too long and nullifies Bazel&amp;rsquo;s test caching features. Coverage metrics can be useful in implementing a heuristic to identify which subset of the integration tests to run on a given change at the expense of occasional false negatives.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Classes in Starlark:&lt;/strong> Aspect has come up with an idiom to represent classes in Starlark, and they claim it has simplified maintenance of their JavaScript rules significantly. Worth a look.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Monorepos and Git:&lt;/strong> VMware claims that Perforce is much faster than Git at syncing GBs of source code (1min vs. 12min). Meroton has developed a &amp;ldquo;monorepo emulation&amp;rdquo; mode on top of many small Git repos leveraging Gerrit&amp;rsquo;s cross-repo atomic commits. AOSP (Android) has done something similar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Abusing &amp;ldquo;exec requirements&amp;rdquo; to tune remote workers:&lt;/strong> &lt;a href="https://stripe.com/">Stripe&lt;/a> has implemented lots of custom features to tune the behavior of remote workers via &amp;ldquo;exec requirement&amp;rdquo; tags at the action/target level. They can do things like mock time on the remote containers to exercise timing conditions (e.g. leap year switches) or to request access to certain internal-only network endpoints. They can also emit trace data from actions (by configuring a &amp;ldquo;listener&amp;rdquo; that propagates those details) and then merge such traces into the Bazel &lt;a href="https://bazel.build/advanced/performance/json-trace-profile">JSON trace profile&lt;/a> to show what exactly the long-running actions are doing. Think visualizing what a nested &lt;code>make -j8&lt;/code> is doing.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Building without the Internet:&lt;/strong> Salesforce mirrors all external dependencies internally and denies all downloads by default from untrusted sources. They do allow the build farm to talk to internal sources to fetch artifacts though, because their tests need to do that. The &amp;ldquo;resolved file&amp;rdquo; feature in Bazel can help create a catalog of dependencies, and the &amp;ldquo;download config&amp;rdquo; to deny external access.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>RE for arbitrary builds:&lt;/strong> EngFlow is doing a lot of work to support arbitrary builds using remote execution, not just Bazel builds. They have &amp;ldquo;revived&amp;rdquo; &lt;a href="https://github.com/bazelbuild/reclient">Google&amp;rsquo;s reclient&lt;/a>&amp;mdash;a compiler wrapper that uses RE&amp;mdash;and offer support for CMake. The idea in CMake is to use reclient where possible (compiling and linking) and to run CMake itself on a remote worker to paper over the limitations of actions not supported by reclient.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Memory consumption is a widespread problem:&lt;/strong> Everybody dislikes how Bazel consumes memory. Google is doing work on this and we should continue to see improvements. One that sounded promising is the addition of support to discard partial parts of the build graph (e.g. for things not in the critical path).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Blogging is cool:&lt;/strong> Many people opened with &amp;ldquo;I read your blog!&amp;rdquo; upon meeting them which was&amp;hellip; flattering, I must confess. I need to write more. Subscribe to this blog if you haven&amp;rsquo;t yet!&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="reference-material">Reference material&lt;/h1>
&lt;p>A bunch of papers mentioned during the many discussions that happened:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.inf.u-szeged.hu/~gertom/Kutatas/BGS12.pdf">Code Coverage-Based Regression Test Selection and Prioritization in WebKit&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://research.google/pubs/pub48413/">Code Coverage at Google&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/facebook/sapling">Sapling from Facebook (git-compatible highly-scalable SCM)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">Build systems à la carte&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/microsoft/scalar">Scalar (Microsoft extensions for very large git repos)&lt;/a>&lt;/li>
&lt;/ul></description><enclosure url="https://jmmv.dev/images/2023-10-30-bazelcon.jpg" length="663230" type="image/jpeg"/></item></channel></rss>