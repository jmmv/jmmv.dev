<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Julio Merino (jmmv.dev)</title><link>https://jmmv.dev/</link><description>Recent content on Julio Merino (jmmv.dev)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>julio@meroh.net (Julio Merino)</managingEditor><webMaster>julio@meroh.net (Julio Merino)</webMaster><copyright>Copyright 2004&#150;2025 Julio Merino</copyright><lastBuildDate>Sun, 23 Nov 2025 17:00:00 -0800</lastBuildDate><atom:link href="https://jmmv.dev/feed.xml" rel="self" type="application/rss+xml"/><item><title>BazelCon 2025 recap</title><link>https://jmmv.dev/2025/11/bazelcon-2025-recap.html</link><pubDate>Sun, 23 Nov 2025 17:00:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/11/bazelcon-2025-recap.html</guid><description>&lt;p>It has been just over two years since I started Blog System/5, and that means it&amp;rsquo;s time for the now-usual(?) BazelCon 2025 trip report!&lt;/p>
&lt;p>The conference, arranged by the Linux Foundation, took place in Atlanta, GA, USA over three days: one for tutorials and two for the main talks. An extra hackathon day, organized by Aspect Build, followed. Unfortunately, a canceled flight meant I missed the tutorials, but I attended the rest of the events. As usual, it was a super-fun time to connect with old acquaintances and an energizing event that left me with plenty of new topics to research.&lt;/p>
&lt;p>What follows is not a complete summary of the conference, as there were many talks I did not attend and conversations I missed. If you want the full firehose of videos, see the &lt;a href="https://www.youtube.com/playlist?list=PLak8-7eFSpowmNiR2lhvJEomLA140yban">Bazel Con 2025 YouTube playlist&lt;/a>. And if you want a TL;DR&amp;hellip; I&amp;rsquo;d pick the following highlights:&lt;/p>
&lt;ul>
&lt;li>The ecosystem is maturing with &lt;code>bzlmod&lt;/code> becoming mandatory and the BUILD Foundation being a reality in the near horizon.&lt;/li>
&lt;li>Performance remains a key focus of the Bazel core team and the community, with innovative approaches like Skycache for client-side speed, sophisticated RE improvements for backend efficiency, and new rulesets like &lt;code>rules_img&lt;/code> that focus on build speed.&lt;/li>
&lt;li>Community tooling is expanding Bazel&amp;rsquo;s scope, with projects like Aspect&amp;rsquo;s task runner aiming to solve long-standing workflow gaps.&lt;/li>
&lt;/ul>
&lt;p>But the above is just tiny peek into the conference. So, strap your seat belts and let&amp;rsquo;s dive into the conference.&lt;/p>
&lt;h1 id="opening-words">Opening words&lt;/h1>
&lt;p>Google opened by emphasizing their commitment to Bazel, highlighting its growing internal adoption. Their reasoning is that Bazel improves security and hermeticity, in addition to the usual benefits of faster builds and easier open-sourcing of code. This statement seems to be a response to last year&amp;rsquo;s proposal to create a non-Google Bazel Foundation, which would act as a &amp;ldquo;backup plan&amp;rdquo; should Google ever withdraw from the project.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/N4e5TsiFqzQ?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>Google provided two examples of its growing Bazel adoption. The first is &lt;a href="https://quantumai.google/">Quantum AI&lt;/a>, primarily written in Python and Rust, which saw an 80% reduction in CI time after a migration to Bazel that was driven by just one SWE. The second is their &lt;a href="https://cloud.google.com/distributed-cloud">Google Distributed Cloud (GDC)&lt;/a>, a version of their cloud product that can run on-premise and in air-gapped instances. The GDC codebase weighs 2.6 GB, is developed by 1,300 engineers, and produces 600 GB of release artifacts. I have to question if the latter is a number to be proud of: when does this madness in bloat stop?&lt;/p>
&lt;p>The introduction concluded with a few statistics: Bazel&amp;rsquo;s &lt;code>#general&lt;/code> Slack channel has grown by 18% from the previous year to 8,500 users; there are about 10,800 repos on GitHub with &lt;code>MODULE.bazel&lt;/code> files; and there are about 120,000 &lt;code>bzl&lt;/code> files on GitHub.&lt;/p>
&lt;h1 id="community-updates">Community updates&lt;/h1>
&lt;p>The next session was the customary round of community updates, presented by Jay Conrod from EngFlow and Alex Eagle from Aspect Build.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/Zpfl82MU4U0?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>Here are the highlights:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Training day:&lt;/strong> There were six different sessions on the Sunday before the conference, and EngFlow is leading training efforts worldwide.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Gazelle:&lt;/strong> C++ support is on the way for this tool. Version 2.0 will simplify the extensions interface and improve performance.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>BCR Mirror:&lt;/strong> Cloudflare is now hosting a mirror for the Bazel Central Registry (BCR). You can use it with Bazel 8.4+ by adding &lt;code>common --module_mirrors=https://bcr.cloudflaremirrors.com/&lt;/code> to your configuration&amp;mdash;and this will become a default in a future release.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Documentation:&lt;/strong> The most common complaint in community surveys remains the documentation and the steep learning curve. To address this, &lt;a href="https://registry.bazel.build/">the BCR website&lt;/a> now features icons for sponsorship requests, deprecation notices, and provenance attestations. Furthermore, the Starlark documentation has been published and is now easier to read. In a move to empower the community, the documentation has been migrated out of Google&amp;rsquo;s internal infrastructure and is available at &lt;a href="https://preview.bazel.build/">https://preview.bazel.build/&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>BUILD Foundation:&lt;/strong> The foundation currently has three founding members (Spotify, Uber, and Canva) and is looking for four more. The initial meeting is scheduled for December 4th. More on this in its own section.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Bzlmod was also a significant topic in this talk, but since it was covered at length in other presentations as well, I have dedicated a separate section to it below.&lt;/p>
&lt;h1 id="state-of-the-union">State of the union&lt;/h1>
&lt;p>As is tradition, the next session was the State of the Union talk, led by John Field and Tobias Werth from Google.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/FwruvTfClwk%20?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>Here are some of the highlights from the update:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Local remote repo caching:&lt;/strong> This &lt;a href="https://docs.google.com/document/d/1ZScqiIQi9l7_8eikbsGI-rjupdbCI7wgm1RYD76FJfM/edit">new feature&lt;/a> is intended to allow the caching of repository rules across different workspaces.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Experimental WASM support:&lt;/strong> There is &lt;a href="https://github.com/bazelbuild/bazel/discussions/25537">experimental support for WASM tools in repo rules&lt;/a> to enable platform-independent tooling, but its future is still uncertain.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Performance improvements:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Changes to &lt;code>NestedSets&lt;/code> can save up to 20% of memory.&lt;/li>
&lt;li>Optimizations in Merkle tree handling can reduce wall time by up to 30%.&lt;/li>
&lt;li>Analysis phase caching is coming soon (see the &amp;ldquo;Skycache&amp;rdquo; section below for more details).&lt;/li>
&lt;li>There are ongoing efforts to cap disk usage.&lt;/li>
&lt;li>Path stripping, a feature announced last year, is now more mature and integrated with more rule sets, offering up to an 84% reduction in build time.&lt;/li>
&lt;li>Analysis time on flag changes has been reduced.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Java improvements:&lt;/strong> Caching has been improved, and method signature changes no longer affect downstream header builds.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Starlark flags:&lt;/strong> A new scoping API is available for Starlark flags.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;code>PROJECT.scl&lt;/code>:&lt;/strong> A &lt;a href="https://github.com/bazelbuild/bazel/issues/24839">new file&lt;/a> is being introduced to provide a canonical place for project owners to map targets to flags. More details on its own section.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Starlarkification:&lt;/strong> This effort is almost complete. All rules are now decoupled, with the exception of a few integration points for C++. As of Bazel 9, autoloading of rules is disabled, which means users must now explicitly &lt;code>@load&lt;/code> all the rules they use.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Starlark type system:&lt;/strong> &lt;a href="https://github.com/bazelbuild/starlark/issues/106">Type annotations and type-checking&lt;/a> are coming to Starlark. The syntax will be supported in Bazel 9, with type-checking planned for Bazel 10. The syntax aims for compatibility with Python 3 types, which introduces some limitations on what can be expressed.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>JetBrains Bazel plugin:&lt;/strong> The &lt;a href="https://plugins.jetbrains.com/plugin/22977-bazel">JetBrains-owned Bazel plugin&lt;/a> has reached general availability, making the Google-owned plugin a legacy tool. This new plugin promises a much-improved user experience, as it is faster and better integrates the Bazel build graph with IntelliJ&amp;rsquo;s native understanding of the project structure, avoiding expensive &amp;ldquo;sync&amp;rdquo; steps.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Internal APIs:&lt;/strong> There is ongoing work to separate core logic from service interactions (such as remote builds and file system operations), which sounds very similar to how Buck 2 was designed from the start.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Much like the community updates talk, this one also opened with bzlmod. Let&amp;rsquo;s dive into that topic next.&lt;/p>
&lt;h1 id="bzlmod">bzlmod&lt;/h1>
&lt;p>The workspace is dead; long live bzlmod! With Bazel 9, support for old-style workspaces has been removed, and given that the vast majority of rulesets now support bzlmod, it&amp;rsquo;s time for everyone to complete their migration. This is a positive development because bzlmod, through the &lt;a href="https://registry.bazel.build/">Bazel Central Registry (BCR)&lt;/a>, simplifies rule discovery, project dependencies, and version conflict resolution. Interestingly, but not surprisingly, bzlmod and the BCR have effectively become a package manager for C++.&lt;/p>
&lt;p>But it&amp;rsquo;s not all roses. The bzlmod migration has been a significant source of friction for the community due to the intrusive and difficult nature of the change. If you haven&amp;rsquo;t completed the transition, you can no longer upgrade to newer Bazel versions. The official documentation has also been subpar (which is not surprising), although a great set of &lt;a href="https://blog.engflow.com/2024/06/27/migrating-to-bazel-modules-aka-bzlmod---the-easy-parts/">articles from EngFlow&lt;/a> is now available to clarify the migration process in great detail.&lt;/p>
&lt;p>To assist with the migration, an &lt;a href="https://bazel.build/external/migration_tool">automated migration tool&lt;/a> is now available, and various people have reported success using AI tools to help with the transition. In a related development, there is now a Maintainer Community Program (MCP) for the BCR.&lt;/p>
&lt;p>One major pain point I have faced, and one that seems to affect many others, is the tendency of the Bazel ecosystem to couple rule versions with library versions. For example, if you are using an old version of &lt;code>protobuf&lt;/code> with an equally old version of &lt;code>rules_proto&lt;/code> that is not compatible with bzlmod, you must upgrade &lt;code>rules_proto&lt;/code> to migrate. However, this in turn forces you to upgrade &lt;code>protobuf&lt;/code> itself. Updating a library can introduce API incompatibilities and behavioral changes, making the upgrade to bzlmod and subsequent major Bazel releases much more difficult than it needs to be.&lt;/p>
&lt;h1 id="re-action-routing">RE action routing&lt;/h1>
&lt;p>Before we dive into remote execution, let me clarify some terminology. Remote Execution is abbreviated as RE, not RBE. RBE was Google&amp;rsquo;s now-discontinued cloud product for RE. While the terms are often used interchangeably today (even on Bazel&amp;rsquo;s own website), it&amp;rsquo;s a good idea to stick to RE. Similarly, avoid using the term &amp;ldquo;build farm&amp;rdquo; as there is a specific RE implementation named &lt;a href="https://github.com/buildfarm/buildfarm">Buildfarm&lt;/a>.&lt;/p>
&lt;p>Remote execution is always a hot topic at BazelCon, and for good reason. One of Bazel&amp;rsquo;s biggest selling points is the performance boost from distributing builds across multiple machines, and nearly every Bazel-related startup offers some form of remote execution solution.&lt;/p>
&lt;p>In the first RE-focused talk, Son Luong Ngoc from BuildBuddy explained how their product routes actions to maximize performance and minimize execution latency.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/iQqLtuBzkKE?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The talk began with a clear premise: remote builds are spiky and hard to binpack, so how can they be scheduled efficiently for both performance and cost? Here are some of the key features of their RE implementation:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Executor types:&lt;/strong> BuildBuddy provides both managed (OCI, Firecracker, macOS) and self-hosted (Docker, Windows, GPU, and more) executors, each with different performance, isolation, and cost characteristics.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Multiple action queues:&lt;/strong> Executors are organized into pools, and actions can specify which pool they should run on. When an action is received, the scheduler enqueues it in up to three different executors to minimize tail latency, based on the &lt;a href="https://dl.acm.org/doi/10.1145/2517349.2522716">Sparrow scheduler research paper&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Work stealing:&lt;/strong> Dynamic scaling of executor pools is critical for handling spiky build workloads while keeping costs down. To make this more efficient, BuildBuddy allows new executors to steal work from existing ones, which helps redistribute the load.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Action merging:&lt;/strong> This feature coalesces multiple execution requests for the same action into a single execution. As we learned, this can be problematic if a misbehaving executor stalls multiple clients (e.g., several CI jobs). To address this, BuildBuddy speculatively re-executes a running action on a different executor after a certain threshold has passed.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Action cancellation:&lt;/strong> When a user presses Ctrl+C, they are likely to modify code and restart the build, so continuing to run in-flight actions is wasteful. For greater efficiency, BuildBuddy catches the finished event &lt;em>from the BEP&lt;/em> and attempts to cancel all remotely-queued actions.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Binpacking:&lt;/strong> Different actions have different resource requirements, and it can be difficult to manually assign them to the right pool and executor. BuildBuddy automatically profiles executed actions (for metrics like peak memory and CPU consumption) and stores this information in the &lt;code>auxiliary_metadata&lt;/code> field of the action result, which is then stored on the server. The scheduler uses these details to route actions more effectively.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Cold starts:&lt;/strong> Executing remote actions is similar to running lambda functions: a worker must be started, a container image fetched, and the action executed. To optimize this, BuildBuddy uses affinity routing, where a key is computed based on the primary output name (which is unique for each action) to extract platform, target, and output details. This allows similar actions to be routed to similar executors.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Recycled runners:&lt;/strong> Some customers need to maintain heavyweight processes on the remote worker, such as test databases or the Docker daemon. While not hermetic, this is often desirable for high-performance scenarios. The use of these features is customized through execution properties.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Custom resources:&lt;/strong> Some actions may require access to specialized resources like GPUs, FPGAs, or simulators. For better binpacking, customers can define the &amp;ldquo;size&amp;rdquo; of different executor types and annotate actions with the resources they consume.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Fair scheduling:&lt;/strong> With multi-tenancy, users can set a &amp;ldquo;priority&amp;rdquo; for the actions of a build using the &lt;code>--remote_execution_priority&lt;/code> flag. A common use case is to define three priority bands: interactive builds, CI, and cron jobs. The BuildBuddy scheduler takes this property into account.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>After detailing these existing features, the talk concluded with a glimpse into the future: extending the RE protocol with a remote &lt;em>build graph&lt;/em> API. The current protocol is very chatty, making it difficult to colocate actions (such as a compile-link-test chain). A protocol that understands action relationships could significantly improve this.&lt;/p>
&lt;p>This talk left me wondering which of these features are also offered by other major RE vendors and open-source implementations. I briefly chatted with the EngFlow folks at the conference and they told me they have most of these too; it&amp;rsquo;d be nice to have a comparison chart among vendors and free solutions.&lt;/p>
&lt;h1 id="re-cost-savings-vs-reliability">RE cost savings vs. reliability&lt;/h1>
&lt;p>The next major topic for RE was cost savings and reliability, which was covered in at least two talks.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/Otjbpn2rB3w?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The first talk, presented by Rahul Roy from Glean, focused on how their adoption of Buildbarn for scalability unexpectedly doubled their CI costs. The primary causes for this increase were an up-to-20% per-action overhead in the Buildbarn worker and a lack of Bazel client caching in their GitHub Actions runners.&lt;/p>
&lt;p>To solve these issues, they chose to adopt &lt;a href="https://aws.amazon.com/ec2/spot/">spot instances&lt;/a> in their deployment of Buildbarn on GCP&amp;rsquo;s Kubernetes offering, but this is not as easy as it seems:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The default Kubernetes autoscaler relies on CPU and memory utilization for its decisions, but these metrics are poor predictors of CI traffic patterns. Action queue length is a much better indicator of developer activity, so a custom autoscaler is needed to achieve reasonable behavior.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Fair scaling can disrupt ongoing builds because GCP only provides a 90-second shutdown notice before preempting instances, which is not enough time to terminate running actions gracefully.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cold runners are significantly slower than hot ones because they start with empty local caches. To mitigate this, they implemented a solution to reuse runner disks, but only for disks that had been used for builds covering more than 50% of the build graph. This strategy reduced startup times from eight minutes to less than one.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/NO028kW_VDc?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The second talk, given by Gabriel Russo from Databricks and Yuval Kaplan from EngFlow, focused on building at scale and how a naive move to remote execution can actually make CI slower.&lt;/p>
&lt;p>They investigated the specific problem of using Docker in actions. The default behavior for remote actions is to bring up a fresh worker for each execution and tear it down afterward, wiping all state. However, Docker is stateful, which meant that actions were performing a great deal of redundant work. To solve this, they moved the snapshotter (a part of &lt;code>containerd&lt;/code>) out of the action sandbox and into the execution container, allowing it to be shared across all actions on a given machine.&lt;/p>
&lt;p>The takeaway is that you must be careful with RE. Your intuition for how local processes interact, especially with local state, does not always apply, and you can inadvertently make builds much slower and more expensive. But how do you develop such intuition? That question provides a perfect segue to the next talk.&lt;/p>
&lt;h1 id="understanding-build-behavior">Understanding build behavior&lt;/h1>
&lt;p>Bazel is a complex piece of software, and its interactions with other systems are not always straightforward. When things go wrong, can the data tell us what happened? Users are often frustrated by unexpected cache misses, frequently rebuilt targets, non-hermetic actions, and flaky tests. This was the topic of a talk co-presented by Eloise Pozzi from Canva and Helen Altshuler from EngFlow.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/NdZIeAbS32Q?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The answer to the question above is obviously yes, the data can tell us. But it&amp;rsquo;s not easy because there is &lt;em>a lot&lt;/em> of data to comb through. Bazel produces the following datasets:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Build Event Protocol (BEP):&lt;/strong> A stream of events that Bazel sends to a remote server to publish build metadata and report progress. The metadata is the closest thing you will get to &amp;ldquo;usage telemetry&amp;rdquo; from Bazel as it captures all builds that were executed (who ran them and with which flags, what was executed, etc.) My pet peeve is that the BEP is incredibly complex and really difficult to manipulate post-facto, but I encourage you to generate one locally (via &lt;code>--build_event_json_file&lt;/code>) and to spend &amp;ldquo;a few&amp;rdquo; minutes understanding what&amp;rsquo;s in there.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Exec log:&lt;/strong> This log captures everything that happened for actions, regardless of where they ran (the BEP only contains minimal details on local-only actions). It is not captured by default due to its verbosity. The &lt;code>--execution_log_compact_file&lt;/code> flag, available since Bazel 7.1, makes it possible to capture this log unconditionally. Note that you need a parser to convert this binary log into something that can be read and compared across versions, and you need to manually build this parser out of Bazel&amp;rsquo;s source tree; yikes.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Exec graph log:&lt;/strong> This log captures how actions depend on each other. It can help quantify drag on the critical path, determine if the critical path is unique, or identify if there are competing ones. Use it to identify actions to prioritize for end-to-end build optimization.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Query commands:&lt;/strong> See &lt;a href="https://bazel.build/query/language">the reference&lt;/a> for &lt;code>bazel query&lt;/code>, &lt;code>bazel cquery&lt;/code>, and &lt;code>bazel aquery&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>JSON profile:&lt;/strong> Also known as the &lt;a href="https://bazel.build/advanced/performance/json-trace-profile">performance profile&lt;/a>, this captures a timeline of all actions executed by Bazel and can help understand build bottlenecks and tune parallelization.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>RE profile:&lt;/strong> Similar to the JSON profile but this is captured server-side by some RE implementations. EngFlow generates one of these with specific details on how the workers executed actions (e.g. which pool ran an action, which is not something that&amp;rsquo;s visible to Bazel).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Returning to the BEP, it&amp;rsquo;s worth noting that one of the last messages it emits is &lt;code>buildToolLogs&lt;/code>, which contains links to some of the other logs mentioned above. If you are using remote caching, these links will point to remote cache entries, allowing you to fetch them after the fact for any user build you need to investigate.&lt;/p>
&lt;p>The talk also included a description of how to debug cache misses between CI and interactive developer builds, and I felt it was an almost-literal rehearsal of &lt;a href="/2025/07/bazel-action-determinism.html">the article I wrote months ago&lt;/a> on the same topic.&lt;/p>
&lt;h1 id="ide-support-for-monorepos">IDE support for monorepos&lt;/h1>
&lt;p>The next talk I attended, which hits close to my heart, was on exposing developer tools to the &lt;code>PATH&lt;/code>. I believe that &lt;code>bazel run&lt;/code> provides a terrible user experience, so I was keen to hear about alternatives. The talk was given by Florian Berchtold from Zipline.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/g_5jyXsCELk?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>One possible solution to this dilemma is to use &lt;a href="https://direnv.net/">direnv&lt;/a>, a long-standing tool that hooks into the shell&amp;rsquo;s before-prompt command to run arbitrary code when entering specific directories. Scary? Yes. Useful? Also yes. The idea is to leverage direnv to bring project-specific tools into the &lt;code>PATH&lt;/code>.&lt;/p>
&lt;p>But where do these tools come from? While some people use package managers like &lt;a href="https://github.com/NixOS/nixpkgs">nixpkgs&lt;/a>, this can lead to duplication and inconsistencies in a Bazel-native world. For example, it&amp;rsquo;s common to pull in &lt;code>buildifier&lt;/code> via bzlmod, but you might also want to expose it in the &lt;code>PATH&lt;/code>. This is where &lt;a href="https://github.com/buildbuddy-io/bazel_env.bzl">&lt;code>bazel_env&lt;/code>&lt;/a> comes in: a hook for direnv that fetches tools using Bazel.&lt;/p>
&lt;p>The talk explained how to use &lt;code>bazel_env&lt;/code> with dev containers to install &lt;code>bazelisk&lt;/code>, &lt;code>direnv&lt;/code>, IDE extensions, and even &lt;a href="https://github.com/withered-magic/starpls">starpls&lt;/a> (the LSP for Starlark). It was also mentioned that for C++, &lt;a href="https://github.com/hedronvision/bazel-compile-commands-extractor">bazel-compile-commands-extractor&lt;/a> with &lt;code>clangd&lt;/code> works reasonably well for VSCode but struggles with large repositories. For those, &lt;a href="https://github.com/luminartech/dev-tools?tab=readme-ov-file#configure-vs-code-for-bazel">configure-vscode-for-bazel&lt;/a> is recommended for a better experience.&lt;/p>
&lt;p>The speaker also prepared a sample repository to demonstrate Bazel integration in the IDE for various languages, which you can find at &lt;a href="https://github.com/hofbi/bazel-ide">hofbi/bazel-ide&lt;/a>.&lt;/p>
&lt;h1 id="skycache">Skycache&lt;/h1>
&lt;p>A few months ago, we hosted &lt;a href="https://www.linkedin.com/feed/update/urn:li:activity:7295871444343734272/">a Buildbarn mini-conference&lt;/a> at Snowflake where, in my opinion, the most exciting talk was Ed Schouten&amp;rsquo;s presentation on Bonanza. Shortly after, I published an article imagining &lt;a href="/2025/03/bazel-next-generation.html">the next generation of Bazel builds&lt;/a>, because Bazel&amp;rsquo;s fat client model is problematic in many scenarios.&lt;/p>
&lt;p>At BazelCon, we now heard Google&amp;rsquo;s approach to solving slow cold builds and Bazel client scalability in a talk on Skycache by Shahan Yang.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/1A8LMZ21t6Y?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The core idea of Skycache is to serialize and remotely cache &lt;a href="https://bazel.build/reference/skyframe">Skyframe&lt;/a>, Bazel&amp;rsquo;s internal tracking system for build state (also known as the &amp;ldquo;build graph&amp;rdquo;). In his talk, Shahan outlined three major considerations for making this solution viable:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Top-down pruning:&lt;/strong> When you get a cache hit for a node in the graph, you don&amp;rsquo;t have to worry about anything below that node anymore. You can throw away everything underneath to keep memory usage constrained.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Invalidation computation:&lt;/strong> To determine what needs to be re-fetched from the cache, Skycache assumes &amp;ldquo;the same baseline&amp;rdquo; and then looks for file changes between the local system and the cache to find &amp;ldquo;what&amp;rsquo;s missing&amp;rdquo;. I know, this sounds fuzzy; refer back to the talk for the specifics.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Efficiency:&lt;/strong> For some nodes, it&amp;rsquo;s cheaper to recompute them than to fetch them from the cache, and this was true for many nodes before applying two optimizations. One was in the nested sets data structure, because the original approach to serializing them caused a 10x space blowup. The other was around serializing individual node values, because most of the time, those values share internals across nodes.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Internal dogfooding of Skycache showed that some builds dropped from 46 to 13 seconds, with similar reductions observed for analyzed targets, loaded packages, and more.&lt;/p>
&lt;p>On the server side, this solution is RAM-intensive (similar to Bazel&amp;rsquo;s in-memory representations) and is complicated by the fact that users want to build at older versions and with a high version cadence. To be effective, Skycache needs to maintain &amp;ldquo;thousands of base images&amp;rdquo;.&lt;/p>
&lt;p>A specific insight toward the end of the talk was that, for Google as a whole, 2.5% of targets account for 90% of all targets built. This suggests a potential optimization where only those targets are cached, but this has not yet been implemented.&lt;/p>
&lt;p>There is no open-source implementation of Skycache, but the talk provided hints about which classes would need to be implemented to make it work. It seems that it shouldn&amp;rsquo;t be too difficult: the serialization code is already in place, so all that&amp;rsquo;s required is integration with a key-value store and Git.&lt;/p>
&lt;p>While this talk was fascinating, I can&amp;rsquo;t help but feel that Google&amp;rsquo;s solution is a bit strange. They are opting to maintain a fat Bazel client instead of moving it entirely to the cloud, as Bonanza is attempting to do, and this feels weird to me knowing how the rest of their infrastructure works (or used to work a few years back).&lt;/p>
&lt;h1 id="dynamic-actions-and-buck-2">Dynamic actions and Buck 2&lt;/h1>
&lt;p>Yes, this was BazelCon, but given Buck&amp;rsquo;s spiritual heritage, it was no surprise to see some Buck 2 content. Andreas Herrmann from Tweag took the stage to compare Bazel and Buck 2&amp;rsquo;s approaches to the efficient compilation of Haskell, highlighting the key role of dynamic actions in Buck 2.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/eA-3Gfr4epU?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The core of the issue lies in how Haskell modules and libraries are compiled and exposed in the Haskell rules. The summary is as follows:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Modules are individual &lt;code>.hs&lt;/code> source files. These act as the compilation unit.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Libraries are collections of modules, and is what&amp;rsquo;s often modeled in the build via &lt;code>haskell_library&lt;/code> rules. Therefore, library targets tend to group various modules.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compiling an &lt;code>.hs&lt;/code> file produces an &lt;code>.o&lt;/code> object file but also a &lt;code>.hi&lt;/code> interface file. Think of the latter as a precompiled header or an interface JAR.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>To compile a module, we need the &lt;code>.hi&lt;/code> files of its dependencies, &lt;em>not&lt;/em> their &lt;code>.o&lt;/code> files. This is the key difference between compiling a &lt;code>cc_library&lt;/code> vs. a &lt;code>haskell_library&lt;/code>, because in the C/C++ case, all individual sources can be compiled in any order, but in the Haskell case, they cannot.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>With this in mind, the central question is: how can we parallelize the compilation of modules &lt;em>within a library&lt;/em> when they must be compiled in dependency order?&lt;/p>
&lt;p>In Bazel, the solution is to model the internal library modules as separate &lt;code>haskell_module&lt;/code> rules, each with a static representation of its cross-module dependencies. However, this approach can be incredibly noisy. While Gazelle can help mitigate the issue, it is still not an ideal user experience.&lt;/p>
&lt;p>Buck 2, on the other hand, provides dynamic dependencies, which make it possible to infer the module-level dependency graph &lt;em>at build time&lt;/em>. The idea is to have an action that runs &lt;code>ghc -m&lt;/code> to emit the cross-module dependency &amp;ldquo;mini-graph&amp;rdquo; for a set of modules, and then use a dynamic action to generate module-level compilation actions with the correct dependencies.&lt;/p>
&lt;h1 id="task-execution-via-starlark">Task execution via Starlark&lt;/h1>
&lt;p>One of my &lt;a href="/2015/04/on-bazel-and-open-source.html">original critiques of Bazel in 2015&lt;/a> was that while Bazel is excellent at &lt;em>building&lt;/em>, it is not well-suited for other workflows. The specific example I gave was that developers want to &lt;em>install&lt;/em> the software they have just built (the equivalent of &lt;code>make install&lt;/code>), which is not easy to model in Bazel.&lt;/p>
&lt;p>Well, fear no more. Aspect Build is developing a solution to this problem with Starlark-defined tasks and a custom CLI to run them. I found this to be very exciting, and it was a &amp;ldquo;hot topic&amp;rdquo; at the hackathon that followed the conference.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/j7-IMZ2q5W4?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The premise of the talk was that, even with Bazel, developers still often rely on auxiliary scripts to install tools, Makefiles to drive workflows like setting up test servers or linting code, and YAML files to define complex CI tasks. While all of this should ideally be expressed in Bazel, there is currently no good way to do so.&lt;/p>
&lt;p>In essence, Bazel is missing a &amp;ldquo;task runner&amp;rdquo;, and this is where &lt;a href="https://aspect.build/axl">Aspect&amp;rsquo;s newly-announced Extension Language (AXL)&lt;/a> comes in. It&amp;rsquo;s a Starlark dialect for running tasks, which requires the &lt;a href="https://github.com/aspect-build/aspect-cli">Aspect CLI&lt;/a> to execute. The CLI is a companion tool to Bazel that once &amp;ldquo;replaced&amp;rdquo; Bazel but no longer does.&lt;/p>
&lt;p>With the new AXL language, you can define tasks in a way that is very similar to defining rules: you create a Starlark function, receive a context, and can then perform &amp;ldquo;stuff&amp;rdquo;. The key difference between tasks and rules is that tasks can trivially execute a build with &lt;code>ctx.bazel.build&lt;/code>. Even more exciting is the ability to iterate over the BEP events that the build emits and interact with them!&lt;/p>
&lt;p>The talk also demonstrated the use of WASM binaries for things like buildozer to write platform-agnostic AXL scripts that help with migrations and the like. But the sky is the limit here, and the new &lt;a href="https://github.com/aspect-extensions/">aspect-extensions&lt;/a> GitHub organization is meant to collect all user-contributed tasks.&lt;/p>
&lt;h1 id="build-foundation">BUILD Foundation&lt;/h1>
&lt;p>The desire to create a Bazel foundation to protect the project and ecosystem, should Google ever &amp;ldquo;pull the plug&amp;rdquo;, was announced a year ago, but not much has seemed to happen since. In reality, a lot has been going on behind the scenes, but nothing has yet materialized for the average user.&lt;/p>
&lt;p>As part of the unconference, we voted to have a BoF on the foundation to discuss its future.&lt;/p>
&lt;p>The main question we tried to answer during the session was, &amp;ldquo;What could the foundation &lt;em>do&lt;/em>?&amp;rdquo; Many ideas were brainstormed, including funding a technical writer, improving the quality of pull requests, maintaining important rulesets, and tackling tricky IDE integrations. However, the most popular idea was for the foundation to act as an intermediary between the community and Google, helping to prioritize the projects that the community needs most.&lt;/p>
&lt;p>I think there is an AI transcript of the session somewhere but there is no recording. You&amp;rsquo;ll have to stay tuned for the news, or you can get involved via Slack. Reach out to Alex Eagle or Helen Altshuler.&lt;/p>
&lt;h1 id="flagsets">Flagsets&lt;/h1>
&lt;p>When you have a small repository with a single project, you can easily record project settings (such as compilation targets and debug flags) in the top-level &lt;code>.bazelrc&lt;/code> file. But what do you do when you start combining multiple projects into one repository? The build settings for a backend service might be different from those required for a frontend application.&lt;/p>
&lt;p>&lt;code>PROJECT.scl&lt;/code> files are here to help, and Susan Steinman and Greg Estren from Google were on hand to explain them.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/kqMOwABJguc?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The key problem being addressed is that while everyone intuitively understands what a &amp;ldquo;project&amp;rdquo; is, Bazel lacks a first-class representation of this concept. By introducing such a concept, the goal is to make &lt;code>bazel build //foo&lt;/code> work consistently everywhere, without the need to specify any flags. This is the opposite of the current situation, where it is common for developers to create auxiliary scripts to run Bazel with different flags for different targets.&lt;/p>
&lt;p>As for the format of &lt;code>PROJECT.scl&lt;/code>, the presenters reminded us that &lt;code>.bazelrc&lt;/code> is an ad-hoc language and one of the few places where Bazel does not use Starlark, despite the community&amp;rsquo;s desire for consistency. As a result, these new project files are written in the language we have all come to appreciate.&lt;/p>
&lt;p>More specifically, &lt;code>PROJECT.scl&lt;/code> files can appear multiple times in the directory tree, just like &lt;code>BUILD&lt;/code> files. The first one found when walking up the tree from a given build target is the one that is used. The file contains a project definition, which in turn contains buildable units. These units can enforce different policies for flags, such as setting default flag values for a target or preventing users from modifying certain flags. Finally, it is also possible to define multiple configurations for a unit (e.g., release vs. development) and to switch between them using &lt;code>--scl_config=NAME&lt;/code>.&lt;/p>
&lt;h1 id="target-aware-workflows-with-bazel-diff">Target-aware workflows with bazel-diff&lt;/h1>
&lt;p>One mistake that &lt;em>everyone&lt;/em> makes when moving to a monorepo is retaining operations that scale with the &lt;em>size of the monorepo&lt;/em> instead of the &lt;em>size of the change&lt;/em>. In particular, it is extremely common to see CI workflows that run &lt;code>bazel test //...&lt;/code>, either executing all tests from scratch or hoping that remote caching will prevent the re-running of unmodified tests. This is a bad practice. The overhead is significant, and the end-user experience is often terrible, especially when flaky tests are present.&lt;/p>
&lt;p>&lt;a href="https://github.com/Tinder/bazel-diff/">bazel-diff&lt;/a> is a tool that helps determine the targets affected by a given code change, allowing Bazel to build and test &lt;em>only&lt;/em> those targets. Maxwell Elliott and Connor Wybranowsky were on hand to share the impact that developing this tool at Tinder has had on the company&amp;rsquo;s developer workflows.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/rCFc3tFcVVE?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The initial results of deploying &lt;code>bazel-diff&lt;/code> were a 40% reduction in CI times at the 90th percentile, and up to a 76% reduction in the worst case. These kinds of improvements were transformative for users. In particular, because CI flows became much faster and more accurate, developers began to take ownership of test breakages and flakiness.&lt;/p>
&lt;p>Unfortunately, as is often the case with &amp;ldquo;transformative performance improvements&amp;rdquo; (remember SSDs or the M1 chip?), the codebase continued to grow and eventually consumed all the gains from &lt;code>bazel-diff&lt;/code>.&lt;/p>
&lt;p>To improve on the original deployment, the new approach is to integrate &lt;code>bazel-diff&lt;/code> more deeply with CI. The idea is to dynamically generate pipelines based on the changes in a pull request and select which ones to run at review time. For example, if any of the modified files have automated formatters, only the formatter pipelines will be triggered.&lt;/p>
&lt;p>To recap, the presenters mentioned that the end-to-end adoption of &lt;code>bazel-diff&lt;/code> has helped them save up to 93% of their time in CI. While the extra gains beyond the initial 76% did not lead to the same kinds of cultural changes that were originally observed, developers always appreciate faster workflows.&lt;/p>
&lt;h1 id="supply-chain-security">Supply chain security&lt;/h1>
&lt;p>If you have attended previous BazelCons, you will know that supply chain security is a recurring topic. This year was no different, with Mark Zeren from Broadcom and Tony Aiuto from Datadog presenting the latest news in this area.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/Q4p-I9TsUnA?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>The reason this topic is relevant to the conference is that Bazel is a key tool for producing reliable SBOMs, thanks to its hermeticity, sandboxing features, and fine-grained build graph entries. However, it&amp;rsquo;s not quite there yet.&lt;/p>
&lt;p>From the beginning, Bazel included &lt;code>rules_license&lt;/code> as a way to define per-package licensing details. However, this ruleset was &amp;ldquo;thrown over the wall&amp;rdquo; by Google when Bazel was first open-sourced and has not been fit for purpose.&lt;/p>
&lt;p>Today, there is a new ruleset called &lt;a href="https://github.com/bazel-contrib/supply-chain">&lt;code>supply-chain&lt;/code>&lt;/a>, with only one person from Google on the eight-person team. This new ruleset focuses on two things: metadata rules that code authors can apply to their &lt;code>BUILD&lt;/code> files, and tools to generate provenance information and produce SBOMs. These two components are separate because the metadata rules are designed to be stable over time, while the tools are expected to change frequently.&lt;/p>
&lt;p>What is missing from the new ruleset is licensing: the ability to generate copyright notices, validate linkage, and so on.&lt;/p>
&lt;h1 id="faster-container-builds-with-rules_img">Faster container builds with rules_img&lt;/h1>
&lt;p>As I mentioned earlier, your intuition about what works well for local actions may not apply to remote actions, and container image building is a prime example of this.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/biYXmAv4Ppk?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>In this talk, Malte Poll from Tweag took the stage to introduce &lt;a href="https://github.com/bazel-contrib/rules_img">&lt;code>rules_img&lt;/code>&lt;/a>, a new ruleset that replaces &lt;code>rules_oci&lt;/code> and &lt;code>rules_docker&lt;/code>. It is designed to minimize large blob transfers, resulting in significantly more efficient container builds.&lt;/p>
&lt;p>I do not have written notes on this talk because I was too focused absorbing the many, many details given during the talk, so I strongly encourage you to watch it.&lt;/p>
&lt;h1 id="my-talk-on-java-test-slowness">My talk on Java test slowness&lt;/h1>
&lt;p>To conclude this long recap, I will leave you with my own lightning talk on how our Java integration tests at Snowflake became significantly slower after we migrated from Maven to Bazel.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/-1qrpqFsqQ0?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>It&amp;rsquo;s only eight minutes long, but if you want the summary: Maven and Bazel compile Java code differently. Maven writes class files to a few directories on disk, while Bazel creates intermediate JAR files for every Java library. With Bazel&amp;rsquo;s more-detailed build graph, this causes an explosion in the &lt;code>CLASSPATH&lt;/code> size and means that class files must be read from compressed JAR (ZIP) files instead of from disk.&lt;/p>
&lt;p>I spent some time analyzing the problem and ruled out obvious factors like sandboxing and ZIP compression. I concluded that reading from JAR files is indeed slower than reading individual files from disk. (Why? I&amp;rsquo;m not sure, but I suspect there is an optimization that could be made in the class loader to fix this.)&lt;/p>
&lt;p>To mitigate the problem, I created a new rule that uses the &lt;code>singlejar&lt;/code> tool to merge all intermediate JARs into one. But this was easier said than done. The resulting combined JAR was huge and could not be reused across tests, so I had to develop a complex dependency-pruning rule to generate a combined JAR that could be reused across all tests without introducing class duplicatesall while remaining remote-execution-friendly.&lt;/p>
&lt;p>With this new rule in place, we saw test runtimes drop by about 10 seconds per test, which brought them back to pre-Bazel levels. And with the improvements that Bazel brings to the build, an end-to-end reduction in test times.&lt;/p>
&lt;hr>
&lt;p>And that&amp;rsquo;s a wrap! This has been more of a detailed summary than a brief recap, but my goal was to clean up and share all the notes I took during the conference. Apologies for the many talks I could not cover in this recap. Once again, head to the &lt;a href="https://www.youtube.com/playlist?list=PLak8-7eFSpowmNiR2lhvJEomLA140yban">BazelCon 2025 YouTube playlist&lt;/a> for all recordings.&lt;/p>
&lt;p>If you are involved with Bazel at all or have any interest in build systems, I strongly encourage you to plan to attend next year. You&amp;rsquo;ll learn a lot from the talks of course, but what&amp;rsquo;s more, you&amp;rsquo;ll get to meet key people from tens of companies&amp;mdash;people that hold the keys to how modern build tools and scalable development processes are being developed worldwide.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-11-23-bazelcon.jpg" length="570766" type="image/jpeg"/></item><item><title>You are holding BUILD files wrong</title><link>https://jmmv.dev/2025/09/you-are-holding-build-files-wrong.html</link><pubDate>Fri, 26 Sep 2025 09:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/09/you-are-holding-build-files-wrong.html</guid><description>&lt;p>I&amp;rsquo;ve heard it from people new to Bazel but also from people very familiar with the Bazel ecosystem: BUILD files must go away. And they must go away because they are redundant: they just repeat the dependency information that&amp;rsquo;s already encoded in the in-code import/use statements.&lt;/p>
&lt;p>Hearing this from newcomers to Bazel isn&amp;rsquo;t surprising: after all, most newcomers are used to build tools that provide zero facilities to express dependencies across the sources of your own project. Hearing it from old-timers, however, is disappointing because it misses the point of what BUILD files can truly offer.&lt;/p>
&lt;p>In my opinion: if that&amp;rsquo;s how you are writing BUILD files, you are holding them wrong. There is much more to BUILD files than mindlessly repeating import statement dependencies. Let&amp;rsquo;s see why.&lt;/p>
&lt;h1 id="the-problem">The problem&lt;/h1>
&lt;p>Suppose you are given the following change to review:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-diff" data-lang="diff">&lt;span class="line">&lt;span class="cl">&lt;span class="gd">--- a/src/main/com/example/compiler/parser/Parser.java
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gd">&lt;/span>&lt;span class="gi">+++ b/src/main/com/example/compiler/parser/Parser.java
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gi">&lt;/span>&lt;span class="gu">@@ -1,8 +1,10 @@
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">&lt;/span> package com.example.compiler.parser;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> import com.example.compiler.ast.Ast;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gi">+import com.example.compiler.ast.Statement;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gi">&lt;/span> import com.example.compiler.lexer.Lexer;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> import com.example.compiler.lexer.Token;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gi">+import com.example.compiler.utils.FileReader;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gi">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Parser for a simple language.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> class Parser {
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>By looking at this diff, possibly from a Pull Request (PR) review, you can &lt;em>guess&lt;/em> the following:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The &lt;code>com.example.compiler.parser&lt;/code> Java package already depends on the &lt;code>com.example.compiler.ast&lt;/code> package.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;code>com.example.compiler.parser&lt;/code> Java package already depends on the &lt;code>com.example.compiler.lexer&lt;/code> package.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The addition of the &lt;code>import com.example.compiler.ast.Statement&lt;/code> line does not modify the dependency graph: the edge from the &lt;code>parser&lt;/code> package to the &lt;code>ast&lt;/code> package existed beforehand, and this new import statement is just leveraging it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The addition of the &lt;code>import com.example.compiler.utils.FileReader&lt;/code> line is&amp;hellip; uh, well, given this limited context, you just can&amp;rsquo;t tell! Is it OK or is it not? Did &lt;code>com.example.compiler.parser&lt;/code> &lt;em>already depend on&lt;/em> &lt;code>com.example.compiler.utils&lt;/code> via some other file in the same package&amp;mdash;in which case this new import changes nothing dependency-wise&amp;mdash;or did it not&amp;mdash;in which case this new import deserves questioning from a high-level architecture perspective?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="software-architecture">Software architecture&lt;/h1>
&lt;p>The snippet I presented above is for Java but, in reality, the problem I described applies to every other language: all languages out there have some sort of import/use statements and all languages have some sort of mechanism to group code in module-like entities. By inspecting standalone changes at the file level, we cannot tell whether new cross-module dependencies are being introduced or not.&lt;/p>
&lt;p>And being able to reason about modules is critical: we humans work best when we can reason about higher level relationships than files. We think of software as a collection of modules with layered dependencies and constraints that should not be violated. Enforcing these conceptual models via import/use statements is impossible, but the build graph&amp;mdash;the very thing that BUILD files define&amp;mdash;is the best place to encode them in a programmatic manner.&lt;/p>
&lt;p>So: my point is that BUILD files give you a chance to encode the high-level architecture of your software project as a graph of dependencies that lives outside of the code. If you keep your BUILD files lean and human-managed, you have a good chance of detecting invalid dependencies from a layering perspective as soon as they are introduced.&lt;/p>
&lt;p>The word &amp;ldquo;lean&amp;rdquo; in the previous paragraph is doing a lot of the heavy lifting though because by &amp;ldquo;lean&amp;rdquo; I mean simple BUILD files that define targets that map to concepts. This bypasses &amp;ldquo;best practices&amp;rdquo; that dictate one BUILD file per directory because you may need to use recursive globs to group sources into larger conceptual units, and this can also result in reduced build performance because you end up with fewer, larger targets. And that&amp;rsquo;s fine.&lt;/p>
&lt;p>For one, if recursive globs are a problem because they end up bundling too many related concepts in one target, you have got a problem with your directory structure and you should fix that. And for another, if larger targets end up hurting build performance, you have got a problem with your modularity and you should work towards breaking those big targets apart. At the end of the day, these two issues are symptoms of having too many unrelated concepts in one module. Simplifying the build structure may result in a transient performance regression, but working towards breaking those apart will help everyone in your organization.&lt;/p>
&lt;p>None of this is novel though, as these ideas can be found outside of Bazel. Think about shared libraries in large C or C++ projects, multiple Maven modules in a large Java code base, or multiple crates in a large Rust project. If you have ever done any of these, you &lt;em>know&lt;/em> that manually defining modules is useful because it forces you and your fellow developers to think in terms of APIs at the module boundaries.&lt;/p>
&lt;p>Changing the module-level architecture of a project is something that happens infrequently and, when it does, you want the more senior people in the team to question and review such changes. And, for that, you must make these changes visible as soon as they happen.&lt;/p>
&lt;h1 id="reverse-dependencies">Reverse dependencies&lt;/h1>
&lt;p>Expressing modules in your build graph is great, but people seem to like having tools to automatically update dependencies based on code changes. This is not incompatible with what I have said so far, but in order to keep a clean software architecture, you will need to have a strong code review culture because any undesirable new edges introduced in a change will have to be vetted up at code review. But&amp;hellip; what if they aren&amp;rsquo;t? Can we do better?&lt;/p>
&lt;p>Of course we can! Bazel gives us a way to express restrictions via reverse dependencies: aka &lt;em>visibility rules&lt;/em>. When you maintain a conceptual dependency graph by hand, you will find cases where you want to express things like:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>com.example.compiler.utils&lt;/code> can be consumed from &lt;code>com.example.compiler.lexer&lt;/code>, which is the lowest level layer of the compiler.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>com.example.compiler.utils&lt;/code> cannot be consumed from any other layer unless we discuss the implications.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Visibility rules allow you to express these restrictions programmatically. The difference with forward dependencies is that, if you ever wanted to use &lt;code>com.example.compiler.utils&lt;/code> from a module that has not been pre-declared as an allowed consumer, you would need to modify the BUILD file definitions in &lt;code>com.example.compiler.utils&lt;/code> to widen the visibility rules. This would require &lt;em>talking&lt;/em> to the owners of such module, either in person or via the code review, to be allowed as a consumer of those APIs.&lt;/p>
&lt;h1 id="putting-it-all-together">Putting it all together&lt;/h1>
&lt;p>Now that we know the theory behind my proposal, let&amp;rsquo;s revisit the &lt;code>utils&lt;/code> package from the earlier example. To enforce our desired architecture, the &lt;code>BUILD&lt;/code> file in &lt;code>src/main/com/example/compiler/utils/BUILD&lt;/code> might look like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">java_library&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;utils&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">glob&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="s2">&amp;#34;*.java&amp;#34;&lt;/span>&lt;span class="p">]),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">visibility&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;//src/main/com/example/compiler/lexer:__pkg__&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is a &amp;ldquo;lean&amp;rdquo; &lt;code>BUILD&lt;/code> file. It defines a single, conceptual &lt;code>utils&lt;/code> library, and doesn&amp;rsquo;t bother about specifying source files: it trusts that whatever you throw into the &lt;code>com/example/compiler/utils/&lt;/code> directory truly belongs to that module. Most importantly, the &lt;code>visibility&lt;/code> attribute declares that &lt;em>only&lt;/em> code within the &lt;code>lexer&lt;/code> package is allowed to depend on this &lt;code>utils&lt;/code> library.&lt;/p>
&lt;p>With this rule in place, the problematic code change we saw earlier (adding an &lt;code>import&lt;/code> of &lt;code>FileReader&lt;/code> to the &lt;code>parser&lt;/code>) would no longer be a silent, ambiguous change. The moment the developer (or the CI system) tries to build the code, they would get an immediate, explicit error from Bazel stating that the &lt;code>parser&lt;/code> target is not allowed to see the &lt;code>utils&lt;/code> target.&lt;/p>
&lt;p>The architectural violation is caught automatically. The desired conversation with the module owners is now forced to happen, exactly as intended.&lt;/p>
&lt;h1 id="helping-ai-models">Helping AI models&lt;/h1>
&lt;p>Finally, we get to the most hyped topic of all times: AI agents. Remember when I said above that a clean conceptual module-based architecture is critical for humans to understand how a project works? Well, guess what, the same applies to AI models.&lt;/p>
&lt;p>If you try to use AI agents on an existing codebase, you will notice that they try to reason about the current architecture by reading individual file names and their contents, and then chasing through their file-level dependencies.&lt;/p>
&lt;p>But what if you could make these AI agents to follow your conceptual dependency chain by teaching them, via an &lt;a href="https://modelcontextprotocol.io/">MCP server&lt;/a>, to follow your build graph? Presumably, their ability to reason would increase because they&amp;rsquo;d be faced with cleaner concepts that explain the story behind your codebase in big blocks.&lt;/p>
&lt;h1 id="your-turn">Your turn&lt;/h1>
&lt;p>I hope to have convinced you that manually managing your BUILD files in a Bazel project is &lt;em>a good idea&lt;/em> for long-term maintainability and for the successful use of AI tools. For this to be possible, you have to forego the &amp;ldquo;standard practice&amp;rdquo; of having very small BUILD targets and instead capture your conceptual modular architecture in the build graph. And once you do that, BUILD files magically become manageable by humans, without the need for fancy automation that pushes complexity under the rug.&lt;/p>
&lt;p>But that&amp;rsquo;s just my opinion.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-09-26-you-are-holding-build-files-wrong.jpg" length="87330" type="image/jpeg"/></item><item><title>Bazel and glibc versions</title><link>https://jmmv.dev/2025/09/glibc-versions-bazel.html</link><pubDate>Fri, 19 Sep 2025 00:08:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/09/glibc-versions-bazel.html</guid><description>&lt;p>Imagine this scenario: your team uses Bazel for fast, distributed C++ builds. A developer builds a change on their workstation, all tests pass, and the change is merged. The CI system picks it up, gets a cache hit from the developer&amp;rsquo;s build, and produces a release artifact. Everything looks green. But when you deploy to production, the service crashes with a mysterious error: &lt;code>version 'GLIBC_2.28' not found&lt;/code>. What went wrong?&lt;/p>
&lt;p>The answer lies in the subtle but dangerous interaction between Bazel&amp;rsquo;s caching, remote execution, and differing glibc versions across your fleet. In previous posts in this series, I&amp;rsquo;ve covered the fundamentals of &lt;a href="/2025/07/bazel-action-determinism.html">action non-determinism&lt;/a>, &lt;a href="/2025/09/bazel-remote-caching.html">remote caching&lt;/a>, and &lt;a href="/2025/09/bazel-remote-execution.html">execution execution&lt;/a>. Now, finally, we&amp;rsquo;ll build on those to tackle this specific problem.&lt;/p>
&lt;p>This article dives deep into how glibc versions can break build reproducibility and presents several ways to fix it&amp;mdash;from an interesting hack (which spawned this whole series) to the ultimate, most robust solution.&lt;/p>
&lt;h1 id="the-scenario">The scenario&lt;/h1>
&lt;p>Suppose you have a pretty standard (corporate?) development environment like the following:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Developer workstations (WS).&lt;/strong> This is where Bazel runs during daily development, and Bazel can execute build actions both locally and remotely.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>A CI system.&lt;/strong> This is a distributed cluster of machines that run jobs, including PR merge validation and production release builds. These jobs execute Bazel too, who in turn executes build actions both locally and remotely.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>The remote execution (RE) system.&lt;/strong> This is a distributed cluster of worker machines that execute individual Bazel build actions remotely. The key components we want to focus on today are the AC, the CAS, and the workers&amp;mdash;all of which I covered in detail in the previous two articles.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>The production environment (PROD).&lt;/strong> This is where you deploy binary artifacts to serve your users. No build actions run here.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;figure>
&lt;img src="/images/2025-09-19-glibc-versions-bazel-environment.png" width="100%" />
&lt;/figure>
&lt;p>All of the systems above run some version of Linux, and it is tempting to wish to keep such version in sync across them all. The reasons would include keeping operations simpler and ensuring that build actions can run consistently no matter where they are executed.&lt;/p>
&lt;p>However, this wish is misguided and plain impossible. It is misguided because you may not want to run the same Linux distribution on all three environments: after all, the desktop distribution you run on WS may not be the best choice for RE workers, CI nodes, nor production. And it is plain impossible because, even if you aligned versions to the dot, you would need to take upgrades at some point: distributed upgrades must be rolled out over a period of time (weeks or even months) for reliability, so you&amp;rsquo;d have to deal with version skew anyway.&lt;/p>
&lt;p>To make matters more complicated, the remote AC is writable from all of WS, CI, and RE to maximize Bazel cache hits and optimize build times. This goes against best security practices (so there are mitigations in place to protect PROD), but it&amp;rsquo;s a necessity to support an ongoing onboarding into Bazel and RE.&lt;/p>
&lt;h1 id="the-problem">The problem&lt;/h1>
&lt;p>The question becomes: can the Linux version skew among all machines involved cause problems with remote caching?&lt;/p>
&lt;p>It sure can because C and C++ build actions tend to pick up system-level dependencies in a way that Bazel is unaware of (by default), and those influence the output the actions produce. Here, look at this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">$ nm prod-binary | grep GLIBC_2.28
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> U mtx_init@@GLIBC_2.28
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>The version of glibc leaks into binaries&lt;/strong> and &lt;strong>this is invisible to Bazel&amp;rsquo;s C/C++ action keys&lt;/strong>. glibc versions its symbols to provide runtime backwards compatibility when their internal details change, and this means that binaries built against newer glibc versions may not run on systems with older glibc versions.&lt;/p>
&lt;p>How is this a problem though? Let&amp;rsquo;s take a look by making the problem specific. Consider the following environment:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Environment&lt;/th>
&lt;th>Purpose&lt;/th>
&lt;th>glibc version&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>WS&lt;/td>
&lt;td>Developer workstations&lt;/td>
&lt;td>2.28&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>CI-1&lt;/td>
&lt;td>CI production environment&lt;/td>
&lt;td>2.17&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>CI-2&lt;/td>
&lt;td>CI staging environment&lt;/td>
&lt;td>2.28&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>RE&lt;/td>
&lt;td>Shared RE cluster&lt;/td>
&lt;td>2.17&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>PROD&lt;/td>
&lt;td>Production deployments&lt;/td>
&lt;td>2.17&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>In this environment, developers run Bazel in WS for their day-to-day work, and CI-1 runs Bazel to support development flows (PR merge-time checks) and to produce binaries for PROD. CI-2 sometimes runs builds too. All of these systems can write to the AC that lives in RE.&lt;/p>
&lt;p>As it so happens, one of the C++ actions involved in the build of &lt;code>prod-binary&lt;/code>, say &lt;code>//base:my_lib&lt;/code>, has a &lt;code>local&lt;/code> tag which forces the action to bypass remote execution. This can lead to the following sequence of events:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>A developer runs a build on a WS. &lt;code>//base:my_lib&lt;/code> has changed so it is rebuilt on the WS. The action uses the C++ compiler, so the object files it produces pick up the dependency on glibc 2.28. The result of the action is injected into the remote cache.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>CI-1 schedules a job to build &lt;code>prod-binary&lt;/code> for release. This job runs Bazel on a machine with glibc 2.17 and leverages the RE cluster which also contain glibc 2.17. Many C++ actions get rebuilt &lt;em>but&lt;/em> &lt;code>//base:my_lib&lt;/code> is reused from the cache. The production artifact now has a dependency on symbols from glibc 2.28.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Release engineering picks the output of CI-1, deploys the production binary to PROD, and&amp;hellip; boom, PROD explodes:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">./prod-binary: /lib64/libc.so.6: version `GLIBC_2.28&amp;#39; not found (required by ./prod-binary)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;p>The fact that the developer WS could write to the AC is very problematic on its own, but we could encounter this same scenario if we first ran the production build on CI-2 for testing purposes and then reran it on CI-1 to generate the final artifact.&lt;/p>
&lt;p>So, what do we do now? In a default Bazel configuration, C and C++ action keys are underspecified and can lead us to non-deterministic behavior when we have a mixture of host systems compiling them.&lt;/p>
&lt;h1 id="solution-a-manually-partition-the-ac">Solution A: manually partition the AC&lt;/h1>
&lt;p>Let&amp;rsquo;s start with the case where you aren&amp;rsquo;t yet ready to strictly restrict writes to the AC from RE workers, yet you want to prevent obvious mistakes that lead to production breaks.&lt;/p>
&lt;p>The idea here is to capture the glibc version that is used in the local and remote environments, pick the higher of the two, and make that version number an input to the C/C++ toolchain. This causes the version to become part of the cache keys and should prevent the majority of the mistakes we may see.&lt;/p>
&lt;p>WARNING: This is The Hack I recently implemented and that drove me to writing this article series! Prefer the options presented later, but know that you have this one up your sleeve if you must mitigate problems quickly.&lt;/p>
&lt;p>To implement this hack, the first thing we have to do is capture the local glibc version. We can do this with:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;glibc-local-version&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;glibc-local-version.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;grep GNU_LIBC_VERSION bazel-out/stable-status.txt &lt;/span>&lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>&lt;span class="s2"> | cut -d &amp;#39; &amp;#39; -f 2- &amp;gt;$@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">stamp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">tags&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;sandboxed&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>One important tidbit here is the use of the &lt;code>stable-status.txt&lt;/code> file, indirectly via the requirement of stamping. This is necessary to force this action to rerun on every build because we don&amp;rsquo;t want to hit the case of using an old &lt;code>bazel-out&lt;/code> tree against an upgraded system. As a consequence, we need to modify the script pointed at by &lt;code>--workspace_status_command&lt;/code> script (you have one, right?) to emit the glibc version:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;STABLE_GNU_LIBC_VERSION &lt;/span>&lt;span class="k">$(&lt;/span>getconf GNU_LIBC_VERSION&lt;span class="k">)&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The second thing we have to do is capture the remote glibc version. This is&amp;hellip; trickier because there is no tag to force Bazel to run an action remotely. Even if we assume remote execution, features like the dynamic spawn strategy or the remote local fallback could cause the action to run locally at random. To prevent problems, we have to detect whether the action is running within RE workers or not, and the way to do that will depend on your environment:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;glibc-remote-version&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;glibc-remote-version.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> if [ ! -e /etc/remote-worker.cookie ]; then
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> # Trick dynamic scheduling (when it is enabled) into
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> # preferring to run the action remotely.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> #
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> # You have two choices here: fail hard, which makes
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> # this correct, or accept that this is a heuristic by
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> # making the failure unlikely with a sleep. You might
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> # want the sleep if you don&amp;#39;t want build breakages
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> # when there is significant action queuing, for
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> # example.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> exit 1
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> #sleep 60
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> fi
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> getconf GNU_LIBC_VERSION &amp;gt;$@
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The third part of the puzzle is to select the highest glibc version between the two that we collected. We can do this with the following &lt;code>genrule&lt;/code>, leveraging &lt;code>sort&lt;/code>&amp;rsquo;s &lt;code>-V&lt;/code> flag to compare versions. This flag is a GNU extension&amp;hellip; but we are talking about glibc anyway here so I&amp;rsquo;m not going to be &lt;a href="/2021/08/useless-use-of-gnu.html">bothered by it&lt;/a>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;glibc-max-version&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;:glibc-local-version&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;:glibc-remote-version&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;glibc-max-version.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> local=&amp;#34;$$(cat $(location :glibc-local-version)
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> | cut -d &amp;#39; &amp;#39; -f 2)&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> remote=&amp;#34;$$(cat $(location :glibc-remote-version)
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> | cut -d &amp;#39; &amp;#39; -f 2)&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> echo &amp;#34;Local glibc version: $$&lt;/span>&lt;span class="si">{local}&lt;/span>&lt;span class="s2">&amp;#34; 1&amp;gt;&amp;amp;2
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> echo &amp;#34;Remote glibc version: $$&lt;/span>&lt;span class="si">{remote}&lt;/span>&lt;span class="s2">&amp;#34; 1&amp;gt;&amp;amp;2
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> chosen=&amp;#34;$$(printf &amp;#34;$$local&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">$$remote&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s2">&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> | sort -rV | head -1)&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> echo &amp;#34;$$&lt;/span>&lt;span class="si">{chosen}&lt;/span>&lt;span class="s2">&amp;#34; &amp;gt;$@
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And, finally, we can go to our C++ toolchain definition and modify it to depend on the &lt;code>glibc-max-version&lt;/code> produced by the previous action:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">filegroup&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;toolchain_files&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;:glibc-max-version&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cc_toolchain&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;glibc_safe_toolchain&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">all_files&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">toolchain_files&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Ta-da! All of our C/C++ actions now encode the highest possible glibc version that the outputs they produce may depend on. And, while not perfect, this is an easy workaround to guard against most mistakes.&lt;/p>
&lt;p>But can we do better? Of course.&lt;/p>
&lt;h1 id="solution-b-restrict-ac-writes-to-re-only">Solution B: restrict AC writes to RE only&lt;/h1>
&lt;p>Based on the previous articles, what we should think about is plugging the AC hole and forcing build actions to &lt;em>always&lt;/em> run on the RE workers. In this way, we would precisely control the environment that generates action outputs and we should be good to go.&lt;/p>
&lt;p>Unfortunately, we can still encounter problems! Remember how I said that, at some point, you will have to upgrade glibc versions? What happens when you are in the middle of a rolling upgrade to your RE workers? The worker pool will end up with different &amp;ldquo;partitions&amp;rdquo;, each with a different glibc version, and you will still run into this issue.&lt;/p>
&lt;p>To handle this case, you would need to have &lt;em>different&lt;/em> worker pools, one with the old glibc version and one with the new version, and then make the worker pool name be part of the action keys. You would then have to migrate from one pool to the other in a controlled manner. This would work well at the expense of reducing cache effectiveness, causing a a big toll on operations, and making the rollout risky because the switch from one pool to another is a all-or-nothing proposition.&lt;/p>
&lt;h1 id="solution-c-sysroots">Solution C: sysroots&lt;/h1>
&lt;p>The real solution comes in the form of sysroots. The idea is to install multiple parallel versions of glibc in &lt;em>all&lt;/em> environments and then modify the Bazel C/C++ toolchain to explicitly use a specific one. In this way, the glibc version becomes part of the cache key and all build outputs are pinned to a deterministic glibc version. This allows us to roll out a new version slowly with a code change, pinning the version switch to a specific code commit that can be rolled back if necessary, and keeping the property of &lt;a href="https://reproducible-builds.org/">reproducible builds&lt;/a> for older commits.&lt;/p>
&lt;p>This is the solution outlined at the end of &lt;a href="/2024/08/glibc-versions-runtime.html">Picking glibc versions at runtime&lt;/a> and is the only solution that can provide you 100% safety against the problem presented in this article. It is difficult to implement, though, because convincing GCC and clang to not use system-provided libraries is tricky and because this solution will sound alien to most of your peers.&lt;/p>
&lt;h1 id="what-will-you-do">What will you do?&lt;/h1>
&lt;p>The problem presented in this article is far from theoretical, but it&amp;rsquo;s often forgotten about because typical build environments don&amp;rsquo;t present significant skew across Linux versions. This means that facing new glibc symbols is unlikely, so the chances of ending up with binary-incompatible artifacts are low. But they can still happen, and they can happen at the worst possible moment.&lt;/p>
&lt;p>Therefore, you need to take action. I&amp;rsquo;d strongly recommend that you go towards the sysroot solution because it&amp;rsquo;s the only one that&amp;rsquo;ll give you a stable path for years to come, but I also understand that it&amp;rsquo;s hard to implement. Therefore, take the solutions in the order I gave them to you: start with the hack to mitigate obvious problems, follow that up with securing the AC, and finally go down the sysroot rabbit hole.&lt;/p>
&lt;p>As for the glibc 2.17 mentioned en-passing above, well, it is ancient by today standards at 13 years of age, but it is what triggered this article in the first place. glibc 2.17 was kept alive for many years by the CentOS 7 distribution&amp;mdash;an LTS system used as a core building block by companies and that reached EOL a year ago, causing headaches throughout the industry. Personally, I believe that relying on LTS distributions is a mistake that ends up costing more money/time than tracking a rolling release, but I&amp;rsquo;ll leave that controversial topic for a future opinion post.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-09-19-glibc-versions-bazel-cover-image.jpg" length="182393" type="image/jpeg"/></item><item><title>Trusting builds with Bazel remote execution</title><link>https://jmmv.dev/2025/09/bazel-remote-execution.html</link><pubDate>Fri, 12 Sep 2025 08:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/09/bazel-remote-execution.html</guid><description>&lt;p>The previous article on &lt;a href="/2025/09/bazel-remote-caching.html">Bazel remote caching&lt;/a> concluded that using &lt;em>just&lt;/em> a remote cache for Bazel builds was suboptimal due to limitations in what can and cannot be cached for security reasons. The reason behind the restrictions was that it is impossible to safely reuse a cache across users. Or is it?&lt;/p>
&lt;p>In this article, we&amp;rsquo;ll see how leveraging remote execution in conjunction with a remote cache opens the door to safely sharing the cache across users. The reason is that remote execution provides a trusted execution environment for actions, and this opens the door to cross-user result sharing. Let&amp;rsquo;s see why and how.&lt;/p>
&lt;h1 id="remote-execution-basics">Remote execution basics&lt;/h1>
&lt;p>As we saw in &lt;a href="/2025/07/bazel-action-determinism.html">the article about action determinism&lt;/a>, Bazel&amp;rsquo;s fundamental unit of execution is &lt;em>the action&lt;/em>. Consequently, a remote execution system is going to concern itself with efficiently running individual actions, not builds, and caching the results of those. This distinction is critical because there are systems out there that work differently, such as &lt;a href="https://www.microsoft.com/en-us/research/publication/cloudbuild-microsofts-distributed-and-caching-build-service/">Microsoft&amp;rsquo;s CloudBuild&lt;/a>, &lt;a href="https://www.buildbuddy.io/docs/remote-bazel/">Buildbuddy&amp;rsquo;s Remote Bazel&lt;/a>, or even &lt;a href="/2025/03/bazel-next-generation.html">the shiny and new Bonanza&lt;/a>.&lt;/p>
&lt;p>When we configure remote execution via the &lt;code>--remote_executor&lt;/code> flag, Bazel enables the &lt;code>remote&lt;/code> action &lt;a href="/2019/12/bazel-strategies.html">execution strategy&lt;/a> by default for all actions, just as if we had done &lt;code>--strategy=remote&lt;/code>. But this is only a default and users can mix-and-match remote and local strategies by leveraging the various &lt;code>--strategy*&lt;/code> selection flags or by specifying execution requirements in individual actions.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-09-12-bazel-remote-execution-strategies.png" width="100%" />
&lt;/figure>
&lt;p>A remote execution system is complicated as it is typically implemented by many services:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Multiple frontends.&lt;/strong> These are responsible for accepting user requests and tracking results. These might include implement a second-level CAS to fan out traffic to clients.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>A scheduler.&lt;/strong> This is responsible for enqueuing action requests and distributing them to workers. Whether the scheduler uses a pull or push model to distribute work is implementation dependent.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Multiple workers.&lt;/strong> These are responsible for action execution and are organized in pools of distinct types (workers for x86, workers for arm64, etc.) Internally, a worker is divided into two conceptual parts: the &lt;strong>worker&lt;/strong> itself, which is the privileged service that monitors action execution, and the &lt;strong>runner&lt;/strong>, which is a containerized process that actually runs the untrusted action code.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>The components of a remote cache (a CAS and an AC).&lt;/strong> The CAS is essential for communication between Bazel and the workers. The AC, which is optional, is necessary for action caching. The architecture of the cache varies from service to service.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>For the purposes of this article, I want to focus primarily on the workers and their interactions with the AC and the CAS. I&amp;rsquo;m not going to talk about frontends nor schedulers except for showing how they help isolate remote action execution from the Bazel process.&lt;/p>
&lt;h1 id="worker-and-accas-interactions">Worker and AC/CAS interactions&lt;/h1>
&lt;p>Let&amp;rsquo;s look at the interaction between these components in more detail. To set the stage, take a look at the &lt;code>combine&lt;/code> action from this sample build file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;generate&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;gen.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;echo generated &amp;gt;$@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;combine&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;combined.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;:src.txt&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;:gen.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;cat $(location :src.txt) $(location :gen.txt) &amp;gt;$@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>combine&lt;/code> action has two types of inputs: a checked-in source file, &lt;code>src.txt&lt;/code>, and a file generated during the build, &lt;code>gen.txt&lt;/code>. This distinction is interesting because the way these files end up in the CAS is different: Bazel is the one responsible for uploading &lt;code>src.txt&lt;/code> into the CAS, but &lt;code>gen.txt&lt;/code> is uploaded by the worker upon action completion.&lt;/p>
&lt;p>When we ask Bazel to build &lt;code>//:combine&lt;/code> remotely, and assuming &lt;code>//:generate&lt;/code> has already been built and cached at some point in the past, we&amp;rsquo;ll experience something like this:&lt;/p>
&lt;figure>
&lt;img src="/images/2025-09-12-bazel-remote-execution-execution.png" width="100%" />
&lt;/figure>
&lt;p>That&amp;rsquo;s a lot of interactions, right?! Yes; yes they are. A remote execution system is not simple and it&amp;rsquo;s not always an obvious win: coordinating all of these networked components is costly. The overheads become tangible when dealing with short-lived actions&amp;mdash;a better fit for persistent workers&amp;mdash;or when you have a sequential chain of actions&amp;mdash;a good fit for &lt;a href="/2019/12/bazel-dynamic-execution-strategy.html">the dynamic execution strategy&lt;/a>.&lt;/p>
&lt;p>What I want you to notice here, because it&amp;rsquo;s critical for our analysis, is the shaded area. Note how all interactions within this area are driven by the remote execution service, &lt;em>not&lt;/em> Bazel. Once an action enters the remote execution system, neither Bazel &lt;em>nor the machine running Bazel&lt;/em> have any way of tampering with the execution of the remote action. They cannot influence the action&amp;rsquo;s behavior, and they cannot interfere with the way it saves its outputs into the AC and the CAS.&lt;/p>
&lt;p>And this decoupling, my friend, is the key insight that allows Bazel to safely share the results of actions across users no matter who initiated them. However, the devil lies in the implementation details.&lt;/p>
&lt;h1 id="securing-the-worker">Securing the worker&lt;/h1>
&lt;p>Given the above, we now know that remote workers are a trusted environment: the actions that go into a worker are fully specified by their action key and, therefore, whatever they produce and is stored into the AC and the CAS will match that action key. So if we trust the inputs to the action, we can trust its outputs, and we can do this retroactively&amp;hellip; right?&lt;/p>
&lt;p>Well, not so fast. For this to be true, actions must be deterministic, and they aren&amp;rsquo;t always &lt;a href="/2025/07/bazel-action-determinism.html">as we already saw&lt;/a>. Some sources of non-determinism are &amp;ldquo;OK&amp;rdquo; in this context though, like timestamps, because these come from within the worker and cannot be tampered with. Other sources of non-determinism are problematic though, like this one:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;generate&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;gen.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;curl -L https://secure.example.com/payload.txt &amp;gt;$@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>An attacker could compromise the network request to modify the content of the downloaded file, but only for long enough to poison the remote cache with a malicious artifact. Once poisoned, they could restore the remote file to its original content and it would be very difficult to notice that the entry in the remote cache did not match the intent of this rule.&lt;/p>
&lt;p>It is tempting to say: &amp;ldquo;ah, the above should be fixed by ensuring the checksum of the download is valid&amp;rdquo;, like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;generate&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;gen.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> curl -L https://secure.example.com/payload.txt &amp;gt;$@
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> [ &amp;#34;$$(sha256sum $@ | awk &amp;#39;{print $1}&amp;#39;)&amp;#34; = &amp;#34;known checksum&amp;#34; ]
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And I&amp;rsquo;d say, yes, you absolutely need to do checksum validation because there are legitimate cases where you&amp;rsquo;ll find yourself writing code like this&amp;hellip; in repo rules. Unfortunately, such checks are still insufficient for safe remote execution because, remember: actions can run from unreviewed code, or the code that runs them can be merged into the tree after a careless review (which is more common than you think). Consequently, the only thing you can and must do here is to &lt;strong>disable network access&lt;/strong> in the remote worker.&lt;/p>
&lt;p>That said, &lt;em>just&lt;/em> disabling network access may still be &amp;ldquo;not good enough&amp;rdquo; to have confidence in the safety of remote execution. A remote execution system is trying to run untrusted code within a safe production environment: code that could try to attack the worker to escape whatever sandbox/container you have deployed, code that could try to influence other actions running on the same machine, or code that could exfiltrate secrets present in the environment. Securing these is going to come down to standard practices for untrusted code execution, none of which are specific to Bazel, so I&amp;rsquo;m not going to cover them. Needless to say, it&amp;rsquo;s a difficult problem.&lt;/p>
&lt;h1 id="securing-the-build">Securing the build&lt;/h1>
&lt;p>If we have done all of the above, we now have a remote execution system that we can trust to run actions in a secure manner and to store their results in &lt;em>both&lt;/em> the AC and the CAS. But&amp;hellip; this, on its own, is still insufficient to secure builds end-to-end, and we would like to have trusted end-to-end builds to establish a chain of trust between sources and production artifacts, right?&lt;/p>
&lt;p>To secure a build, we must protect the AC and restrict writes to it to happen exclusively from the remote workers. Only them, who we have determined cannot be interfered with, know that the results of an action correspond to its declared inputs&amp;mdash;and therefore, only them can establish the critical links between an AC entry and one or more files in the CAS. You&amp;rsquo;d imagine that simply setting &lt;code>--noremote_upload_local_results&lt;/code> would be enough, but it isn&amp;rsquo;t. A malicious user could still tamper with this flag in transient CI runs or&amp;hellip; well, in their local workstation. And it&amp;rsquo;s because of this latter scenario that the only possible way to close this gap is via network level ACLs: the AC should only be writable from within the remote execution cluster.&lt;/p>
&lt;p>But&amp;hellip; you guessed it: that&amp;rsquo;s &lt;em>still&lt;/em> insufficient. Even if we disallow Bazel clients from writing to the AC, an attacker can still make Bazel run malicious actions &lt;em>outside&lt;/em> of the remote execution cluster&amp;mdash;that is, on the CI machine locally, which does have network access. Such action wouldn&amp;rsquo;t record its result in the AC, but the &lt;em>output&lt;/em> of the action would go into the CAS, and this problematic action could then be consumed by a subsequent action as an input.&lt;/p>
&lt;p>The problem here stems from users being able to bypass remote execution by tweaking &lt;code>--strategy*&lt;/code> flags. One option to protect against this situation is the same as we saw before: disallow CI runs of PRs that modify Bazel flags so that users cannot &amp;ldquo;escape&amp;rdquo; remote execution. Unfortunately, this doesn&amp;rsquo;t have great ergonomics because users often need to change the &lt;code>.bazelrc&lt;/code> file as part of routine operation.&lt;/p>
&lt;p>Bazel&amp;rsquo;s answer to this problem is the widely-unknown &lt;strong>invocation policy&lt;/strong> feature. I say unknown because I do not see it documented in the output of &lt;code>bazel help&lt;/code> and I cannot find any details about it whatsoever online&amp;mdash;yet I know of its existence from my time at Google and I see its implementation in the Bazel code base, so we can reverse-engineer how it works.&lt;/p>
&lt;h1 id="invocation-policies">Invocation policies&lt;/h1>
&lt;p>As the name implies, an &lt;strong>invocation policy&lt;/strong> is a mechanism to enforce specific command-line flag settings during a build or test with the goal of ensuring that conventions and security policies are consistently applied. The policy does so by defining rules to set, override, or restrict the values of flags, such as &lt;code>--strategy&lt;/code>.&lt;/p>
&lt;p>The policy is defined using the &lt;code>InvocationPolicy&lt;/code> protobuf message defined in &lt;a href="https://cs.opensource.google/bazel/bazel/+/master:src/main/protobuf/invocation_policy.proto;drc=04aec051070d5bb0455b8ed0aea9a869b4078af4">&lt;code>src/main/protobuf/invocation_policy.proto&lt;/code>&lt;/a>. This message contains a list of &lt;code>FlagPolicy&lt;/code> messages, each of which defines a rule for a specific flag. The possible rules, which can be applied conditionally on the Bazel command being executed, are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>SetValue&lt;/code>: Sets a flag to a specific value. You can control whether the user can override this value. This is useful for enforcing best practices or build-time configurations.&lt;/li>
&lt;li>&lt;code>UseDefault&lt;/code>: Forces a flag to its default value, effectively preventing the user from setting it.&lt;/li>
&lt;li>&lt;code>DisallowValues&lt;/code>: Prohibits the use of certain values for a flag. If a user attempts to use a disallowed value, Bazel will produce an error. You can also specify a replacement value to be used instead of the disallowed one.&lt;/li>
&lt;li>&lt;code>AllowValues&lt;/code>: Restricts a flag to a specific set of allowed values. Any other value will be rejected.&lt;/li>
&lt;/ul>
&lt;p>To use an invocation policy, you have to define the policy as an instance of the &lt;code>InvocationPolicy&lt;/code> message in text or base64-encoded binary protobuf format and pass the payload to Bazel using the &lt;code>--invocation_policy&lt;/code> flag in a way that users cannot influence (e.g. directly from your CI infrastructure, not from workflow scripts checked into the repo).&lt;/p>
&lt;p>Let&amp;rsquo;s say you want to enforce a policy where the &lt;code>--genrule_strategy&lt;/code> flag is always set to &lt;code>remote&lt;/code> when running the &lt;code>bazel test&lt;/code> command, and you want to prevent users from overriding this setting. We define the following policy in a &lt;code>policy.txt&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-proto" data-lang="proto">&lt;span class="line">&lt;span class="cl">&lt;span class="n">flag_policies&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span> &lt;span class="n">flag_name&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s">&amp;#34;genrule_strategy&amp;#34;&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span> &lt;span class="n">commands&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s">&amp;#34;build&amp;#34;&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span> &lt;span class="n">set_value&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span> &lt;span class="n">flag_value&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s">&amp;#34;remote&amp;#34;&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span> &lt;span class="n">behavior&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">FINAL_VALUE_THROW_ON_OVERRIDE&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span> &lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And then we invoke Bazel like this (again, remember: this flag should be passed by CI in a way that users cannot influence):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">bazel --invocation_policy&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="k">$(&lt;/span>cat policy.txt&lt;span class="k">)&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> build ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you now try to play with the &lt;code>--genrule_strategy&lt;/code> flag, you&amp;rsquo;ll notice that any overrides you provide don&amp;rsquo;t work. (Bazel 9 will offer a new &lt;code>FINAL_VALUE_THROW_ON_OVERRIDE&lt;/code> flag behavior to error out instead of silently ignoring overrides which will make the experience nicer in this case.)&lt;/p>
&lt;h1 id="case-study-remote-local-fallback-poisoning">Case study: remote local fallback poisoning&lt;/h1>
&lt;p>Before concluding, I&amp;rsquo;d like to show you an interesting outage we faced due to Bazel being allowed to write AC entries from a trusted CI environment. The problem we saw was that, at some point, users started reporting that their builds were completely broken: somehow, the build of our custom singlejar helper tool, a C++ binary that&amp;rsquo;s commonly used in Java builds, started failing due to the inability of the C++ compiler to find some header files.&lt;/p>
&lt;p>This didn&amp;rsquo;t make any sense. If we built the tree at a previous point in time, the problem didn&amp;rsquo;t surface. And as we discovered later, if we disabled remote caching on a current commit the problem didn&amp;rsquo;t appear either. Through a series of steps, we found that singlejar&amp;rsquo;s build from scratch would fail if we tried to build it locally &lt;em>without&lt;/em> the sandbox. But&amp;hellip; that&amp;rsquo;s not something we do routinely, so how did this kind of breakage leak into the AC?&lt;/p>
&lt;p>The problem stemmed from our use of &lt;code>--remote_local_fallback&lt;/code>, a flag we had enabled long ago to mitigate flakiness when leveraging remote execution. Because of this flag, we had hit this problematic path:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>An build started on CI. This build used a remote-only configuration, forcing all actions to run on the remote cluster.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Bazel ran actions remotely for a while, but at some point, encountered problems while building singlejar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Because of &lt;code>--remote_local_fallback&lt;/code>, Bazel decided to build singlejar on the CI machine, not on the remote worker, and it used the &lt;code>standalone&lt;/code> strategy, &lt;em>not&lt;/em> the &lt;code>sanboxed&lt;/code> strategy, to do so. This produced an action result that was later incompatible with sandboxed / remote actions.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Because of &lt;code>--remote_upload_local_results&lt;/code>, the &amp;ldquo;bad&amp;rdquo; action result was injected into the AC.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From here on, any remote build that picked the bad action result would fail.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The mitigation to this problem was to flush the problematic artifact from the remote cache, and the immediate solution was to set &lt;code>--remote_local_fallback_strategy=sandboxed&lt;/code> which&amp;hellip; Bazel claims is deprecated and a no-op, but in reality this works and I haven&amp;rsquo;t been able to find an alternative (at least not in Bazel 7) via any of the other strategy flags.&lt;/p>
&lt;p>The real solution, however, is to ensure that remote execution doesn&amp;rsquo;t require the local fallback option for reliability reasons, and to prevent Bazel from injecting AC entries for actions that do not run in the remote workers.&lt;/p>
&lt;h1 id="parting-words">Parting words&lt;/h1>
&lt;p>With that, this series to revisit Bazel&amp;rsquo;s action execution fundamentals, remote caching, and remote execution is complete. Which means I can &lt;em>finally&lt;/em> tell you the thing that started this whole endeavor: the very specific, cool, and technical solution I implemented to work around a hole in the action keys that can lead to very problematic non-determinism.&lt;/p>
&lt;p>But, to read on that topic, you&amp;rsquo;ll have to wait for the next episode!&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-09-12-bazel-remote-execution-cover-image.jpg" length="147776" type="image/jpeg"/></item><item><title>Understanding Bazel remote caching</title><link>https://jmmv.dev/2025/09/bazel-remote-caching.html</link><pubDate>Fri, 05 Sep 2025 08:30:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/09/bazel-remote-caching.html</guid><description>&lt;p>The previous article on &lt;a href="/2025/07/bazel-action-determinism.html">Bazel action non-determinism&lt;/a> provided an introduction to actions: what they are, how they are defined, and how they act as the fundamental unit of execution in Bazel. What the article did not mention is that actions are &lt;em>also&lt;/em> the fundamental unit of caching during execution to avoid doing already-done work.&lt;/p>
&lt;p>In this second part of the series, I want to revisit the very basics of how Bazel runs actions and how remote caching (&lt;em>not&lt;/em> remote execution, because that&amp;rsquo;ll come later) works. The goal here is to introduce the &lt;strong>Action Cache (AC)&lt;/strong>, the &lt;strong>Content Addressable Storage (CAS)&lt;/strong>, how they play together, and then have some fun in describing the many ways in which it&amp;rsquo;s possible to poison such a cache in an accidental or malicious manner.&lt;/p>
&lt;h1 id="the-action-cache-ac">The Action Cache (AC)&lt;/h1>
&lt;p>Picture this build file with two targets that generate one action each:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;foo&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;foo.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;sleep 5; echo foo &amp;gt;$@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;bar&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;bar.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;:foo&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;sleep 5; { cat $&amp;lt; ; echo bar; } &amp;gt;$@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And now this sequence of commands:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;code>bazel build //:bar&lt;/code>: This first command causes Bazel to build &lt;code>//:bar&lt;/code>, possibly from scratch. This takes at least 10 seconds due to the &lt;code>sleep&lt;/code> calls we introduced in the commands. As a side-effect of this operation, Bazel populates its in-memory graph with the actions that it executed and the outputs they produced.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>bazel build //:bar&lt;/code>: This second command asks Bazel to do the same build as the first command and, because we &lt;em>just&lt;/em> built &lt;code>//:bar&lt;/code> and Bazel&amp;rsquo;s in-memory state is untouched, we expect Bazel to do absolutely nothing. In fact, this command completes (or should complete) in just a few milliseconds due to Bazel&amp;rsquo;s design.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>bazel shutdown&lt;/code>: This third command shuts the background local Bazel server process down. All in-memory state populated by the first command is lost.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>bazel build //:bar&lt;/code>: This fourth command asks Bazel to do the same build as the first and second commands. We didn&amp;rsquo;t run a &lt;code>bazel clean&lt;/code> so all on-disk state is still present, so we should expect Bazel to &lt;em>not&lt;/em> rebuild &lt;code>//:foo&lt;/code> nor &lt;code>//:bar&lt;/code>. And indeed they are not rebuilt: Bazel also &amp;ldquo;does nothing&amp;rdquo; like in that second command (the &lt;code>sleep&lt;/code>s don&amp;rsquo;t run), but the build is visibly slower in this case.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The problem or, rather, question is&amp;hellip; how does Bazel &lt;em>know&lt;/em> that there is nothing to do on that fourth command? A system like Make would discover that all output files are &amp;ldquo;up to date&amp;rdquo; by comparing their timestamps against those of their inputs, but remember that Bazel tracks output staleness by inspecting the content &lt;em>digests&lt;/em> of the inputs and ensuring they haven&amp;rsquo;t changed.&lt;/p>
&lt;p>Enter the &lt;strong>Action Cache (AC)&lt;/strong>: an on-disk persistent cache that helps Bazel determine whether the outputs of an action are already present on disk and whether they already have the expected (up-to-date) content. The AC lives under &lt;code>~/.cache/bazel/_bazel_${USER?}/${WORKSPACE_HASH?}/action_cache/&lt;/code> and is stored in a special binary format that you can dump with &lt;code>bazel dump --action_cache&lt;/code>.&lt;/p>
&lt;p>Conceptually, the AC maps the &lt;code>ActionKey&lt;/code>s that we saw in the previous article to their corresponding &lt;code>ActionResult&lt;/code>s. In practice, the AC keys are a more succinct representation of the on-disk state of the inputs to the action: up until Bazel 9, the keys were known as &amp;ldquo;digest keys&amp;rdquo; but things have &lt;a href="https://github.com/bazelbuild/bazel/commit/ec10da4e3fada5fdf80d809d44b32e331e2b322b">changed recently&lt;/a> to allow Bazel to better explain why certain actions are rebuilt; the details are uninteresting in this article though.&lt;/p>
&lt;p>But what is an &lt;code>ActionResult&lt;/code>? The &amp;ldquo;action result&amp;rdquo; records, well, the side-effects of the action. Among other things, the &lt;code>ActionResult&lt;/code> contains:&lt;/p>
&lt;ul>
&lt;li>The exit code of the process executed by the action.&lt;/li>
&lt;li>A mapping of output &lt;em>names&lt;/em> to output &lt;em>digests&lt;/em>.&lt;/li>
&lt;/ul>
&lt;p>The mapping of output names to digests is the piece of information I want to focus on because this is what allows the fourth Bazel invocation above to discover that it has &amp;ldquo;nothing to do&amp;rdquo;. When Bazel has lost its in-memory state of an action, Bazel queries the AC to determine the names of its outputs. If those files exist on disk, then Bazel can compute their digests and compare those against the digests recorded in the &lt;code>ActionResult&lt;/code>. If they match, Bazel can conclude that the action does not have to be re-executed.&lt;/p>
&lt;p>And this explains why the fourth Bazel invocation is visibly slower than the second invocation, even if both are &amp;ldquo;fully cached&amp;rdquo;: when the in-memory state of an action is lost, Bazel has to re-digest all input and output files that are on disk, and these are slow operations, typically I/O-bound. If you have seen annoying pauses with the &lt;code>checking cached actions&lt;/code> message, you now know what they are about.&lt;/p>
&lt;h1 id="introducing-remote-caching">Introducing remote caching&lt;/h1>
&lt;p>The AC is, maybe surprisingly, a concept that exists even if Bazel is &lt;em>not&lt;/em> talking to a remote cache or execution system. But what happens when we introduce a remote cache into the mix?&lt;/p>
&lt;p>First of all, the remote cache needs to be able to answer the same questions as the local AC: &amp;ldquo;given an action key, is the action result already known?&amp;rdquo; But let&amp;rsquo;s think through what goes into the result of such a query. Does the remote AC capture the same information that goes into a local &lt;code>ActionResult&lt;/code>, or does it do something different?&lt;/p>
&lt;p>Given that we are talking about a remote cache, it&amp;rsquo;s tempting to say that the value of the cache entry should embed the &lt;em>content&lt;/em> of the output files: after all, if Bazel scores a remote AC hit, Bazel will need to retrieve the resulting output files to use them for subsequent actions, right? Not so fast:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>What if Bazel &lt;em>already&lt;/em> has the output files on disk but is just querying the remote AC because the local in-memory state was lost? In this case, you want the response from the cache to be as small and quick as possible: you do not want to fetch the output contents again because they may be very large.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>What if you (the user) &lt;em>don&amp;rsquo;t care&lt;/em> about the output&amp;rsquo;s content? Take a look at the actions in the example above: if &lt;em>all&lt;/em> of them are cached, when I ask Bazel to build &lt;code>//:bar&lt;/code> I &lt;em>probably&lt;/em> only want to download &lt;code>bar.txt&lt;/code> from the remote cache. I may not care about the intermediate &lt;code>foo.txt&lt;/code>, so why should I be forced to fetch it when I query the cache just to know if &lt;code>//:foo&lt;/code> is known?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>What if I&amp;rsquo;m using remote execution and I&amp;rsquo;m building and running a test? The test runs remotely, so the local machine does not need to download &lt;em>any&lt;/em> file at all!&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>This is why the &lt;code>ActionResult&lt;/code>, even for the remote AC, does &lt;em>not&lt;/em> contain the content of the outputs.&lt;/p>
&lt;p>But then&amp;hellip; how is the remote cache ever useful across users or machines, or even in a simple sequence like this?&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">bazel build //:bar
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bazel clean
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bazel build //:bar
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>bazel clean&lt;/code> in between these two builds causes all disk state (the local AC and the local output tree) to be lost. In this situation, Bazel will leverage the remote AC to know the names of the output files and their digests for each action&amp;hellip; but if those outputs are not present on the local disk anymore, then what? Do we just rebuild the action? That&amp;rsquo;d&amp;hellip; work, but it&amp;rsquo;d defeat the whole purpose of remote caching.&lt;/p>
&lt;p>Enter the &lt;strong>Content Addressable Storage (CAS)&lt;/strong>, another cache provided by the remote caching system to solve this problem. The CAS maps file digests (&lt;em>not&lt;/em> names!) to their &lt;em>contents&lt;/em>. Nothing more, nothing less. By leveraging both the AC and the CAS, Bazel can recreate its on-disk view of an already-built target by first checking with the AC what files should exist and then leveraging the CAS to fetch those files.&lt;/p>
&lt;p>Let&amp;rsquo;s visualize everything explained above via sequence diagrams.&lt;/p>
&lt;p>This first diagram represents the initial &lt;code>bazel build //:bar&lt;/code> invocation, assuming that &lt;code>//:bar&lt;/code> has not been built at all by anyone beforehand. This means that Bazel will not be able to score any local nor remote AC hits and therefore will have to execute all actions:&lt;/p>
&lt;figure>
&lt;img src="/images/2025-09-05-bazel-remote-caching-uncached-build.png" width="100%" />
&lt;/figure>
&lt;p>This second diagram represents the second &lt;code>bazel build //:bar&lt;/code> invocation executed after &lt;code>bazel clean&lt;/code>. In this case, all local state has been lost, but Bazel is able to score remote cache hits and recreate the local disk state by downloading entries from the remote AC and CAS. The dashed lines against the CAS represent optional operations, controlled by the use (or not) of the &amp;ldquo;Build Without The Bytes&amp;rdquo; feature.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-09-05-bazel-remote-caching-cached-build.png" width="100%" />
&lt;/figure>
&lt;p>Before moving on to the fun stuff, a little subtlety: whenever the AC and CAS use digests, they don&amp;rsquo;t just use a hash. Instead, they use hash/size pairs. This adds extra protection against &lt;a href="https://en.wikipedia.org/wiki/Length_extension_attack">length extension attacks&lt;/a> and allows both Bazel and the remote cache to cheaply detect data inconsistencies should they ever happen.&lt;/p>
&lt;h1 id="lets-poison-the-cache">Let&amp;rsquo;s poison the cache&lt;/h1>
&lt;p>With any remote caching system, we must fear the possibility of invalid cached entries. We have two main types of &amp;ldquo;invalid entries&amp;rdquo; to worry about:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Actions that point to results that, when reused, lead to inconsistent or broken builds.&lt;/strong> This can happen if the cache keys fail to capture some detail of the execution environment. For example: if we have different glibc versions on the machines that store action results into the remote cache, we can end up with object files that are incompatible across machines because the glibc version is &lt;em>not&lt;/em> part of the cache key.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Actions that point to malicious results injected by a malicious actor.&lt;/strong> The attack vector looks like this: a malicious actor makes a &lt;code>CppCompile&lt;/code> action point to a poisoned object file that steals credentials and uploads them to a remote server. This object file is later pulled by other machines when building tools that engineers run or when building binaries that end up in production, leading to the compromised code spreading to those binaries.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Scary stuff. But can this attack vector happen? Let&amp;rsquo;s see how an attacker might try to compromise the remote cache.&lt;/p>
&lt;p>If the attacker can inject a malicious blob into the CAS, we now have a new entry indexed by its digest that points to some dangerous file. But&amp;hellip; how can we access such file? To access such file, we must first know its digest. Bazel uses the digests stored in the AC to determine which files to download from the CAS so, as long as there is no entry in the AC pointing to the bad blob, the bad blob is invisible to users and is not used. We have no problem here.&lt;/p>
&lt;p>The real danger comes from an attacker having write access to the AC. If the attacker can write arbitrary entries to the AC, they can pretty much point any action to compromised results. Therefore, the content of the AC is precious.&lt;/p>
&lt;h1 id="protecting-the-remote-cache">Protecting the remote cache&lt;/h1>
&lt;p>In order to offer a secure and reliable remote cache system, we must restrict who can write to the cache. And because we can&amp;rsquo;t control what users do on their machines (intentionally or not), the only option we have is to restrict writes to the AC to builds that run on CI. After all, CI is a trusted environment so we can assume attackers cannot compromise it.&lt;/p>
&lt;p>But that&amp;rsquo;s not enough! Attackers can &lt;em>still&lt;/em> leverage a naive CI system to inject malicious outputs into the cache. Consider this: an attacker creates a PR that modifies the scripts executed by CI. This change leverages the credentials of the CI system to write a poisoned entry into the AC. This poisoned entry targets an action that almost-never changes (something at the bottom of the build graph) to prevent it from being evicted soon after. The attacker runs the PR through CI and then deletes the PR to erase traces of their actions. From there on, the poisoned artifact remains in the cache and can be reused by other users.&lt;/p>
&lt;p>Yikes. How do we protect against this? The reality is that we just cannot, at least not in a very satisfactory way. If the CI system runs untrusted code as submitted in a PR, the CI system can be compromised. We can mitigate the threat by doing these:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>For CI runs against PRs (code not yet reviewed and merged):&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Disallow running the CI workflows if the changes modify the CI infrastructure in any way (CI configurations, scripts run by CI, the Bazel configuration files, etc.)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Configure Bazel with &lt;code>--noremote_upload_local_results&lt;/code> so that &lt;code>genrule&lt;/code>s or other actions that could produce tampered outputs cannot propagate those to other users.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>For CI runs against merged code:&lt;/p>
&lt;ul>
&lt;li>Configure Bazel with &lt;code>--remote_upload_local_results&lt;/code> so that they are the only ones that can populate the remote cache. If there is any malicious activity happening at this stage, which could still happen via sloppy code reviews or smart deceit, at least you will be able to collect audit logs and have the possibility of tracing back the bad changes to a person.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>This configuration should provide a reasonably secure system at the expense of slightly lower cache hit rates: users will not be able to benefit from cached artifacts until their code has been merged and later built by CI. But&amp;hellip; doing otherwise would be reckless.&lt;/p>
&lt;p>Before concluding: what about the CAS? Is it truly safe to allow users to freely write to the CAS? As we have seen before, it is really difficult for a malicious entry in the CAS to become problematic unless it is referenced by the AC. But still, we have a couple of scenarios to worry about:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>DoS attacks:&lt;/strong> Malicious users could bring the remote cache &amp;ldquo;down&amp;rdquo; (making it less effective) by flooding the CAS with noise, pushing valid artifacts out of it, or by exhausting all available network bandwidth. This is not a big concern in a corporate environment where you&amp;rsquo;d be able to trace abusive load to a user, but you might still run into this due to accidental situations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Information disclosure:&lt;/strong> If a malicious user can somehow guess the digest of a sensitive file (e.g. a file with secrets), they could fetch such file. So&amp;hellip; how much do you trust cryptography?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="next-steps">Next steps&lt;/h1>
&lt;p>As presented in this article, deploying an effective remote cache for Bazel in a manner that&amp;rsquo;s secure is not trivial. And if you try to make the setup secure, the effectiveness of the remote cache is lower that desirable because users can only leverage remote caching for builds executed on CI: any builds they run locally, possibly with configurations that CI doesn&amp;rsquo;t plan for, won&amp;rsquo;t be cached.&lt;/p>
&lt;p>The only way to offer a truly secure remote caching system is by &lt;em>also&lt;/em> leveraging remote execution. We&amp;rsquo;ll see how and why in the next episode.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-09-05-bazel-remote-caching-cover-image.jpg" length="969844" type="image/jpeg"/></item><item><title>Bazel and action (non-) determinism</title><link>https://jmmv.dev/2025/07/bazel-action-determinism.html</link><pubDate>Mon, 21 Jul 2025 08:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/07/bazel-action-determinism.html</guid><description>&lt;p>A key feature of Bazel is its ability to produce fast, reliable builds by caching the output of actions. This system, however, relies on a fundamental principle: build actions must be deterministic. For the most part, Bazel helps ensure that they are, but in the odd cases when they aren&amp;rsquo;t, builds can fail in subtle and frustrating ways, eroding trust in the build system.&lt;/p>
&lt;p>This article is the first in a series on Bazel&amp;rsquo;s execution model. Having explained these concepts many times, I want to provide a detailed reference before explaining a cool solution to a problem I recently developed at work. We will start with action non-determinism, then cover remote caching and execution, and finally, explore the security implications of these features.&lt;/p>
&lt;p>This first article explains what non-determinism is, how it manifests, and how you can diagnose and prevent it in your own builds. Let&amp;rsquo;s begin.&lt;/p>
&lt;h1 id="bazel-execution-basics">Bazel execution basics&lt;/h1>
&lt;p>Consider the following example build file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">cc_library&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;bs5-lib&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;lib1.c&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;lib2.c&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cc_binary&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;bs5-bin&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;main.c&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">deps&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;:bs5-lib&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This build file specifies two &lt;strong>targets&lt;/strong>: the &lt;code>bs5-lib&lt;/code> target, which builds a C library from two source files, and the &lt;code>bs5-bin&lt;/code> target, which builds a C binary from one source file and links it against the &lt;code>bs5-lib&lt;/code> library.&lt;/p>
&lt;p>These two targets instantiate the &lt;code>cc_library&lt;/code> and &lt;code>cc_binary&lt;/code> &lt;strong>rules&lt;/strong> by binding them to specific &lt;strong>attributes&lt;/strong> (the values of &lt;code>srcs&lt;/code> and &lt;code>deps&lt;/code>).&lt;/p>
&lt;p>Processing these rules during dependency analysis yields a collection of &lt;strong>actions&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The &lt;code>cc_library&lt;/code> rule used to define the &lt;code>bs5-lib&lt;/code> target generates:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>A &lt;code>CppCompile&lt;/code> action to compile the &lt;code>lib1.c&lt;/code> file into the &lt;code>lib1.o&lt;/code> object file.&lt;/p>
&lt;p>Its command line may be: &lt;code>cc -o lib1.o lib1.c&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A &lt;code>CppCompile&lt;/code> action to compile the &lt;code>lib2.c&lt;/code> file into the &lt;code>lib2.o&lt;/code> object file.&lt;/p>
&lt;p>Its command line may be: &lt;code>cc -o lib2.o lib2.c&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A &lt;code>CppArchive&lt;/code> action to link &lt;code>lib1.o&lt;/code> and &lt;code>lib2.o&lt;/code> together into the &lt;code>bs5-lib.a&lt;/code> archive.&lt;/p>
&lt;p>Its command line may be: &lt;code>ar rcsD bs5-lib.a lib1.o lib2.o&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>The &lt;code>cc_binary&lt;/code> rule used to define the &lt;code>bs5-bin&lt;/code> target generates:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>A &lt;code>CppCompile&lt;/code> action to compile the &lt;code>main.c&lt;/code> file into the &lt;code>main.o&lt;/code> object file.&lt;/p>
&lt;p>Its command line may be: &lt;code>cc -o main.o main.c&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A &lt;code>CppLink&lt;/code> action to link &lt;code>main.o&lt;/code> and &lt;code>bs5-lib.a&lt;/code> together into the &lt;code>bs5-bin&lt;/code> executable.&lt;/p>
&lt;p>Its command line may be: &lt;code>cc -o bs5-bin main.o bs5-lib.a&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Note that nowhere in the list above do you see target names. Actions work with &lt;em>file&lt;/em>-level dependencies, not &lt;em>target&lt;/em>-level dependencies. If you need to visualize this, think of the target dependency graph and the action dependency graph as two disjoint entities. (Skyframe tracks them as just one graph but we can ignore that fact here.)&lt;/p>
&lt;p>It&amp;rsquo;s this, actions, that are the atomic unit of execution in Bazel. Once Bazel is done with its &lt;strong>loading&lt;/strong> and &lt;strong>analysis&lt;/strong> phases, it enters the &lt;strong>execution&lt;/strong> phase. During execution, the &amp;ldquo;only&amp;rdquo; thing that Bazel does is dispatch actions for execution via its &lt;a href="/2019/12/bazel-strategies.html">execution strategies&lt;/a>, trying to maximize parallelism as determined by the constraints of the action dependency graph.&lt;/p>
&lt;h1 id="build-actions-anatomy">Build actions anatomy&lt;/h1>
&lt;p>To break down an action into its parts, let&amp;rsquo;s examine what goes into defining the &lt;code>CppLink&lt;/code> action above, and to do that, let&amp;rsquo;s first focus on its simple command line to produce the &lt;code>bs5-bin&lt;/code> binary from the &lt;code>main.o&lt;/code> object file and the &lt;code>bs5-lib.a&lt;/code> static library:&lt;/p>
&lt;pre tabindex="0">&lt;code>cc -o bs5-bin main.o bs5-lib.a
&lt;/code>&lt;/pre>&lt;p>Bazel tracks the command line as part of the action, but things are a bit more complex than that. And to explain the &amp;ldquo;complexity&amp;rdquo;, let&amp;rsquo;s try to understand what problems Bazel is trying to solve compared to a more rudimentary build tool like Make.&lt;/p>
&lt;p>If you have used (or still use) Make, you would have likely expressed the corresponding build rule as:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-make" data-lang="make">&lt;span class="line">&lt;span class="cl">&lt;span class="nf">bs5-main&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">main&lt;/span>.&lt;span class="n">o&lt;/span> &lt;span class="n">bs&lt;/span>5-&lt;span class="n">lib&lt;/span>.&lt;span class="n">a&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">$(&lt;/span>CC&lt;span class="k">)&lt;/span> &lt;span class="k">$(&lt;/span>LDFLAGS&lt;span class="k">)&lt;/span> -o bs5-main main.o bs5-lib.a
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>which looks&amp;hellip; OK, I guess. But what happens if you do this?&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Build the binary.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">make bs5-main
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Build the binary _again_ in stripped mode.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">make bs5-main &lt;span class="nv">LDFLAGS&lt;/span>&lt;span class="o">=&lt;/span>-s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>An inconsistent build! The &lt;code>bs5-main&lt;/code> binary is &lt;em>not&lt;/em> stripped as you would expect because the second &lt;code>make&lt;/code> invocation does &lt;em>nothing&lt;/em>! &lt;code>make&lt;/code> has no idea that the &lt;code>LDFLAGS&lt;/code> variable is involved in the target definition so it doesn&amp;rsquo;t know that the target has to be rebuilt to honor the variable change.&lt;/p>
&lt;p>This type of scenario is what leads to having to run &lt;code>make clean&lt;/code> from time to time in a Make-based build system because the outputs that Make produces get out of sync with environmental changes. And the reason is that the &lt;em>only&lt;/em> thing that &lt;code>make&lt;/code> tracks to determine whether a target needs to be rebuilt are the file timestamps of the inputs that are &lt;em>explicitly listed&lt;/em> in the rule (&lt;code>main.o&lt;/code> and &lt;code>bs5-lib.a&lt;/code> in this example).&lt;/p>
&lt;p>Now you&amp;rsquo;d say: but you can fix it! &amp;ldquo;Just&amp;rdquo; do:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-make" data-lang="make">&lt;span class="line">&lt;span class="cl">&lt;span class="c"># An unconditional rule that captures the content of LDFLAGS.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nf">.PHONY&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">ldflags&lt;/span>.&lt;span class="n">stamp&lt;/span>.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">ldflags.stamp.2&lt;/span>&lt;span class="o">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @echo &lt;span class="k">$(&lt;/span>LDFLAGS&lt;span class="k">)&lt;/span> &amp;gt;ldflags.stamp.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># A conditional rule that only updates the timestamp of the stamp file if the
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># content captured by the unconditional rule changes.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nf">ldflags.stamp&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">ldflags&lt;/span>.&lt;span class="n">stamp&lt;/span>.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @cmp -s ldflags.stamp ldflags.stamp.2 &lt;span class="o">||&lt;/span> cp ldflags.stamp.2 ldflags.stamp
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># The rule we had before, but with an extra dependency on the stamp file.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nf">bs5-main&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">main&lt;/span>.&lt;span class="n">o&lt;/span> &lt;span class="n">bs&lt;/span>5-&lt;span class="n">lib&lt;/span>.&lt;span class="n">a&lt;/span> &lt;span class="n">ldflags&lt;/span>.&lt;span class="n">stamp&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">$(&lt;/span>CC&lt;span class="k">)&lt;/span> &lt;span class="k">$(&lt;/span>LDFLAGS&lt;span class="k">)&lt;/span> -o bs5-main main.o bs5-lib.a
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And indeed this ensures that the &lt;code>bs5-main&lt;/code> target gets re-linked if &lt;code>LDFLAGS&lt;/code> changes. But I hope you&amp;rsquo;ll agree that this is &lt;em>awful&lt;/em> and that nobody does it because: one, most folks writing &lt;code>Makefile&lt;/code>s aren&amp;rsquo;t aware of the problem; and, two, even if they are, it&amp;rsquo;s too hard to get it right (see&amp;hellip; we forgot about the value of &lt;code>CC&lt;/code> and whatever other environment variables might influence &lt;code>CC&lt;/code>&amp;rsquo;s behavior like, you know, the &lt;code>PATH&lt;/code>?).&lt;/p>
&lt;p>I didn&amp;rsquo;t come here to bash against Make. OK, maybe I &lt;em>did&lt;/em> because folks out there often say &amp;ldquo;Make works just fine and it&amp;rsquo;s much simpler than Bazel!&amp;rdquo; when in reality they are oblivious to a bunch of very real problems that later &lt;a href="/2023/08/costs-exposed-monorepo-multirepo.html">waste &lt;em>other people&lt;/em>&amp;rsquo;s time&lt;/a> when their build environment subtly breaks. &amp;lt;/rant&amp;gt;&lt;/p>
&lt;p>Bazel and other next-generation build systems solve this specific problem and more by being comprehensive about what they track at the action level, and using that information to determine whether an action needs to be rebuilt or not. In particular, a Bazel action is defined by these parts:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>The command line to execute&lt;/strong>, which in this case is &lt;code>cc -o bs5-bin main.o bs5-lib.a&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Hashes of the input files&lt;/strong> required to execute the command. These include &amp;ldquo;obvious&amp;rdquo; inputs like the source files specified in the targets but &lt;em>also&lt;/em> the files required to execute the tools of the action (e.g. the compiler&amp;rsquo;s own files). In this case, the list of input files could look like: &lt;code>main.o&lt;/code>, &lt;code>bs5-lib.a&lt;/code>, &lt;em>and&lt;/em> &lt;code>cc&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>The configuration of the environment&lt;/strong> in which the action runs. This includes environment variables, the host and target platforms, and things like that. In this case, the configuration could include the value of &lt;code>PATH&lt;/code> and whether we are building in debug or optimized mode. Configurations are expressed as a hash, though, because of the many details that go into computing them.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>These three properties define &lt;em>quite&lt;/em> precisely the relation between the context of an action and the outputs it produces, and this is the main technique that Bazel uses to &lt;a href="/2020/12/google-no-clean-builds.html">avoid clean builds&lt;/a> at large scale.&lt;/p>
&lt;h1 id="hello-non-determinism">Hello non-determinism&lt;/h1>
&lt;p>But pay attention to the &amp;ldquo;quite&amp;rdquo; word in &amp;ldquo;quite precisely&amp;rdquo; right above. I did not say &amp;ldquo;perfectly&amp;rdquo; because there are still ways for non-deterministic behavior to leak into a Bazel build, meaning that &lt;code>bazel clean&lt;/code> and unexpected rebuilds (e.g. due to cache expiration) could still change the behavior of a build.&lt;/p>
&lt;p>Consider this innocuous example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;date&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;date.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;date &amp;gt;$@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This rule says: stick the output of the &lt;code>date&lt;/code> command, which prints the current date, into the &lt;code>date.txt&lt;/code> file. Obviously, &amp;ldquo;current date&amp;rdquo; varies over time so we should expect the above to give us trouble. And indeed it does: look at this sequence of commands where I&amp;rsquo;ve removed all irrelevant Bazel console noise:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">$ bazel build //:date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: 2 processes: 1 internal, 1 linux-sandbox.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ cat bazel-bin/date.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Mon Jul 7 17:59:29 PDT 2025
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel build //:date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: 1 process: 1 internal.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ cat bazel-bin/date.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Mon Jul 7 17:59:29 PDT 2025
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel clean
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel build //:date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: 2 processes: 1 internal, 1 linux-sandbox.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ cat bazel-bin/date.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Mon Jul 7 18:02:15 PDT 2025
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The first Bazel build claims to have executed 1 action in the sandbox and the &lt;code>date.txt&lt;/code> file shows us the date when that happened. The second Bazel build does nothing and &lt;code>date.txt&lt;/code> remains unmodified. But if we later follow that by a Bazel clean and a third Bazel build, we see that the content of &lt;code>date.txt&lt;/code> is now different. Non-determinism has leaked into the build, and&amp;hellip; that&amp;rsquo;s problematic.&lt;/p>
&lt;h1 id="how-bad-is-non-determinism-really">How bad is non-determinism really?&lt;/h1>
&lt;p>Non-determinism is a problem because it prevents achieving &lt;a href="https://reproducible-builds.org/">reproducible builds&lt;/a>. On the one hand, this voids the security guarantees that come from being able to reproduce builds in different environments: if the output of the build is not bit-for-bit identical to its inputs, you can&amp;rsquo;t verify that a binary that&amp;rsquo;s being used in production actually comes from the sources it claims to have been built from. On the other hand, this leads to situations where developers get different behavior depending on when/where they build the code: you do not want to hear the &amp;ldquo;works on my machine&amp;rdquo; excuse when troubleshooting a bug. So, it &lt;em>is&lt;/em> bad.&lt;/p>
&lt;p>But one interesting property of Bazel&amp;rsquo;s action model is that a single non-deterministic action does not necessarily poison the whole build. Take a look at this build file that defines a chain of actions:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># date target: Writes a non-deterministic date to its output.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;date&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;date.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;date &amp;gt;$@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># copy target: Consumes the output of &amp;#34;date&amp;#34; and copies it to&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># its output.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;copy&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;copy.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;cp $&amp;lt; $@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;:date&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># count target: Consumes the output of &amp;#34;copy&amp;#34; and produces an&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># output that does not vary due to the input non-determinism.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;count&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;count.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;wc -l $&amp;lt; &amp;gt;$@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;:copy&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># copy2 target: Consumes the output of &amp;#34;count&amp;#34; and copies it to&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># its output.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">genrule&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;copy2&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;copy2.txt&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cmd&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;cp $&amp;lt; $@&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;:count&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The interesting bit here is in the &lt;code>count&lt;/code> target, which counts the lines in its input and writes the resulting number to its output. While this target consumes a non-deterministic input, its output is deterministic because the number of lines in the input is constant: &lt;code>date&lt;/code> writes a different timestamp each time, but it always produces one line.&lt;/p>
&lt;p>The fact that the target produces a deterministic output allows Bazel to stop &amp;ldquo;propagating&amp;rdquo; non-determinism across the build. Remember that actions track &lt;em>input hashes&lt;/em>, &lt;strong>not&lt;/strong> &lt;em>input timestamps&lt;/em>. Once &lt;code>count&lt;/code> is re-executed after changes to &lt;code>date&lt;/code>, the output of &lt;code>count&lt;/code> will have the same hash as it did before, and &lt;code>copy2&lt;/code> will conclude that it doesn&amp;rsquo;t need to be rerun.&lt;/p>
&lt;p>Let&amp;rsquo;s try it:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">$ bazel build //:copy2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: &lt;span class="m">5&lt;/span> processes: &lt;span class="m">1&lt;/span> internal, &lt;span class="m">4&lt;/span> linux-sandbox.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ rm -f bazel-bin/date.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel build //:copy2 --explain log
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INFO: &lt;span class="m">4&lt;/span> processes: &lt;span class="m">1&lt;/span> action cache hit, &lt;span class="m">1&lt;/span> internal, &lt;span class="m">3&lt;/span> linux-sandbox.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ cat log
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Build options: --explain&lt;span class="o">=&lt;/span>log
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Executing action &lt;span class="s1">&amp;#39;BazelWorkspaceStatusAction stable-status.txt&amp;#39;&lt;/span>: unconditional execution is requested.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Executing action &lt;span class="s1">&amp;#39;Executing genrule //:date&amp;#39;&lt;/span>: One of the files has changed.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Executing action &lt;span class="s1">&amp;#39;Executing genrule //:copy&amp;#39;&lt;/span>: One of the files has changed.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Executing action &lt;span class="s1">&amp;#39;Executing genrule //:count&amp;#39;&lt;/span>: One of the files has changed.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The sequence of commands above proves the point: the first build of the &lt;code>copy2&lt;/code> target tells us that Bazel executed 4 sandboxed actions (one for each target). If we then remove the non-deterministic file from the output tree and ask Bazel to rebuild the &lt;code>copy2&lt;/code> target, we see how it only rebuilt 3 targets and 1 of them scored a cache hit. And by inspecting the log we asked Bazel to produce, we see that it effectively rebuilt &lt;code>date&lt;/code>, &lt;code>copy&lt;/code>, and &lt;code>count&lt;/code>, but it didn&amp;rsquo;t have to rebuild &lt;code>copy2&lt;/code> because the non-determinism didn&amp;rsquo;t propagate further.&lt;/p>
&lt;p>In a Make world, the above sequence of commands would have invalidated the whole build because Make just checks timestamps, and targets almost-always update the timestamps of their outputs unless we go through great extents to prevent it (like I did earlier on in the stamp file rule with its call to &lt;code>cmp -s&lt;/code>).&lt;/p>
&lt;h1 id="possible-non-determinism-causes">Possible non-determinism causes&lt;/h1>
&lt;p>In the previous example, it was rather obvious that a call to &lt;code>date&lt;/code> could be problematic. But this is not the only source of non-determinism, and oftentimes the reason behind the non-determinism isn&amp;rsquo;t as obvious. Here is a more comprehensive list of possible causes:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Date and time.&lt;/strong> You might not be calling &lt;code>date&lt;/code>, but build tools&amp;mdash;especially code generators and archivers like zip&amp;mdash;love injecting timestamps in their output files. These may be obvious, like comments in generated files, or subtle, like values written in binary metadata headers.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>System identifiers.&lt;/strong> Similarly to &amp;ldquo;current date&amp;rdquo;, there are tools that query the current PID, UID, GID, etc. and inject those values in their outputs.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Sort ordering.&lt;/strong> Hash tables are the star data structure in computer science and they are everywhere. Unfortunately, there are tools that leak their internal use of hash tables into output files by, for example, emitting unsorted lists.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Accessing the network.&lt;/strong> Just &lt;em>don&amp;rsquo;t&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Unexpected/unknown dependencies on host tools.&lt;/strong> Calling a tool from the system means introducing hidden dependencies on whatever the tool itself depends on. For example, the tool might read a configuration file that alters its behavior.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="/2019/12/bazel-dynamic-execution-introduction.html">Dynamic execution&lt;/a>.&lt;/strong> This powerful feature that helps improve incremental build times in interactive scenarios can easily lead to non-determinism if the remote execution environment and the local execution environment aren&amp;rsquo;t equivalent (where equivalent is tricky to define).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://github.com/bazel-contrib/rules_foreign_cc">Foreign CC rules&lt;/a>.&lt;/strong> Bazel tries to enforce action determinism as we saw earlier, but other build systems make little efforts to do so. If you end up nesting build systems, as is the case when using this ruleset, it&amp;rsquo;s very likely that you are introducing non-determinism.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Randomness.&lt;/strong> Tools can decide to read from &lt;code>/dev/random&lt;/code> and do something with that value, in which case you definitely have non-determinism.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="doesnt-sandboxing-fix-it-all">Doesn&amp;rsquo;t sandboxing fix it all?&lt;/h1>
&lt;p>The list above is long, and there is this assumption, especially from newcomers to Bazel, that Bazel&amp;rsquo;s sandboxing ensures that build behavior is deterministic.&lt;/p>
&lt;p>In a theoretical world, that would be true: Bazel would execute each action in a precisely controlled environment to ensure that actions behaved exactly the same from run to run. This would require using a cycle-accurate virtual machine to precisely control instruction scheduling (multithreading can also introduce non-determinism) and entropy sources, but as you can imagine, this would make build execution extremely slow.&lt;/p>
&lt;p>In a practical world, sandboxing has to grant some concessions in the name of performance: otherwise, people will end up &lt;a href="https://github.com/bazelbuild/bazel/issues/8230">disabling sandboxing&lt;/a>, nullifying all of its benefits.&lt;/p>
&lt;p>Furthermore, sandboxing isn&amp;rsquo;t something magical you can &amp;ldquo;do&amp;rdquo; from userspace (unless you write a full machine emulator). Sandboxing requires kernel support, and different kernels offer different sandboxing technologies. In turn, this means that what Bazel can sandbox or not depends on the machine that Bazel is running on. For example: Bazel&amp;rsquo;s sandbox on Linux is able to restrict file accesses, offer stable PIDs, and forbid network accesses&amp;mdash;but the macOS sandbox, &lt;a href="/2019/11/macos-sandbox-exec.html">based on the deprecated sandbox-exec&lt;/a>, cannot mangle the PID namespace.&lt;/p>
&lt;h1 id="diagnosing-non-determinism">Diagnosing non-determinism&lt;/h1>
&lt;p>So. We know non-deterministic actions can exist in a Bazel build and that sandboxing isn&amp;rsquo;t going to protect us from them. In that case, how can we tell if such actions have leaked into our build? We can use the &amp;ldquo;execution log&amp;rdquo; feature in Bazel to write a detailed log of all the actions that Bazel executes. Then, we can &lt;code>diff&lt;/code> the logs of two separate builds and see if they differ.&lt;/p>
&lt;p>Looking back to our chain of actions from the last example, we could capture two fresh execution logs by doing this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">$ bazel clean
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel build --noremote_accept_cached --execution_log_json_file&lt;span class="o">=&lt;/span>before //:copy2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel clean
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel build --noremote_accept_cached --execution_log_json_file&lt;span class="o">=&lt;/span>after //:copy2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note: it is important to start from a clean build &lt;em>and&lt;/em> to tell Bazel to not reuse remotely-cached actions. In this way, we force Bazel to reexecute the whole build, which should uncover non-determinism if it exists. Also, make sure to keep &lt;code>--execution_log_sort&lt;/code> enabled (the default).&lt;/p>
&lt;p>Once we have run the above, we can proceed to diff the logs. I like doing &lt;code>diff -u before after | cdiff&lt;/code>, but you can use whichever file diffing UI you prefer:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-diff" data-lang="diff">&lt;span class="line">&lt;span class="cl">&lt;span class="gd">--- before 2025-07-15 18:02:46.838524511 -0700
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gd">&lt;/span>&lt;span class="gi">+++ after 2025-07-15 18:02:51.870531304 -0700
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gi">&lt;/span>&lt;span class="gu">@@ -25,7 +25,7 @@
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">&lt;/span> &amp;#34;actualOutputs&amp;#34;: [{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;path&amp;#34;: &amp;#34;bazel-out/k8-fastbuild/bin/date.txt&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;digest&amp;#34;: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gd">- &amp;#34;hash&amp;#34;: &amp;#34;d6e32f2792db61b80e67707fa24bc3f3704d65267b871809cd9d2969fe80d39d&amp;#34;,
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gd">&lt;/span>&lt;span class="gi">+ &amp;#34;hash&amp;#34;: &amp;#34;c2ae04c2b2ff29fd70372a9e399a8f8d5f18ea7395d45d9a34fdbc9decac854b&amp;#34;,
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gi">&lt;/span> &amp;#34;sizeBytes&amp;#34;: &amp;#34;29&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;hashFunctionName&amp;#34;: &amp;#34;SHA-256&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> },
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">@@ -63,7 +63,7 @@
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">&lt;/span> &amp;#34;inputs&amp;#34;: [{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;path&amp;#34;: &amp;#34;bazel-out/k8-fastbuild/bin/date.txt&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;digest&amp;#34;: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gd">- &amp;#34;hash&amp;#34;: &amp;#34;d6e32f2792db61b80e67707fa24bc3f3704d65267b871809cd9d2969fe80d39d&amp;#34;,
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gd">&lt;/span>&lt;span class="gi">+ &amp;#34;hash&amp;#34;: &amp;#34;c2ae04c2b2ff29fd70372a9e399a8f8d5f18ea7395d45d9a34fdbc9decac854b&amp;#34;,
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gi">&lt;/span> &amp;#34;sizeBytes&amp;#34;: &amp;#34;29&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;hashFunctionName&amp;#34;: &amp;#34;SHA-256&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> },
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Voila. The first chunk of the log tells us that the first non-deterministic action is the one that writes the &lt;code>date.txt&lt;/code> file, and the second chunk of the log tells us that there is another action that consumes said file as an input.&lt;/p>
&lt;h1 id="keeping-on-top-of-non-determinism">Keeping on top of non-determinism&lt;/h1>
&lt;p>Let&amp;rsquo;s finish the article by giving you some practical tips to remove non-determinism from the build and to make sure it doesn&amp;rsquo;t come back:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Set up a CI pipeline that identifies new instances of non-determinism&lt;/strong>. Unless you are proactive about it, non-determinism will creep back in because neither the local sandbox not remote execution can fully prevent it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Keep the local sandbox enabled.&lt;/strong> It may not be perfect but it&amp;rsquo;s much better than nothing. Also, enable &lt;code>--nosandbox_default_allow_network&lt;/code> explicitly because, for historical reasons, the sandbox did &lt;em>not&lt;/em> forbid network access and the default hasn&amp;rsquo;t been flipped yet.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Rely on hermetic toolchains.&lt;/strong> Do not use the system-provided ones because they tend to have dependencies on system-provided files that are invisible to the Bazel action definitions. (E.g. if you use the host-provided &lt;code>gcc&lt;/code>, the compiler will happily embed &lt;code>/usr/lib/gcc/x86_64-linux-gnu/15/crtbegin.o&lt;/code> into the final binary and this will be invisible to Bazel.)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Force remote execution.&lt;/strong> Sometimes, non-determinism is inevitable or really hard to avoid (e.g. if you use the Foreign CC ruleset). Under these conditions, your best bet is to force the problematic actions to run remotely under a strictly controlled environment and to provision the remote cache so that such actions &amp;ldquo;never&amp;rdquo; fall out. If done correctly, this will &amp;ldquo;hide&amp;rdquo; the non-determinism because, once an action has been built, it will never be rebuilt again until its known inputs actually change.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Sanitize the action&amp;rsquo;s environment.&lt;/strong> Use &lt;code>--action_env&lt;/code> and &lt;code>--host_action_env&lt;/code> to keep settings like the &lt;code>PATH&lt;/code> consistent across machines, and use &lt;code>--strict_action_env&lt;/code> to minimize the environment variables that leak into action execution.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Think about network access.&lt;/strong> If you must, do it from repo rules and &lt;em>always&lt;/em> verify that whatever you downloaded matches known checksums. If you are strict about checksum validation, you&amp;rsquo;ll still have a non-hermetic build, but at least, you&amp;rsquo;ll have a deterministic one. If you have such behavior in a test, don&amp;rsquo;t allow its results to be cached by means of the &lt;code>no-remote-cache&lt;/code> tag.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>And with that, it&amp;rsquo;s time to conclude until the next episode on remote caching.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-07-21-bazel-action-determinism-cover.jpg" length="520669" type="image/jpeg"/></item><item><title>Lessons along the EndBOX journey</title><link>https://jmmv.dev/2025/06/endbox-journey-lessons.html</link><pubDate>Tue, 17 Jun 2025 09:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/06/endbox-journey-lessons.html</guid><description>&lt;p>About six months ago, during one of my long runs, I had a wild idea: what if I built an OS disk image that booted straight into EndBASIC, bundled it with a Raspberry Pi, a display, a custom 3D-printed case, and made a tiny, self-contained retro BASIC computer? Fast-forward to today and such an idea exists in the form of &amp;ldquo;the EndBOX prototype&amp;rdquo;!&lt;/p>
&lt;p>This article isn&amp;rsquo;t the product announcement though&amp;mdash;&lt;a href="https://www.endbasic.dev/2025/06/unveiling-the-endbox.html">that&amp;rsquo;s elsewhere&lt;/a>. What I want to do here is look back at the Blog System/5 articles I&amp;rsquo;ve written over the past months because what might have seemed like scattered topics were actually stepping stones toward the EndBOX.&lt;/p>
&lt;p>Let&amp;rsquo;s look at what I learned along the way and why, even though developing EndBASIC may sound like a &amp;ldquo;useless waste of time&amp;rdquo;, it&amp;rsquo;s a great playground and the source of inspiration for the articles you&amp;rsquo;ve come to appreciate here.&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2024/04/endbasic-st7735s.html">&amp;ldquo;Porting the EndBASIC console to an LCD&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>On April 26th, 2024&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2024-04-26-rpi-lcd-set-data.png" width="100%" />
&lt;/figure>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>TL;DR:&lt;/strong> The article starts with an introduction to EndBASIC&amp;rsquo;s console framework and how I refactored it to separate display rendering primitives from higher-level operations. This design was inspired by NetBSD&amp;rsquo;s wscons, and the text explains how so. After that, the article continues to show how to extend the redesigned interface to talk to an SPI-attached LCD, how the SPI communication works, and how double-buffering and damage tracking allow for fast rendering performance.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Relevance:&lt;/strong> This is the article that started the EndBOX but I didn&amp;rsquo;t know it at the time. You&amp;rsquo;ll notice that the article ends with a list of parts to build your own embedded box&amp;hellip; but because the software wasn&amp;rsquo;t readily available as a downloadable SD card image, I haven&amp;rsquo;t heard of anyone trying to use it at all.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Lessons learned:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;em>SPI bus access:&lt;/em> I had to reverse-engineer the sample C code that came with the ST7735s LCD, figure out how to access the SPI bus from Rust, and re-implement parts of it in my own terms. I also had to learn about DTB overlays because the SPI bus is disabled by default. I did not have to dive deep into DTBs at this point, but that came to bite me later.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Rasterization algorithms:&lt;/em> Up until that point, EndBASIC had leveraged the SDL library and HTML canvas elements for graphics rendering. But when writing directly to an LCD&amp;hellip; the only thing you can do is poke pixels. So I had to read on &lt;a href="https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm">Bresenham&amp;rsquo;s line algorithm&lt;/a> and the &lt;a href="https://en.wikipedia.org/wiki/Midpoint_circle_algorithm">Midpoint circle algorithm&lt;/a>, implement them and, of course, find a way to write unit tests.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2024/12/netbsd-build-system.html">&amp;ldquo;Revisiting the NetBSD build system&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>On December 28th, 2024&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2024-12-28-netbsd-tools.png" />
&lt;/figure>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>TL;DR:&lt;/strong> The article presents a general overview of how the NetBSD build system shines in achieving cross-platform, cross-architecture, and root-less builds.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Relevance:&lt;/strong> I had to get back into NetBSD after many years of not touching it because its cross-building features were key to getting EndBOX up and running.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Lessons learned:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;em>Not much has changed:&lt;/em> This is more a realization than a lesson, but it was good to see that not much had changed since I used to use NetBSD on a daily basis. This is good because it shows how resilient BSD systems are, but also bad because some problems that made me leave NetBSD are still present.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>NetBSD is still unique:&lt;/em> I don&amp;rsquo;t know of any other OS that supports cross-building as trivially as NetBSD does, much less without requiring root access to generate disk images. I hear FreeBSD 15 will sport these same features, and that&amp;rsquo;s exiting, but &amp;ldquo;I&amp;rsquo;ll believe them when I see them&amp;rdquo;.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2025/01/make-help.html">&amp;ldquo;Self-documenting Makefiles&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>On January 10th, 2025&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2025-01-10-make-help.png" />
&lt;/figure>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>TL;DR:&lt;/strong> This article is a hands-on tutorial on how to write &lt;code>Makefile&lt;/code>s that provide help messages by scanning their own content.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Relevance:&lt;/strong> I had read about this idea before but had never put it to practice. In developing the EndBOX, I had to create a rather complex &lt;code>Makefile&lt;/code> to glue together the patching of the NetBSD tree, the build of the NetBSD toolchain and release, the cross-compilation of EndBASIC for aarch64, and the bundling of all pieces together into a final disk image.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Lessons learned:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;em>Fragility:&lt;/em> Implementing this idea is simple, but in the discussions that followed the article publication, I realized at least two problems: trailing space in variable assignments in &lt;code>make&lt;/code> is meaningful and this approach cannot easily work if you have includes in your &lt;code>Makefile&lt;/code>s. Not a big deal for my use case, but having practiced this, I know when and when not do retry this in the future.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Use make and you&amp;rsquo;ll have a bad time:&lt;/em> Nothing surprising here, but getting the &lt;code>Makefile&lt;/code> to orchestrate all these disparate builds and to do it &lt;em>correctly&lt;/em> without spurious rebuilds has been painful. What&amp;rsquo;s worse is that the resulting build process takes a long time because &lt;code>make&lt;/code> is unable to properly parallelize all build steps. It hurts to see my 72-core server &amp;ldquo;stall&amp;rdquo; when a &lt;code>configure&lt;/code> script runs.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2025/01/netbsd-graphics-wo-x11.html">&amp;ldquo;Hands-on graphics without X11&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>On January 17th, 2025&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2025-01-17-wsdisplay-devices.png" />
&lt;/figure>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>TL;DR:&lt;/strong> This article presents a deep dive into NetBSD&amp;rsquo;s console drivers and how those can be used to render graphics directly to the framebuffer without relying on X11 or Wayland.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Relevance:&lt;/strong> Figuring this out was the key to unblocking the EndBOX project. I had built an earlier prototype of the OS image that used EndBASIC&amp;rsquo;s SDL console over X11 but&amp;hellip; the boot times were atrocious and I wasn&amp;rsquo;t sure I could make them better. Researching how to leverage the framebuffer removed this roadblock as I could get graphics rendering almost immediately after the kernel finished booting.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Lessons learned:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;em>wsdisplay and wskbd APIs:&lt;/em> I had looked at the internals of these devices in the past but never paid much attention to the versatile APIs they expose. I had to do this now, and it was insightful.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>gdb scripting:&lt;/em> Nothing new (I knew this was possible), but I think it was the first time I put it into practice&amp;hellip; for the article&amp;rsquo;s sake.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2025/02/ioctls-rust.html">&amp;ldquo;ioctls from Rust&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>On February 13th, 2025&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2025-02-13-ioctls-rust-cover-image.jpg" />
&lt;/figure>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>TL;DR:&lt;/strong> An overview on what ioctls are and how to invoke them from Rust when bindings don&amp;rsquo;t yet exist for them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Relevance:&lt;/strong> This was a direct follow-up to the previous article: that one was focused on gaining access to the framebuffer, which I prototyped from C, and this one was about productionizing those prototypes in the form of a Rust backend for EndBASIC&amp;rsquo;s console abstraction.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Lessons learned:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;em>ioctl formats:&lt;/em> Not all ioctls are the same. Some deal with simple data types whereas other deal with large structures&amp;mdash;and the way they are expressed is different.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Integrating ioctls in Rust:&lt;/em> This was &amp;ldquo;just a matter of programming&amp;rdquo;, but it was cool to see how the &lt;code>nix&lt;/code> crate makes it easy to expose ioctls in a Rust-native manner so that they just look like function calls.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2025/02/hardware-autoconfiguration.html">&amp;ldquo;Hardware discovery: ACPI &amp;amp; Device Tree&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>On February 28th, 2025&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2025-02-28-w2k-device-manager.png" />
&lt;/figure>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>TL;DR:&lt;/strong> A deep dive on how device discovery works on a modern machine, including details on ACPI and Device Tree, how they differ, and how they are put in memory so that the kernel can read them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Relevance:&lt;/strong> During the development of the EndBOX, I had to enable SPI to render to the LCD via a DT overlay. I also had to find and install a DTB for the Raspberry Pi Zero 2 W so that NetBSD could boot on this board and so that the WiFi could work too.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Lessons learned:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;em>ACPI and Device Tree:&lt;/em> I pretty much knew nothing about these, so learning about the foundations behind them and how they differ was interesting on its own.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Device Tree overlays:&lt;/em> I had to write an overlay from scratch to enable the SPI bus on NetBSD&amp;mdash;and then get the LCD to actually work (which was its own time sink).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Linux vs. NetBSD DTBs:&lt;/em> NetBSD reuses Linux DTBs, but NetBSD&amp;rsquo;s copy is ancient and contains local changes (to e.g. disable the unsupported Videocore). I had to figure out, through sweat and tears, how to port the DTB for the Pi Zero 2 W from Linux to NetBSD without breaking anything else.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2025/05/beginning-3d-printing.html">&amp;ldquo;Beginning 3D printing&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>On May 28th, 2025&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2025-05-28-prusa-and-mac-pro.jpg" />
&lt;/figure>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>TL;DR:&lt;/strong> A beginner-level introduction to 3D printing, including 3D modeling basics, slicing, and actual printing considerations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Relevance:&lt;/strong> The final step in showing off the EndBOX was to create a case for it that matched the design I had envisioned months earlier.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Lessons learned:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;em>Unprintable objects:&lt;/em> The way 3D printers work imposes constraints on the kinds of items that can be printed, and I had to adjust my design a few times.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Modeling vs. slicing:&lt;/em> They are two very different things, and I had never imagined that the second existed.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>It&amp;rsquo;s not trivial:&lt;/em> Even after figuring out the basics, getting a perfect print is difficult. I guess the real world is analog and subject to imperfections.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>And that&amp;rsquo;s all for today. If you enjoyed any of these articles, it&amp;rsquo;s because working on the EndBOX gave me reasons to chase those topics down. To keep this kind of content going, I need time to play, explore, and tinker, so if you&amp;rsquo;d like to support the journey, please subscribe to or sponsor the project.&lt;/p>
&lt;p>&lt;a class="btn btn-primary btn-lg" href="https://www.buymeacoffee.com/jmmv"> Sponsor the EndBOX&lt;/a>&lt;/p>
&lt;p>As for what&amp;rsquo;s next&amp;mdash;well, I&amp;rsquo;m starting to rethink how I can apply the lessons of the EndBOX to something more impactful. Maybe it&amp;rsquo;s time to turn &amp;ldquo;just a fun ride&amp;rdquo; into something greater, because while BASIC may not be the future, the many components that have gone into building EndBASIC and the EndBOX may be. Stay tuned!&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-06-17-endbox-journey-lessons.jpg" length="451795" type="image/jpeg"/></item><item><title>Whatever happened to sandboxfs?</title><link>https://jmmv.dev/2025/06/whatever-happened-to-sandboxfs.html</link><pubDate>Wed, 11 Jun 2025 10:00:00 -0400</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/06/whatever-happened-to-sandboxfs.html</guid><description>&lt;p>Back in 2017&amp;ndash;2020, while I was on the Blaze team at Google, I took on a 20% project that turned into a bit of an obsession: &lt;a href="https://github.com/bazelbuild/sandboxfs">sandboxfs&lt;/a>. Born out of my work supporting iOS development, it was my attempt to solve a persistent pain point that frustrated both internal teams and external users alike: Bazel&amp;rsquo;s &lt;a href="https://github.com/bazelbuild/bazel/issues/8230">poor sandboxing performance on macOS&lt;/a>.&lt;/p>
&lt;p>sandboxfs was a user-space file system designed to efficiently create virtual file hierarchies backed by real files&amp;mdash;a faster alternative to the &amp;ldquo;symlink forests&amp;rdquo; that Bazel uses to prepare per-action sandboxes. The idea was simple: if we could lower sandbox creation overhead, we could make Bazel&amp;rsquo;s sandboxing actually usable on macOS.&lt;/p>
&lt;p>Unfortunately, things didn&amp;rsquo;t play out as I dreamed. Today, sandboxfs is effectively abandoned, and macOS sandboxing performance remains an unsolved problem. In this post, I&amp;rsquo;ll walk you through why I built sandboxfs, what worked, what didn&amp;rsquo;t, and why&amp;mdash;despite its failure&amp;mdash;I still think the core idea holds promise.&lt;/p>
&lt;h1 id="sandboxing-101">Sandboxing 101&lt;/h1>
&lt;p>To understand how sandboxfs was intended to help with sandboxed build performance, we need to first dive into how Bazel runs build actions. For those unfamiliar with Bazel&amp;rsquo;s terminology, a &lt;em>build action&lt;/em> or &lt;em>action&lt;/em> is an individual build step, like a single compiler or linker execution.&lt;/p>
&lt;p>To run actions, Bazel uses &lt;a href="/2019/12/bazel-strategies.html">the strategies abstraction&lt;/a> to decouple action tracking in the build graph from how those actions are actually executed. The default strategy for local builds is the &lt;code>sandboxed&lt;/code> strategy, which isolates the processes that an action runs from the rest of the system. The goal is to make these processes behave in a deterministic manner.&lt;/p>
&lt;p>The sandboxed strategy achieves action isolation via two different mechanisms:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The use of kernel-level sandboxing features to restrict what the action can do (limit network access, limit reads and writes to parts of the file system, etc.). One such mechanism is &lt;a href="/2019/11/macos-sandbox-exec.html">sandbox-exec on macOS&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The creation of an execution root (or &lt;em>execroot&lt;/em>) in which the action runs. The execroot contains the minimum set of files required for the action to run: namely, the toolchain and the action inputs (source files, toolchain dependencies, etc.). One way to do this is via symlink forests.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="symlink-forests">Symlink forests&lt;/h1>
&lt;p>The default mechanism to create an execroot in Bazel is to leverage &lt;em>symlink forests&lt;/em>: file hierarchies that use symlinks to refer to files that live elsewhere.&lt;/p>
&lt;p>Creating a symlink forest is an operation that scales linearly with the number of files in it, and each symlink creation requires &lt;em>at least&lt;/em> two system calls: one to create the symlink and another to delete it when the sandbox is torn down. Plus symlink forests typically have complex directory structures, so there are extra &lt;code>mkdir&lt;/code> and &lt;code>rmdir&lt;/code> operations to handle all intermediate path components. Doing thousands of these operations may only take milliseconds, but&amp;hellip; overheads in action execution &lt;a href="/2018/04/bazel-xcode-locations-cache.html">quickly compound&lt;/a> and turn into visible build slowdowns.&lt;/p>
&lt;p>To illustrate what this means in practice, consider this target:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">cc_library&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;foo&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">srcs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;foo.c&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This target makes Bazel spawn one action to compile &lt;code>foo.c&lt;/code> into &lt;code>foo.o&lt;/code>. Said action needs to: run the compiler; read the &lt;code>foo.c&lt;/code> file; and access any system includes that &lt;code>foo.c&lt;/code> may reference. Thus, the sandbox used to run this action may look like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">.../sandbox/external/cc/bin/clang -&amp;gt; /usr/bin/clang
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.../sandbox/external/cc/include/stdio.h -&amp;gt; /usr/include/stdio.h
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.../sandbox/external/cc/include/stdlib.h -&amp;gt; /usr/include/stdlib.h
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.../sandbox/libfoo/foo.c -&amp;gt; /home/jmmv/sample/libfoo/foo.c
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Having this symlink forest in place, Bazel would run the equivalent of this command to perform the compilation:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">cd .../sandbox &amp;amp;&amp;amp; ./external/cc/bin/clang -nostdinc -I./external/cc/include -o libfoo/foo.o -c libfoo/foo.c
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When Bazel runs this, it expects that &lt;code>clang&lt;/code> will only access files in the &lt;code>external/cc/include&lt;/code> directory it previously created inside the sandbox. But because reality may not match expectations, Bazel wraps the command by whatever technology the host OS provides to enforce sandboxing.&lt;/p>
&lt;h1 id="motivation-for-sandboxfs">Motivation for sandboxfs&lt;/h1>
&lt;p>Creating symlink forests on an action basis was very expensive on macOS&amp;hellip; or so everyone said. When I arrived to the Blaze team, sandboxing had already been disabled by default on macOS builds and the rationale behind that was that &amp;ldquo;symlinks were too slow&amp;rdquo;.&lt;/p>
&lt;p>There were some flaws with this claim:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>It was impossible to prove. I ran many microbenchmarks to exercise symlink creations and deletions in large amounts and could never observe a significant performance degradation compared to Linux.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Building Bazel with itself, with sandboxing enabled, did not show any sort of substantial performance loss. Yet Bazel has relatively large C++ and Java actions in its own build so you would have expected to see &lt;em>something&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If macOS was truly bad at something as fundamental as &amp;ldquo;symlink management&amp;rdquo;, you&amp;rsquo;d imagine that &lt;em>someone else&lt;/em> would have found the issue and asked about it online (as it often happens with &lt;a href="https://www.youtube.com/watch?v=qbKGw8MQ0i8">misguided NTFS complaints&lt;/a>). But there were none to be found.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Still, I devised the sandboxfs plan right after developing &lt;a href="https://github.com/jmmv/sourcachefs">sourcachefs&lt;/a>&amp;mdash;another short-lived stint in file systems development&amp;mdash;and I charged ahead. I wanted sandboxfs to exist because it did solve an obvious scalability issue (issuing tens of thousands of syscalls per symlink forest creation is &lt;em>not&lt;/em> free) and because I wanted sanboxfs to exist &lt;a href="/2017/02/introducing-pkg_comp-2.0.html">for &lt;code>pkg_comp&lt;/code>&amp;rsquo;s own benefit&lt;/a>.&lt;/p>
&lt;h1 id="what-does-sandboxfs-do">What does sandboxfs do?&lt;/h1>
&lt;p>sandboxfs replaces symlink forests with a virtual file hierarchy that can be materialized in constant time. Here is the flow of operations:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Bazel generates an in-memory manifest of the execroot structure and which files are backed by which other files.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Bazel sends this manifest to sandboxfs via an RPC (which means we have at least one system call to send a message through a socket and a couple of context switches).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>sandboxfs updates its in-memory representation of the file system and exposes a new sandbox at its mount point.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Bazel runs the action in the new sandbox.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>sandboxfs catches all I/O in the sandbox and redirects it to the relevant real backing files.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>It&amp;rsquo;s this last point that presents the trade off behind sandboxfs, because sandboxfs doesn&amp;rsquo;t make all costs magically go away. Instead of paying the cost of setting up the sandbox upfront via many system calls, we pay a different cost over all reads and writes that go through the virtual file system. The original hypothesis was that this would be worth it, because most (but not all) build actions are &lt;em>not&lt;/em> I/O bound, and most build actions do &lt;em>not&lt;/em> access all the files that are mapped into their sandbox.&lt;/p>
&lt;p>Going back to the example from before, Bazel would send an RPC like this to sandboxfs:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;CreateSandbox&amp;#34;: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Path: &amp;#34;/736&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Mappings: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;external/cc/bin/clang&amp;#34;: &amp;#34;/usr/bin/clang&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;external/cc/include/stdio.h&amp;#34;: &amp;#34;/usr/include/stdio.h&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;external/cc/include/stdlib.h&amp;#34;: &amp;#34;/usr/include/stdlib.h&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;libfoo/foo.c&amp;#34;: &amp;#34;/home/jmmv/sample/libfoo/foo.c&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> },
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And this would cause the following file hierarchy to be immediately available under the mount point:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">.../sandboxfs/736/external/cc/bin/clang
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.../sandboxfs/736/external/cc/include/stdio.h
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.../sandboxfs/736/external/cc/include/stdlib.h
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.../sandboxfs/736/libfoo/foo.c
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that I did &lt;em>not&lt;/em> write what these files point to in this snippet because sandboxfs does &lt;em>not&lt;/em> use symlinks. sandboxfs exposes the files as if they were real files, and it does that to prevent tools from resolving symlinks and discovering sibling files they aren&amp;rsquo;t supposed to see. From the point of view of &lt;code>clang&lt;/code> when it runs, everything it sees under &lt;code>.../sandboxfs/736/external/cc/include/stdio.h&lt;/code> is &lt;em>a copy&lt;/em> of whatever is in &lt;code>/usr/include/stdio.h&lt;/code>.&lt;/p>
&lt;h1 id="what-went-well">What went well&lt;/h1>
&lt;p>Overall, sandboxfs was a fun exercise and a great journey to learn more about Rust, FUSE and file systems, and macOS internals:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>I got to learn Rust. I was lucky to find a random coworker at Google that offered to review my code, and his input was an invaluable learning resource for me.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>I got to learn about FUSE in quite a bit of detail. I had already played with it before, but by working on sandboxfs, I had to debug some gnarly problems.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>I got to experience rewriting pre-existing Go code in Rust (because the original sandboxfs implementation was in Go). This was an enlightening exercise because, as I tried to convert the code &amp;ldquo;verbatim&amp;rdquo;, I discovered many subtle concurrency bugs and data races that Rust just didn&amp;rsquo;t let me write.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The initial performance evaluation of using sandboxfs for real iOS builds &lt;a href="https://blog.bazel.build/2018/04/13/preliminary-sandboxfs-support.html">showed promise&lt;/a>: I observed that a specific iOS app &amp;ldquo;only&amp;rdquo; got a 55% performance penalty when using sandboxfs instead of the 270% penalty it got from symlink forests. A good win, but insufficient to justify enabling sandboxing by default.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="what-went-wrong">What went wrong&lt;/h1>
&lt;p>Many things really. Let&amp;rsquo;s start with wrong assumptions:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Symlink forest creation may not have been the biggest problem in sandboxing performance. As I mentioned in the opening, microbenchmarking this area of macOS didn&amp;rsquo;t show obvious slowdowns and building Bazel with itself didn&amp;rsquo;t show major performance differences with and without sandboxing. But iOS builds suffered massively from sandboxing, and the problem was elsewhere: the Objective C and Swift compilers cache persistent state on disk, and sandboxing was preventing such state from actually being persisted.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The need for sandboxing on interactive builds was questionable. Yes, it&amp;rsquo;d have been neat to have it, but in practice, the benefits are little: if your CI builds are powered by remote execution, which tends to happen when you use Bazel, then the implicit sandboxing of remote execution gives you almost all protections that you&amp;rsquo;d get from using sandboxing.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>There were also implementation problems:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The original implementation of sandboxfs was written in Go, and I hit performance issues with the way &lt;a href="https://github.com/bazil/fuse">bazil/fuse&lt;/a> dealt with FUSE operations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The previous was fixed by rewriting sandboxfs in Rust, but then I hit performance problems with the JSON-based RPC interface that sandboxfs had grown in a rush. Fixing this properly required a deep redesign to use path compression and to bypass JSON altogether. But I didn&amp;rsquo;t get to this because&amp;hellip;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="/2020/01/osxfuse-hardlinks-dladdr.html">Kernel bugs / limitations&lt;/a> in OSXFUSE erased the possibility of implementing a critical performance optimization.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>And then I also hit unexpected changes in the ecosystem:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Apple &lt;a href="https://support.apple.com/en-ca/guide/deployment/depa5fb8376f/web">deprecated kernel extensions&lt;/a>, making the use of FUSE really convoluted and its future uncertain. Apple provided alternate APIs to implement file systems in user space, but those were designed for iCloud-style services and were/are not suitable for sandboxfs.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>At around the same time in 2019, &lt;a href="https://colatkinson.site/macos/fuse/2019/09/29/osxfuse/">OSXFUSE went closed source&lt;/a>. This meant that relying on it for any future work was not well-advised. There were still code dumps for older versions, but that was not something I was able to maintain.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Because of the previous two, I would have had to expose the sandboxfs virtual file system over NFSv4 instead of FUSE. &lt;a href="https://github.com/buildbarn/bb-clientd">Buildbarn&amp;rsquo;s bb-clientd&lt;/a> provides a dual FUSE/NFSv4 implementation, which proves that this is technically doable, but adding an NFSv4 frontend to sandboxfs meant having to rewrite it from scratch. Plus I&amp;rsquo;m not sure we&amp;rsquo;d have gotten good-enough performance if we went this route.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>At that point in mid-2019, given the other problems illustrated above&amp;hellip; I had no interest nor time to rewrite sandboxfs &amp;ldquo;correctly&amp;rdquo; (remember, this was a 20% project at first, which unsurprisingly turned into an 120% project). It&amp;rsquo;d have been nice to do though, because &amp;ldquo;now I know how to do it right&amp;rdquo;.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="is-sandboxfs-needed">Is sandboxfs needed?&lt;/h1>
&lt;p>I still believe that Bazel needs something like sandboxfs for efficient sandboxed builds. As I mentioned earlier, creating symlink forests does not scale for action execution, and with ever-growing toolchain sizes, the problem is getting worse over time. However, the benefits of local sandboxing are unclear if you are already using remote execution.&lt;/p>
&lt;p>That said, people keep complaining about poor Bazel sandboxing performance on macOS, which means there still is a clear user need to make this better. And I&amp;rsquo;m not convinced the various &amp;ldquo;workarounds&amp;rdquo; that have been tried in this area (like reusing sandboxes) are sound designs nor that they can actually deliver on their promise.&lt;/p>
&lt;p>In my case&amp;hellip; I don&amp;rsquo;t run Bazel on Mac anymore at work. What&amp;rsquo;s more: I do not even use a Mac for personal reasons these days, which means my ulterior motive to use sandboxfs in &lt;code>pkg_comp&lt;/code> is gone. But! If you wanted to redesign sandboxfs from scratch, let&amp;rsquo;s talk!&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-06-11-sandboxfs-cover-concept.png" length="7119929" type="image/jpeg"/></item><item><title>Beginning 3D printing</title><link>https://jmmv.dev/2025/05/beginning-3d-printing.html</link><pubDate>Wed, 28 May 2025 09:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/05/beginning-3d-printing.html</guid><description>&lt;p>Hello readers and sorry for the 2-month radio silence. I&amp;rsquo;ve been pretty busy at work, traveling during school breaks, hacking on EndBASIC when time permitted, and&amp;hellip; as of two weeks ago&amp;hellip; tinkering with 3D printing as a complete beginner. So, today, I&amp;rsquo;d like to walk you through the latter because it has been a really fun and rewarding journey, albeit frustrating at times.&lt;/p>
&lt;p>You&amp;rsquo;d think that to use a 3D printer, you&amp;rsquo;d design a 3D model and then&amp;hellip; just&amp;hellip; send it to the printer? That&amp;rsquo;s almost true, but it ignores the realities of producing a physical object from an &amp;ldquo;abstract&amp;rdquo; model: when designing such a model, you need to take into account the limitations of 3D printing and you need to translate your model into something the 3D printer can understand via a process called &lt;em>slicing&lt;/em>.&lt;/p>
&lt;p>Let&amp;rsquo;s take a brief peek at all of these steps. I&amp;rsquo;ll assume you are a complete beginner like I am. The pictures I&amp;rsquo;ll show are all for a &amp;ldquo;first project&amp;rdquo; I did to remake the bars of a bird cage I have, as the birds had fully destroyed the previous ones.&lt;/p>
&lt;h1 id="step-1-modeling">Step 1: Modeling&lt;/h1>
&lt;p>The very first step in printing a 3D object is to create the model of what you want to print, of course. You might think that this is trivial, but there are two difficulties: the first lies in choosing and using the software, and the second lies in the physical constraints of 3D printing.&lt;/p>
&lt;p>As for the software part, you&amp;rsquo;ll need a CAD program, and there are many to choose from. Here are the ones I considered:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://www.freecad.org/">&lt;strong>FreeCAD&lt;/strong>&lt;/a> is &lt;em>the&lt;/em> free and open source solution. This is the first program I reached for given my preferences to favor free software but&amp;hellip; oh my: if you have ever thought that the &lt;a href="https://www.gimp.org/">GIMP&lt;/a>&amp;rsquo;s UI was difficult, you are in for a shock here. FreeCAD&amp;rsquo;s UI is not beginner friendly &lt;em>at all&lt;/em> and it&amp;rsquo;s also not high-DPI friendly: the buttons that show up in my monitor are &lt;em>tiny&lt;/em>, which brings a new meaning to hunt-and-peck. It seems extremely comprehensive though.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-05-28-freecad.png" />
&lt;figcaption>Simple FreeCAD project showing the design of a bar for a bird cage.&lt;/figcaption>
&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.autodesk.com/products/fusion-360/overview">&lt;strong>Fusion 360&lt;/strong>&lt;/a> is Autodesk&amp;rsquo;s answer to 3D modeling. This is a product I did not know about: I had never done &amp;ldquo;Computer Assisted Design&amp;rdquo; before, and the only times I heard of this term were in the context of AutoCAD by the same company, so I was a little surprised to see that they have another flagship brand for 3D design. As it turns out, Fusion 360 is free for non-commercial use and for hobbyist use if your revenue is less than 1K a year. I chose to steer clear of this product because I did not want to be bound by these terms &lt;em>and&lt;/em> I did not want to be tied to Windows or macOS.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.tinkercad.com/">&lt;strong>TinkerCAD&lt;/strong>&lt;/a> is another product from Autodesk, but this one is completely free and available as a web application. TinkerCAD is really well made and it is beginner friendly: after just a couple of minutes (literally), I was up and running designing my first model, and I have watched my kid come up with cool objects on his own with close to zero instructions. Unfortunately, as I made progress in my designs, I started suffering from its simplicity and by now I regret not having spent the time to learn FreeCAD from the get go.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-05-28-tinkercad.png" />
&lt;figcaption>Simple TinkerCAD project showing the design of a bar for a bird cage.&lt;/figcaption>
&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://openscad.org/">&lt;strong>OpenSCAD&lt;/strong>&lt;/a> is a scriptable CAD application where you write code to generate your model. Interestingly, I only came across this program because KDE&amp;rsquo;s Discover app mentioned it to me when I searched for &amp;ldquo;CAD&amp;rdquo;, not because I saw it recommended in any 3D printing-related forums. If you have ever used &lt;a href="https://github.com/POV-Ray/povray">POV-Ray&lt;/a> before, you know what this is about, and to be honest, the idea behind scripting the models sounds really tempting. But that&amp;rsquo;s where I left it.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>There are several more options out there so go explore them if none of these satisfy you. My personal suggestion is that you start with TinkerCAD to quickly get something out of your printer and scratch your itch. But, as soon as you get into designing anything &amp;ldquo;moderately complex&amp;rdquo;, that you watch a couple of introductory videos for FreeCAD to rip the band-aid off and use a real application. I&amp;rsquo;ve started doing that now and the &amp;ldquo;parametric&amp;rdquo; aspects of FreeCAD make me feel much more confident that my creations will work out and that they&amp;rsquo;ll not be messed up by me touching &amp;ldquo;the wrong mouse button&amp;rdquo;.&lt;/p>
&lt;p>With software out of the way, let&amp;rsquo;s move to the fact that 3D models are just that: conceptual models that only exist on the computer. When you want to bring those to reality, you need to account for the constraints that 3D printing brings. Here are some:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Layered plastic deposition.&lt;/strong> This concept is &lt;em>the&lt;/em> key to designing something you can actually print. A 3D printer works by melting &lt;em>filament&lt;/em> (a long string of plastic) and depositing such plastic horizontally on top of another surface. Objects are printed layer by layer, starting from the layer that touches the bed and moving &lt;em>up&lt;/em> the Z axis. Which means that&amp;hellip; some shapes are impossible to print! If your model has any overhang larger than maybe a couple millimeters, you can&amp;rsquo;t print it&amp;mdash;unless you add superfluous support structures that need to be removed later.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Colors&amp;hellip; or lack thereof.&lt;/strong> While it is certainly possible to print objects with multiple colors on them, the printer add-on to auto-switch colors is pretty expensive, and even if you buy that, you&amp;rsquo;ll likely be bound to a limited set (4, maybe 8) anyway. This means you have to design your model as separate pieces and perform some post-processing if you need multiple colors. You &lt;em>can&lt;/em> combine different colors in one print if they are isolated to different layers though&amp;mdash;but as you can imagine, manually switching colors half-way through a print is going to be annoying.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Warping.&lt;/strong> Matter shrinks as it cools, and you may end up in the situation that your print shrinks and warps as it cools down. This has happened to me a few times already and it was obviously annoying and not something I was expecting. You need to be aware that this can happen and design your model accordingly. I&amp;rsquo;ve seen various suggestions online but haven&amp;rsquo;t put them in practice yet, so I have nothing to suggest here.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>These constraints are just the very minimum. I&amp;rsquo;ll leave you with this excellent 80-minute guide on &lt;a href="https://blog.rahix.de/design-for-3d-printing/">designing for 3D printing&lt;/a> written by Rahix, which covers these topics and more to try to get to a good print on the first try.&lt;/p>
&lt;h1 id="step-2-slicing">Step 2: Slicing&lt;/h1>
&lt;p>Let&amp;rsquo;s say you are done creating your 3D model. Can you send it to the printer? No! The printer doesn&amp;rsquo;t know anything about &amp;ldquo;3D models&amp;rdquo;: it only knows about &lt;a href="https://en.wikipedia.org/wiki/Logo_(programming_language)">Logo&lt;/a>-like instructions&amp;mdash;known as G-Code&amp;mdash;that tell it how to operate on a layer by layer basis. The process of converting your 3D model to G-Code is called &lt;em>slicing&lt;/em> and is performed by a &lt;em>slicer&lt;/em> application.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-05-28-slicer-model.png" />
&lt;figcaption>PrusaSlicer model view showing the imported bird cage bar model (in orange) with auto-generated support structures (in green).&lt;/figcaption>
&lt;/figure>
&lt;p>The slicer takes the model as an input, &amp;ldquo;slices&amp;rdquo; through it on the horizontal plane to generate very fine layers, and then produces G-Code to make the printer operate the &lt;em>extruder&lt;/em> (the word for the part that melts filament and deposits it on the printing plane) across the plane of every layer. The output of the slicer is a G-Code file which contains such instructions in detail, and &lt;em>this&lt;/em> is the file that can be fed to the printer.&lt;/p>
&lt;p>This slicing step is very interesting and is also where you&amp;rsquo;ll typically mess things up (assuming you got a 3D printable design in the first place) because of the myriad parameters that exist.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-05-28-slicer-settings.png" />
&lt;figcaption>PrusaSlicer settings view in Expert Mode. There are &lt;i>a lot&lt;/i> of settings.&lt;/figcaption>
&lt;/figure>
&lt;p>During slicing you&amp;rsquo;ll do things like:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Laying out your model on the printing bed, possibly combining multiple objects to print them in one go and rotating them so that they can be printed.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Adjusting settings like the infill, which tells the printer how much plastic to use in the &amp;ldquo;inner&amp;rdquo; parts of the object: more infill means a sturdier object, but also a more expensive and slower to print object.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Asking the slicer to auto-generate a brim (an extra support structure on the base layer that increases bed adhesion), to add support structures for overhangs, or to add &amp;ldquo;mouse ears&amp;rdquo; to help with adhesion.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Choosing the type of filament to use and its properties.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Selecting the right printer (because the G-Code instructions are printer-specific, as you can imagine).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Configuring whether you want to switch colors half-way through the print or not.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>And a long list of etceteras. The nice thing is that the slicer detects various problematic conditions and offers to resolve them before sending the output to the printer&amp;mdash;but the bad thing is that it doesn&amp;rsquo;t detect everything, and some of the choices it makes are maybe-not-so-great. For example, if you ask the slicer to add support structures for overhangs, it may generate structures that you don&amp;rsquo;t like or that are harder to remove later on, whereas if you manually adjust the model to contain such structures, you have more control over the results.&lt;/p>
&lt;p>As for which pieces of software exist for slicing, every printer comes with its own slicer software. In my case, I&amp;rsquo;ve been using &lt;a href="https://github.com/prusa3d/PrusaSlicer">PrusaSlicer&lt;/a> which is the one that matches my printer and is open source. And because PrusaSlicer is open source&amp;hellip; you can imagine that other companies have taken it as the basis for their own printers, like Bambu Lab has done with their &lt;a href="https://bambulab.com/en-us/download/studio">Bambu Studio&lt;/a>.&lt;/p>
&lt;h1 id="step-3-printing">Step 3: Printing&lt;/h1>
&lt;p>And finally, we come to the printing process itself. Once you send the G-Code to the printer, the printer starts by heating up the extruder and the bed. You need a hot extruder to melt the filament, and you need a hot bed to help the filament attach to the printing surface. The printer then performs &lt;em>mesh bed leveling&lt;/em> (which not all printers do) to understand subtle variations in the height of the bed across its surface. And then the printer starts moving the extruder on the XY plane to generate the object one layer at a time. It is fascinating to watch; look:&lt;/p>
&lt;figure>
&lt;video width="100%" controls>
&lt;source src="/images/2025-05-28-prusa-printing.mp4" type="video/mp4">
&lt;/video>
&lt;figcaption>Prusa i3 MK3S+ printing one of the bird cage bars shown in the project above.&lt;/figcaption>
&lt;/figure>
&lt;p>But&amp;hellip; how do you send the G-Code to the printer? Well, it depends on the printer. If you choose to go the &lt;a href="https://bambulab.com/">Bambu Lab&lt;/a> route, which is &amp;ldquo;the Apple of 3D printers&amp;rdquo; as a coworker put it to me (hey Daniel!), it&amp;rsquo;s simple: you click a button from their slicing app and boom, the printer starts working. No need to worry about file transfers and no need to worry about calibration steps; it just works. And in fact, if you look for recommendations online, most people will point you towards choosing one of these printers:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://amzn.to/4kfvKy8">Bambu Lab A1 Mini&lt;/a>: Maximum print volume of 180 x 180 x 180 mm.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://amzn.to/4kHCGE5">Bambu Lab A1&lt;/a>: Maximum print volume of 256 x 256 x 256 mm.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>But do you know &lt;em>how&lt;/em> Bambu Lab&amp;rsquo;s magic operation happens? Via a cloud service, &lt;em>&amp;ldquo;of course&amp;rdquo;&lt;/em>. And if the cloud service is down, good luck printing: from what I could find, it seems like these printers cannot operate without a network connection. And if the printer requires a cloud service, then you also face all the usual privacy and security (or lack thereof) problems, with possibly some risky ones (malicious G-Code trying to make the printer malfunction, maybe?).&lt;/p>
&lt;p>So, what are the alternatives? Well, there are a ton of them. Two machines from other vendors that pop up in almost all reviews are:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://amzn.to/3HeKwGI">Prusa MK4S&lt;/a>: This is the &amp;ldquo;entry level&amp;rdquo; machine from &lt;a href="https://www.prusa3d.com/">Prusa&lt;/a>, another big brand in this space with similar price points to the well-regarded Bambu Lab machines.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://amzn.to/3Fx7w35">Ender 3 V3&lt;/a>: This is a much more affordable printer and comes from &lt;a href="https://www.creality.com/">Creality&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Which one to pick? As a beginner, it&amp;rsquo;s difficult. I read many reviews online and, as I mention above, most people suggested to &amp;ldquo;just&amp;rdquo; choose Bambu Lab for its simplicity and beginner-friendliness to achieve good quality results. These reviewers highlighted that other machines require a lot of manual tinkering (which actually made them more appetizing to me) and also warned to stay clear of Creality due to quality and safety issues. And if you research deeper, you&amp;rsquo;ll start to realize that the way to &amp;ldquo;level up&amp;rdquo; in 3D printing is to build your own printer while 3D-printing some of its own pieces.&lt;/p>
&lt;p>In the end, I chose to go the Prusa route, but the high prices put me off: after all, I&amp;rsquo;m just getting started and I do not need to make a huge investment in a &amp;ldquo;hobby&amp;rdquo; that may not last, so I got a second-hand, lightly-used &lt;a href="https://amzn.to/4dxTD1c">Prusa i3 MK3S+&lt;/a> for a fraction of the price of a new one. And then the surprises started: the printer has &lt;em>zero&lt;/em> network connectivity. This was a bit unexpected (I somehow assumed it&amp;rsquo;d offer local-only network printing), but in the end turned out to be &lt;em>great&lt;/em> because this means that there is zero cloud garbage involved in the printing process. The printer just has an SD card slot and a USB port, so I plugged the latter into a computer running PrusaSlicer and&amp;hellip; nothing. PrusaSlicer did not have any option to actually &lt;em>print&lt;/em> to the physically-attached printer. Weird.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-05-28-prusa-and-mac-pro.jpg" />
&lt;figcaption>Pursa i3 MK3S+ next to the Mac Pro 2013 controlling it.&lt;/figcaption>
&lt;/figure>
&lt;p>As it turns out, you need a print &lt;em>server&lt;/em> to actually control the machine from its USB port. Researching this topic online will almost certainly convince you that you need &lt;a href="https://github.com/guysoft/OctoPi">OctoPi&lt;/a> running on a Raspberry Pi in order to print. But&amp;hellip; a Pi is just a computer, so whatever OctoPi does can also be done on a Linux machine&amp;mdash;the Mac Pro I had already connected to the printer in the picture right above. And indeed that&amp;rsquo;s the case: once I installed &lt;a href="https://octoprint.org/">OctoPrint&lt;/a>, I could connect to the printer and drive it. (What&amp;rsquo;s more, it &lt;em>is&lt;/em> possible to add a &amp;ldquo;physical printer&amp;rdquo; to the PrusaSlicer, but all PrusaSlicer will do is embed the print server&amp;rsquo;s web interface.)&lt;/p>
&lt;figure>
&lt;img src="/images/2025-05-28-octoprint.png" class="with-border" />
&lt;figcaption>PrusaSlicer printer view connected to the OctoPrint server.&lt;/figcaption>
&lt;/figure>
&lt;p>OctoPrint itself is &amp;ldquo;the CUPS of 3D printing&amp;rdquo;. It&amp;rsquo;s a piece of software that knows how to send the G-Code to the printer via its USB connection, but it&amp;rsquo;s also a system that queues print jobs, provides monitoring and G-Code inspection features, allows for timelapse recording via a webcam, and much more. It feels overkill to be honest, but it does the job and there don&amp;rsquo;t seem to be any simpler alternatives, so that&amp;rsquo;s what it is.&lt;/p>
&lt;p>The very last thing to touch on regarding the printing process are the filament materials. The basic filament type is PLA, and it seems like it&amp;rsquo;s the easiest one to get started with. There are alternatives of different quality and properties out there for different applications, but that&amp;rsquo;s a world I haven&amp;rsquo;t explored yet.&lt;/p>
&lt;hr>
&lt;p>And with that, you should now have the very basic knowledge to start creating your own objects and feel like a Real Engineer (like I did). Keep in mind that you don&amp;rsquo;t actually need to &lt;em>own&lt;/em> a 3D printer though: there are on-demand print services available that will ship the prints back to you for cheap&amp;mdash;but there is no getting around to learning CAD modeling within the constraints of 3D printing. I&amp;rsquo;d also recommend playing with the slicer software to understand the implications of certain choices in the model regarding printing limitations (the need for support structures and the like) and print times. In the end, I&amp;rsquo;m happy I got my own printer because of the various trial-and-error iterations I went through before getting some decent prints out.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-05-28-bird-cage-bar.jpg" />
&lt;figcaption>Finished project of the bird cage bars.&lt;/figcaption>
&lt;/figure></description><enclosure url="https://jmmv.dev/images/2025-05-28-prusa-box.jpg" length="3411105" type="image/jpeg"/></item><item><title>The next generation of Bazel builds</title><link>https://jmmv.dev/2025/03/bazel-next-generation.html</link><pubDate>Mon, 24 Mar 2025 08:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/03/bazel-next-generation.html</guid><description>&lt;p>Today marks the 10th anniversary of &lt;a href="https://blog.engflow.com/2024/10/01/birth-of-the-bazel/">Bazel&amp;rsquo;s public announcement&lt;/a> so this is the perfect moment to reflect on what the next generation of build systems in the Bazel ecosystem may look like.&lt;/p>
&lt;p>I write this with the inspiration that comes from attending &lt;a href="https://www.linkedin.com/feed/update/urn:li:activity:7295871444343734272/">the first ever conference on Buildbarn&lt;/a>, one of the many remote execution systems for Bazel. In the conference, Ed Schouten, the creator of &lt;a href="https://github.com/buildbarn">Buildbarn&lt;/a>, presented Bonanza: a skunkworks reimagination of Bazel for truly large builds.&lt;/p>
&lt;p>In this article, I want to dive into what Bonanza is and what similar projects to &amp;ldquo;replace Bazel&amp;rdquo; have existed. To get there though, we need to start first with a critique of the current implementation of Bazel.&lt;/p>
&lt;h1 id="problems-scaling-up">Problems scaling up&lt;/h1>
&lt;p>The predecessor to Bazel, Blaze, is a build system designed at Google for Google&amp;rsquo;s monorepo scale. Blaze grew over the years assuming:&lt;/p>
&lt;ul>
&lt;li>that every engineer had a beefy workstation under their desk;&lt;/li>
&lt;li>that remote execution was expected to be used by default;&lt;/li>
&lt;li>that the remote execution cluster was reachable through a fast and low latency network; and&lt;/li>
&lt;li>that each office had physical hardware hosting a local cache of remote build artifacts.&lt;/li>
&lt;/ul>
&lt;p>These assumptions allowed Blaze to &amp;ldquo;scale up&amp;rdquo; to the very large codebase that Google builds, but they came with some downsides.&lt;/p>
&lt;p>One consequence of these assumptions is that the Bazel process&amp;mdash;confusingly named the &amp;ldquo;Bazel server&amp;rdquo;&amp;mdash;that runs on your machine is very resource hungry. The reason is that this process has to scan the source tree to understand the dependency graph and has to coordinate thousands of RPCs against a remote cluster&amp;mdash;two operations that aren&amp;rsquo;t cheap. What&amp;rsquo;s worse is that the Bazel server process is stateful: at start up, Bazel goes through the expensive steps of computing the analysis graph from disk and, to prevent redoing this work in every build, Bazel keeps this graph in its in-memory &amp;ldquo;analysis cache&amp;rdquo;.&lt;/p>
&lt;p>&lt;a href="https://bazel.build/advanced/performance/iteration-speed">The analysis cache is fragile.&lt;/a> The Bazel server process may auto-restart, and certain flags used to control the build cause the cache to be discarded. These are not rare flags, no: these include basic flags like &lt;code>-c&lt;/code> to change the compilation mode from debug to release, among many others. Cache discards are very intrusive to user workflows because an iterative build that would have taken a second now takes maybe thirty, for example.&lt;/p>
&lt;p>This user experience degradation makes Bazel&amp;rsquo;s front-page claim of being fast hard to believe. Bazel is really fast at running gigantic builds from scratch and it is really efficient when executing incremental builds. But the problem is that &amp;ldquo;truly incremental builds&amp;rdquo; are a rarity, so you end up paying the re-analysis cost many more times than is necessary. If you run Bazel in a CI environment, you know that these costs are far from negligible because every single Bazel process invocation on a fresh CI node can take &lt;em>minutes&lt;/em> to &amp;ldquo;warm up&amp;rdquo;.&lt;/p>
&lt;h1 id="problems-scaling-down">Problems scaling down&lt;/h1>
&lt;p>There is also the other side of the coin, which is that Bazel does not scale &lt;em>down&lt;/em> very well. This was one of my &lt;a href="/2015/04/on-bazel-and-open-source.html">original critiques&lt;/a> when Bazel went open source in 2015: at that time, I really wished for a declarative build system like Bazel to replace the mess that was and is Make plus the GNU Autotools, but the fact that Bazel was written in Java meant that it would never do this (mostly for non-technical reasons).&lt;/p>
&lt;p>Regardless, &lt;a href="/2016/01/joining-blaze-team.html">I &lt;em>did&lt;/em> join the Blaze team&lt;/a> after that, and I spent most of my time coercing Blaze and Bazel to run nicely on &amp;ldquo;small&amp;rdquo; laptop computers. I succeded in some areas, but it was a losing battle: Java had certain deficiencies that prevent implementing &lt;em>lean&lt;/em> software. &lt;a href="https://wiki.openjdk.org/display/loom/Main">Project Loom&lt;/a> and &lt;a href="https://en.wikipedia.org/wiki/Project_Valhalla_(Java_language)">Project Valhalla&lt;/a> promise to bring the necessary features to Java, but these features aren&amp;rsquo;t quite there yet&amp;mdash;and even when they are, retrofitting these into Bazel will be a very hard feat.&lt;/p>
&lt;p>In any case. Bazel works, and it works nicely for many use cases, but it lives in this limbo state where it isn&amp;rsquo;t awesome for very large builds and it isn&amp;rsquo;t awesome for very small builds either. So, let&amp;rsquo;s look at the former: how do we make Bazel awesome for humongous builds? By lifting it in its entirety to the cloud.&lt;/p>
&lt;h1 id="enter-bonanza">Enter Bonanza&lt;/h1>
&lt;p>Bonanza is Ed&amp;rsquo;s playground for a new build system: a build system that takes remote execution to the limit. Where Bazel is only capable of shipping individual build actions to the cloud, Bonanza uses the cloud for &lt;em>everything&lt;/em>, including external dependency handling, build graph construction and iteration, and more.&lt;/p>
&lt;p>To understand what Bonanza brings to the table in the context of hugely scalable builds, let&amp;rsquo;s distill the salient points that Ed highlighted in his &lt;a href="https://docs.google.com/presentation/d/1uh6CxvvziQunw55e_bs1Juz3jfaiE-QJVs2DCfeMeTw/edit#slide=id.g339c289dd60_1_29">&amp;ldquo;Bonanza in a nutshell&amp;rdquo;&lt;/a> slide from his conference presentation (recording coming soon):&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Bonanza can only execute build actions remotely.&lt;/strong> There is no support for local execution, which makes the build driver (the process that runs on your machine) simpler and eliminates all sorts of inconsistencies that show up when mixing local and remote execution. Bazel&amp;rsquo;s &lt;a href="/2019/12/bazel-strategies.html">execution strategies&lt;/a> tend to enforce hermeticity, but they don&amp;rsquo;t always succeed because of sandboxing limitations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Bonanza performs analysis remotely.&lt;/strong> When traditional Bazel is configured to execute all actions remotely, the Bazel server process is essentially a driver that constructs and walks a graph of nodes. This &lt;em>in-memory&lt;/em> graph is known as &lt;a href="https://bazel.build/reference/skyframe">Skyframe&lt;/a> and is used to represent &lt;em>and execute&lt;/em> a Bazel build. Bonanza lifts the same graph theory from the Bazel server process, puts it into a remote cluster, and relies on a distributed persistent cache to store the graph&amp;rsquo;s nodes. The consequence of storing the graph in a distributed storage system is that, all of a sudden, &lt;em>all&lt;/em> builds become incremental. There is no more &amp;ldquo;cold build&amp;rdquo; effect like the one you see with Bazel when you lose the analysis cache.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Bonanza runs repo rules remotely.&lt;/strong> Repo rules are what Bazel uses to interact with out-of-tree dependencies, and they can do things like download Git repositories, toolchain binaries, or detect what compiler exists in the system. What you should know is that Blaze &lt;em>did not&lt;/em> and &lt;em>does not&lt;/em> have repo rules nor support for workspaces because Google uses a strict monorepo. Both the repo rules and the workspace were bolted-on additions to Blaze when it was open-sourced as Bazel, and it shows: these features do not integrate cleanly with the rest of Bazel&amp;rsquo;s build model, and they have been clunky for years. Bonanza fixes these issues with a cleaner design.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Bonanza encrypts data in transit and at rest.&lt;/strong> Bonanza brings to life some of the features discussed for the Remote Execution v3 protocol, which never saw the light of day, and encryption is one of them. By encrypting all data that flows through the system, Bonanza can enforce provenance guarantees if you control the action executors. This is important because it allows security-conscious companies to easily trust using &lt;a href="https://bazel.build/community/remote-execution-services">remote build service providers&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Bonanza only supports rules written in Starlark.&lt;/strong> When Bazel launched, it included support for &lt;a href="https://github.com/bazelbuild/starlark">Starlark&lt;/a>: a new extensibility language with which to write build logic in. Unfortunately, for historical reasons, Bazel&amp;rsquo;s core still included Java-native implementations of the most important and complex rules: namely, C++, Java and protobuf. Google has been chasing the dream of externalizing all rule implementations into Starlark for the last 10 years, and only in Bazel 8 they &lt;em>mostly&lt;/em> have achieved this goal. Bonanza starts with a clean design that requires build logic to be written in Starlark, and it pushes this to the limit: &lt;a href="https://github.com/buildbarn/bonanza/blob/472f8e9917e8ce64c21e365e178b5bb2941865bc/starlark/builtins_core/exports.bzl">almost everything&lt;/a>, including &lt;a href="https://github.com/buildbarn/bonanza/blob/472f8e9917e8ce64c21e365e178b5bb2941865bc/starlark/bazel_tools/command_line_option/BUILD.bazel">flags&lt;/a>, is Starlark.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Bonanza aims to be Bazel compatible.&lt;/strong> Of the modern build systems that use a functional evaluation model like Bazel, only Bazel has been able to grow a significant community around it. This means that the ecosystem of tools and rules, as well as critical features like good IDE support, is thriving in Bazel whereas this cannot be said of other systems. Bonanza makes the right choice of being Bazel compatible so that it can reuse this huge ecosystem. Anyone willing to evaluate Bonanza will be able to do so with relative ease.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>When you combine all of these points, you have a build system where the client process on your development machine or on CI is thin: all the client has to do is upload the project state to the remote execution cluster, which in the common case will involve &lt;em>just&lt;/em> uploading modified source files. From there, the remote cluster computes the delta of what you uploaded versus any previously-built artifacts and reevaluates the minimum set of graph nodes to produce the desired results.&lt;/p>
&lt;p>Are your hopes up yet? Hopefully so! But beware that Bonanza is &lt;em>just&lt;/em> a proof of concept for now. The &lt;a href="https://github.com/buildbarn/bonanza">current implementation&lt;/a> shows that all of the ideas above are feasible and it can fully evaluate the complex &lt;a href="https://github.com/buildbarn/bb-storage">bb-storage project&lt;/a> from scratch&amp;mdash;but it doesn&amp;rsquo;t yet provide the necessary features to &lt;em>execute&lt;/em> the build. Ed appreciates PRs though!&lt;/p>
&lt;h1 id="meanwhile-at-google">Meanwhile, at Google&lt;/h1>
&lt;p>My time at Google is now long behind as I left almost five years ago, but back then there were two distinct efforts that attempted to tackle the scalability issues described in this article. (I can&amp;rsquo;t name names because they were never public, but if you probe ChatGPT to see if it knows about these efforts, it somehow knows specific details.)&lt;/p>
&lt;p>One such effort was to make Blaze &amp;ldquo;scale up&amp;rdquo; to handle even larger builds by treating them all as incremental. The idea was to persist the analysis graph in a distributed storage system so that Blaze would never have to recompute it from scratch. This design still kept a relatively fat Blaze process on the client machine, but it is quite similar to what Bonanza does. Google had advantages over Bonanza in terms of simplicity because, as I mentioned earlier, Blaze works in a pure monorepo and does &lt;em>not&lt;/em> have to worry about repo rules.&lt;/p>
&lt;p>The other such effort was to make Blaze &amp;ldquo;scale down&amp;rdquo; by exploring a rewrite in Go. This rewrite was carefully crafted to optimize memory layouts, avoiding unnecessary pointer chasing (which was impossible to avoid in Java). The results of this experiment proved that Blaze could be made to analyze large portions of Google&amp;rsquo;s build graph in just a fraction of the time, without any sort of analysis caching or significant startup penalties. Unfortunately, this rewrite was way ahead of its time: the important rulesets required to build Google&amp;rsquo;s codebase were still implemented inside of Blaze as Java code, so this experimental build system couldn&amp;rsquo;t do anything useful outside of Go builds.&lt;/p>
&lt;h1 id="meanwhile-at-meta">Meanwhile, at Meta&lt;/h1>
&lt;p>My knowledge of Meta&amp;rsquo;s build system is limited, but almost two years ago, Meta released &lt;a href="https://buck2.build/">Buck 2&lt;/a>, a complete reimplementation of their original Bazel-inspired build system. This reimplementation &lt;a href="https://buck2.build/docs/about/why/">checked most of the boxes&lt;/a> for what I thought a &amp;ldquo;Bazel done right&amp;rdquo; would look like:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Buck 2 is written in a real systems language (Rust).&lt;/strong> As explained earlier, I had originally criticised Java&amp;rsquo;s choice as one of Bazel&amp;rsquo;s weaknesses. It turns out Meta realized this same thing because Buck 1 had also been written in Java and they chose to go the risky full-rewrite route to fix it. (To be fair, you need to understand that Java had been a reasonable choice back then: when both Blaze and Buck 1 were originally designed, C++11&amp;mdash;possibly the only reasonable edition of C++&amp;mdash;didn&amp;rsquo;t even exist.)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Buck 2 is completely language agnostic.&lt;/strong> Its core build engine does not have any knowledge of the languages it can build, and all language support is provided via Starlark extensions. This stems from learning about earlier design mistakes of both Blaze and Buck 1. Meta chose to address this as part of the Rust rewrite, whereas Google has been addressing it incrementally.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Buck 2 has first-class support for virtual file systems&lt;/strong>. These are a necessity when supporting very large codebases and when integrating with remote build systems, but are also completely optional. Blaze also had support for these, but not Bazel.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>At launch, I was excited and eager to give Buck 2 a try, but then the disappointment came in: as much as it walks and quacks like Bazel due to its use of Starlark&amp;hellip; the API that Buck 2 exports to define rules is &lt;em>not compatible&lt;/em> with Bazel&amp;rsquo;s. This means that Buck 2 cannot be used in existing Bazel codebases, so the ability to evaluate its merits in a real codebase is&amp;hellip; insurmountable. In my mind, this made Buck 2 dead on arrival, and it&amp;rsquo;s yet to be seen if Meta will be able to grow a significant public ecosystem around it.&lt;/p>
&lt;p>In any case, I do not have any experience with Buck 2 because of the previous, so I cannot speak to its ability to scale either up or down. And this is why I wrote this section: to highlight that being Bazel-compatible is critical in this day and age if you want to have a chance at replacing a modern system like Bazel. Bonanza &lt;em>is&lt;/em> Bazel-compatible so it has a chance of demonstrating its value with ease.&lt;/p>
&lt;h1 id="what-lies-ahead">What lies ahead&lt;/h1>
&lt;p>If you ask me, it seems impossible to come up with a single build system that can satisfy the wishes of tiny open-source projects that long for a lean and clean build system and that can satisfy the versatility and scale requirements of vast corporate codebases.&lt;/p>
&lt;p>Bazel-the-implementation tries to appeal to both and falls short, yet Bazel-the-ecosystem provides the lingua franca of what those implementations need to support.&lt;/p>
&lt;p>My personal belief is that &lt;em>we need two build systems&lt;/em> that speak the same protocol (Starlark and Bazel&amp;rsquo;s build API) so that users can interchangeably choose whichever one works best for their use case:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>On the one hand, we need a massively scalable build system that does all of the work in the cloud. This is to support building monorepos, to support super-efficient CI runs, and to support &amp;ldquo;headless&amp;rdquo; builds like those offered by hosted VSCode instances. Bonanza seems to have the right ideas and the right people behind it to fulfill this niche.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>On the other hand, we need a tiny build system that does all of the work locally and that can be used by the myriad of open-source projects that the industry relies on. This system has to be written in Rust (oops, I said it) with minimal dependencies and be kept lean and fast so that IDEs can communicate with it quickly. This is a niche that is not fulfilled by anyone right now and that my mind keeps coming to; it&amp;rsquo;d be fun to create this project given &lt;a href="/2022/05/remembering-buildtool.html">my last failed attempt&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>The time for these next-generation Bazel-compatible build systems is &lt;em>now&lt;/em>. Google has spent the last 10 years Starlark-ifying Bazel, making the core execution engine replaceable. We are reaching a point where the vast majority of the build logic can be written in Starlark as Bonanza proves, and thus we should be able to have different build &lt;em>tools&lt;/em> that implement the same build &lt;em>system&lt;/em> for different use cases.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-03-24-laptop-vs-datacenter.jpg" length="525451" type="image/jpeg"/></item><item><title>Bazel at Snowflake two years in</title><link>https://jmmv.dev/2025/03/bazel-at-snowflake-two-years-in.html</link><pubDate>Fri, 14 Mar 2025 18:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/03/bazel-at-snowflake-two-years-in.html</guid><description>&lt;p>Two and a half years ago, I &lt;a href="/2022/10/bye-microsoft-hi-snowflake.html">joined Snowflake&lt;/a> to help their mission of migrating to Bazel. I spent the first year of this period as an Individual Contributor (IC) diving deep into the migration tasks, and then I took over the Tech Lead (TL) role of the team to see the project through completion.&lt;/p>
&lt;p>This week, we publicly announced that we completed our migration to Bazel for the largest part of our codebase and we provided details on our journey. I did not publish that article here for obvious reasons, so&amp;hellip; today&amp;rsquo;s entry is going to be a light one: all I want to do is point you at our announcement as well as the various &lt;em>other&lt;/em> related articles that came before it.&lt;/p>
&lt;p>Don&amp;rsquo;t despair though: those articles, including the announcement, are all full of technical details&amp;mdash;just like the kind of content you expect to receive from Blog System/5. So, even if this piece is light, you have enough reading material for the weekend via the links below.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2023/03/addressing-bazel-ooms.html">&amp;ldquo;Addressing Bazel OOMs&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>March 16th, 2023&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2023-03-16-header.jpg" />
&lt;/figure>
&lt;p>This was the very first article that we in the Engineering Systems organization&amp;mdash;previously known as Developer Productivity Engineering&amp;mdash;wrote publicly about our work. Me writing it was no coincidence as I was the one advocating for more openness about the cool stuff we were doing. Yes, I missed blogging about Bazel &lt;a href="/tags/bazel/index.html">as I had done in the years prior&lt;/a>.&lt;/p>
&lt;p>In this article about Out-Of-Memory (OOM) conditions, I covered the very interesting problem of trying to fit Bazel builds into limited laptop resources. This was dj-vu for me: back when I was in the Blaze team at Google, I owned the same problem of making Blaze, a tool that had grown assuming massive workstations, run decently on machines with limited resources.&lt;/p>
&lt;p>The problems were technically challenging and worth talking about, hence this article. In it, I covered three issues: preventing Bazel from spawning too many memory-hungry compilers and linkers at once; making nested builds behave nicely; and tuning Bazel to drive a large number of remote tasks with limited memory resources.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2023/10/analyzing-ooms-in-intellij-with-bazel.html">&amp;ldquo;Analyzing OOMs in IntelliJ with Bazel&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>October 6th, 2023&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-07-12gb-heap-no-discard.png" />
&lt;/figure>
&lt;p>Our saga dealing with OOMs was arduous and long, which you can tell by the time gap between the previous article and this one.&lt;/p>
&lt;p>In this piece, I looked at how IntelliJ itself was running into memory limits, which resulted in the IDE and its container VM freezing during normal operation. The result of this work was careful tuning of the Bazel project settings to make it fit within reasonable limits, but the interesting part&amp;mdash;and the one described here&amp;mdash;was the process to arrive to those findings.&lt;/p>
&lt;p>Not too long after I wrote this, we pivoted away from constrained laptop builds to cloud-based workstations, which made all OOM conditions vanish at the expense of using much more RAM (maybe &lt;em>too much&lt;/em> RAM, but alas&amp;hellip; it&amp;rsquo;s cheap). Stay tuned for an upcoming article (not from me this time!) on this topic.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="/2023/10/build-farm-visualizations.html">&amp;ldquo;Build farm visualizations&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>October 20th, 2023&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2023-10-20-old-farm-io-issues-trace.png" />
&lt;/figure>
&lt;p>As part of our migration to Bazel, we didn&amp;rsquo;t just convert our build from one tool to another. We also decided to deploy our own remote execution cluster from the get go based on &lt;a href="https://github.com/buildbarn">Buildbarn&lt;/a> which&amp;hellip; gave us its own set of problems. Buildbarn&amp;rsquo;s architecture is straightforward in paper, but there are a ton of knobs to control how it runs. Making it scale to the huge volume of traffic we experience was not an easy feat.&lt;/p>
&lt;p>One specific problem we faced was overall poor performance of our cluster, which was eventually root-caused to our remote execution workers using slow local storage volumes. This issue had escaped us for a while, and it wasn&amp;rsquo;t until I wrote a tool to &lt;em>visualize&lt;/em> the cluster behavior that it didn&amp;rsquo;t become obvious. From there, the solution was easy.&lt;/p>
&lt;p>Wanna know more? We are hosting a 1-day conference &lt;em>next week&lt;/em> on Buildbarn specifically. &lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSeG4We59b6labcH77JOiblk7F3MRi8LH6SbjIrFTNCBYXeJnA/viewform">See the schedule and sign up&lt;/a> if you can make it!&lt;/p>
&lt;hr>
&lt;p>&lt;strong>&lt;a href="https://www.snowflake.com/en/engineering-blog/fast-reliable-builds-snowflake-bazel/">&amp;ldquo;Fast and Reliable Builds at Snowflake with Bazel&amp;rdquo;&lt;/a>&lt;/strong>&lt;br/>
&lt;em>March 13th, 2025&lt;/em>&lt;/p>
&lt;figure>
&lt;img src="/images/2025-03-13-snowflake-blog-header.png" />
&lt;/figure>
&lt;p>And finally, the crown jewel. This is the official article published just yesterday where I present the 2-year journey of our migration. In it, I explain the challanges that we faced with our C++ and Java codebases specifically, the choices behind our use of remote execution, and the path we took to production. I conclude with a glimpse on what lies ahead of us.&lt;/p>
&lt;hr>
&lt;p>That&amp;rsquo;s all for today. I promised it would be short :)&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-03-14-bazel-at-snowflake-cover.jpg" length="792369" type="image/jpeg"/></item><item><title>Hardware discovery: ACPI &amp; Device Tree</title><link>https://jmmv.dev/2025/02/hardware-autoconfiguration.html</link><pubDate>Fri, 28 Feb 2025 16:15:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/02/hardware-autoconfiguration.html</guid><description>&lt;p>If you grew up in the PC scene during the 1980s or early 1990s, you know how painful it was to get hardware to work. And if you did not witness that (lucky you) here is how it went: every piece of hardware in your PC&amp;mdash;say a sound card or a network card&amp;mdash;had physical switches or jumpers in it. These switches configured the card&amp;rsquo;s I/O address space, interrupts, and DMA ports, and you had to be careful to select values that did not overlap with other cards.&lt;/p>
&lt;p>But that wasn&amp;rsquo;t all. Once you had configured the physical switches, you had to tell the operating system and/or software &lt;em>which&lt;/em> specific cards you had and how you had configured them. Remember &lt;code>SET BLASTER=A220 I5 D1 H5&lt;/code>? This DOS environment variable told programs which specific Sound Blaster you had installed and which I/O settings you had selected via its jumpers.&lt;/p>
&lt;p>Not really fun. It was common to have hardware conflicts that yielded random lock-ups, and thus &lt;a href="https://wiki.osdev.org/ISA">ISA &amp;ldquo;Plug and Play&amp;rdquo;&lt;/a>, or PnP for short, was born in the early 1990s&amp;mdash;a protocol for the legacy ISA bus to enumerate its devices and to configure their settings via software. Fast-forward to today&amp;rsquo;s scene where we just attach devices to external USB connectors and things &amp;ldquo;magically work&amp;rdquo;.&lt;/p>
&lt;p>But how? How does the kernel know which physical devices exist and how does it know which of the many device drivers it contains can handle each device? Enter the world of hardware discovery.&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h1 id="hardware-topology">Hardware topology&lt;/h1>
&lt;p>When you learn about the &lt;a href="https://en.wikipedia.org/wiki/Von_Neumann_architecture">Von Neumann architecture&lt;/a> in school, you are typically told that there is a CPU, a chunk of memory, and&amp;hellip; &amp;ldquo;I/O devices&amp;rdquo;. The CPU and memory portions are where all the focus is put and the I/O devices portion is always &amp;ldquo;left to the reader&amp;rdquo;. However, there is &lt;em>a lot&lt;/em> of stuff happening in that nebulous cloud.&lt;/p>
&lt;p>The first question that arises is: what&amp;rsquo;s in that I/O cloud? Well, take a look:&lt;/p>
&lt;figure>
&lt;img src="/images/2025-02-28-w2k-device-manager.png" />
&lt;figcaption>The Windows 2000 Device Manager showing the devices by their connection, not by their type. I've chosen to show you this configuration of a virtual machine instead of what a current Windows 11 system shows because the older view is simpler to digest.&lt;/figcaption>
&lt;/figure>
&lt;p>Whoa, that&amp;rsquo;s a lot of stuff, but we can classify the items in the &amp;ldquo;nebulous cloud of I/O devices&amp;rdquo; into two categories:&lt;/p>
&lt;ul>
&lt;li>The devices themselves, obviously.&lt;/li>
&lt;li>The busses that connect those devices to the CPU.&lt;/li>
&lt;/ul>
&lt;p>Both are important: you might have a fancy keyboard with extra keys that requires a special driver, and this keyboard might come in PS/2 and USB versions. The driver for the keyboard may be the same for each version, but the &amp;ldquo;glue&amp;rdquo; that attaches this keyboard to either bus is different, and the way the kernel can tell whether the keyboard is attached to one port or another also differs.&lt;/p>
&lt;p>So how does the kernel know how to find hardware without tons of repeated code for every bus, you ask? It does so via its knowledge of the hardware topology. Just above, I showed you Windows&amp;rsquo; view of this, but for the rest of this article, I&amp;rsquo;ll use the BSD internals (and NetBSD specifically) because that&amp;rsquo;s what I know best. Don&amp;rsquo;t let that put you off though: all kernels have to do something similar and the differences among them are likely not meaningful.&lt;/p>
&lt;p>Here is a little snippet of the &lt;a href="https://github.com/NetBSD/src/blob/a6998e32a89571344dc476036a4af47672d183f0/sys/arch/amd64/conf/GENERIC">default NetBSD kernel configuration file for the amd64 platform&lt;/a>. This snippet lays out the topology of serial ports in the PC and the busses in which they may appear:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">pci* at mainbus? bus ?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pcib* at pci? dev ? function ?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">puc* at pci? dev ? function ?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">com* at puc? port ?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">isa0 at mainbus?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">isa0 at pcib?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">com0 at isa? port 0x3f8 irq 4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">com1 at isa? port 0x2f8 irq 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">acpi0 at mainbus0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">com* at acpi?
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Daunting if you have never seen anything like this, I know, but let me translate this to a diagram:&lt;/p>
&lt;figure>
&lt;img src="/images/2025-02-28-com-device-tree.png" />
&lt;figcaption>Representation of how the &lt;tt>com&lt;/tt> device is expected to appear under various busses according to the kernel configuration file.&lt;/figcaption>
&lt;/figure>
&lt;p>Much clearer in picture form, right? What this chunk of configuration does is tell the kernel the places where the &lt;code>com&lt;/code> driver can find serial ports. We have a chunk that says that &lt;code>com0&lt;/code> and &lt;code>com1&lt;/code> can appear on the ISA bus at &lt;em>specific&lt;/em> I/O addresses and interrupts, and in turn that the ISA bus may be a directly-addressable physical bus (&lt;code>isa0 at mainbus?&lt;/code>) and/or an ISA bus exposed via a PCI bridge (&lt;code>isa0 at pcib?&lt;/code>). Then, we have additional entries telling us that the serial ports can also be configured via ACPI (&lt;code>com* at acpi?&lt;/code>), and that the serial ports may exist on expansion cards (&lt;code>com* at puc?&lt;/code>) providing communication ports via the PCI bus (&lt;code>puc* at pci?&lt;/code>).&lt;/p>
&lt;p>The problem is: the kernel configuration tells us &lt;em>what may exist&lt;/em>, not &lt;em>what actually exists&lt;/em> on a machine. In a sense, the configuration file &amp;ldquo;wires&amp;rdquo; the code of the device drivers like &lt;code>com&lt;/code> so that they can find devices that appear under the &lt;code>isa&lt;/code>, &lt;code>pci&lt;/code>, or &lt;code>acpi&lt;/code> busses. But the kernel must still, at runtime, check and see where the devices actually are. How does that happen?&lt;/p>
&lt;h1 id="hardware-auto-configuration">Hardware auto-configuration&lt;/h1>
&lt;p>To answer the question of how the kernel discovers which hardware is present and where it is, let&amp;rsquo;s dissect NetBSD&amp;rsquo;s &lt;a href="https://man.netbsd.org/autoconf.9">autoconf(9)&lt;/a> manual page:&lt;/p>
&lt;blockquote>
&lt;p>Autoconfiguration is the process of matching hardware devices with an appropriate device driver. In its most basic form, autoconfiguration consists of the recursive process of finding and attaching all devices on a bus, including other busses.&lt;/p>&lt;/blockquote>
&lt;p>From this paragraph, we can extract the following: the kernel contains a collection of device drivers (like the &lt;code>com&lt;/code> presented earlier). Device drivers are just code that knows how to interact with specific devices, but the &amp;ldquo;location&amp;rdquo; of these devices in the hardware topology may vary (the &amp;ldquo;bindings&amp;rdquo; to &lt;code>isa&lt;/code>, &lt;code>puc&lt;/code>, and &lt;code>acpi&lt;/code> in the earlier example). Moving on:&lt;/p>
&lt;blockquote>
&lt;p>The autoconfiguration framework supports direct configuration where the bus driver can determine the devices present. The autoconfiguration framework also supports indirect configuration where the drivers must probe the bus looking for the presence of a device. Direct configuration is preferred since it can find hardware regardless of the presence of proper drivers.&lt;/p>&lt;/blockquote>
&lt;p>Direct and indirect configuration. Hmm. This sounds like the PnP story, and it kinda does. See, pay close attention to these two lines from the earlier snippet:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">com0 at isa? port 0x3f8 irq 4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">com1 at isa? port 0x2f8 irq 3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>These are the BSD equivalent of the &lt;code>SET BLASTER=A220 I5 D1 H5&lt;/code> command for DOS I mentioned in the introduction: they tell the kernel which precise addresses and interrupts to use for the two standard PC serial ports &lt;em>if an ISA bus is present&lt;/em>.&lt;/p>
&lt;p>But what about &lt;code>com* at puc?&lt;/code> and &lt;code>com* at acpi?&lt;/code>? These lines are neat because they do &lt;em>not&lt;/em> tell us, in advance, where to find the serial ports: we expect the kernel to discover those details at runtime so that we don&amp;rsquo;t have to recompile the kernel when the hardware changes. But even if these two look similar, they are quite different: the &lt;code>com* at puc?&lt;/code> is an indirect configuration entry: the &lt;code>puc&lt;/code> driver will have to probe the PCI bus for the presence of a communications card and, if one exists, tell the &lt;code>com&lt;/code> driver that it can attach to it. On the other hand, the &lt;code>com* at acpi?&lt;/code> entry is direct: the kernel will read the ACPI configuration (a static table) to know where the ports are and then use those details to configure the &lt;code>com&lt;/code> driver.&lt;/p>
&lt;p>Alright, so this raises &lt;em>another&lt;/em> question. What &lt;em>is&lt;/em> ACPI?&lt;/p>
&lt;h1 id="acpi">ACPI&lt;/h1>
&lt;p>ACPI, despite being declared with &lt;code>acpi0 at mainbus0&lt;/code> in a form similar to &lt;code>isa0 at mainbus?&lt;/code>, is &lt;em>not&lt;/em> a bus: ACPI does not physically connect devices to one another. To understand what ACPI does, we can start by realizing that it stands for &lt;a href="https://en.wikipedia.org/wiki/ACPI">Advanced Configuration and Power Interface&lt;/a> and then, quoting the Wikipedia article:&lt;/p>
&lt;blockquote>
&lt;p>Advanced Configuration and Power Interface (ACPI) is an open standard that operating systems can use to discover and configure computer hardware components, to perform power management (e.g. putting unused hardware components to sleep), auto configuration (e.g. Plug and Play and hot swapping), and status monitoring.&lt;/p>&lt;/blockquote>
&lt;p>ACPI is about configuration, and the kernel uses the ACPI tables, present in any modern PC, to find where devices are. To illustrate how this works, let&amp;rsquo;s look at the &lt;code>com* at acpi?&lt;/code> line. This line says that the serial port can be configured via ACPI if ACPI happens to have an entry for it. And you know, we can peek into the ACPI tables of a running machine to see what that might be:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl"># acpidump -dt | grep -A15 COM1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Device (COM1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Name (_HID, EisaId (&amp;#34;PNP0501&amp;#34;) /* 16550A-compatible COM Serial Port */) // _HID: Hardware ID
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Name (_UID, One) // _UID: Unique ID
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Name (_CRS, ResourceTemplate () // _CRS: Current Resource Settings
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> IO (Decode16,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0x03F8, // Range Minimum
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0x03F8, // Range Maximum
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0x01, // Alignment
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0x08, // Length
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> IRQNoFlags ()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {4}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> })
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>(Pro-tip: you can use &lt;code>acpidump&lt;/code> to extract the Windows license key bound to your machine, if any. I&amp;rsquo;ve needed to do this in the past to install Windows in a VM after replacing the host OS with FreeBSD.)&lt;/em>&lt;/p>
&lt;p>Voila. The ACPI tables provided by the system tell us a similar story to what the explicit &lt;code>com0 at isa?&lt;/code> entry did (and no surprise here because this is a legacy device): there is a serial port at base address 0x3f8 that uses interrupt 4. But also, this table tells us the hardware identifier for this entry: &lt;code>PNP0501&lt;/code>. Grepping through the NetBSD kernel code base for this identifier, we land on the &lt;a href="https://github.com/NetBSD/src/blob/caa9bad5633244c08bb86b00eab45f3d92882415/sys/dev/acpi/com_acpi.c#L60">&lt;code>dev/acpi/com_acpi.c&lt;/code>&lt;/a> file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="k">static&lt;/span> &lt;span class="k">const&lt;/span> &lt;span class="k">struct&lt;/span> &lt;span class="n">device_compatible_entry&lt;/span> &lt;span class="n">compat_data&lt;/span>&lt;span class="p">[]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cm">/* 16550A-compatible COM port */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span> &lt;span class="p">.&lt;/span>&lt;span class="n">compat&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;PNP0501&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">.&lt;/span>&lt;span class="n">value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">COM_TYPE_NORMAL&lt;/span> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="p">};&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>(Another pro-tip: master &lt;a href="https://github.com/BurntSushi/ripgrep">ripgrep&lt;/a>. Knowing how to find a needle in the haystack of a large code base will grant you super-powers among your coworkers. Being able to pinpoint where specifically to start an investigation based on a &amp;ldquo;random-looking&amp;rdquo; string is invaluable.)&lt;/em>&lt;/p>
&lt;p>Aha! This &lt;code>com_acpi.c&lt;/code> file provides the necessary glue to direct the generic serial port &lt;code>com&lt;/code> driver to the hardware via whatever the ACPI tables prescribe. From here, the kernel can proceed to &lt;em>attach&lt;/em> the driver to the device and connect the dots between the user-space &lt;code>/dev/ttyS0&lt;/code> interface to the physical serial port.&lt;/p>
&lt;h1 id="device-tree">Device Tree&lt;/h1>
&lt;p>In the world of embedded devices powered by SOCs&amp;mdash;&amp;quot;&lt;a href="https://en.wikipedia.org/wiki/System_on_a_chip">System on a Chip&lt;/a>&amp;quot;, a term that describes single chips that provide all functions to build a computer, ranging from the CPU to sound and network cards&amp;mdash;we don&amp;rsquo;t have ACPI tables. What we used to have instead was explicit code &lt;em>for every board/chip combination&lt;/em> that knew how to address the hardware in each SOC. Linux used to be a mess of half-baked and abandoned forks, each supporting a different board without hopes of unification into mainline due to the lack of generic interfaces.&lt;/p>
&lt;p>The &lt;a href="https://www.devicetree.org/">Device Tree&lt;/a> specification fixed this issue for the most part for architectures like aarch64. With Device Tree, each hardware or OS vendor provides a static table that describes the layout of a board&amp;rsquo;s hardware separately from the code of the kernel. Then, the kernel peeks into this table to know which devices exist and where they are in the machine layout, much like it does with ACPI.&lt;/p>
&lt;p>A big difference with ACPI, however, is that the kernel cannot query the Device Tree from the hardware because&amp;hellip; well, the Device Tree is external to the hardware. The kernel expects the Device Tree to &amp;ldquo;exist in memory&amp;rdquo; either because the kernel image &lt;em>embeds&lt;/em> the Device Tree for the target board or because the boot loader loads the Device Tree from disk and passes it to the kernel.&lt;/p>
&lt;p>Once the kernel has the Device Tree though, the hardware discovery process is similar to the one in ACPI: the kernel scans the Device Tree and looks for drivers that can attach to device nodes based on hardware identifiers. From the perspective of the kernel configuration, things look very similar between amd64 and aarch64. See this snippet from the &lt;a href="https://github.com/NetBSD/src/blob/a6998e32a89571344dc476036a4af47672d183f0/sys/arch/evbarm/conf/GENERIC64">generic kernel of the evbarm port&lt;/a>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">armfdt0 at root
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">simplebus* at fdt? pass 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">com* at fdt? pass 4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This configuration snippet tells the aarch64 kernel that a &lt;code>com&lt;/code> device may appear on &lt;code>fdt&lt;/code>, which stands for &amp;ldquo;Flat Device Tree&amp;rdquo;. In turn, &lt;code>armfdt0 at root&lt;/code> says that there is a specific driver named &lt;code>armfdt0&lt;/code> that provides access to the &lt;code>fdt&lt;/code> loaded by the boot loader on an ARM machine.&lt;/p>
&lt;p>We can inspect the Device Tree from the command line as the Device Tree is exposed via the same interface that OpenFirmware used due to its historical roots. For example, to fetch the portion of the Device Tree for the serial port on an aarch64 machine:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># ofctl serial1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">[&lt;/span>Caching &lt;span class="m">121&lt;/span> nodes and &lt;span class="m">781&lt;/span> properties&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">clocks 0000000e &lt;span class="m">00000000&lt;/span> ........ ........ ........
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">compatible 6272636d 2c62636d &lt;span class="m">32383335&lt;/span> 2d617578 &lt;span class="s2">&amp;#34;brcm,bcm2835-aux
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> 0010: 2d756172 7400.... ........ ........ -uart&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">interrupts &lt;span class="m">00000001&lt;/span> 0000001d ........ ........ ........
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">name &lt;span class="m">73657269&lt;/span> 616c00.. ........ ........ &lt;span class="s2">&amp;#34;serial&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">phandle 0000004c ........ ........ ........ ...L
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pinctrl-0 0000000f ........ ........ ........ ....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pinctrl-names &lt;span class="m">64656661&lt;/span> 756c7400 ........ ........ default.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">reg 7e215040 &lt;span class="m">00000040&lt;/span> ........ ........ ~!P@...@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">status 6f6b6179 00...... ........ ........ okay.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># &lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>A binary dump. OK, fine, we can intuit &lt;em>something&lt;/em> out of this, but it isn&amp;rsquo;t particularly clear. The problem here is that we are looking at the binary encoding of the Device Tree (the DTB). But the DTB is built from a set of corresponding source files (one or more DTS files), and if we look at the common &lt;a href="https://github.com/NetBSD/src/blob/caa9bad5633244c08bb86b00eab45f3d92882415/sys/external/gpl2/dts/dist/arch/arm/boot/dts/bcm283x.dtsi#L385">DTS for Broadcom 283x boards&lt;/a>, we find the following more-readable content:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">/ {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> aliases {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> /* ... */
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> serial1 = &amp;#34;/soc/serial@7e215040&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> };
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> soc {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> /* ... */
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> serial@7e215040 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> compatible = &amp;#34;brcm,bcm2835-aux-uart&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> reg = &amp;lt;0x7e215040 0x40&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> interrupts = &amp;lt;0x01 0x1d&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> clocks = &amp;lt;0x0e 0x00&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> status = &amp;#34;okay&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pinctrl-names = &amp;#34;default&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pinctrl-0 = &amp;lt;0x0f&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> phandle = &amp;lt;0x4c&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> };
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> };
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">};
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The detail to highlight here is the &lt;code>brcm,bcm2835-aux-uart&lt;/code> identifier. If we search for this in the code base with the ripgrep super-powers you gained earlier, we find the &lt;a href="https://github.com/NetBSD/src/blob/caa9bad5633244c08bb86b00eab45f3d92882415/sys/arch/arm/broadcom/bcm2835_com.c#L54">&lt;code>arch/arm/broadcom/bcm2835_com.c&lt;/code>&lt;/a> file, which contains:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="k">static&lt;/span> &lt;span class="k">const&lt;/span> &lt;span class="k">struct&lt;/span> &lt;span class="n">device_compatible_entry&lt;/span> &lt;span class="n">compat_data&lt;/span>&lt;span class="p">[]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span> &lt;span class="p">.&lt;/span>&lt;span class="n">compat&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;brcm,bcm2835-aux-uart&amp;#34;&lt;/span> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">DEVICE_COMPAT_EOL&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">};&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once again: we found the glue that connects a generic &lt;code>com&lt;/code> driver to a specific hardware device.&lt;/p>
&lt;h1 id="loading-dtbs-at-boot-time">Loading DTBs at boot time&lt;/h1>
&lt;p>Let&amp;rsquo;s dig a bit further though. I mentioned earlier that the boot loader is responsible for loading the Device Tree into memory and passing it to the kernel. How is that done? Well, it really depends on the specific machine you are dealing with. In here, I&amp;rsquo;m just going to &lt;em>very briefly&lt;/em> touch upon how the Raspberry Pi does it because that&amp;rsquo;s the specific non-PC hardware I have access to. And for this, I&amp;rsquo;ll take you through the investigative journey I took.&lt;/p>
&lt;p>The specific problem I faced was that NetBSD was &lt;em>not&lt;/em> able to discover the SPI bus even when I had enabled the right SPI driver in the kernel for my Raspberry Pi 3B. By that point, I was aware that DTBs existed and I suspected that something might be wrong with them, so my first instinct was to check and see what the DTB had to say about the SPI.&lt;/p>
&lt;p>Digging through the FAT partition of the disk image I was using, I found the &lt;code>dtb/broadcom/bcm2837-rpi-3-b.dtb&lt;/code> file&amp;mdash;the DTB for my specific board. The way the Raspberry Pi boot loader finds this file is by looking for a file matching the board&amp;rsquo;s own name (&lt;code>bcm2837-rpi-3-b.dtb&lt;/code>) in the location specified by the &lt;a href="https://www.raspberrypi.com/documentation/computers/config_txt.html#os_prefix">&lt;code>os_prefix&lt;/code> configuration property&lt;/a> in the &lt;code>config.txt&lt;/code> placed at the root of the FAT partition.&lt;/p>
&lt;p>Once I found that file and after learning about the &lt;code>dtc&lt;/code> tool (the Device Tree Compiler) which transforms DTS files into DTBs and vice versa, I could decompile the DTS:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">$ dtc -I dtb -O dts bcm2837-rpi-3-b.dtb -o bcm2837-rpi-3-b.dts
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">... various warnings ...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then, peeking into the decompiled DTS file, I found:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">spi@7e204000 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> compatible = &amp;#34;brcm,bcm2835-spi&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> reg = &amp;lt;0x7e204000 0x200&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> interrupts = &amp;lt;0x02 0x16&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> clocks = &amp;lt;0x06 0x14&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #address-cells = &amp;lt;0x01&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #size-cells = &amp;lt;0x00&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> status = &amp;#34;disabled&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> dmas = &amp;lt;0x0b 0x06 0x0b 0x07&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> dma-names = &amp;#34;tx\0rx&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> phandle = &amp;lt;0x49&amp;gt;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">};
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I verified that the SPI kernel driver recognized the &lt;code>brcm,bcm2835-spi&lt;/code> identifier just as we did earlier on for the serial port. And it did match, so I was puzzled for a moment.&lt;/p>
&lt;p>But then I noticed the innocuous &lt;code>status = &amp;quot;disabled&amp;quot;&lt;/code> line. Aha! The SPI device was disabled by default. I modified that line with &lt;code>status = &amp;quot;okay&amp;quot;&lt;/code> following what other entries in the DTS did, recompiled the DTS into the DTB:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">$ dtc -I dts -O dtb bcm2837-rpi-3-b.dts -o bcm2837-rpi-3-b.dtb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">... various warnings ...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;hellip; rebooted the board and&amp;hellip; voila!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl"># dmesg | grep spi
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ 1.000003] bcmspi0 at simplebus1: SPI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ 1.000003] bcmspi0: interrupting on icu irq 54
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ 1.000003] spi0 at bcmspi0: SPI bus
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The kernel successfully attached the SPI driver and the SPI bus started working, which in turn led to a multi-hour debugging session to make the EndBASIC ST7735S driver work&amp;mdash;but in the end it did.&lt;/p>
&lt;figure>
&lt;video width="100%" controls>
&lt;source src="/images/2025-02-28-rpi3-lcd-endbox.mp4" type="video/mp4">
&lt;/video>
&lt;figcaption>Demonstration of the "EndBASIC Dev Kit" box I'm working on, booting NetBSD, showing the EndBASIC console on a small LCD, and then running the Game of Life.&lt;/figcaption>
&lt;/figure>
&lt;p>Yes, there are nicer ways to do what I did here because the DTBs are provided by upstream and you should not be modifying them. What you should do instead is create a DTB overlay, which is a separate small DTB that &amp;ldquo;patches&amp;rdquo; the upstream DTB, and then tell the boot loader to process it via the &lt;code>dtoverlay&lt;/code> stanza in the &lt;code>config.txt&lt;/code> file. Details left to you, reader. Just beware that the Raspberry Pi boot loader is picky about file paths and &lt;a href="https://www.raspberrypi.com/documentation/computers/config_txt.html">the documentation is your friend&lt;/a> here.&lt;/p>
&lt;h1 id="how-do-acpi-and-device-tree-differ">How do ACPI and Device Tree differ?&lt;/h1>
&lt;p>Based on everything I told you about here, ACPI and Device Tree look oddly similar&amp;mdash;and that&amp;rsquo;s because they are! From the perspective of &lt;em>describing&lt;/em> hardware to the kernel, the two technologies are equivalent, but they differ for historical reasons. ACPI has its roots in APM, a PC technology, whereas Device Tree is based on &lt;a href="https://en.wikipedia.org/wiki/Open_Firmware">OpenFirmware&lt;/a>, a technology that originated at Sun Microsystems for its SPARC machines and that was later used by Apple on their PowerPC-based Macs.&lt;/p>
&lt;p>One difference between the two, though, is that ACPI does more than just describe hardware. ACPI provides a bunch of hardware-specific routines in a bytecode that the operating system can call into to manipulate the hardware. This is often maligned because ACPI introduces non-free and opaque blobs in the interaction between the operating system kernel and the hardware, but &lt;a href="https://mjg59.dreamwidth.org/68350.html">Matthew Garret has a great essay on why ACPI is necessary&lt;/a> and why it is better than all other alternatives, possibly including Device Tree.&lt;/p>
&lt;p>In any case, that&amp;rsquo;s all for today. I found this exercise of dealing with the Device Tree pretty fun and I thought I could share something interesting with you all. I intentionally omitted many details because the topic of hardware configuration is vast and tricky, but you can continue building your knowledge from the bits above and from the fabulous &lt;a href="https://wiki.osdev.org/">OSDev wiki&lt;/a>.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-02-28-jumpers.jpg" length="89630" type="image/jpeg"/></item><item><title>ioctls from Rust</title><link>https://jmmv.dev/2025/02/ioctls-rust.html</link><pubDate>Thu, 13 Feb 2025 09:00:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/02/ioctls-rust.html</guid><description>&lt;p>In Unix-like systems, &amp;ldquo;everything is a file and a file is defined as a byte stream you can &lt;code>open&lt;/code>, &lt;code>read&lt;/code> from, &lt;code>write&lt;/code> to, and ultimately &lt;code>close&lt;/code>&amp;rdquo;&amp;hellip; right? &lt;em>Right?&lt;/em> Well, not quite. It&amp;rsquo;s better to say &lt;em>file descriptors&lt;/em> provide access to almost every system that the kernel provides, but not that they can all be manipulated with the same quartet of system calls, nor that they all behave as byte streams.&lt;/p>
&lt;p>Because you see: network connections are manipulated via file descriptors indeed, but you don&amp;rsquo;t &lt;code>open&lt;/code> them: you &lt;code>bind&lt;/code>, &lt;code>listen&lt;/code>/&lt;code>accept&lt;/code> and/or &lt;code>connect&lt;/code> to them. And then you don&amp;rsquo;t &lt;code>read&lt;/code> from and &lt;code>write&lt;/code> to network connections: you somehow &lt;code>send&lt;/code> to and &lt;code>recv&lt;/code> from them. Device drivers are similar: yes, hardware devices are represented as &amp;ldquo;virtual files&amp;rdquo; in the &lt;code>/dev&lt;/code> hierarchy and many support &lt;code>read&lt;/code> and &lt;code>write&lt;/code>&amp;hellip; but these two system calls are not sufficient to access the breath of functionality that the hardware drivers provide. No, you need &lt;code>ioctl&lt;/code>.&lt;/p>
&lt;p>&lt;code>ioctl&lt;/code> is the poster child of the system call that breaks Unix&amp;rsquo;s &amp;ldquo;everything is a file&amp;rdquo; paradigm. &lt;code>ioctl&lt;/code> is the API that allows out-of-band communication with the kernel side of an open file descriptor. To see cool examples, &lt;a href="/2025/01/netbsd-graphics-wo-x11.html">refer back to my previous article&lt;/a> where I demonstrated how to drive graphics from the console without X11: in that post, we had to &lt;code>open&lt;/code> the console device, but then we had to use &lt;code>ioctl&lt;/code> to obtain the properties of the framebuffer, and then we had to &lt;code>mmap&lt;/code> the device&amp;rsquo;s content for direct access: no &lt;code>read&lt;/code>s nor &lt;code>write&lt;/code>s involved.&lt;/p>
&lt;p>All the code I showed you in that earlier post was written in C to keep the graphics article to-the-point, but the code I&amp;rsquo;m really working on is part of EndBASIC, and thus it is all Rust. And the thing is, &lt;code>ioctl&lt;/code>s are not easy to issue from Rust. In fact, after 7 years of Rust-ing, it&amp;rsquo;s the first time I&amp;rsquo;ve had to reach for &lt;code>unsafe&lt;/code> code blocks, and there was no good documentation on how to deal with &lt;code>ioctl&lt;/code>. So this posts aims to fix that by presenting what ways there are to call &lt;code>ioctl&lt;/code>s from Rust&amp;hellip; and, of course, diving a bit deeper into what &lt;code>ioctl&lt;/code>s actually &lt;em>are&lt;/em>.&lt;/p>
&lt;h1 id="our-target">Our target&lt;/h1>
&lt;p>For all examples below, I&amp;rsquo;ll be using a relatively simple &lt;code>ioctl&lt;/code> from NetBSD&amp;rsquo;s &lt;a href="https://man.netbsd.org/wsdisplay.4">wsdisplay(4)&lt;/a> driver. This API is available via the console device file, typically &lt;code>/dev/ttyE0&lt;/code>, and is named &lt;code>WSDISPLAYIO_GINFO&lt;/code>. Here is what the manual page has to say:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">The following ioctl(2) calls are provided by the wsdisplay driver or by
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">devices which use it. Their definitions are found in
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;dev/wscons/wsconsio.h&amp;gt;.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WSDISPLAYIO_GINFO (struct wsdisplay_fbinfo)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Retrieve basic information about a framebuffer display.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> The returned structure is as follows:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> struct wsdisplay_fbinfo {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> u_int height;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> u_int width;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> u_int depth;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> u_int cmsize;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> };
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> The height and width members are counted in pixels. The
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> depth member indicates the number of bits per pixel, and
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> cmsize indicates the number of color map entries accessible
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> through WSDISPLAYIO_GETCMAP and WSDISPLAYIO_PUTCMAP. This
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> call is likely to be unavailable on text-only displays.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Calling this API from a C program would be trivial and look like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;dev/wscons/wsconsio.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;ioctl.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// ... open `/dev/ttyE0` as fd ...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">struct&lt;/span> &lt;span class="n">wsdisplay_fbinfo&lt;/span> &lt;span class="n">fbi&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">ioctl&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fd&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">WSDISPLAYIO_GINFO&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">fbi&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// Handle error.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// fbi now contains the data returned by the kernel.
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The reason I&amp;rsquo;m picking &lt;code>WSDISPLAYIO_GINFO&lt;/code> specifically to talk about &lt;code>ioctl&lt;/code>s in this article is three-fold:&lt;/p>
&lt;ul>
&lt;li>it returns a small structure with &lt;a href="/2024/10/x86-64-programming-models.html">platform-dependent integers&lt;/a>, so the sample code in the article will be relatively short;&lt;/li>
&lt;li>it relies on platform-specific integer types, so we&amp;rsquo;ll have to account for that in Rust; and&lt;/li>
&lt;li>it is &amp;ldquo;rare enough&amp;rdquo; (we are talking about NetBSD after all) that it is not going to be supported by any of the common Rust crates like libc or nix, so we&amp;rsquo;ll have to do extra work to call it.&lt;/li>
&lt;/ul>
&lt;h1 id="what-is-an-ioctl-anyway">What is an ioctl anyway?&lt;/h1>
&lt;p>The manual page helpfully provides us a copy of the data structure returned by the &lt;code>ioctl&lt;/code>, and the BSD manual pages are typically &lt;em>awesome&lt;/em>, but it&amp;rsquo;s worth double-checking that the code snippet actually matches the code it documents. Peeking into &lt;code>/usr/include/dev/wscons/wsconsio.h&lt;/code> as the manual page directs us, we find:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="cm">/* Basic display information. Not applicable to all display types. */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">struct&lt;/span> &lt;span class="n">wsdisplay_fbinfo&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">u_int&lt;/span> &lt;span class="n">height&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="cm">/* height in pixels */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">u_int&lt;/span> &lt;span class="n">width&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="cm">/* width in pixels */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">u_int&lt;/span> &lt;span class="n">depth&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="cm">/* bits per pixel */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">u_int&lt;/span> &lt;span class="n">cmsize&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="cm">/* color map size (entries) */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">};&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#define WSDISPLAYIO_GINFO _IOR(&amp;#39;W&amp;#39;, 65, struct wsdisplay_fbinfo)
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>OK, great, the &lt;code>wsdisplay_fbinfo&lt;/code> structure perfectly aligns with the manual page contents. But what&amp;rsquo;s more interesting is the &lt;code>#define&lt;/code>, which says that &lt;code>WSDISPLAYIO_GINFO&lt;/code> is:&lt;/p>
&lt;ul>
&lt;li>an ioctl that &lt;em>reads&lt;/em> from the kernel (&lt;code>_IOR&lt;/code>),&lt;/li>
&lt;li>that invokes function number 65 from the &lt;code>W&lt;/code> class (which probably stands for &amp;ldquo;the &lt;em>W&lt;/em>scons device driver&amp;rdquo;), and&lt;/li>
&lt;li>that places the returned data into a structure of type &lt;code>wsdisplay_fbinfo&lt;/code> (not to be confused with &lt;code>wsdisplayio_fbinfo&lt;/code>).&lt;/li>
&lt;/ul>
&lt;p>In a way, this is just like any other function or system call, except that it&amp;rsquo;s not defined as such and is instead funneled through a single API. &lt;code>ioctl&lt;/code> is, therefore, &amp;ldquo;just&amp;rdquo; a grab bag of arbitrary functionality, and what can be invoked on a given file descriptor depends on what the file descriptor represents.&lt;/p>
&lt;p>The reasons for this design are historical and, of course, there could have been other options.&lt;/p>
&lt;p>For example: you know how regular files have an internal structure, right? The vast majority of file formats out there contain a header, which then specifies various sections within the file, which then contain data. The same could have been done with device drivers: their virtual files could have predefined some internal format such that, e.g. the &lt;code>wsdisplay_fbinfo&lt;/code> structure always appeared at offset 0x1000 of the virtual file. &lt;code>read&lt;/code> and &lt;code>write&lt;/code> would have been sufficient for this design, albeit you&amp;rsquo;d almost-certainly wanted to combine it with &lt;code>mmap&lt;/code> for more efficient access.&lt;/p>
&lt;p>Or another example: device drivers could have used an RPC-like mechanism where each write to the file descriptor is a &amp;ldquo;message&amp;rdquo; that requests a specific function, and that the kernel responds to with an answer. &lt;code>read&lt;/code> and &lt;code>write&lt;/code> would have been sufficient for this design.&lt;/p>
&lt;p>Or yet another example: the requests to the device driver could have been intermixed with the data, such that if the data contained a specific sequence, the kernel would invoke a function instead of processing data. Sounds crazy, right? But that&amp;rsquo;s what pseudo-terminals do: all those &lt;a href="https://en.wikipedia.org/wiki/ANSI_escape_code">control sequences&lt;/a> to change colors and the like are telling the terminal driver to do something special.&lt;/p>
&lt;p>In any case, these are all alternate designs and&amp;hellip; I&amp;rsquo;m sure they all live in some form or another in current systems. There is no consistency in how &lt;code>/dev&lt;/code> pseudo-files expose their behavior, and &lt;code>ioctl&lt;/code>s are just one of the options we have to deal with. So without further ado, let&amp;rsquo;s look at three different ways of calling these services from Rust.&lt;/p>
&lt;h1 id="option-1-nix">Option 1: nix&lt;/h1>
&lt;p>The first option to call an &lt;code>ioctl&lt;/code> from Rust is to leverage the neat &lt;a href="https://docs.rs/nix/">nix crate&lt;/a>, which provides idiomatic access to Unix primitives. This crate is not to be confused with NixOS, with which it has no relation.&lt;/p>
&lt;p>To use nix to invoke &lt;code>ioctl&lt;/code>s, we need to do two things.&lt;/p>
&lt;p>First, we need to define the data structure used by the &lt;code>ioctl&lt;/code>. In C, we would just &lt;code>#include &amp;lt;dev/wscons/wsconsio.h&amp;gt;&lt;/code>, but in Rust we don&amp;rsquo;t have access to the C-style headers. Instead, we have to do extra work to define the same memory layout of the C &lt;code>wsdisplay_fbinfo&lt;/code> structure, but in Rust:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">ffi&lt;/span>::&lt;span class="n">c_uint&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[repr(C)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">struct&lt;/span> &lt;span class="nc">WsDisplayFbInfo&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">height&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">width&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">depth&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">cmsize&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It is &lt;em>very important&lt;/em> to declare the structure as having a C representation so that its memory layout matches what the C compiler produces for the same structure. The kernel expects C semantics in its system call boundary, and we must adhere to that. Additionally, we must ensure that the types of each field match the C definitions. Rust only has fixed-size integer types like &lt;code>i16&lt;/code> and &lt;code>u32&lt;/code>, but C provides platform-dependent integer types like &lt;code>int&lt;/code> or &lt;code>unsigned long&lt;/code> and these are sometimes used in public kernel interfaces (a mistake, if you ask me). Fear not, though: the &lt;code>std::ffi&lt;/code> module provides aliases for those C types.&lt;/p>
&lt;p>And second, we have to do something unique to the nix crate: we have to define a wrapper function for the &lt;code>ioctl&lt;/code> so that we can invoke the &lt;code>ioctl&lt;/code> as if it were any other function. nix makes this very easy by providing macros that mimic the syntax of the C &lt;code>#define&lt;/code> we saw earlier on:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">nix&lt;/span>::&lt;span class="n">ioctl_read&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="fm">ioctl_read!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wsdisplayio_ginfo&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="sa">b&lt;/span>&lt;span class="sc">&amp;#39;W&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">65&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">WsDisplayFbInfo&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And with that, we are ready to put everything together in a fully-fledged program:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">ffi&lt;/span>::&lt;span class="n">c_uint&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">io&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">mem&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">os&lt;/span>::&lt;span class="n">fd&lt;/span>::&lt;span class="p">{&lt;/span>&lt;span class="n">AsRawFd&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">FromRawFd&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">OwnedFd&lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">nix&lt;/span>::&lt;span class="n">fcntl&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">nix&lt;/span>::&lt;span class="n">ioctl_read&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">nix&lt;/span>::&lt;span class="n">sys&lt;/span>::&lt;span class="n">stat&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[repr(C)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[derive(Debug)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[allow(unused)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">struct&lt;/span> &lt;span class="nc">WsDisplayFbInfo&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">height&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">width&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">depth&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">cmsize&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="fm">ioctl_read!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wsdisplayio_ginfo&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="sa">b&lt;/span>&lt;span class="sc">&amp;#39;W&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">65&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">WsDisplayFbInfo&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">fn&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>-&amp;gt; &lt;span class="nc">io&lt;/span>::&lt;span class="nb">Result&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">oflag&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fcntl&lt;/span>::&lt;span class="n">OFlag&lt;/span>::&lt;span class="n">empty&lt;/span>&lt;span class="p">();&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">oflag&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">insert&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fcntl&lt;/span>::&lt;span class="n">OFlag&lt;/span>::&lt;span class="no">O_RDWR&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">oflag&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">insert&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fcntl&lt;/span>::&lt;span class="n">OFlag&lt;/span>::&lt;span class="no">O_NONBLOCK&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">oflag&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">insert&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fcntl&lt;/span>::&lt;span class="n">OFlag&lt;/span>::&lt;span class="no">O_EXCL&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fd&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">raw&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">fcntl&lt;/span>::&lt;span class="n">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;/dev/ttyE0&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">oflag&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">stat&lt;/span>::&lt;span class="n">Mode&lt;/span>::&lt;span class="n">empty&lt;/span>&lt;span class="p">())&lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">unsafe&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">OwnedFd&lt;/span>::&lt;span class="n">from_raw_fd&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">raw&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fbi&lt;/span>: &lt;span class="nc">WsDisplayFbInfo&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">unsafe&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">fbi&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">mem&lt;/span>::&lt;span class="n">zeroed&lt;/span>&lt;span class="p">();&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">wsdisplayio_ginfo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fd&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">as_raw_fd&lt;/span>&lt;span class="p">(),&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fbi&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="n">unwrap&lt;/span>&lt;span class="p">();&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="fm">eprintln!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;fbinfo: &lt;/span>&lt;span class="si">{:?}&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fbi&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nb">Ok&lt;/span>&lt;span class="p">(())&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/ioctls-rust/nix/src/main.rs" type="text/plain">nix/src/main.rs&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>There is one surprising detail in this code though: if we went through the hassle of defining a wrapper function for &lt;code>WSDISPLAYIO_GINFO&lt;/code> via the idiomatic nix crate, and idiomatic nix usage doesn&amp;rsquo;t require &lt;code>unsafe&lt;/code> blocks&amp;hellip; why did we have to wrap the call to &lt;code>wsdisplayio_ginfo&lt;/code> in an &lt;code>unsafe&lt;/code> block? The reason may be that &lt;code>ioctl&lt;/code> can do &lt;em>whatever&lt;/em> to the running process and Rust needs to be over-conservative.&lt;/p>
&lt;p>In any case, the above is clean and it works. But&amp;hellip; using nix comes with a cost:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">$ cargo build
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Compiling libc v0.2.169
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Compiling cfg_aliases v0.2.1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Compiling bitflags v2.8.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Compiling cfg-if v1.0.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Compiling nix v0.29.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Compiling ioctls-rust-nix v0.1.0 (/home/jmmv/os/homepage/static/src/ioctls-rust/nix)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Finished `dev` profile [unoptimized + debuginfo] target(s) in 1.71s
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We have pulled 5 crates into the project just to open a file and invoke an &lt;code>ioctl&lt;/code>. Not a huge deal in this day and age but&amp;hellip; this contributes to the perception that the Rust ecosystem is a mess of bloated dependencies. Can we do differently?&lt;/p>
&lt;h1 id="option-2-libc">Option 2: libc&lt;/h1>
&lt;p>What if we bypassed nix altogether and invoked libc directly? After all, we can see that nix &lt;em>depends on&lt;/em> libc anyway, so we might as well use it at the expense of losing nix&amp;rsquo;s idiomatic representation of Unix&amp;rsquo;s interfaces.&lt;/p>
&lt;p>Sure, we can do that: we can invoke the &lt;code>libc::ioctl&lt;/code> function directly, which has this prototype:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="k">pub&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">fn&lt;/span> &lt;span class="nf">ioctl&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fd&lt;/span>: &lt;span class="nc">c_int&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">request&lt;/span>: &lt;span class="nc">Ioctl&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">..&lt;/span>&lt;span class="p">.)&lt;/span>&lt;span class="w"> &lt;/span>-&amp;gt; &lt;span class="nc">c_int&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Alright then: we need a file descriptor as the first argument, which we have. And then we need an &lt;code>Ioctl&lt;/code> as the second argument, which we&amp;hellip; wait, what is this &lt;code>Ioctl&lt;/code> type? If we look for its definition in the libc source code, we find that &lt;code>Ioctl&lt;/code> is an alias for an integer type (&lt;code>unsigned long&lt;/code> or &lt;code>int&lt;/code> depending on the platform), and this matches the C definition of &lt;code>ioctl&lt;/code>. OK, nothing special.&lt;/p>
&lt;p>But then&amp;hellip; what do we pass in this second argument? If we were writing C, we would use the &lt;code>WSDISPLAY_GINFO&lt;/code> constant, but we don&amp;rsquo;t have that in Rust because we don&amp;rsquo;t get access to the C header files. So what &lt;em>is&lt;/em> &lt;code>WSDISPLAY_GINFO&lt;/code>? Remember that we previously saw that it is defined as such:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#define WSDISPLAYIO_GINFO _IOR(&amp;#39;W&amp;#39;, 65, struct wsdisplay_fbinfo)
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;hellip; which doesn&amp;rsquo;t help us much at this point. But we can chase the definition of &lt;code>_IOR&lt;/code>, end up in &lt;code>/usr/include/sys/ioccom.h&lt;/code>, and see:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#define _IOC(inout, group, num, len) \
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp"> ((inout) | (((len) &amp;amp; IOCPARM_MASK) &amp;lt;&amp;lt; IOCPARM_SHIFT) | \
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp"> ((group) &amp;lt;&amp;lt; IOCGROUP_SHIFT) | (num))
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#define _IOR(g,n,t) _IOC(IOC_OUT, (g), (n), sizeof(t))
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Ugh. We are combining the various arguments to &lt;code>_IOR&lt;/code> into a number. This is hard to decipher by just reading the code, so we can ask the compiler to tell us the actual value of the constant instead:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;dev/wscons/wsconsio.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;stdio.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kt">int&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;%x&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">WSDISPLAYIO_GINFO&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And if we run the program, we get that &lt;code>WSDISPLAYIO_GINFO&lt;/code> is &lt;code>0x40105741&lt;/code>. Knowing that, it&amp;rsquo;s &lt;a href="https://en.wikipedia.org/wiki/Small_matter_of_programming">an SMOP&lt;/a> to call the &lt;code>ioctl&lt;/code> using the &lt;a href="https://docs.rs/libc/">libc crate&lt;/a> alone:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">ffi&lt;/span>::&lt;span class="p">{&lt;/span>&lt;span class="n">c_char&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">c_uint&lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">io&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">mem&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">os&lt;/span>::&lt;span class="n">fd&lt;/span>::&lt;span class="p">{&lt;/span>&lt;span class="n">AsRawFd&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">FromRawFd&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">OwnedFd&lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">const&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="no">WSDISPLAYIO_GINFO&lt;/span>: &lt;span class="kt">u64&lt;/span> &lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mh">0x40105741&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[repr(C)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[derive(Debug)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[allow(unused)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">struct&lt;/span> &lt;span class="nc">WsDisplayFbInfo&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">height&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">width&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">depth&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">cmsize&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">fn&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>-&amp;gt; &lt;span class="nc">io&lt;/span>::&lt;span class="nb">Result&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fd&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">unsafe&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="n">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;/dev/ttyE0&lt;/span>&lt;span class="se">\0&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">as_ptr&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="k">const&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">c_char&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="no">O_RDWR&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="no">O_NONBLOCK&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="no">O_EXCL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">if&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">==&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">return&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">Err&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">io&lt;/span>::&lt;span class="n">Error&lt;/span>::&lt;span class="n">last_os_error&lt;/span>&lt;span class="p">());&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">unsafe&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">OwnedFd&lt;/span>::&lt;span class="n">from_raw_fd&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fbi&lt;/span>: &lt;span class="nc">WsDisplayFbInfo&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">unsafe&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">fbi&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">mem&lt;/span>::&lt;span class="n">zeroed&lt;/span>&lt;span class="p">();&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="n">ioctl&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">fd&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">as_raw_fd&lt;/span>&lt;span class="p">(),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="no">WSDISPLAYIO_GINFO&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fbi&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">WsDisplayFbInfo&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">if&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">==&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">return&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">Err&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">io&lt;/span>::&lt;span class="n">Error&lt;/span>::&lt;span class="n">last_os_error&lt;/span>&lt;span class="p">());&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="fm">eprintln!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;fbinfo: &lt;/span>&lt;span class="si">{:?}&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fbi&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nb">Ok&lt;/span>&lt;span class="p">(())&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/ioctls-rust/libc/src/main.rs" type="text/plain">libc/src/main.rs&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>As you can see from this code snippet, we &lt;em>also&lt;/em> have to define the &lt;code>WsdisplayFbInfo&lt;/code> structure to match the kernel&amp;rsquo;s, so avoiding nix didn&amp;rsquo;t really make things simpler for us&amp;mdash;and in fact, it made them uglier because now we have to deal with libc&amp;rsquo;s oddities like raw C strings, global &lt;code>errno&lt;/code> values, and an opaque constant for the &lt;code>ioctl&lt;/code> number. Not great.&lt;/p>
&lt;h1 id="option-3-ffi">Option 3: FFI&lt;/h1>
&lt;p>Which makes one wonder&amp;hellip; can we avoid replicating the C interfaces in Rust and instead leverage the system-provided header files? Yes we can. Instead of trying to invoke the &lt;code>ioctl&lt;/code>s from Rust, we can invoke them via some custom C glue code. Rust is going to call into the system-provided libc &lt;em>anyway&lt;/em> when we invoke a system call, so we might as well switch to C a bit &amp;ldquo;earlier&amp;rdquo;.&lt;/p>
&lt;p>The idea in this case, as in any other computing problem, is to add a layer of abstraction: instead of dealing with the kernel-defined data structures from Rust, we define &lt;em>our own&lt;/em> structures and APIs to detach the Rust world from the C world. Here, look:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;dev/wscons/wsconsio.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;sys/ioctl.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">struct&lt;/span> &lt;span class="n">my_ginfo&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">height&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">width&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">depth&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">};&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kt">int&lt;/span> &lt;span class="nf">get_ginfo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">fd&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="k">struct&lt;/span> &lt;span class="n">my_ginfo&lt;/span>&lt;span class="o">*&lt;/span> &lt;span class="n">gi&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">struct&lt;/span> &lt;span class="n">wsdisplay_fbinfo&lt;/span> &lt;span class="n">fbi&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">int&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">ioctl&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fd&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">WSDISPLAYIO_GINFO&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">fbi&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">result&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">result&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">gi&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">height&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fbi&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">height&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">gi&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">width&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fbi&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">width&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">gi&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="n">depth&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fbi&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">depth&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/ioctls-rust/ffi/src/ffi.c" type="text/plain">ffi/src/ffi.c&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>We start by declaring our own version of &lt;code>wsdisplay_ginfo&lt;/code>, which I&amp;rsquo;ve called &lt;code>my_ginfo&lt;/code>, that only includes the few fields we want to propagate to Rust. Yes, in this example the indirection is utterly pointless because we go from 4 to 3 fields so we haven&amp;rsquo;t made our lives easier, but there are &lt;code>ioctl&lt;/code>s that return larger structures from which we might only need a few values. Then we define a trivial function to wrap the &lt;code>ioctl&lt;/code> and transform its return value into our own structure.&lt;/p>
&lt;p>Then, we go to Rust, re-define our &lt;code>my_ginfo&lt;/code> structure as &lt;code>MyGinfo&lt;/code> (both of which we fully control so we can easily verify that they match) and we call the wrapping function:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">ffi&lt;/span>::&lt;span class="p">{&lt;/span>&lt;span class="n">c_char&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">c_int&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">c_uint&lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">io&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">mem&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">use&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">std&lt;/span>::&lt;span class="n">os&lt;/span>::&lt;span class="n">fd&lt;/span>::&lt;span class="p">{&lt;/span>&lt;span class="n">AsRawFd&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">FromRawFd&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">OwnedFd&lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[repr(C)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[derive(Debug)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="cp">#[allow(unused)]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">struct&lt;/span> &lt;span class="nc">MyGInfo&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">height&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">width&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">depth&lt;/span>: &lt;span class="nc">c_uint&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">extern&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;C&amp;#34;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">fn&lt;/span> &lt;span class="nf">get_ginfo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fd&lt;/span>: &lt;span class="nc">c_int&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">gi&lt;/span>: &lt;span class="o">*&lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">MyGInfo&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>-&amp;gt; &lt;span class="nc">c_int&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">fn&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>-&amp;gt; &lt;span class="nc">io&lt;/span>::&lt;span class="nb">Result&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fd&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">unsafe&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="n">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;/dev/ttyE0&lt;/span>&lt;span class="se">\0&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">as_ptr&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="k">const&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">c_char&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="no">O_RDWR&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="no">O_NONBLOCK&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">|&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">libc&lt;/span>::&lt;span class="no">O_EXCL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">if&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">==&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">return&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">Err&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">io&lt;/span>::&lt;span class="n">Error&lt;/span>::&lt;span class="n">last_os_error&lt;/span>&lt;span class="p">());&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">unsafe&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">OwnedFd&lt;/span>::&lt;span class="n">from_raw_fd&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">};&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">gi&lt;/span>: &lt;span class="nc">MyGInfo&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">unsafe&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">gi&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">mem&lt;/span>::&lt;span class="n">zeroed&lt;/span>&lt;span class="p">();&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">let&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">get_ginfo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fd&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">as_raw_fd&lt;/span>&lt;span class="p">(),&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">gi&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="k">mut&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">MyGInfo&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">if&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">==&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">return&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">Err&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">io&lt;/span>::&lt;span class="n">Error&lt;/span>::&lt;span class="n">last_os_error&lt;/span>&lt;span class="p">());&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="fm">eprintln!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;my_ginfo: &lt;/span>&lt;span class="si">{:?}&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">gi&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nb">Ok&lt;/span>&lt;span class="p">(())&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/ioctls-rust/ffi/src/main.rs" type="text/plain">ffi/src/main.rs&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>The trick now is to link the C code with the Rust code together, and for that, we create a &lt;code>build.rs&lt;/code> script. In here, we leverage the &lt;a href="https://docs.rs/cc/">cc crate&lt;/a> to put things together, which is an extra dependency that is only used at build time:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-rust" data-lang="rust">&lt;span class="line">&lt;span class="cl">&lt;span class="k">fn&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">if&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="fm">cfg!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">target_os&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;netbsd&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="fm">println!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;cargo::rerun-if-changed=src/ffi.c&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">cc&lt;/span>::&lt;span class="n">Build&lt;/span>::&lt;span class="n">new&lt;/span>&lt;span class="p">().&lt;/span>&lt;span class="n">file&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;src/ffi.c&amp;#34;&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="n">compile&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;ffi&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">else&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="fm">println!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;cargo::rerun-if-changed=src/dummy.c&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">cc&lt;/span>::&lt;span class="n">Build&lt;/span>::&lt;span class="n">new&lt;/span>&lt;span class="p">().&lt;/span>&lt;span class="n">file&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;src/dummy.c&amp;#34;&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="n">compile&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;ffi&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/ioctls-rust/ffi/build.rs" type="text/plain">ffi/build.rs&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>And with that, we are done.&lt;/p>
&lt;h1 id="which-option-wins">Which option wins?&lt;/h1>
&lt;p>Well, let&amp;rsquo;s see:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">$ cargo build --release
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Compiling ioctls-rust-ffi v0.1.0 (/home/jmmv/ioctls-rust/ffi)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Compiling ioctls-rust-libc v0.1.0 (/home/jmmv/ioctls-rust/libc)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Compiling ioctls-rust-nix v0.1.0 (/home/jmmv/ioctls-rust/nix)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Finished `release` profile [optimized] target(s) in 1.89s
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ls -lh target/release/ioctls-rust-* | grep -v \\.d
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-rwxr-xr-x 2 jmmv jmmv 455K Feb 12 08:04 target/release/ioctls-rust-ffi
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-rwxr-xr-x 2 jmmv jmmv 455K Feb 12 08:04 target/release/ioctls-rust-libc
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-rwxr-xr-x 2 jmmv jmmv 464K Feb 12 08:04 target/release/ioctls-rust-nix
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ strip -s target/release/ioctls-rust-*
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ls -lh target/release/ioctls-rust-* | grep -v \\.d
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-rwxr-xr-x 2 jmmv jmmv 353K Feb 12 08:05 target/release/ioctls-rust-ffi
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-rwxr-xr-x 2 jmmv jmmv 353K Feb 12 08:05 target/release/ioctls-rust-libc
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-rwxr-xr-x 2 jmmv jmmv 358K Feb 12 08:05 target/release/ioctls-rust-nix
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>From a binary size perspective, there are no meaningful differences. As expected, the usage of the nix crate results in slightly more code than the other alternatives because nix has to do extra work to translate global &lt;code>errno&lt;/code> values into Rust &lt;code>Result&lt;/code> types and the like. But the libc and FFI alternatives seem identical.&lt;/p>
&lt;p>At runtime, however, we should expect the FFI option to perform a teeny tiny bit worse (though good luck measuring that) than the libc option because we have to convert between the kernel structure and our own structure in the happy path&amp;hellip; all for dubious benefit.&lt;/p>
&lt;p>All in all, I&amp;rsquo;ll take option 1. I do not like the fact of having to manually replicate the kernel structures in my own code so, if I had the time, I&amp;rsquo;d try to upstream the definitions to the well-tested libc crate or write another reusable crate with just those. But, barring that, the idiomatic nix interfaces make calling Unix primitives a breeze.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-02-13-ioctls-rust-cover-image.jpg" length="440615" type="image/jpeg"/></item><item><title>Hands-on graphics without X11</title><link>https://jmmv.dev/2025/01/netbsd-graphics-wo-x11.html</link><pubDate>Fri, 17 Jan 2025 09:45:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/01/netbsd-graphics-wo-x11.html</guid><description>&lt;p>&lt;em>A crash course on direct framebuffer and keyboard access via NetBSD&amp;rsquo;s wscons&lt;/em>&lt;/p>
&lt;p>Look at these two consoles:&lt;/p>
&lt;figure>
&lt;img src="/images/2025-01-17-netbsd-vs-endbasic-console.png" />
&lt;figcaption>Side-by-side comparison of the NetBSD console right after boot vs. the EndBASIC console.&lt;/figcaption>
&lt;/figure>
&lt;p>Same colors, (almost) same font, same&amp;hellip; everything? Other than for the actual text they display, they look identical, don&amp;rsquo;t they? But the one on the right can do things that the one on the left cannot. Witness this:&lt;/p>
&lt;figure>
&lt;video width="100%" controls>
&lt;source src="/images/2025-01-17-endbasic-console.mp4" type="video/mp4">
&lt;/video>
&lt;figcaption>Demonstration of the EndBASIC hybrid console by issuing a couple of graphics primitives.&lt;/figcaption>
&lt;/figure>
&lt;p>A square? OK, meh, we had those in the DOS days with &lt;a href="https://en.wikipedia.org/wiki/Box-drawing_characters">box-drawing characters&lt;/a>. But a circle?! That&amp;rsquo;s only possible because the console on the right is a hybrid console that supports mixing the usual textual grid of a terminal with overlapping graphics.&lt;/p>
&lt;p>Now, if you have been following the development of &lt;a href="https://www.endbasic.dev/">EndBASIC&lt;/a>, this is not surprising. The defining characteristic of the EndBASIC console is that it&amp;rsquo;s hybrid as the video shows. What&amp;rsquo;s newsworthy, however, is that the EndBASIC console can now run directly on a framebuffer exposed by the kernel. No X11 nor Wayland in the picture (pun intended).&lt;/p>
&lt;p>But how? The answer lies in NetBSD&amp;rsquo;s flexible wscons framework, and this article dives into what it takes to render graphics on a standard Unix system. I&amp;rsquo;ve found this exercise exciting because, in the old days, graphics were trivial (&lt;a href="https://en.wikipedia.org/wiki/Mode_13h">mode 13h&lt;/a>, anyone?) and, for many years now, computers use framebuffer-backed textual consoles. The kernel is obviously rendering &amp;ldquo;graphics&amp;rdquo; by drawing individual letters; so why can&amp;rsquo;t you, a user of the system, do so too?&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h1 id="wscons-overview">wscons overview&lt;/h1>
&lt;p>&lt;a href="https://man.netbsd.org/wscons.4">wscons(4)&lt;/a>, or Workstation Console in its full form, is NetBSD&amp;rsquo;s framework to access the physical console attached to a computer.&lt;/p>
&lt;p>wscons abstracts the details of the hardware display and input devices so that the kernel and the user-space configuration tools can treat them all uniformly across the tens of platforms that NetBSD supports. If you use &lt;a href="https://man.netbsd.org/wsconsctl.8">wsconsctl(8)&lt;/a> on a modern amd64 laptop to control its display, you use wsconsctl on an ancient vax box to control its display too.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-01-17-wsdisplay-devices.png" />
&lt;figcaption>Layered architecture of wsdisplay and its backing devices.&lt;/figcaption>
&lt;/figure>
&lt;p>The output architecture of wscons is composed of multiple devices, layered like this:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://man.netbsd.org/wsdisplay.4">wsdisplay(4)&lt;/a> sits at the top of the stack and implements the console in hardware-independent terms. The functionality at this level includes handling of VT100-like sequences, cursor positioning logic, text wrapping, scrolling decisions, etc.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Under wsdisplay sit the drivers that know how to access specific hardware devices. These include, among others: &lt;a href="https://man.netbsd.org/vga.4">vga(4)&lt;/a>, which does not do graphics at all; &lt;a href="https://man.netbsd.org/genfb.4">genfb(4)&lt;/a>, which is a generic framebuffer driver that talks to the &amp;ldquo;native&amp;rdquo; framebuffer of the system (e.g. the one configured by the EFI); and &lt;a href="https://man.netbsd.org/radeonfb.4">radeonfb(4)&lt;/a>, which implements an accelerated console on AMD cards. These drivers know how to initialize and interact with the hardware.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Under the graphical drivers sits &lt;a href="https://man.netbsd.org/vcons.4">vcons(4)&lt;/a>, the driver that implements one or more graphical consoles in terms of a grid of pixels. vcons is parameterized on &amp;ldquo;raster operations&amp;rdquo; (rasops), a set of virtual methods to perform low-level operations. An example is the &lt;code>moverows&lt;/code> method, which is used by wsdisplay to implement scrolling in the most efficient way provided by the hardware. vcons provides default (inefficient) implementations of these methods, but the upper drivers like radeonfb can provide hardware-accelerated specializations when instantiating vcons. vcons also interacts with &lt;a href="https://man.netbsd.org/wsfont.4">wsfont(4)&lt;/a> to render text to the console.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;figure>
&lt;img src="/images/2025-01-17-wskbd-devices.png" />
&lt;figcaption>Layered architecture of wskbd and its backing devices, including the optional wsmux wrapper.&lt;/figcaption>
&lt;/figure>
&lt;p>The input architecture of wscons is similar in terms of layering of devices, albeit somewhat simpler:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://man.netbsd.org/wsmux.4">wsmux(4)&lt;/a> is an optional component that multiplexes multiple input devices under a single virtual device for event extraction.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://man.netbsd.org/wsbkd.4">wskbd(4)&lt;/a> sits at the top of the stack (not accounting for wsmux) and implements generic keyboard handling. The functionality at this level includes translating keycodes to layouts, handling key input repetition, and more. wskbd exposes a stream of wsevents to user-space so that user-space can process state changes (e.g. key presses).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Under wskbd sit the device drivers that know how to deal with specific hardware devices. These include, among others: &lt;a href="https://man.netbsd.org/ukbd.4">ukbd(4)&lt;/a> for USB keyboard input and &lt;a href="https://man.netbsd.org/pckbd.4">pckbd(4)&lt;/a> for PC/AT keyboard input. These drivers wait for hardware input, generate events, and provide a map of keycodes to key symbols to the upper layer so that wskbd can operate in generic terms.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The input architecture can handle other types of devices like mice and touch panels (both via &lt;a href="https://man.netbsd.org/wsmouse.4">wsmouse(4)&lt;/a>), but I&amp;rsquo;m not going to cover those here. Just know that they sit under wsmux at the equivalent level of wskbd and produce a set of wsevents in the exact same manner as wskbd.&lt;/p>
&lt;h1 id="querying-framebuffer-properties">Querying framebuffer properties&lt;/h1>
&lt;p>As you can sense from the overview, the whole architecture under wsdisplay is geared towards video devices&amp;hellip; if it wasn&amp;rsquo;t for the vga driver: in the common case, wsdisplay is backed by a graphical framebuffer managed by vcons for text rendering, yet the user only sees a textual console. But if the kernel has direct access to the framebuffer, so should user-space too.&lt;/p>
&lt;p>The details on how to do this click if you read through the operations described in the wsdisplay manual page. In particular, you may notice the &lt;code>WSDISPLAYIO_GET_FBINFO&lt;/code> call which retrieves extended information about, you guessed it, a framebuffer display.&lt;/p>
&lt;p>Let&amp;rsquo;s try it: I wrote a trivial program to open the display device (named &lt;code>/dev/ttyE0&lt;/code> for reasons that escape me), call this function, and store the results in an &lt;code>fbinfo&lt;/code> structure:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/param.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/types.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/ioctl.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;dev/wscons/wsconsio.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;err.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;fcntl.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;stdlib.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;unistd.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">int main(void) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Open the main wsdisplay device.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> int fd = open(&amp;#34;/dev/ttyE0&amp;#34;, O_RDWR | O_NONBLOCK | O_EXCL);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (fd == -1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;open failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Query information about the framebuffer.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> struct wsdisplayio_fbinfo fbinfo;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (ioctl(fd, WSDISPLAYIO_GET_FBINFO, &amp;amp;fbinfo) == -1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;ioctl failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> close(fd);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> exit(EXIT_SUCCESS);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/netbsd-graphics-wo-x11/wsdisplay-fbinfo.c" type="text/plain">wsdisplay-fbinfo.c&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Hmm, but this program does not have any visible output, right? The code just queries the framebuffer information and does nothing with it. The reason is that the content of the &lt;code>wsdisplayio_fbinfo&lt;/code> structure is large and I didn&amp;rsquo;t want to pretty-print it myself. I thought it&amp;rsquo;d be fun to show you how to use GDB to inspect large data structures and how to script the process. Here, look:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">gdb -q \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -ex &amp;#39;set print pretty on&amp;#39; \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -ex &amp;#39;break exit&amp;#39; \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -ex &amp;#39;run&amp;#39; \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -ex &amp;#39;frame 1&amp;#39; \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -ex &amp;#39;print fbinfo&amp;#39; \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -ex &amp;#39;cont&amp;#39; \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -ex &amp;#39;quit&amp;#39; \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ./wsdisplay-fbinfo
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/netbsd-graphics-wo-x11/wsdisplay-fbinfo.sh" type="text/plain">wsdisplay-fbinfo.sh&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>This call to GDB starts the sample program shown above and automates various GDB commands to set a breakpoint, step through the program, and pretty-print the &lt;code>fbinfo&lt;/code> structure right before exiting. When we execute this command as root (which is important to get access to the &lt;code>/dev/ttyE0&lt;/code> device), we get this:&lt;/p>
&lt;figure>
&lt;img src="/images/2025-01-17-wsdisplay-fbinfo-gdb.png" />
&lt;figcaption>Content of the &lt;tt>fbinfo&lt;/tt> structure as grabbed by the sample &lt;tt>wsdisplay-fbinfo&lt;/tt> program and printed by GDB.&lt;/figcaption>
&lt;/figure>
&lt;p>Neat. We get sensible stuff from the kernel! &lt;code>fbi_width&lt;/code> is 640 and &lt;code>fbi_height&lt;/code> is 480, which matches the 640x480 resolution I have configured in my test VM.&lt;/p>
&lt;h1 id="drawing-to-the-framebuffer">Drawing to the framebuffer&lt;/h1>
&lt;p>But note these other fields in the structure printed above:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="k">struct&lt;/span> &lt;span class="n">wsdisplayio_fbinfo&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">uint64_t&lt;/span> &lt;span class="n">fbi_fbsize&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">uint64_t&lt;/span> &lt;span class="n">fbi_fboffset&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// ... more fields ...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>fbi_fbsize&lt;/code> and &lt;code>fbi_fboffset&lt;/code> fields are &lt;em>begging&lt;/em> us to use &lt;code>mmap&lt;/code> to memory-map the area of the device starting at &lt;code>fbi_fboffset&lt;/code> and spanning &lt;code>fbi_fbsize&lt;/code> bytes. Presumably we can write to the framebuffer if we do this, but beforehand, we have to switch the console to &amp;ldquo;framebuffer mode&amp;rdquo; by using the &lt;code>WSDISPLAYIO_SMODE&lt;/code> (&amp;ldquo;set mode&amp;rdquo;) call. This call accepts an integer to indicate which mode to set:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>WSDISPLAYIO_MODE_EMUL&lt;/code>: Set the display to emulating (text) mode. This is the default operation mode of wsdisplay and configures the console to &amp;ldquo;emulate&amp;rdquo; a text terminal.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>WSDISPLAYIO_MODE_MAPPED&lt;/code>: Set the display to mapped (graphics) mode. This allows access to the framebuffer and allows the &lt;code>mmap&lt;/code> operation to succeed.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>WSDISPLAYIO_MODE_DUMBFB&lt;/code>: Set the display to mapped (framebuffer) mode. This is similar to &lt;code>WSDISPLAYIO_MODE_MAPPED&lt;/code> and, for our purposes in the demo below, works the same. I haven&amp;rsquo;t found a concise description of how these two differ, but from my reading of the code, the &amp;ldquo;mapped&amp;rdquo; mode offers access to the framebuffer as well as device-specific control registers, whereas &amp;ldquo;dumb framebuffer&amp;rdquo; just exposes the framebuffer memory.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>In any case. Once we know that we have to switch the console device to a graphical mode before mapping the framebuffer, and having access to the pixel format described in the &lt;code>fbinfo&lt;/code> structure&amp;hellip; drawing something fun is just a few byte manipulation operations away:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/param.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/types.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/ioctl.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/mman.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;dev/wscons/wsconsio.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;err.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;fcntl.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;stdlib.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;unistd.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">int main(void) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Open the main wsdisplay device.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> int fd = open(&amp;#34;/dev/ttyE0&amp;#34;, O_RDWR | O_NONBLOCK | O_EXCL);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (fd == -1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;open failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Query information about the framebuffer.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> struct wsdisplayio_fbinfo fbinfo;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (ioctl(fd, WSDISPLAYIO_GET_FBINFO, &amp;amp;fbinfo) == -1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;ioctl failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Ensure the framebuffer aligns with the expectations of our demo
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // code below.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (fbinfo.fbi_bitsperpixel != 32)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> errx(1, &amp;#34;bitsperpixel not supported by this demo&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (fbinfo.fbi_pixeltype != WSFB_RGB)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> errx(1, &amp;#34;pixeltype not supported by this demo&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Configure the wsdisplay to enter &amp;#34;dumb framebuffer&amp;#34; mode.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> unsigned int mode = WSDISPLAYIO_MODE_DUMBFB;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (ioctl(fd, WSDISPLAYIO_SMODE, &amp;amp;mode) == -1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;ioctl failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Map the framebuffer memory. Must come after the SMODE ioctl.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uint32_t *ptr = (uint32_t*)mmap(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0, fbinfo.fbi_fbsize, PROT_READ | PROT_WRITE, MAP_SHARED,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> fd, fbinfo.fbi_fboffset);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (ptr == MAP_FAILED)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;mmap failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Fill the screen multiple times with pixels of different
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // colors to render a simple animation.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> size_t pixels = fbinfo.fbi_fbsize / sizeof(uint32_t);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> int off = 0;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> for (int i = 0; i &amp;lt; 100; i++) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> int r = off; int g = off; int b = off;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> for (size_t i = 0; i &amp;lt; pixels; i++) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> r = (r + 1) % 255; g = (g + 2) % 255; b = (b + 3) % 255;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ptr[i] = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> | (r &amp;lt;&amp;lt; fbinfo.fbi_subtype.fbi_rgbmasks.red_offset)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> | (g &amp;lt;&amp;lt; fbinfo.fbi_subtype.fbi_rgbmasks.green_offset)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> | (b &amp;lt;&amp;lt; fbinfo.fbi_subtype.fbi_rgbmasks.blue_offset);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> off += 10;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> usleep(1);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Configure the wsdisplay to enter &amp;#34;console emulation&amp;#34; mode.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // In other words: return to the console.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> mode = WSDISPLAYIO_MODE_EMUL;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (ioctl(fd, WSDISPLAYIO_SMODE, &amp;amp;mode) == -1) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;ioctl failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> close(fd);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> return EXIT_SUCCESS;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/netbsd-graphics-wo-x11/wsdisplay-draw.c" type="text/plain">wsdisplay-draw.c&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>And if we run this:&lt;/p>
&lt;figure>
&lt;video width="100%" controls>
&lt;source src="/images/2025-01-17-wsdisplay-draw.mp4" type="video/mp4">
&lt;/video>
&lt;figcaption>The demo &lt;tt>wsdisplay-draw&lt;/tt> program running on the NetBSD console immediately after logging in.&lt;/figcaption>
&lt;/figure>
&lt;p>Voila. We&amp;rsquo;ve got graphics without paying the X11 startup tax. Switching from the console to graphics is instantaneous, like in the good old mode 13h days.&lt;/p>
&lt;h1 id="handling-keyboard-input">Handling keyboard input&lt;/h1>
&lt;p>Rendering graphics is just half of the puzzle when writing an interactive application though. The other half is handling input. And, for that, we have to turn to the wskbd device.&lt;/p>
&lt;p>After we switch the console to mapped mode, keystrokes don&amp;rsquo;t go to &lt;code>stdin&lt;/code> anymore. We have to write code to explicitly read from an attached keyboard, and we can do this via the &lt;code>/dev/wskbd0&lt;/code> device representing the first attached keyboard.&lt;/p>
&lt;p>Once we open the keyboard device for reading, wscons sends us its own representation of events known as wsevents. We can write a trivial program to read one key press:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/param.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/types.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/ioctl.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;dev/wscons/wsconsio.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;err.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;fcntl.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;stdio.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;stdlib.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;unistd.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">int main(int argc, char** argv) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Open the main wskbd device.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> int fd = open(&amp;#34;/dev/wskbd0&amp;#34;, O_RDONLY);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (fd == -1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;open failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Wait for one key down press only.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> for (;;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> struct wscons_event ev;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> int ret = read(fd, &amp;amp;ev, sizeof(ev));
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (ret == -1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;read failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (ev.type == WSCONS_EVENT_KEY_DOWN) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> printf(&amp;#34;value: %d, char &amp;#39;%c&amp;#39;\n&amp;#34;, ev.value, (char)ev.value);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> break;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> close(fd);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> return EXIT_SUCCESS;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/netbsd-graphics-wo-x11/wskbd-trivial.c" type="text/plain">wskbd-trivial.c&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>But&amp;hellip; if we try to run it and press a key, say &lt;code>k&lt;/code>, we might get:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl"># ./wskbd-trivial
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">value: 37, char &amp;#39;%&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Huh. We pressed &lt;code>k&lt;/code> but the character we got is &lt;code>%&lt;/code>. Not what we expected! Well, as it turns out, the &amp;ldquo;value&amp;rdquo; that wsevents report for key presses (37 in this case) is the raw keycode of the key. This is hardware-specific and needs to be translated to an actual symbol via a keymap.&lt;/p>
&lt;p>One feature of wskbd is that it exposes the keymap as configured in the kernel so there is a single source of truth for the machine. We can query a portion of it with another program:&lt;/p>
&lt;div class="src">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/param.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/types.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;sys/ioctl.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;dev/wscons/wsconsio.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;dev/wscons/wsksymdef.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;err.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;fcntl.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;stdio.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;stdlib.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;string.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#include &amp;lt;unistd.h&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">int main(int argc, char** argv) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Open the main wskbd device.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> int fd = open(&amp;#34;/dev/wskbd0&amp;#34;, O_RDONLY);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (fd == -1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;open failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Allocate space for the biggest possible keymap.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> struct wscons_keymap map[WSKBDIO_MAXMAPLEN];
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> memset(map, 0, sizeof(struct wscons_keymap) * WSKBDIO_MAXMAPLEN);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Get the keymap from the device.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> struct wskbd_map_data data;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> data.maplen = WSKBDIO_MAXMAPLEN;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> data.map = map;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (ioctl(fd, WSKBDIO_GETMAP, &amp;amp;data) == -1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> err(1, &amp;#34;ioctl failed&amp;#34;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Dump keymap entries.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> printf(&amp;#34;Keymap length: %u entries\n&amp;#34;, data.maplen);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> for (size_t i = 0; i &amp;lt; data.maplen; i++) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> // Skip printing entries that are not for letters.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (map[i].command != KS_voidSymbol)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> char normal = map[i].group1[0];
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> char shifted = map[i].group1[1];
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (normal &amp;lt; &amp;#39;a&amp;#39; || normal &amp;gt; &amp;#39;z&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> printf(&amp;#34;Keycode %zd: &amp;#39;%c&amp;#39;, &amp;#39;%c&amp;#39;\n&amp;#34;, i, normal, shifted);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> close(fd);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> return EXIT_SUCCESS;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;div class="footer">
&lt;div class="filename">
&lt;a href="/src/netbsd-graphics-wo-x11/wskbd-map.c" type="text/plain">wskbd-map.c&lt;/a>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>And if we run it, we might get:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-plain" data-lang="plain">&lt;span class="line">&lt;span class="cl"># ./wskbd-map
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keymap length: 222 entries
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 16: &amp;#39;q&amp;#39;, &amp;#39;Q&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 17: &amp;#39;w&amp;#39;, &amp;#39;W&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 18: &amp;#39;e&amp;#39;, &amp;#39;E&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 19: &amp;#39;r&amp;#39;, &amp;#39;R&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 20: &amp;#39;t&amp;#39;, &amp;#39;T&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 21: &amp;#39;y&amp;#39;, &amp;#39;Y&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 22: &amp;#39;u&amp;#39;, &amp;#39;U&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 23: &amp;#39;i&amp;#39;, &amp;#39;I&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 24: &amp;#39;o&amp;#39;, &amp;#39;O&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 25: &amp;#39;p&amp;#39;, &amp;#39;P&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 30: &amp;#39;a&amp;#39;, &amp;#39;A&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 31: &amp;#39;s&amp;#39;, &amp;#39;S&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 32: &amp;#39;d&amp;#39;, &amp;#39;D&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 33: &amp;#39;f&amp;#39;, &amp;#39;F&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 34: &amp;#39;g&amp;#39;, &amp;#39;G&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 35: &amp;#39;h&amp;#39;, &amp;#39;H&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 36: &amp;#39;j&amp;#39;, &amp;#39;J&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 37: &amp;#39;k&amp;#39;, &amp;#39;K&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 38: &amp;#39;l&amp;#39;, &amp;#39;L&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 44: &amp;#39;z&amp;#39;, &amp;#39;Z&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 45: &amp;#39;x&amp;#39;, &amp;#39;X&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 46: &amp;#39;c&amp;#39;, &amp;#39;C&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 47: &amp;#39;v&amp;#39;, &amp;#39;V&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 48: &amp;#39;b&amp;#39;, &amp;#39;B&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 49: &amp;#39;n&amp;#39;, &amp;#39;N&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Keycode 50: &amp;#39;m&amp;#39;, &amp;#39;M&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This dump is telling us how keycodes map to symbols, both in &amp;ldquo;normal&amp;rdquo; and in shifted form. If we look up keycode 37, we indeed find the letter &lt;code>k&lt;/code>. With this, it&amp;rsquo;s just an &lt;a href="https://en.wikipedia.org/wiki/Small_matter_of_programming">SMOP&lt;/a> to come up with a program that parses the keymap as exposed by wskbd and converts keycodes to something useful.&lt;/p>
&lt;p>This is all good and dandy, but what happens if the keyboard is not connected when you try to open &lt;code>/dev/wskbd0&lt;/code>? (Spoiler: the &lt;code>open&lt;/code> call fails.) Or what happens if your computer has more than one keyboard attached? (Spoiler: you can only read events from one.) This is where wsmux comes to the rescue&amp;mdash;a device driver that multiplexes multiple input devices into one.&lt;/p>
&lt;p>By default, the system reserves &lt;code>/dev/wsmux0&lt;/code> as the multiplexer for all attached mice and &lt;code>/dev/wsmux1&lt;/code> as the multiplexer for all attached keyboards. We can define our own too via the &lt;a href="https://man.netbsd.org/wsmuxctl.8">wsmuxctl(8)&lt;/a> command line utility.&lt;/p>
&lt;p>wsmux then supports &amp;ldquo;hot plugging&amp;rdquo;. You can then open a &lt;code>/dev/wsmuxN&lt;/code> device even when there is no physical hardware attached, and whenever a peripheral is connected, it automatically becomes part of the mux. So, if we modify the program above to open &lt;code>/dev/wsmux1&lt;/code> instead of &lt;code>/dev/wskbd0&lt;/code>, the program will be resilient to missing keyboards and it&amp;rsquo;ll recognize multiple keyboards. Easy peasy!&lt;/p>
&lt;h1 id="what-will-you-build">What will you build?&lt;/h1>
&lt;p>You are now equipped with the basics to write graphical applications on a NetBSD system (and maybe OpenBSD too) without running X11. I know NetBSD may not be your jam, but it is a good choice for embedded projects due to its console architecture and other features like &lt;a href="/2024/12/netbsd-build-system.html">its build system&lt;/a>.&lt;/p>
&lt;p>If the code above still seems mysterious, you can read the source code for the &lt;a href="https://cvsweb.netbsd.org/bsdweb.cgi/xsrc/external/mit/xf86-video-wsfb/">xf86-video-wsfb&lt;/a> and &lt;a href="https://cvsweb.netbsd.org/bsdweb.cgi/xsrc/external/mit/xf86-input-ws/">xf86-input-ws&lt;/a> drivers for X.org. The code is easy enough to read, although it is longer because it has to support all the bells and whistles of wsdisplay and wskbd. (I took shortcuts above by making various assumptions on pixel formats and the like.)&lt;/p>
&lt;p>And, guess what, I am indeed working on an embedded project! A little dev box that can boot straight into EndBASIC with super-fast boot times and for which I couldn&amp;rsquo;t afford the X11 startup penalty.&lt;/p>
&lt;figure>
&lt;video width="100%" controls>
&lt;source src="/images/2025-01-17-endbasic-netbsd-boot.mp4" type="video/mp4">
&lt;/video>
&lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;p>Stay tuned. In the meantime, what will &lt;em>YOU&lt;/em> build? For those of us in the U.S., there is a 3-day weekend ahead and this can be a good distraction. Have fun!&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-01-17-cover-image.png" length="25978" type="image/jpeg"/></item><item><title>Self-documenting Makefiles</title><link>https://jmmv.dev/2025/01/make-help.html</link><pubDate>Fri, 10 Jan 2025 09:00:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/01/make-help.html</guid><description>&lt;p>Make, as arcane as a build tool can be, may still be a good first fit for certain scenarios. &amp;ldquo;Heresy!&amp;rdquo;, you say, as you hear a so-called &amp;ldquo;Bazel expert&amp;rdquo; utter these words.&lt;/p>
&lt;p>The specific problem I&amp;rsquo;m facing is that I need to glue together &lt;a href="/2024/12/netbsd-build-system.html">the NetBSD build system&lt;/a>, &lt;a href="/2013/11/patch-management-with-quilt.html">a quilt patch set&lt;/a>, EndBASIC&amp;rsquo;s Cargo-based Rust build, and a couple of QEMU invocations to produce a Frankenstein disk image for a Raspberry Pi. And the thing is: Make allows doing this sort of stitching with relative ease. Sure, Make is not the best option because the overall build performance is &amp;ldquo;meh&amp;rdquo; and because incremental builds are almost-impossible to get right&amp;hellip; but adopting Bazel for this project would be an almost-infinite time sink.&lt;/p>
&lt;p>Anyway. When using Make in this manner, you often end up with what&amp;rsquo;s essentially a &amp;ldquo;command dispatcher&amp;rdquo; and, over time, the number of commands grows and it&amp;rsquo;s hard to make sense of which one to use for what. Sure, you can write a &lt;code>README.md&lt;/code> with instructions, but I guarantee you that the text will get out of sync faster than you can read this article. There is a better way, though.&lt;/p>
&lt;figure>
&lt;img src="/images/2025-01-10-make-help.png" />
&lt;figcaption>Sample output of the &lt;tt>make help&lt;/tt> command that we will implement in this article.&lt;/figcaption>
&lt;/figure>
&lt;p>What if we could provide a &lt;code>make help&lt;/code> command that showed an overview of the project&amp;rsquo;s &amp;ldquo;build interface&amp;rdquo;? And what if we could embed such information inside the &lt;code>Makefile&lt;/code>s themselves, close to the entities that they document? This idea is neither new nor mine, and it has been written about before by different people. However, I bet that most of you haven&amp;rsquo;t heard about it before so it&amp;rsquo;s worth for me to repeat it. And I think that my solution is a bit more comprehensive than others I&amp;rsquo;ve found. So here you go.&lt;/p>
&lt;div class="container action-highlight p-4 my-4 d-md-none">
&lt;div class="row text-center">
&lt;p>A blog on operating systems, programming languages, testing, build systems, my own software
projects and even personal productivity. Specifics include FreeBSD, Linux, Rust, Bazel and
EndBASIC.&lt;/p>
&lt;/div>
&lt;div class="row">
&lt;div class="col">
&lt;div class="form-group">
&lt;form action="https://endtracker.azurewebsites.net/api/sites/e8da9f62-b7ac-4fe9-bf20-7c527199a376/subscribers/add" method="post">
&lt;input type="text" name="email"
placeholder="Enter your email"
class="form-control input-sm text-center my-1"/>
&lt;button type="submit" class="btn btn-primary btn-block my-1">Subscribe&lt;/button>
&lt;/form>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="row px-2">
&lt;div class="col col-sm-5 text-left">
&lt;small>&lt;span class="subscriber-count">0&lt;/span> subscribers&lt;/small>
&lt;/div>
&lt;div class="col col-sm-7 text-right">
&lt;p>
&lt;a rel="me" href="https://mastodon.online/@jmmv">
&lt;img src="/images/badges/mastodon-logo.svg" width="32px" height="32px" alt="Follow @jmmv on Mastodon">
&lt;/a>
&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;amp;screen_name=jmmv">
&lt;img src="/images/badges/Twitter_logo_blue.svg" width="32px" height="32px" alt="Follow @jmmv on Twitter">
&lt;/a>
&lt;a href="/feed.xml">&lt;img src="/images/badges/feed-icon-28x28.png" alt="RSS feed">&lt;/a>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h1 id="targets">Targets&lt;/h1>
&lt;p>As I mentioned in the introduction, Make is often used as a command dispatcher: with very little code, you can write what essentially are multiple shell scripts with automatic chaining, all wrapped in one single interface. It&amp;rsquo;s all pretty terrible, but people are used to this pattern due to Make&amp;rsquo;s ubiquity and somehow expect it when they face a Make-based project.&lt;/p>
&lt;p>To implement this command dispatcher idea, each user-facing action is exposed via a &lt;em>target&lt;/em>. These targets tend to be marked as &amp;ldquo;phony&amp;rdquo;&amp;mdash;i.e. they are targets that produce no outputs of their own. Take a look at this &lt;code>Makefile&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-make" data-lang="make">&lt;span class="line">&lt;span class="cl">&lt;span class="nf">.PHONY&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">build&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">build&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">target&lt;/span>/&lt;span class="n">debug&lt;/span>/&lt;span class="n">program&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">target/debug/program&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">src&lt;/span>/&lt;span class="n">main&lt;/span>.&lt;span class="n">rs&lt;/span> &lt;span class="n">src&lt;/span>/&lt;span class="n">lib&lt;/span>.&lt;span class="n">rs&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> cargo build
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">.PHONY&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">test&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">test&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">build&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> cargo &lt;span class="nb">test&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the snippet above, the &lt;code>target/debug/program&lt;/code> target represents a built &lt;em>file&lt;/em>. This target depends on a list of sources and specifies what command to run to generate the output when it is missing or out of date (according to file modification times, &lt;a href="/2020/12/google-no-clean-builds.html#file-modification-times">yikes&lt;/a>). When you type &lt;code>make target/debug/program&lt;/code>, you expect the file &lt;code>target/debug/program&lt;/code> to exist on disk after the command completes.&lt;/p>
&lt;p>But the snippet also shows two phony targets: &lt;code>build&lt;/code> and &lt;code>test&lt;/code>. When you type &lt;code>make build&lt;/code> or &lt;code>make test&lt;/code>, you do not expect neither a &lt;code>build&lt;/code> nor a &lt;code>test&lt;/code> file to be created, no. What you expect is that the project is built and tested. And for this, Make evaluates the dependencies of the phony targets (if any are specified, as is the case for &lt;code>build&lt;/code>) and then unconditionally executes any commands in the phony targets (as is the case for &lt;code>test&lt;/code>).&lt;/p>
&lt;p>With this in mind, the first thing we want to do in our &lt;code>make help&lt;/code> command is to document these &amp;ldquo;special&amp;rdquo; targets that represent user-facing actions. To do this, we&amp;rsquo;ll leverage one not-well-known aspect of Make&amp;rsquo;s syntax: the list of dependencies of a target is &lt;em>cumulative&lt;/em> across multiple target definitions of the same name. Basically, these target definitions are equivalent:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-make" data-lang="make">&lt;span class="line">&lt;span class="cl">&lt;span class="c"># All dependencies in one line.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nf">target/debug/program&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">src&lt;/span>/&lt;span class="n">main&lt;/span>.&lt;span class="n">rs&lt;/span> &lt;span class="n">src&lt;/span>/&lt;span class="n">lib&lt;/span>.&lt;span class="n">rs&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># Dependencies spread over multiple lines.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nf">target/debug/program&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">src&lt;/span>/&lt;span class="n">main&lt;/span>.&lt;span class="n">rs&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">target/debug/program&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">src&lt;/span>/&lt;span class="n">lib&lt;/span>.&lt;span class="n">rs&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Knowing this, we can add &amp;ldquo;extra&amp;rdquo; lines for a target and use one of those to document the target so that we do not end up with super-long lines. For example, we can do:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-make" data-lang="make">&lt;span class="line">&lt;span class="cl">&lt;span class="nf">target/debug/program&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="c"># Builds the program.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nf">target/debug/program&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">src&lt;/span>/&lt;span class="n">main&lt;/span>.&lt;span class="n">rs&lt;/span> &lt;span class="n">src&lt;/span>/&lt;span class="n">lib&lt;/span>.&lt;span class="n">rs&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And then we are just one &lt;code>grep&lt;/code> away from extracting the targets and their documentation:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">sed -e&lt;span class="s1">&amp;#39;s/^\([^: ]\+\):.*#\(.*\)$/\1 \2/p;d&amp;#39;&lt;/span> Makefile &lt;span class="p">|&lt;/span> column -t -l &lt;span class="m">2&lt;/span> &lt;span class="p">|&lt;/span> sort
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>OK fine. It&amp;rsquo;s a bit more complicated than just &lt;code>grep&lt;/code> because we have to reformat the lines a bit and we need to create a nicely formatted table. Also, I know the &lt;code>sed&lt;/code> syntax is awful, but I really don&amp;rsquo;t want to call into Perl or Python as other guides tell you just for this silly string manipulation. There are native Unix tools that can help us here, and they are much lighter-weight.&lt;/p>
&lt;h1 id="variables">Variables&lt;/h1>
&lt;p>All other &amp;ldquo;self-documenting &lt;code>Makefile&lt;/code>&amp;rdquo; tutorials I found out there focus exclusively on documenting targets. But &lt;code>Makefile&lt;/code>s often expose another dimension of their API, and this is the collection of user-settable configuration variables that they accept.&lt;/p>
&lt;p>Many &lt;code>Makefile&lt;/code>s do things like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-make" data-lang="make">&lt;span class="line">&lt;span class="cl">&lt;span class="nv">CFLAGS&lt;/span> &lt;span class="o">?=&lt;/span> -O2
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;hellip; to indicate that &lt;code>CFLAGS&lt;/code> is set to &lt;code>-O2&lt;/code>. But note: the &lt;code>?=&lt;/code> operator invites users to override the variable&amp;rsquo;s value if they choose to. For example, if the user wanted to build the project in debug mode, they could probably do the following and get the code to build without optimizations and with debug symbols:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">$ make &lt;span class="nv">CFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;-O0 -g&amp;#34;&lt;/span> build
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Given that these variables are user-facing, we should document them as well as part of the &lt;code>make help&lt;/code> output.&lt;/p>
&lt;p>To document variables, we don&amp;rsquo;t have the luxury of splitting their definition into multiple lines like we did with targets to prevent super-long lines. That said, we can still add comments at the end of the line, like shown below, and those comments won&amp;rsquo;t be part of the variable&amp;rsquo;s default value. It is important, however, to not leave any space between the default value and the comment, or else the spaces become part of the variable&amp;rsquo;s value.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-make" data-lang="make">&lt;span class="line">&lt;span class="cl">&lt;span class="nv">DEVELOPER&lt;/span> &lt;span class="o">?=&lt;/span> 0# Set to &lt;span class="m">1&lt;/span> to &lt;span class="nb">enable&lt;/span> developer builds.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Like with targets, we are also just one &lt;code>grep&lt;/code> away from extracting the variables and their documentation:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">sed -e &lt;span class="s1">&amp;#39;s/^\([^ ]\+\)[ ]*?=[^#]\+#\(.*\)$/\1 \2/p;d&amp;#39;&lt;/span> Makefile &lt;span class="p">|&lt;/span> column -t -l &lt;span class="m">2&lt;/span> &lt;span class="p">|&lt;/span> sort
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, more complicated than just a &lt;code>grep&lt;/code>, but you get the idea.&lt;/p>
&lt;h1 id="putting-it-all-together">Putting it all together&lt;/h1>
&lt;p>Alright. So now we know how to extract a table documenting targets and a table documenting variables, but these two lists may still be too obscure on their own. Which targets are important? Which variables might the user want to look into first?&lt;/p>
&lt;p>To address this deficiency, we can preface those tables with some prose that explains, at a very high level, what to do when interacting with the project for the first time. To implement this, we can write the instructions in a separate file (like a &lt;code>README.md&lt;/code>) next to the &lt;code>Makefile&lt;/code>, and then have our &lt;code>make help&lt;/code> command print out the text file&amp;rsquo;s contents.&lt;/p>
&lt;p>And so without further ado, here is how we can tie everything together:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-make" data-lang="make">&lt;span class="line">&lt;span class="cl">&lt;span class="nf">.PHONY&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="n">help&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">help&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="c"># Shows interactive help.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span> @cat README.md
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @echo
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @echo &lt;span class="s2">&amp;#34;make variables:&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @echo
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @sed -e &lt;span class="s1">&amp;#39;s/^\([^ ]\+\)[ ]*?=[^#]\+#\(.*\)$$/\1 \2/p;d&amp;#39;&lt;/span> Makefile &lt;span class="p">|&lt;/span> column -t -l &lt;span class="m">2&lt;/span> &lt;span class="p">|&lt;/span> sort
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @echo
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @echo &lt;span class="s2">&amp;#34;make targets:&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @echo
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @sed -e&lt;span class="s1">&amp;#39;s/^\([^: ]\+\):.*#\(.*\)$$/\1 \2/p;d&amp;#39;&lt;/span> Makefile &lt;span class="p">|&lt;/span> column -t -l &lt;span class="m">2&lt;/span> &lt;span class="p">|&lt;/span> sort
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you copy/paste this text, beware that there are embedded tabs in it. The ones at the beginning of the line are obvious, but the ones in the &lt;code>[ ]&lt;/code> character classes are not. The latter are supposed to be &lt;code>[ &amp;lt;tab&amp;gt;]&lt;/code>.&lt;/p>
&lt;p>Now, have fun with this, but please don&amp;rsquo;t use Make for new projects if you can avoid it!&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-01-10-make-help.png" length="110230" type="image/jpeg"/></item></channel></rss>