<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>jmmv.dev</title>
    <link>https://jmmv.dev/</link>
    <description>Recent content on jmmv.dev</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 31 Dec 2019 07:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://jmmv.dev/feed.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Lifting the local lock for dynamic execution</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-local-lockfree.html</link>
      <pubDate>Tue, 31 Dec 2019 07:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-local-lockfree.html</guid>
      <description>In the previous post, we saw how accounting for artifact download times makes the dynamic strategy live to its promise of delivering the best of local and remote build times.
Or does it? If you think about it closely, that change made it so that builds that were purely local couldn&amp;rsquo;t be made worse by enabling the dynamic scheduler: the dynamic strategy would always favor the local branch of a spawn if the remote one took a long time.</description>
    </item>
    
    <item>
      <title>Artifact downloads and dynamic execution</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-download-times.html</link>
      <pubDate>Mon, 30 Dec 2019 11:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-download-times.html</guid>
      <description>In the previous post of this series, we looked at how the now-legacy implementation of the dynamic strategy uses a per-spawn lock to guard accesses to the output tree. This lock is problematic for a variety of reasons and we are going to peek into one of those here.
To recap, the remote strategy does the following:
 Send spawn execution RPC to the remote service. Wait for successful execution (which can come quickly from a cache hit).</description>
    </item>
    
    <item>
      <title>Output conflicts and dynamic execution</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-output-locking.html</link>
      <pubDate>Fri, 27 Dec 2019 10:10:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-output-locking.html</guid>
      <description>When the dynamic scheduler is active, Bazel runs the same spawn (aka command line) remotely and locally at the same time via two separate strategies. These two strategies want to write to the same output files (e.g. object files, archives, or final binaries) on the local disk. In computing, two things trying to affect the same thing require some kind of coÃ¶rdination.
You might think, however, that because we assume that both strategies are equivalent and will write the same contents to disk1, this is not problematic.</description>
    </item>
    
    <item>
      <title>Bazel&#39;s dynamic strategy</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-strategy.html</link>
      <pubDate>Thu, 26 Dec 2019 10:30:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-strategy.html</guid>
      <description>After introducing Bazel&amp;rsquo;s dynamic execution a couple of posts ago, it&amp;rsquo;s time to dive into its actual implementation details as promised. But pardon for the interruption in the last post, as I had to take a little detour to cover a necessary topic (local resources) for today&amp;rsquo;s article.
Simply put, dynamic execution is implemented as &amp;ldquo;just&amp;rdquo; one more strategy called dynamic. The dynamic strategy, however, is different from all others because it does not have a corresponding spawn runner.</description>
    </item>
    
    <item>
      <title>How does Bazel track local resource usage?</title>
      <link>https://jmmv.dev/2019/12/bazel-local-resources.html</link>
      <pubDate>Mon, 23 Dec 2019 22:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-local-resources.html</guid>
      <description>How does Bazel avoid melting your workstation with concurrent subprocesses? Or&amp;hellip; tries to, because I know it still does that sometimes? There are two mechanisms as play: the jobs number and the local resources tracker. Let&amp;rsquo;s dive into them.
The jobs number, given by the --jobs flag, configures the number of concurrent Skyframe evaluators during the execution phase1. What a mouthful. What this essentially means is that jobs indicates the number of threads used to walk the graph looking for actions to execute&amp;mdash;and also executing them.</description>
    </item>
    
    <item>
      <title>Introduction to Bazel&#39;s dynamic execution</title>
      <link>https://jmmv.dev/2019/12/bazel-dynamic-execution-introduction.html</link>
      <pubDate>Fri, 20 Dec 2019 15:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-dynamic-execution-introduction.html</guid>
      <description>Bazel&amp;rsquo;s dynamic execution is a feature that makes your builds faster by using remote and local resources, transparently and at the same time. We launched this feature in Bazel 0.21 back in February 2019 along an introductory blog post and have been hard at work since then to improve it.
The reason dynamic execution makes builds faster is two-fold:
 first, because we can hide hiccups in the connectivity to the remote build service; and, second, because we can take advantage of things like persistent workers, which are designed to offer super-fast edit/build/test cycles.</description>
    </item>
    
    <item>
      <title>What are Bazel&#39;s strategies?</title>
      <link>https://jmmv.dev/2019/12/bazel-strategies.html</link>
      <pubDate>Sat, 14 Dec 2019 18:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/12/bazel-strategies.html</guid>
      <description>&amp;ldquo;Strategies? Will you talk about Bazel&amp;rsquo;s strategy for world domination ðŸ™€?&amp;rdquo; No&amp;hellip; not exactly that.
Dynamic execution has been quite a hot topic in my work over the last few months and I am getting ready to publish a series of posts on it soon. But before I do that, I need to first review Bazel&amp;rsquo;s execution strategies because they play a big role in understanding what dynamic execution is and how it&amp;rsquo;s implemented.</description>
    </item>
    
    <item>
      <title>The /bin/bash baggage of macOS</title>
      <link>https://jmmv.dev/2019/11/macos-bash-baggage.html</link>
      <pubDate>Wed, 20 Nov 2019 23:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/11/macos-bash-baggage.html</guid>
      <description>As you may know, macOS ships with an ancient version of the Bash shell interpreter under /bin/bash. On an up-to-date Catalina installation, we get:
$ /bin/bash --version GNU bash, version 3.2.57(1)-release (x86_64-apple-darwin19) Copyright (C) 2007 Free Software Foundation, Inc.  which is&amp;hellip; old. Bash 3.2.57 was released on November 7th, 2014&amp;mdash;five years ago. The most recent version is 5.0 from the beginning of this year&amp;mdash;so it&amp;rsquo;s not like nothing has changed since then.</description>
    </item>
    
    <item>
      <title>Waiting for process groups, macOS edition</title>
      <link>https://jmmv.dev/2019/11/wait-for-process-group-darwin.html</link>
      <pubDate>Fri, 15 Nov 2019 11:00:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/11/wait-for-process-group-darwin.html</guid>
      <description>In the previous posts, we saw why waiting for a process group is complicated and we covered a specific, bullet-proof mechanism to accomplish this on Linux. Now is the time to investigate this same topic on macOS. Remember that the problem we are trying to solve (#10245) is the following: given a process group, wait for all of its processes to fully terminate.
macOS has a bunch of fancy features that other systems do not have, but process control is not among them.</description>
    </item>
    
    <item>
      <title>Waiting for process groups, Linux edition</title>
      <link>https://jmmv.dev/2019/11/wait-for-process-group-linux.html</link>
      <pubDate>Thu, 14 Nov 2019 11:30:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/11/wait-for-process-group-linux.html</guid>
      <description>In the previous post, we saw why waiting for a process group to terminate is important (at least in the context of Bazel), and we also saw why this is a difficult thing to do in a portable manner. So today, let&amp;rsquo;s dive into how to do this properly on a Linux system.
On Linux, we have two routes: using the child subreaper feature or using PID namespaces. We&amp;rsquo;ll focus on the former because that&amp;rsquo;s what we&amp;rsquo;ll use to fix (#10245) the process wrapper1, and because they are sufficient to fully address our problem.</description>
    </item>
    
    <item>
      <title>Waiting for process groups, introduction</title>
      <link>https://jmmv.dev/2019/11/wait-for-process-group.html</link>
      <pubDate>Tue, 12 Nov 2019 14:20:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/11/wait-for-process-group.html</guid>
      <description>Process groups are a feature of Unix systems to group related processes under a common identifier, known as the PGID. Using the PGID, one can look for these related process and send signals in unison to them. This is typically used by shell interpreters to manage processes.
For example, let&amp;rsquo;s launch a shell command that puts two sleep invocations in the background (those with the 10- and 20-second delays) and then sleeps the direct child (with a 5-second delay)&amp;mdash;while also putting the whole invocation in the background so that we can inspect what&amp;rsquo;s going on:</description>
    </item>
    
    <item>
      <title>Bazel&#39;s process-wrapper helper tool</title>
      <link>https://jmmv.dev/2019/11/bazel-process-wrapper.html</link>
      <pubDate>Fri, 08 Nov 2019 15:30:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/11/bazel-process-wrapper.html</guid>
      <description>As strange as it may sound, a very important job of any build tool is to orchestrate the execution of lots of other programs&amp;mdash;and Bazel is no exception.
Once Bazel has finished loading and analyzing the build graph, Bazel enters the execution phase. In this phase, the primary thing that Bazel does is walk the graph looking for actions to execute. Then, for each action, Bazel invokes its commands&amp;mdash;things like compiler and linker invocations&amp;mdash;as subprocesses.</description>
    </item>
    
    <item>
      <title>A quick glance at macOS&#39; sandbox-exec</title>
      <link>https://jmmv.dev/2019/11/macos-sandbox-exec.html</link>
      <pubDate>Fri, 01 Nov 2019 20:10:00 +0000</pubDate>
      
      <guid>https://jmmv.dev/2019/11/macos-sandbox-exec.html</guid>
      <description>macOS includes a sandboxing mechanism to closely control what processes can do on the system. Sandboxing can restrict file system accesses on a path level, control which host/port pairs can be reached over the network, limit which binaries can be executed, and much more. All applications installed via the App Store are subject to sandboxing.
This sandboxing functionality is exposed via the sandbox-exec(1) command-line utility, which unfortunately has been listed as deprecated for at least the last two major versions of macOS.</description>
    </item>
    
    <item>
      <title>Resurrected ONLamp.com articles</title>
      <link>https://jmmv.dev/2019/10/onlamp-articles.html</link>
      <pubDate>Fri, 11 Oct 2019 10:40:00 -0400</pubDate>
      
      <guid>https://jmmv.dev/2019/10/onlamp-articles.html</guid>
      <description>Quite some time ago, I wrote a handful of guest posts for O&amp;rsquo;Reilly&amp;rsquo;s ONLamp.com online publication. Unfortunately, that site seems now gone from the interwebs and I only noticed by chance upon realizing that some of my links to those articles were now broken.
Fortunately, I was able to find copies of those articles via archive.org&amp;rsquo;s WayBack Machine. So I have now taken the chance to import those articles into this site.</description>
    </item>
    
    <item>
      <title>Sample REST API in Rust and Go</title>
      <link>https://jmmv.dev/2019/09/rest-api-rust-go.html</link>
      <pubDate>Fri, 27 Sep 2019 06:45:40 +0500</pubDate>
      
      <guid>https://jmmv.dev/2019/09/rest-api-rust-go.html</guid>
      <description>Over the summer, I prototyped a bunch of web apps whose ideas had been floating in my mind for a long time. I spent quite a bit of time learning about REST APIs and, as part of these exercises, implemented skeletons of REST servers in both Go and Rust. (Just for context, the last time I wrote a web app was in high school&amp;hellip; and it involved PHP, MySQL, and I think IE6?</description>
    </item>
    
  </channel>
</rss>