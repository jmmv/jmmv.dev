<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Julio Merino (jmmv.dev)</title><link>https://jmmv.dev/post.html</link><description>Recent content in Posts on Julio Merino (jmmv.dev)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>julio@meroh.net (Julio Merino)</managingEditor><webMaster>julio@meroh.net (Julio Merino)</webMaster><copyright>Copyright 2004&#150;2025 Julio Merino</copyright><lastBuildDate>Fri, 28 Feb 2025 16:15:00 -0800</lastBuildDate><atom:link href="https://jmmv.dev/post/feed.xml" rel="self" type="application/rss+xml"/><item><title>Hardware autoconf: ACPI &amp; Device Tree</title><link>https://jmmv.dev/2025/02/hardware-autoconfiguration.html</link><pubDate>Fri, 28 Feb 2025 16:15:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/02/hardware-autoconfiguration.html</guid><description>&lt;p>If you grew up in the PC scene during the 1980s or early 1990s, you know how painful it was to get hardware to work. And if you did not witness that (lucky you) here is how it went: every piece of hardware in your PC&amp;mdash;say a sound card or a network card&amp;mdash;had physical switches or jumpers in it. These switches configured the card&amp;rsquo;s I/O address space, interrupts, and DMA ports, and you had to be careful to select values that did not overlap with other cards.&lt;/p>
&lt;p>But that wasn&amp;rsquo;t all. Once you had configured the physical switches, you had to tell the operating system and/or software &lt;em>which&lt;/em> specific cards you had and how you had configured them. Remember &lt;code>SET BLASTER=A220 I5 D1 H5&lt;/code>? This DOS environment variable told programs which specific Sound Blaster you had installed and which I/O settings you had selected via its jumpers.&lt;/p>
&lt;p>Not really fun. It was common to have hardware conflicts that yielded random lock-ups, and thus &lt;a href="https://wiki.osdev.org/ISA">ISA &amp;ldquo;Plug and Play&amp;rdquo;&lt;/a>, or PnP for short, was born in the early 1990s&amp;mdash;a protocol for the legacy ISA bus to enumerate its devices and to configure their settings via software. Fast-forward to today&amp;rsquo;s scene where we just attach devices to external USB connectors and things &amp;ldquo;magically work&amp;rdquo;.&lt;/p>
&lt;p>But how? How does the kernel know which physical devices exist and how does it know which of the many device drivers it contains can handle each device? Enter the world of hardware discovery.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-02-28-jumpers.jpg" length="89630" type="image/jpeg"/></item><item><title>Hardware autoconf: ACPI &amp; Device Tree</title><link>https://jmmv.dev/2025/02/hardware-autoconfiguration.html</link><pubDate>Fri, 28 Feb 2025 16:15:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/02/hardware-autoconfiguration.html</guid><description>&lt;p>If you grew up in the PC scene during the 1980s or early 1990s, you know how painful it was to get hardware to work. And if you did not witness that (lucky you) here is how it went: every piece of hardware in your PC&amp;mdash;say a sound card or a network card&amp;mdash;had physical switches or jumpers in it. These switches configured the card&amp;rsquo;s I/O address space, interrupts, and DMA ports, and you had to be careful to select values that did not overlap with other cards.&lt;/p>
&lt;p>But that wasn&amp;rsquo;t all. Once you had configured the physical switches, you had to tell the operating system and/or software &lt;em>which&lt;/em> specific cards you had and how you had configured them. Remember &lt;code>SET BLASTER=A220 I5 D1 H5&lt;/code>? This DOS environment variable told programs which specific Sound Blaster you had installed and which I/O settings you had selected via its jumpers.&lt;/p>
&lt;p>Not really fun. It was common to have hardware conflicts that yielded random lock-ups, and thus &lt;a href="https://wiki.osdev.org/ISA">ISA &amp;ldquo;Plug and Play&amp;rdquo;&lt;/a>, or PnP for short, was born in the early 1990s&amp;mdash;a protocol for the legacy ISA bus to enumerate its devices and to configure their settings via software. Fast-forward to today&amp;rsquo;s scene where we just attach devices to external USB connectors and things &amp;ldquo;magically work&amp;rdquo;.&lt;/p>
&lt;p>But how? How does the kernel know which physical devices exist and how does it know which of the many device drivers it contains can handle each device? Enter the world of hardware discovery.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-03-01-jumpers.jpg" length="0" type="image/jpeg"/></item><item><title>ioctls from Rust</title><link>https://jmmv.dev/2025/02/ioctls-rust.html</link><pubDate>Thu, 13 Feb 2025 09:00:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/02/ioctls-rust.html</guid><description>&lt;p>In Unix-like systems, &amp;ldquo;everything is a file and a file is defined as a byte stream you can &lt;code>open&lt;/code>, &lt;code>read&lt;/code> from, &lt;code>write&lt;/code> to, and ultimately &lt;code>close&lt;/code>&amp;rdquo;&amp;hellip; right? &lt;em>Right?&lt;/em> Well, not quite. It&amp;rsquo;s better to say &lt;em>file descriptors&lt;/em> provide access to almost every system that the kernel provides, but not that they can all be manipulated with the same quartet of system calls, nor that they all behave as byte streams.&lt;/p>
&lt;p>Because you see: network connections are manipulated via file descriptors indeed, but you don&amp;rsquo;t &lt;code>open&lt;/code> them: you &lt;code>bind&lt;/code>, &lt;code>listen&lt;/code>/&lt;code>accept&lt;/code> and/or &lt;code>connect&lt;/code> to them. And then you don&amp;rsquo;t &lt;code>read&lt;/code> from and &lt;code>write&lt;/code> to network connections: you somehow &lt;code>send&lt;/code> to and &lt;code>recv&lt;/code> from them. Device drivers are similar: yes, hardware devices are represented as &amp;ldquo;virtual files&amp;rdquo; in the &lt;code>/dev&lt;/code> hierarchy and many support &lt;code>read&lt;/code> and &lt;code>write&lt;/code>&amp;hellip; but these two system calls are not sufficient to access the breath of functionality that the hardware drivers provide. No, you need &lt;code>ioctl&lt;/code>.&lt;/p>
&lt;p>&lt;code>ioctl&lt;/code> is the poster child of the system call that breaks Unix&amp;rsquo;s &amp;ldquo;everything is a file&amp;rdquo; paradigm. &lt;code>ioctl&lt;/code> is the API that allows out-of-band communication with the kernel side of an open file descriptor. To see cool examples, &lt;a href="https://jmmv.dev/2025/01/netbsd-graphics-wo-x11.html">refer back to my previous article&lt;/a> where I demonstrated how to drive graphics from the console without X11: in that post, we had to &lt;code>open&lt;/code> the console device, but then we had to use &lt;code>ioctl&lt;/code> to obtain the properties of the framebuffer, and then we had to &lt;code>mmap&lt;/code> the device&amp;rsquo;s content for direct access: no &lt;code>read&lt;/code>s nor &lt;code>write&lt;/code>s involved.&lt;/p>
&lt;p>All the code I showed you in that earlier post was written in C to keep the graphics article to-the-point, but the code I&amp;rsquo;m really working on is part of EndBASIC, and thus it is all Rust. And the thing is, &lt;code>ioctl&lt;/code>s are not easy to issue from Rust. In fact, after 7 years of Rust-ing, it&amp;rsquo;s the first time I&amp;rsquo;ve had to reach for &lt;code>unsafe&lt;/code> code blocks, and there was no good documentation on how to deal with &lt;code>ioctl&lt;/code>. So this posts aims to fix that by presenting what ways there are to call &lt;code>ioctl&lt;/code>s from Rust&amp;hellip; and, of course, diving a bit deeper into what &lt;code>ioctl&lt;/code>s actually &lt;em>are&lt;/em>.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-02-13-ioctls-rust-cover-image.jpg" length="440615" type="image/jpeg"/></item><item><title>Hands-on graphics without X11</title><link>https://jmmv.dev/2025/01/netbsd-graphics-wo-x11.html</link><pubDate>Fri, 17 Jan 2025 09:45:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/01/netbsd-graphics-wo-x11.html</guid><description>If you have been following the development of EndBASIC, you know its console can display both text and graphics at once. What you may not know is that, now, it can also achieve this feat on the NetBSD console without using X11 at all. This is done by directly rendering to the wsdisplay framebuffer, and this article presents a crash course on direct graphics and keyboard access via NetBSD&amp;rsquo;s wscons framework.</description><enclosure url="https://jmmv.dev/images/2025-01-17-cover-image.png" length="25978" type="image/jpeg"/></item><item><title>Self-documenting Makefiles</title><link>https://jmmv.dev/2025/01/make-help.html</link><pubDate>Fri, 10 Jan 2025 09:00:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2025/01/make-help.html</guid><description>&lt;p>Make, as arcane as a build tool can be, may still be a good first fit for certain scenarios. &amp;ldquo;Heresy!&amp;rdquo;, you say, as you hear a so-called &amp;ldquo;Bazel expert&amp;rdquo; utter these words.&lt;/p>
&lt;p>The specific problem I&amp;rsquo;m facing is that I need to glue together &lt;a href="https://jmmv.dev/2024/12/netbsd-build-system.html">the NetBSD build system&lt;/a>, &lt;a href="https://jmmv.dev/2013/11/patch-management-with-quilt.html">a quilt patch set&lt;/a>, EndBASIC&amp;rsquo;s Cargo-based Rust build, and a couple of QEMU invocations to produce a Frankenstein disk image for a Raspberry Pi. And the thing is: Make allows doing this sort of stitching with relative ease. Sure, Make is not the best option because the overall build performance is &amp;ldquo;meh&amp;rdquo; and because incremental builds are almost-impossible to get right&amp;hellip; but adopting Bazel for this project would be an almost-infinite time sink.&lt;/p>
&lt;p>Anyway. When using Make in this manner, you often end up with what&amp;rsquo;s essentially a &amp;ldquo;command dispatcher&amp;rdquo; and, over time, the number of commands grows and it&amp;rsquo;s hard to make sense of which one to use for what. Sure, you can write a &lt;code>README.md&lt;/code> with instructions, but I guarantee you that the text will get out of sync faster than you can read this article. There is a better way, though.&lt;/p></description><enclosure url="https://jmmv.dev/images/2025-01-10-make-help.png" length="110230" type="image/jpeg"/></item><item><title>Revisiting the NetBSD build system</title><link>https://jmmv.dev/2024/12/netbsd-build-system.html</link><pubDate>Sat, 28 Dec 2024 08:50:00 +0100</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/12/netbsd-build-system.html</guid><description>&lt;p>I recently picked up an embedded project in which I needed to build a highly customized full system image with minimal boot times. As I explored my options, I came to the conclusion that NetBSD, the often-forgotten BSD variant, was the best viable choice for my project.&lt;/p>
&lt;p>One reason for this choice is NetBSD&amp;rsquo;s build system. Once you look and get past the fact that it feels frozen in time since 2002, you realize it is still one of the most advanced build systems you can find for an OS. And it shows: the NetBSD build system allows you to build the full OS from scratch, on pretty much any host POSIX platform, while targeting any hardware architecture supported by NetBSD. All without root privileges.&lt;/p>
&lt;p>Another reason for this choice is that NetBSD was my daily workhorse for many years and I&amp;rsquo;m quite familiar with its internals, which is useful knowledge to quickly achieve the goals I have in mind. In fact, I was a NetBSD Developer with capital D: I had commit access to the project from about 2002 through 2012 or so, and I have just revived my account in service of this project. &lt;code>jmmv@&lt;/code> is back!&lt;/p>
&lt;p>So, strap onto your seats and let&amp;rsquo;s see how today&amp;rsquo;s NetBSD build system looks like and what makes it special. I&amp;rsquo;ll add my own critique at the end, because it ain&amp;rsquo;t perfect, but overall it continues to deliver on its design goals set in the late 1990s.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-12-28-cover-image.jpg" length="403124" type="image/jpeg"/></item><item><title>Synology DS923+ vs. FreeBSD w/ZFS</title><link>https://jmmv.dev/2024/12/synology-ds923-vs-freebsd.html</link><pubDate>Fri, 13 Dec 2024 09:10:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/12/synology-ds923-vs-freebsd.html</guid><description>&lt;p>My interest in storage is longstanding&amp;mdash;I loved playing with different file systems in my early Unix days and then I worked on Google&amp;rsquo;s and Microsoft&amp;rsquo;s distributed storage solutions&amp;mdash;and, about four years ago, I started running a home-grown NAS leveraging FreeBSD and its excellent ZFS support. I first hosted the server on a PowerMac G5 and then upgraded it to an overkill 72-core ThinkStation that I snapped second-hand for a great price.&lt;/p>
&lt;p>But as stable and low maintenance as FreeBSD is, running day-to-day services myself is not my idea of &amp;ldquo;fun&amp;rdquo;. This drove me to replace this machine&amp;rsquo;s routing functionality with a dedicated pfSense box a year ago and, for similar reasons, I have been curious about dedicated NAS solutions.&lt;/p>
&lt;p>I was pretty close to buying a second-hand NAS from the work classifieds channel when a Synology marketing person (hi Kyle!) contacted me to offer a partnership: they&amp;rsquo;d ship me &lt;a href="https://sy.to/hekgh">one of their devices&lt;/a> for free in exchange for me publishing a few articles about it. Given my interest to drive-test one of these appliances without committing to buying one (they ain&amp;rsquo;t cheap and I wasn&amp;rsquo;t convinced I wanted to get rid of my FreeBSD-based solution), I was game.&lt;/p>
&lt;p>And you guessed right: this article is one of those I promised to write but, before you stop reading, the answer is no. This post is &lt;em>not&lt;/em> sponsored by Synology and has not been reviewed nor approved by them. The content here, including any opinions, are purely my own. And what I want do do here is compare how the Synology appliance stacks against my home-built FreeBSD server.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-12-13-ds923-and-thinkstation.jpg" length="329916" type="image/jpeg"/></item><item><title>Demystifying secure NFS</title><link>https://jmmv.dev/2024/11/demystifying-secure-nfs.html</link><pubDate>Sun, 03 Nov 2024 16:00:00 -0800</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/11/demystifying-secure-nfs.html</guid><description>&lt;p>I recently got a &lt;a href="https://sy.to/hekgh">Synology DS923+&lt;/a> for evaluation purposes which led me to setting up NFSv4 with Kerberos. I had done this about a year ago with FreeBSD as the host, and going through this process once again reminded me of how painful it is to secure an NFS connection.&lt;/p>
&lt;p>You see, Samba is much easier to set up, but because NFS is the native file sharing protocol of Unix systems, I felt compelled to use it instead. However, if you opt for NFSv3 (the &amp;ldquo;easy default&amp;rdquo;), you are left with a system that has zero security: traffic travels unencrypted and unsigned, and the server trusts the client when the client asserts who is who. Madness for today&amp;rsquo;s standards. Yet, when you look around, people say &amp;ldquo;oh, but NFSv3 is fine if you trust the network!&amp;rdquo; But seriously, who trusts the network in this day and age?&lt;/p>
&lt;p>You have to turn to NFSv4 &lt;em>and&lt;/em> combine it with Kerberos for a secure file sharing option. And let me tell you: the experience of setting these up and getting things to work is horrible, and the documentation out there is terrible. Most documents are operating-system specific so they only tell you what works when a specific server and a specific client talk to each other. Other documents just &lt;em>assume&lt;/em>, and thus omit, various important details of the configuration.&lt;/p>
&lt;p>So. This article is my recollection of &amp;ldquo;lab notes&amp;rdquo; on how to set this whole thing up along with the necessary background to understand NFSv4 and Kerberos. My specific setup involes the Synology DS923+ as the NFSv4 server; Fedora, Debian, and FreeBSD clients; and the supporting KDC on a pfSense (or FreeBSD) box.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-11-03-synology-ds923plus-nas.jpg" length="232646" type="image/jpeg"/></item><item><title>BazelCon 2024 recap</title><link>https://jmmv.dev/2024/10/bazelcon-2024-recap.html</link><pubDate>Tue, 22 Oct 2024 08:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/10/bazelcon-2024-recap.html</guid><description>Just like that, BazelCon 2024 came and went. So&amp;hellip; it&amp;rsquo;s obviously time to summarize the two events of last week: BazelCon 2024 and the adjacent Build Meetup. There is A LOT to cover, but everything is here in just one article!</description><enclosure url="https://jmmv.dev/images/2024-10-22-bazelcon.jpg" length="362903" type="image/jpeg"/></item><item><title>The costs of the i386 to x86-64 upgrade</title><link>https://jmmv.dev/2024/10/x86-64-programming-models.html</link><pubDate>Mon, 07 Oct 2024 09:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/10/x86-64-programming-models.html</guid><description>&lt;p>If you read my previous article on &lt;a href="https://jmmv.dev/2024/09/dos-memory-models.html">DOS memory models&lt;/a>, you may have dismissed everything I wrote as &amp;ldquo;legacy cruft from the 1990s that nobody cares about any longer&amp;rdquo;. After all, computers have evolved from sporting 8-bit processors to 64-bit processors and, on the way, the amount of memory that these computers can leverage has grown orders of magnitude: the 8086, a 16-bit machine with a 20-bit address space, could only use 1MB of memory while today&amp;rsquo;s 64-bit machines can theoretically access 16EB.&lt;/p>
&lt;p>All of this growth has been in service of ever-growing programs. But&amp;hellip; even if programs are now more sophisticated than they were before, do they all &lt;em>really&lt;/em> require access to a 64-bit address space? Has the growth from 8 to 64 bits been a net positive in performance terms?&lt;/p>
&lt;p>Let&amp;rsquo;s try to answer those questions to find some very surprising answers. But first, some theory.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-10-07-x86-64-cover-image.jpg" length="992004" type="image/jpeg"/></item><item><title>Revisiting the DOS memory models</title><link>https://jmmv.dev/2024/09/dos-memory-models.html</link><pubDate>Mon, 30 Sep 2024 08:00:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/09/dos-memory-models.html</guid><description>&lt;p>At the beginning of the year, I wrote a bunch of articles on the various tricks DOS played to overcome the tight memory limits of x86's real mode. There was one question that came up and remained unanswered: what were the various models that the compilers of the day offered?&lt;/p> &lt;p>Tiny, small, medium, compact, large, huge... What did these options mean? What were their effects? And, more importantly... is any of that legacy relevant today in the world of 64-bit machines and gigabytes of RAM? To answer those questions, we must start with a brief review of the 8086 architecture and the binary formats supported by DOS.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-09-30-turbo-cxx-memory-models.png" length="140059" type="image/jpeg"/></item><item><title>Windows NT vs. Unix: A design comparison</title><link>https://jmmv.dev/2024/09/windows-nt-vs-unix-design.html</link><pubDate>Mon, 09 Sep 2024 08:30:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/09/windows-nt-vs-unix-design.html</guid><description>&lt;p>Over the years, I&amp;rsquo;ve repeatedly heard that Windows NT is a very advanced operating system and, being a Unix person myself, it has bothered me to not know &lt;em>why&lt;/em>. I&amp;rsquo;ve been meaning to answer this question for years and I can do so now, which means I want to present you my findings.&lt;/p>
&lt;p>My desire to know about NT&amp;rsquo;s internals started in 2006 when I applied to the Google Summer of Code program to develop Boost.Process. I needed such a library for ATF, but I also saw the project as a chance to learn something about the Win32 API. This journey then continued in 2020 with me &lt;a href="https://jmmv.dev/2020/10/bye-google-hi-microsoft.html">choosing to join Microsoft&lt;/a> after a long stint at Google and me buying the &lt;a href="https://www.amazon.com/Windows-Internals-Part-architecture-management/dp/0735684189?crid=2F7UR8S48RP6O&amp;amp;dib=eyJ2IjoiMSJ9.p9cBb_-Q8GjuK0z0kDLKG6xoExPM_2QWt_jn0PlqVBSWYNyqRp2Cd7MHXFeQ4EiRACaX_Y_9xzECC0YpECzSl5kCBD3u1KUPduAgmnO732G9aqw1aLdQszw8LIXBOE1cYvOf3KYQmQ5vdFV6i4eFOttVvIa2XerkHVGiPd1OzTk32tEOchCbnUqpzW3QqCG7AjEmmKHFGuo5T2_UQDUERaSVRa26oAZHYuePCzDrwbY.bcHnZQWFYjmL64ZRnMieVsUH5JVx-T-WY88kj8V-uno&amp;amp;dib_tag=se&amp;amp;keywords=windows+internals&amp;amp;qid=1725808358&amp;amp;sprefix=windows+internals%2Caps%2C155&amp;amp;sr=8-1&amp;amp;linkCode=ll1&amp;amp;tag=blogsystem5-20&amp;amp;linkId=08d00ee830fe99b6e648add99e1b64c5&amp;amp;language=en_US&amp;amp;ref_=as_li_ss_tl">Windows Internals&lt;/a> 5th edition book in 2021 (which I never fully read due to its incredible detail and length). None of these made me learn what I wanted though: the ways in which NT fundamentally differs from Unix, if at all.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-09-09-windows-nt-vs-unix-design.jpg" length="1049554" type="image/jpeg"/></item><item><title>Picking glibc versions at runtime</title><link>https://jmmv.dev/2024/08/glibc-versions-runtime.html</link><pubDate>Sun, 11 Aug 2024 10:15:00 +0200</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/08/glibc-versions-runtime.html</guid><description>&lt;p>In a recent work discussion, I came across an argument that didn&amp;rsquo;t sound quite right. The claim was that we needed to set up containers in our developer machines in order to run tests against a modern glibc. The justifications were that using &lt;code>LD_LIBRARY_PATH&lt;/code> to load a different glibc didn&amp;rsquo;t work and statically linking glibc wasn&amp;rsquo;t possible either.&lt;/p>
&lt;p>But&amp;hellip; running a program against a version of glibc that&amp;rsquo;s different from the one installed on the system seems like a pretty standard requirement, doesn&amp;rsquo;t it? Consider this: how do the developers of glibc test their changes? glibc has existed for much longer than containers have. And before containers existed, they surely weren&amp;rsquo;t testing glibc changes by installing modified versions of the library over the system-wide one and YOLOing it.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-08-11-glibc-versions-runtime-dynamic.png" length="36593" type="image/jpeg"/></item><item><title>Kyua graduates</title><link>https://jmmv.dev/2024/08/kyua-graduates.html</link><pubDate>Fri, 02 Aug 2024 08:45:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/08/kyua-graduates.html</guid><description>&lt;p>After years of inactivity, the Kyua project has graduated as an open source citizen and has &lt;a href="https://github.com/freebsd/kyua/">a new home&lt;/a> under the FreeBSD umbrella!&lt;/p>
&lt;p>But uh&amp;hellip; wait, what is Kyua and why is this exciting? To resolve confusion and celebrate this milestone, I&amp;rsquo;d like to revisit what Kyua is, how it came to be, why I stopped working on it for a while, why that was a problem for FreeBSD&amp;mdash;and, indirectly, NetBSD&amp;mdash;and how Kyua being free software has helped keep it alive.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-08-02-kyua-graduates.jpg" length="367311" type="image/jpeg"/></item><item><title>Rust doesn't solve the CrowdStrike outage</title><link>https://jmmv.dev/2024/07/crowdstrike-and-rust.html</link><pubDate>Tue, 23 Jul 2024 07:10:00 -0700</pubDate><author>julio@meroh.net (Julio Merino)</author><guid>https://jmmv.dev/2024/07/crowdstrike-and-rust.html</guid><description>&lt;p>Look, I like Rust. I really, really do, and I agree with the premise that memory-unsafe languages like C++ should not be used anymore. But claiming that Rust would have &lt;em>prevented&lt;/em> the massive outage that the world went through last Friday is misleading and actively harmful to Rust&amp;rsquo;s evangelism.&lt;/p>
&lt;p>Having CrowdStrike written in Rust would have &lt;em>minimized&lt;/em> the chances of the outage happening, but not resolved the root cause that allowed the outage to happen in the first place. Thus, it irks me to see various folks blanket-claiming that Rust is the answer. It&amp;rsquo;s not, and pushing this agenda hurts Rust&amp;rsquo;s adoption more than it helps: C++ experts can understand the root cause and see that this claim is misleading, causing further divide in the systems programming world.&lt;/p>
&lt;p>So, why won&amp;rsquo;t Rust help? Let me try to answer that question, but while we are at it, let&amp;rsquo;s also delve deeper into the causes of the outage. In a way, let me put my SRE hat on and write my own version of the postmortem.&lt;/p></description><enclosure url="https://jmmv.dev/images/2024-07-23-rusty-crow.jpg" length="343660" type="image/jpeg"/></item></channel></rss>